==========================================
SLURM_JOB_ID = 333594
SLURM_NODELIST = gnode42
SLURM_JOB_GPUS = 0,1,2,3
==========================================
--------------------------------------------------------------------
Initializing environment by creating cache dir.
Checking and removing for residual files & folders in cache dir....
Done checking and removing for residual files and folders.
Copying data.zip from share 1 to cache ....
Copy complete.
Copying save.zip from share1 to cache ....
Copy complete.
Unzipping data.zip into cache ....
Unzip complete.
Unzipping save.zip ino cache ....
Unzip complete.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Running the mmf code using unzipped data folder ....
********************************************************************
Training VISUAL_BERT_COCO
[32m2021-03-04T00:34:27 | mmf.utils.configuration: [0mOverriding option config to projects/hateful_memes/configs/visual_bert/from_coco.yaml
[32m2021-03-04T00:34:27 | mmf.utils.configuration: [0mOverriding option model to visual_bert
[32m2021-03-04T00:34:27 | mmf.utils.configuration: [0mOverriding option datasets to hateful_memes
[32m2021-03-04T00:34:27 | mmf.utils.configuration: [0mOverriding option run_type to train_val
[32m2021-03-04T00:34:27 | mmf.utils.configuration: [0mOverriding option checkpoint.max_to_keep to 3
[32m2021-03-04T00:34:27 | mmf.utils.configuration: [0mOverriding option checkpoint.resume_best to True
[32m2021-03-04T00:34:30 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T00:34:30 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T00:34:30 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T00:34:30 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T00:34:30 | mmf.utils.distributed: [0mDistributed Init (Rank 2): tcp://localhost:19306
[32m2021-03-04T00:34:30 | mmf.utils.distributed: [0mDistributed Init (Rank 1): tcp://localhost:19306
[32m2021-03-04T00:34:30 | mmf.utils.distributed: [0mDistributed Init (Rank 3): tcp://localhost:19306
[32m2021-03-04T00:34:30 | mmf.utils.distributed: [0mDistributed Init (Rank 0): tcp://localhost:19306
[32m2021-03-04T00:34:31 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 3
[32m2021-03-04T00:34:31 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 1
[32m2021-03-04T00:34:31 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 2
[32m2021-03-04T00:34:31 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 0
[32m2021-03-04T00:34:39 | mmf: [0mLogging to: /scratch/sagarsj42/save/train.log
[32m2021-03-04T00:34:39 | mmf_cli.run: [0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/visual_bert/from_coco.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=train_val', 'checkpoint.max_to_keep=3', 'checkpoint.resume_best=True'])
[32m2021-03-04T00:34:39 | mmf_cli.run: [0mTorch version: 1.6.0
[32m2021-03-04T00:34:39 | mmf.utils.general: [0mCUDA Device 0 is: GeForce GTX 1080 Ti
[32m2021-03-04T00:34:39 | mmf_cli.run: [0mUsing seed 39767104
[32m2021-03-04T00:34:39 | mmf.trainers.mmf_trainer: [0mLoading datasets
[32m2021-03-04T00:34:45 | mmf.trainers.mmf_trainer: [0mLoading model
[32m2021-03-04T00:34:46 | filelock: [0mLock 22498039487952 acquired on /scratch/sagarsj42/distributed_-1/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock
Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]Downloading:   0%|          | 459k/440M [00:00<01:36, 4.55MB/s]Downloading:   1%|          | 3.15M/440M [00:00<00:24, 17.7MB/s]Downloading:   2%|â–         | 9.40M/440M [00:00<00:11, 38.1MB/s]Downloading:   3%|â–Ž         | 15.3M/440M [00:00<00:09, 46.3MB/s]Downloading:   5%|â–         | 21.8M/440M [00:00<00:07, 52.9MB/s]Downloading:   6%|â–Œ         | 27.1M/440M [00:01<00:22, 18.1MB/s]Downloading:   8%|â–Š         | 33.2M/440M [00:01<00:16, 24.3MB/s]Downloading:   9%|â–‰         | 39.4M/440M [00:01<00:13, 30.6MB/s]Downloading:  10%|â–ˆ         | 45.6M/440M [00:01<00:10, 36.7MB/s]Downloading:  12%|â–ˆâ–        | 51.0M/440M [00:02<00:21, 17.9MB/s]Downloading:  13%|â–ˆâ–Ž        | 57.2M/440M [00:02<00:16, 23.1MB/s]Downloading:  14%|â–ˆâ–        | 63.4M/440M [00:02<00:13, 28.8MB/s]Downloading:  16%|â–ˆâ–Œ        | 70.1M/440M [00:02<00:10, 35.5MB/s]Downloading:  17%|â–ˆâ–‹        | 75.7M/440M [00:03<00:19, 19.0MB/s]Downloading:  19%|â–ˆâ–Š        | 81.9M/440M [00:03<00:14, 24.1MB/s]Downloading:  20%|â–ˆâ–‰        | 88.0M/440M [00:03<00:11, 29.5MB/s]Downloading:  21%|â–ˆâ–ˆâ–       | 94.2M/440M [00:03<00:09, 35.1MB/s]Downloading:  23%|â–ˆâ–ˆâ–Ž       | 99.8M/440M [00:04<00:18, 18.9MB/s]Downloading:  24%|â–ˆâ–ˆâ–       | 106M/440M [00:04<00:14, 23.8MB/s] Downloading:  25%|â–ˆâ–ˆâ–Œ       | 112M/440M [00:04<00:11, 29.4MB/s]Downloading:  27%|â–ˆâ–ˆâ–‹       | 118M/440M [00:04<00:09, 35.1MB/s]Downloading:  28%|â–ˆâ–ˆâ–Š       | 125M/440M [00:04<00:07, 40.7MB/s]Downloading:  30%|â–ˆâ–ˆâ–‰       | 130M/440M [00:05<00:15, 19.9MB/s]Downloading:  31%|â–ˆâ–ˆâ–ˆ       | 137M/440M [00:05<00:12, 25.1MB/s]Downloading:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 143M/440M [00:05<00:09, 31.8MB/s]Downloading:  34%|â–ˆâ–ˆâ–ˆâ–      | 150M/440M [00:05<00:15, 18.8MB/s]Downloading:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 156M/440M [00:06<00:12, 23.7MB/s]Downloading:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 162M/440M [00:06<00:09, 29.4MB/s]Downloading:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 169M/440M [00:06<00:07, 35.7MB/s]Downloading:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 175M/440M [00:07<00:17, 15.2MB/s]Downloading:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 181M/440M [00:07<00:13, 19.6MB/s]Downloading:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 186M/440M [00:07<00:11, 22.6MB/s]Downloading:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 192M/440M [00:07<00:08, 28.4MB/s]Downloading:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 197M/440M [00:07<00:07, 30.5MB/s]Downloading:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 202M/440M [00:08<00:10, 22.7MB/s]Downloading:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 208M/440M [00:08<00:08, 29.0MB/s]Downloading:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 215M/440M [00:08<00:06, 35.8MB/s]Downloading:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 222M/440M [00:08<00:05, 42.8MB/s]Downloading:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 228M/440M [00:09<00:13, 15.7MB/s]Downloading:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 234M/440M [00:09<00:10, 20.5MB/s]Downloading:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 240M/440M [00:09<00:07, 25.7MB/s]Downloading:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 247M/440M [00:09<00:06, 31.9MB/s]Downloading:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 253M/440M [00:10<00:10, 18.4MB/s]Downloading:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 259M/440M [00:10<00:07, 23.5MB/s]Downloading:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 265M/440M [00:10<00:05, 29.2MB/s]Downloading:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 272M/440M [00:10<00:04, 35.0MB/s]Downloading:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 277M/440M [00:11<00:08, 19.3MB/s]Downloading:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 284M/440M [00:11<00:06, 24.6MB/s]Downloading:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 290M/440M [00:11<00:04, 30.1MB/s]Downloading:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 296M/440M [00:11<00:04, 35.6MB/s]Downloading:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 302M/440M [00:12<00:07, 18.7MB/s]Downloading:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 308M/440M [00:12<00:05, 23.8MB/s]Downloading:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 314M/440M [00:12<00:04, 29.3MB/s]Downloading:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 320M/440M [00:12<00:03, 35.0MB/s]Downloading:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 326M/440M [00:13<00:06, 19.0MB/s]Downloading:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 332M/440M [00:13<00:04, 24.1MB/s]Downloading:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 338M/440M [00:13<00:03, 29.7MB/s]Downloading:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 345M/440M [00:13<00:02, 35.9MB/s]Downloading:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 350M/440M [00:13<00:04, 19.4MB/s]Downloading:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 357M/440M [00:14<00:03, 24.6MB/s]Downloading:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 363M/440M [00:14<00:02, 30.5MB/s]Downloading:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 369M/440M [00:14<00:01, 35.8MB/s]Downloading:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 375M/440M [00:14<00:03, 18.6MB/s]Downloading:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 381M/440M [00:15<00:02, 23.6MB/s]Downloading:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 387M/440M [00:15<00:01, 29.2MB/s]Downloading:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 392M/440M [00:15<00:01, 30.4MB/s]Downloading:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 399M/440M [00:15<00:01, 36.6MB/s]Downloading:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 404M/440M [00:16<00:01, 18.5MB/s]Downloading:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 410M/440M [00:16<00:01, 22.9MB/s]Downloading:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 417M/440M [00:16<00:00, 29.3MB/s]Downloading:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 424M/440M [00:16<00:00, 36.4MB/s]Downloading:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 429M/440M [00:17<00:00, 19.1MB/s]Downloading:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 435M/440M [00:17<00:00, 23.9MB/s]Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 440M/440M [00:17<00:00, 27.6MB/s]Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440M/440M [00:17<00:00, 25.6MB/s][32m2021-03-04T00:35:03 | filelock: [0mLock 22498039487952 released on /scratch/sagarsj42/distributed_-1/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock

Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[32m2021-03-04T00:35:07 | mmf.trainers.mmf_trainer: [0mLoading optimizer
[32m2021-03-04T00:35:07 | mmf.trainers.mmf_trainer: [0mLoading metrics
[5m[31mWARNING[0m [32m2021-03-04T00:35:07 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.
Use OmegaConf.to_yaml(cfg)

  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T00:35:07 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.
Use OmegaConf.to_yaml(cfg)

  builtin_warn(*args, **kwargs)

[32m2021-03-04T00:35:07 | mmf.utils.checkpoint: [0mLoading checkpoint
Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[5m[31mWARNING[0m [32m2021-03-04T00:35:21 | mmf: [0mKey data_parallel is not present in registry, returning default value of None
[5m[31mWARNING[0m [32m2021-03-04T00:35:21 | mmf: [0mKey distributed is not present in registry, returning default value of None
[5m[31mWARNING[0m [32m2021-03-04T00:35:21 | mmf: [0mKey data_parallel is not present in registry, returning default value of None
[5m[31mWARNING[0m [32m2021-03-04T00:35:21 | mmf: [0mKey distributed is not present in registry, returning default value of None
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.token_type_embeddings_visual.weight from model.bert.embeddings.token_type_embeddings_visual.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.position_embeddings_visual.weight from model.bert.embeddings.position_embeddings_visual.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.projection.weight from model.bert.embeddings.projection.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.projection.bias from model.bert.embeddings.projection.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.pooler.dense.weight from model.bert.pooler.dense.weight
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCopying model.bert.pooler.dense.bias from model.bert.pooler.dense.bias
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mPretrained model loaded
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCheckpoint loaded.
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCurrent num updates: 0
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCurrent iteration: 0
[32m2021-03-04T00:35:21 | mmf.utils.checkpoint: [0mCurrent epoch: 0
[32m2021-03-04T00:35:21 | mmf.trainers.mmf_trainer: [0m===== Model =====
[32m2021-03-04T00:35:21 | mmf.trainers.mmf_trainer: [0mDistributedDataParallel(
  (module): VisualBERT(
    (model): VisualBERTForClassification(
      (bert): VisualBERTBase(
        (embeddings): BertVisioLinguisticEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (token_type_embeddings_visual): Embedding(2, 768)
          (position_embeddings_visual): Embedding(512, 768)
          (projection): Linear(in_features=2048, out_features=768, bias=True)
        )
        (encoder): BertEncoderJit(
          (layer): ModuleList(
            (0): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
      (classifier): Sequential(
        (0): BertPredictionHeadTransform(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (1): Linear(in_features=768, out_features=2, bias=True)
      )
    )
    (losses): Losses(
      (losses): ModuleList(
        (0): MMFLoss(
          (loss_criterion): CrossEntropyLoss(
            (loss_fn): CrossEntropyLoss()
          )
        )
      )
    )
  )
)
[32m2021-03-04T00:35:21 | mmf.utils.general: [0mTotal Parameters: 112044290. Trained Parameters: 112044290
[32m2021-03-04T00:35:21 | mmf.trainers.core.training_loop: [0mStarting training...
[32m2021-03-04T00:40:07 | mmf.trainers.callbacks.logistics: [0mprogress: 100/22000, train/hateful_memes/cross_entropy: 0.7110, train/hateful_memes/cross_entropy/avg: 0.7110, train/total_loss: 0.7110, train/total_loss/avg: 0.7110, max mem: 5909.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 0.35, time: 04m 45s 827ms, time_since_start: 04m 59s 602ms, eta: 17h 23m 16s 155ms
[32m2021-03-04T00:42:03 | mmf.trainers.callbacks.logistics: [0mprogress: 200/22000, train/hateful_memes/cross_entropy: 0.6270, train/hateful_memes/cross_entropy/avg: 0.6690, train/total_loss: 0.6270, train/total_loss/avg: 0.6690, max mem: 5909.0, experiment: run, epoch: 2, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0.00001, ups: 0.87, time: 01m 55s 670ms, time_since_start: 06m 55s 273ms, eta: 07h 16s 163ms
[32m2021-03-04T00:43:11 | mmf.trainers.callbacks.logistics: [0mprogress: 300/22000, train/hateful_memes/cross_entropy: 0.6270, train/hateful_memes/cross_entropy/avg: 0.6217, train/total_loss: 0.6270, train/total_loss/avg: 0.6217, max mem: 5909.0, experiment: run, epoch: 3, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0.00001, ups: 1.47, time: 01m 08s 323ms, time_since_start: 08m 03s 596ms, eta: 04h 07m 06s 224ms
[32m2021-03-04T00:44:13 | mmf.trainers.callbacks.logistics: [0mprogress: 400/22000, train/hateful_memes/cross_entropy: 0.5755, train/hateful_memes/cross_entropy/avg: 0.6102, train/total_loss: 0.5755, train/total_loss/avg: 0.6102, max mem: 5909.0, experiment: run, epoch: 4, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0.00001, ups: 1.61, time: 01m 02s 097ms, time_since_start: 09m 05s 694ms, eta: 03h 43m 33s 102ms
[32m2021-03-04T00:45:08 | mmf.trainers.callbacks.logistics: [0mprogress: 500/22000, train/hateful_memes/cross_entropy: 0.5755, train/hateful_memes/cross_entropy/avg: 0.5626, train/total_loss: 0.5755, train/total_loss/avg: 0.5626, max mem: 5909.0, experiment: run, epoch: 4, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 428ms, time_since_start: 10m 122ms, eta: 03h 15m 02s 050ms
[32m2021-03-04T00:46:09 | mmf.trainers.callbacks.logistics: [0mprogress: 600/22000, train/hateful_memes/cross_entropy: 0.5273, train/hateful_memes/cross_entropy/avg: 0.5240, train/total_loss: 0.5273, train/total_loss/avg: 0.5240, max mem: 5909.0, experiment: run, epoch: 5, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0.00002, ups: 1.64, time: 01m 01s 425ms, time_since_start: 11m 01s 547ms, eta: 03h 39m 05s 009ms
[32m2021-03-04T00:47:09 | mmf.trainers.callbacks.logistics: [0mprogress: 700/22000, train/hateful_memes/cross_entropy: 0.5273, train/hateful_memes/cross_entropy/avg: 0.4865, train/total_loss: 0.5273, train/total_loss/avg: 0.4865, max mem: 5909.0, experiment: run, epoch: 6, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 065ms, time_since_start: 12m 01s 613ms, eta: 03h 33m 13s 895ms
[32m2021-03-04T00:48:08 | mmf.trainers.callbacks.logistics: [0mprogress: 800/22000, train/hateful_memes/cross_entropy: 0.3724, train/hateful_memes/cross_entropy/avg: 0.4456, train/total_loss: 0.3724, train/total_loss/avg: 0.4456, max mem: 5909.0, experiment: run, epoch: 7, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0.00002, ups: 1.69, time: 59s 487ms, time_since_start: 13m 01s 100ms, eta: 03h 30m 11s 286ms
[32m2021-03-04T00:49:00 | mmf.trainers.callbacks.logistics: [0mprogress: 900/22000, train/hateful_memes/cross_entropy: 0.3724, train/hateful_memes/cross_entropy/avg: 0.4262, train/total_loss: 0.3724, train/total_loss/avg: 0.4262, max mem: 5909.0, experiment: run, epoch: 7, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 074ms, time_since_start: 13m 52s 174ms, eta: 02h 59m 36s 675ms
[32m2021-03-04T00:49:59 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T00:49:59 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T00:49:59 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T00:49:59 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T00:50:11 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T00:50:37 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T00:50:37 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, train/hateful_memes/cross_entropy: 0.3724, train/hateful_memes/cross_entropy/avg: 0.4232, train/total_loss: 0.3724, train/total_loss/avg: 0.4232, max mem: 5909.0, experiment: run, epoch: 8, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00003, ups: 1.03, time: 01m 37s 695ms, time_since_start: 15m 29s 869ms, eta: 05h 41m 55s 983ms
[32m2021-03-04T00:50:37 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T00:50:59 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T00:50:59 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T00:50:59 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T00:50:59 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T00:51:09 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T00:51:19 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T00:51:29 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T00:51:29 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, val/hateful_memes/cross_entropy: 1.3996, val/total_loss: 1.3996, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.3860, val/hateful_memes/roc_auc: 0.6992, num_updates: 1000, epoch: 8, iterations: 1000, max_updates: 22000, val_time: 52s 028ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.699155
[32m2021-03-04T00:52:28 | mmf.trainers.callbacks.logistics: [0mprogress: 1100/22000, train/hateful_memes/cross_entropy: 0.3724, train/hateful_memes/cross_entropy/avg: 0.3871, train/total_loss: 0.3724, train/total_loss/avg: 0.3871, max mem: 5909.0, experiment: run, epoch: 9, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00003, ups: 1.69, time: 59s 120ms, time_since_start: 17m 21s 036ms, eta: 03h 25m 56s 219ms
[32m2021-03-04T00:53:28 | mmf.trainers.callbacks.logistics: [0mprogress: 1200/22000, train/hateful_memes/cross_entropy: 0.3306, train/hateful_memes/cross_entropy/avg: 0.3633, train/total_loss: 0.3306, train/total_loss/avg: 0.3633, max mem: 5909.0, experiment: run, epoch: 10, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00003, ups: 1.69, time: 59s 490ms, time_since_start: 18m 20s 526ms, eta: 03h 26m 13s 998ms
[32m2021-03-04T00:54:19 | mmf.trainers.callbacks.logistics: [0mprogress: 1300/22000, train/hateful_memes/cross_entropy: 0.3306, train/hateful_memes/cross_entropy/avg: 0.3403, train/total_loss: 0.3306, train/total_loss/avg: 0.3403, max mem: 5909.0, experiment: run, epoch: 10, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00003, ups: 2.00, time: 50s 845ms, time_since_start: 19m 11s 371ms, eta: 02h 55m 24s 952ms
[32m2021-03-04T00:55:19 | mmf.trainers.callbacks.logistics: [0mprogress: 1400/22000, train/hateful_memes/cross_entropy: 0.2705, train/hateful_memes/cross_entropy/avg: 0.3173, train/total_loss: 0.2705, train/total_loss/avg: 0.3173, max mem: 5909.0, experiment: run, epoch: 11, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00003, ups: 1.69, time: 59s 919ms, time_since_start: 20m 11s 291ms, eta: 03h 25m 43s 411ms
[32m2021-03-04T00:56:19 | mmf.trainers.callbacks.logistics: [0mprogress: 1500/22000, train/hateful_memes/cross_entropy: 0.2705, train/hateful_memes/cross_entropy/avg: 0.2981, train/total_loss: 0.2705, train/total_loss/avg: 0.2981, max mem: 5909.0, experiment: run, epoch: 12, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 547ms, time_since_start: 21m 11s 838ms, eta: 03h 26m 52s 158ms
[32m2021-03-04T00:57:20 | mmf.trainers.callbacks.logistics: [0mprogress: 1600/22000, train/hateful_memes/cross_entropy: 0.2620, train/hateful_memes/cross_entropy/avg: 0.2823, train/total_loss: 0.2620, train/total_loss/avg: 0.2823, max mem: 5909.0, experiment: run, epoch: 13, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00004, ups: 1.64, time: 01m 01s 131ms, time_since_start: 22m 12s 969ms, eta: 03h 27m 50s 803ms
[32m2021-03-04T00:58:12 | mmf.trainers.callbacks.logistics: [0mprogress: 1700/22000, train/hateful_memes/cross_entropy: 0.2620, train/hateful_memes/cross_entropy/avg: 0.2670, train/total_loss: 0.2620, train/total_loss/avg: 0.2670, max mem: 5909.0, experiment: run, epoch: 13, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 542ms, time_since_start: 23m 04s 512ms, eta: 02h 54m 23s 153ms
[32m2021-03-04T00:59:12 | mmf.trainers.callbacks.logistics: [0mprogress: 1800/22000, train/hateful_memes/cross_entropy: 0.1594, train/hateful_memes/cross_entropy/avg: 0.2523, train/total_loss: 0.1594, train/total_loss/avg: 0.2523, max mem: 5909.0, experiment: run, epoch: 14, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00005, ups: 1.67, time: 01m 530ms, time_since_start: 24m 05s 043ms, eta: 03h 23m 47s 207ms
[32m2021-03-04T01:00:14 | mmf.trainers.callbacks.logistics: [0mprogress: 1900/22000, train/hateful_memes/cross_entropy: 0.1594, train/hateful_memes/cross_entropy/avg: 0.2420, train/total_loss: 0.1594, train/total_loss/avg: 0.2420, max mem: 5909.0, experiment: run, epoch: 15, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00005, ups: 1.64, time: 01m 01s 674ms, time_since_start: 25m 06s 717ms, eta: 03h 26m 36s 559ms
[32m2021-03-04T01:01:16 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T01:01:16 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T01:01:16 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T01:01:16 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T01:01:27 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T01:01:38 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T01:01:38 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, train/hateful_memes/cross_entropy: 0.1594, train/hateful_memes/cross_entropy/avg: 0.2400, train/total_loss: 0.1594, train/total_loss/avg: 0.2400, max mem: 5909.0, experiment: run, epoch: 16, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00005, ups: 1.19, time: 01m 24s 388ms, time_since_start: 26m 31s 105ms, eta: 04h 41m 17s 625ms
[32m2021-03-04T01:01:38 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T01:01:55 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T01:01:55 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T01:01:55 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T01:01:55 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T01:02:06 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T01:02:16 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T01:02:26 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T01:02:26 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, val/hateful_memes/cross_entropy: 1.5278, val/total_loss: 1.5278, val/hateful_memes/accuracy: 0.7000, val/hateful_memes/binary_f1: 0.4160, val/hateful_memes/roc_auc: 0.7084, num_updates: 2000, epoch: 16, iterations: 2000, max_updates: 22000, val_time: 47s 355ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T01:03:15 | mmf.trainers.callbacks.logistics: [0mprogress: 2100/22000, train/hateful_memes/cross_entropy: 0.1005, train/hateful_memes/cross_entropy/avg: 0.2317, train/total_loss: 0.1005, train/total_loss/avg: 0.2317, max mem: 5909.0, experiment: run, epoch: 16, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00005, ups: 2.08, time: 48s 958ms, time_since_start: 28m 07s 422ms, eta: 02h 42m 22s 836ms
[32m2021-03-04T01:04:16 | mmf.trainers.callbacks.logistics: [0mprogress: 2200/22000, train/hateful_memes/cross_entropy: 0.0655, train/hateful_memes/cross_entropy/avg: 0.2213, train/total_loss: 0.0655, train/total_loss/avg: 0.2213, max mem: 5909.0, experiment: run, epoch: 17, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00005, ups: 1.64, time: 01m 01s 031ms, time_since_start: 29m 08s 454ms, eta: 03h 21m 24s 300ms
[32m2021-03-04T01:05:16 | mmf.trainers.callbacks.logistics: [0mprogress: 2300/22000, train/hateful_memes/cross_entropy: 0.0648, train/hateful_memes/cross_entropy/avg: 0.2121, train/total_loss: 0.0648, train/total_loss/avg: 0.2121, max mem: 5909.0, experiment: run, epoch: 18, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00005, ups: 1.67, time: 01m 135ms, time_since_start: 30m 08s 589ms, eta: 03h 17m 26s 708ms
[32m2021-03-04T01:06:16 | mmf.trainers.callbacks.logistics: [0mprogress: 2400/22000, train/hateful_memes/cross_entropy: 0.0573, train/hateful_memes/cross_entropy/avg: 0.2046, train/total_loss: 0.0573, train/total_loss/avg: 0.2046, max mem: 5909.0, experiment: run, epoch: 19, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00005, ups: 1.67, time: 01m 187ms, time_since_start: 31m 08s 777ms, eta: 03h 16m 36s 797ms
[32m2021-03-04T01:07:07 | mmf.trainers.callbacks.logistics: [0mprogress: 2500/22000, train/hateful_memes/cross_entropy: 0.0573, train/hateful_memes/cross_entropy/avg: 0.2001, train/total_loss: 0.0573, train/total_loss/avg: 0.2001, max mem: 5909.0, experiment: run, epoch: 19, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00005, ups: 2.00, time: 50s 890ms, time_since_start: 31m 59s 667ms, eta: 02h 45m 23s 598ms
[32m2021-03-04T01:08:07 | mmf.trainers.callbacks.logistics: [0mprogress: 2600/22000, train/hateful_memes/cross_entropy: 0.0448, train/hateful_memes/cross_entropy/avg: 0.1924, train/total_loss: 0.0448, train/total_loss/avg: 0.1924, max mem: 5909.0, experiment: run, epoch: 20, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00005, ups: 1.67, time: 01m 320ms, time_since_start: 32m 59s 988ms, eta: 03h 15m 02s 097ms
[32m2021-03-04T01:09:08 | mmf.trainers.callbacks.logistics: [0mprogress: 2700/22000, train/hateful_memes/cross_entropy: 0.0303, train/hateful_memes/cross_entropy/avg: 0.1856, train/total_loss: 0.0303, train/total_loss/avg: 0.1856, max mem: 5909.0, experiment: run, epoch: 21, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00005, ups: 1.67, time: 01m 767ms, time_since_start: 34m 755ms, eta: 03h 15m 28s 087ms
[32m2021-03-04T01:10:09 | mmf.trainers.callbacks.logistics: [0mprogress: 2800/22000, train/hateful_memes/cross_entropy: 0.0303, train/hateful_memes/cross_entropy/avg: 0.1810, train/total_loss: 0.0303, train/total_loss/avg: 0.1810, max mem: 5909.0, experiment: run, epoch: 22, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00005, ups: 1.64, time: 01m 01s 204ms, time_since_start: 35m 01s 960ms, eta: 03h 15m 51s 317ms
[32m2021-03-04T01:10:58 | mmf.trainers.callbacks.logistics: [0mprogress: 2900/22000, train/hateful_memes/cross_entropy: 0.0298, train/hateful_memes/cross_entropy/avg: 0.1750, train/total_loss: 0.0298, train/total_loss/avg: 0.1750, max mem: 5909.0, experiment: run, epoch: 22, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00005, ups: 2.08, time: 48s 880ms, time_since_start: 35m 50s 840ms, eta: 02h 35m 36s 170ms
[32m2021-03-04T01:11:58 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T01:11:58 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T01:11:58 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T01:11:58 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T01:12:09 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T01:12:18 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T01:12:18 | mmf.trainers.callbacks.logistics: [0mprogress: 3000/22000, train/hateful_memes/cross_entropy: 0.0267, train/hateful_memes/cross_entropy/avg: 0.1693, train/total_loss: 0.0267, train/total_loss/avg: 0.1693, max mem: 5909.0, experiment: run, epoch: 23, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00005, ups: 1.25, time: 01m 20s 200ms, time_since_start: 37m 11s 040ms, eta: 04h 13m 58s 007ms
[32m2021-03-04T01:12:18 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T01:12:33 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T01:12:33 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T01:12:33 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T01:12:33 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T01:12:44 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T01:12:54 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T01:12:54 | mmf.trainers.callbacks.logistics: [0mprogress: 3000/22000, val/hateful_memes/cross_entropy: 1.8931, val/total_loss: 1.8931, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.3783, val/hateful_memes/roc_auc: 0.6921, num_updates: 3000, epoch: 23, iterations: 3000, max_updates: 22000, val_time: 35s 544ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T01:13:55 | mmf.trainers.callbacks.logistics: [0mprogress: 3100/22000, train/hateful_memes/cross_entropy: 0.0216, train/hateful_memes/cross_entropy/avg: 0.1643, train/total_loss: 0.0216, train/total_loss/avg: 0.1643, max mem: 5909.0, experiment: run, epoch: 24, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00005, ups: 1.64, time: 01m 01s 313ms, time_since_start: 38m 47s 900ms, eta: 03h 13m 08s 339ms
[32m2021-03-04T01:14:56 | mmf.trainers.callbacks.logistics: [0mprogress: 3200/22000, train/hateful_memes/cross_entropy: 0.0185, train/hateful_memes/cross_entropy/avg: 0.1592, train/total_loss: 0.0185, train/total_loss/avg: 0.1592, max mem: 5909.0, experiment: run, epoch: 25, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00005, ups: 1.64, time: 01m 01s 000ms, time_since_start: 39m 48s 901ms, eta: 03h 11m 08s 147ms
[32m2021-03-04T01:15:47 | mmf.trainers.callbacks.logistics: [0mprogress: 3300/22000, train/hateful_memes/cross_entropy: 0.0135, train/hateful_memes/cross_entropy/avg: 0.1544, train/total_loss: 0.0135, train/total_loss/avg: 0.1544, max mem: 5909.0, experiment: run, epoch: 25, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00005, ups: 2.00, time: 50s 663ms, time_since_start: 40m 39s 565ms, eta: 02h 37m 54s 061ms
[32m2021-03-04T01:16:48 | mmf.trainers.callbacks.logistics: [0mprogress: 3400/22000, train/hateful_memes/cross_entropy: 0.0100, train/hateful_memes/cross_entropy/avg: 0.1500, train/total_loss: 0.0100, train/total_loss/avg: 0.1500, max mem: 5909.0, experiment: run, epoch: 26, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00005, ups: 1.64, time: 01m 01s 482ms, time_since_start: 41m 41s 047ms, eta: 03h 10m 35s 740ms
[32m2021-03-04T01:17:49 | mmf.trainers.callbacks.logistics: [0mprogress: 3500/22000, train/hateful_memes/cross_entropy: 0.0071, train/hateful_memes/cross_entropy/avg: 0.1457, train/total_loss: 0.0071, train/total_loss/avg: 0.1457, max mem: 5909.0, experiment: run, epoch: 27, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00005, ups: 1.64, time: 01m 01s 044ms, time_since_start: 42m 42s 092ms, eta: 03h 08m 13s 324ms
[32m2021-03-04T01:18:50 | mmf.trainers.callbacks.logistics: [0mprogress: 3600/22000, train/hateful_memes/cross_entropy: 0.0068, train/hateful_memes/cross_entropy/avg: 0.1417, train/total_loss: 0.0068, train/total_loss/avg: 0.1417, max mem: 5909.0, experiment: run, epoch: 28, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00005, ups: 1.67, time: 01m 398ms, time_since_start: 43m 42s 491ms, eta: 03h 05m 13s 384ms
[32m2021-03-04T01:19:41 | mmf.trainers.callbacks.logistics: [0mprogress: 3700/22000, train/hateful_memes/cross_entropy: 0.0054, train/hateful_memes/cross_entropy/avg: 0.1380, train/total_loss: 0.0054, train/total_loss/avg: 0.1380, max mem: 5909.0, experiment: run, epoch: 28, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00005, ups: 1.96, time: 51s 052ms, time_since_start: 44m 33s 544ms, eta: 02h 35m 42s 634ms
[32m2021-03-04T01:20:42 | mmf.trainers.callbacks.logistics: [0mprogress: 3800/22000, train/hateful_memes/cross_entropy: 0.0068, train/hateful_memes/cross_entropy/avg: 0.1352, train/total_loss: 0.0068, train/total_loss/avg: 0.1352, max mem: 5909.0, experiment: run, epoch: 29, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00005, ups: 1.64, time: 01m 01s 160ms, time_since_start: 45m 34s 704ms, eta: 03h 05m 31s 128ms
[32m2021-03-04T01:21:44 | mmf.trainers.callbacks.logistics: [0mprogress: 3900/22000, train/hateful_memes/cross_entropy: 0.0068, train/hateful_memes/cross_entropy/avg: 0.1319, train/total_loss: 0.0068, train/total_loss/avg: 0.1319, max mem: 5909.0, experiment: run, epoch: 30, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00005, ups: 1.64, time: 01m 01s 859ms, time_since_start: 46m 36s 563ms, eta: 03h 06m 36s 613ms
[32m2021-03-04T01:22:46 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T01:22:46 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T01:22:46 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T01:22:46 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T01:22:57 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T01:23:06 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T01:23:06 | mmf.trainers.callbacks.logistics: [0mprogress: 4000/22000, train/hateful_memes/cross_entropy: 0.0054, train/hateful_memes/cross_entropy/avg: 0.1286, train/total_loss: 0.0054, train/total_loss/avg: 0.1286, max mem: 5909.0, experiment: run, epoch: 31, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00005, ups: 1.22, time: 01m 22s 542ms, time_since_start: 47m 59s 106ms, eta: 04h 07m 37s 722ms
[32m2021-03-04T01:23:06 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T01:23:18 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T01:23:18 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T01:23:18 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T01:23:18 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T01:23:28 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T01:23:37 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T01:23:37 | mmf.trainers.callbacks.logistics: [0mprogress: 4000/22000, val/hateful_memes/cross_entropy: 2.0483, val/total_loss: 2.0483, val/hateful_memes/accuracy: 0.7093, val/hateful_memes/binary_f1: 0.4911, val/hateful_memes/roc_auc: 0.7075, num_updates: 4000, epoch: 31, iterations: 4000, max_updates: 22000, val_time: 30s 567ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T01:24:25 | mmf.trainers.callbacks.logistics: [0mprogress: 4100/22000, train/hateful_memes/cross_entropy: 0.0043, train/hateful_memes/cross_entropy/avg: 0.1255, train/total_loss: 0.0043, train/total_loss/avg: 0.1255, max mem: 5909.0, experiment: run, epoch: 31, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00004, ups: 2.08, time: 48s 234ms, time_since_start: 49m 17s 911ms, eta: 02h 23m 54s 062ms
[32m2021-03-04T01:25:26 | mmf.trainers.callbacks.logistics: [0mprogress: 4200/22000, train/hateful_memes/cross_entropy: 0.0054, train/hateful_memes/cross_entropy/avg: 0.1231, train/total_loss: 0.0054, train/total_loss/avg: 0.1231, max mem: 5909.0, experiment: run, epoch: 32, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 779ms, time_since_start: 50m 18s 690ms, eta: 03h 18s 762ms
[32m2021-03-04T01:26:26 | mmf.trainers.callbacks.logistics: [0mprogress: 4300/22000, train/hateful_memes/cross_entropy: 0.0043, train/hateful_memes/cross_entropy/avg: 0.1202, train/total_loss: 0.0043, train/total_loss/avg: 0.1202, max mem: 5909.0, experiment: run, epoch: 33, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 198ms, time_since_start: 51m 18s 889ms, eta: 02h 57m 35s 215ms
[32m2021-03-04T01:27:28 | mmf.trainers.callbacks.logistics: [0mprogress: 4400/22000, train/hateful_memes/cross_entropy: 0.0043, train/hateful_memes/cross_entropy/avg: 0.1176, train/total_loss: 0.0043, train/total_loss/avg: 0.1176, max mem: 5909.0, experiment: run, epoch: 34, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00004, ups: 1.64, time: 01m 01s 668ms, time_since_start: 52m 20s 558ms, eta: 03h 53s 647ms
[32m2021-03-04T01:28:19 | mmf.trainers.callbacks.logistics: [0mprogress: 4500/22000, train/hateful_memes/cross_entropy: 0.0043, train/hateful_memes/cross_entropy/avg: 0.1152, train/total_loss: 0.0043, train/total_loss/avg: 0.1152, max mem: 5909.0, experiment: run, epoch: 34, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00004, ups: 2.00, time: 50s 898ms, time_since_start: 53m 11s 456ms, eta: 02h 28m 27s 226ms
[32m2021-03-04T01:29:20 | mmf.trainers.callbacks.logistics: [0mprogress: 4600/22000, train/hateful_memes/cross_entropy: 0.0043, train/hateful_memes/cross_entropy/avg: 0.1127, train/total_loss: 0.0043, train/total_loss/avg: 0.1127, max mem: 5909.0, experiment: run, epoch: 35, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 969ms, time_since_start: 54m 12s 426ms, eta: 02h 56m 48s 740ms
[32m2021-03-04T01:30:21 | mmf.trainers.callbacks.logistics: [0mprogress: 4700/22000, train/hateful_memes/cross_entropy: 0.0043, train/hateful_memes/cross_entropy/avg: 0.1105, train/total_loss: 0.0043, train/total_loss/avg: 0.1105, max mem: 5909.0, experiment: run, epoch: 36, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 921ms, time_since_start: 55m 13s 348ms, eta: 02h 55m 39s 428ms
[32m2021-03-04T01:31:22 | mmf.trainers.callbacks.logistics: [0mprogress: 4800/22000, train/hateful_memes/cross_entropy: 0.0039, train/hateful_memes/cross_entropy/avg: 0.1083, train/total_loss: 0.0039, train/total_loss/avg: 0.1083, max mem: 5909.0, experiment: run, epoch: 37, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00004, ups: 1.64, time: 01m 01s 249ms, time_since_start: 56m 14s 597ms, eta: 02h 55m 34s 919ms
[32m2021-03-04T01:32:13 | mmf.trainers.callbacks.logistics: [0mprogress: 4900/22000, train/hateful_memes/cross_entropy: 0.0039, train/hateful_memes/cross_entropy/avg: 0.1062, train/total_loss: 0.0039, train/total_loss/avg: 0.1062, max mem: 5909.0, experiment: run, epoch: 37, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00004, ups: 2.00, time: 50s 865ms, time_since_start: 57m 05s 463ms, eta: 02h 24m 58s 054ms
[32m2021-03-04T01:33:13 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T01:33:13 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T01:33:13 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T01:33:13 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T01:33:16 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T01:33:28 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T01:33:28 | mmf.trainers.callbacks.logistics: [0mprogress: 5000/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1041, train/total_loss: 0.0023, train/total_loss/avg: 0.1041, max mem: 5909.0, experiment: run, epoch: 38, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00004, ups: 1.33, time: 01m 15s 235ms, time_since_start: 58m 20s 699ms, eta: 03h 33m 10s 101ms
[32m2021-03-04T01:33:28 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T01:33:39 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T01:33:39 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T01:33:39 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T01:33:39 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T01:33:49 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T01:33:59 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T01:33:59 | mmf.trainers.callbacks.logistics: [0mprogress: 5000/22000, val/hateful_memes/cross_entropy: 1.8406, val/total_loss: 1.8406, val/hateful_memes/accuracy: 0.7204, val/hateful_memes/binary_f1: 0.4834, val/hateful_memes/roc_auc: 0.6891, num_updates: 5000, epoch: 38, iterations: 5000, max_updates: 22000, val_time: 31s 321ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T01:34:59 | mmf.trainers.callbacks.logistics: [0mprogress: 5100/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1020, train/total_loss: 0.0016, train/total_loss/avg: 0.1020, max mem: 5909.0, experiment: run, epoch: 39, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00004, ups: 1.69, time: 59s 770ms, time_since_start: 59m 51s 793ms, eta: 02h 48m 21s 232ms
[32m2021-03-04T01:36:00 | mmf.trainers.callbacks.logistics: [0mprogress: 5200/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1005, train/total_loss: 0.0023, train/total_loss/avg: 0.1005, max mem: 5909.0, experiment: run, epoch: 40, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00004, ups: 1.64, time: 01m 01s 276ms, time_since_start: 01h 53s 070ms, eta: 02h 51m 34s 447ms
[32m2021-03-04T01:36:51 | mmf.trainers.callbacks.logistics: [0mprogress: 5300/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.0986, train/total_loss: 0.0023, train/total_loss/avg: 0.0986, max mem: 5909.0, experiment: run, epoch: 40, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00004, ups: 2.00, time: 50s 926ms, time_since_start: 01h 01m 43s 996ms, eta: 02h 21m 44s 715ms
[32m2021-03-04T01:37:52 | mmf.trainers.callbacks.logistics: [0mprogress: 5400/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.0983, train/total_loss: 0.0023, train/total_loss/avg: 0.0983, max mem: 5909.0, experiment: run, epoch: 41, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 978ms, time_since_start: 01h 02m 44s 974ms, eta: 02h 48m 42s 381ms
[32m2021-03-04T01:38:53 | mmf.trainers.callbacks.logistics: [0mprogress: 5500/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.0965, train/total_loss: 0.0023, train/total_loss/avg: 0.0965, max mem: 5909.0, experiment: run, epoch: 42, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 625ms, time_since_start: 01h 03m 45s 600ms, eta: 02h 46m 43s 220ms
[32m2021-03-04T01:39:54 | mmf.trainers.callbacks.logistics: [0mprogress: 5600/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.0948, train/total_loss: 0.0023, train/total_loss/avg: 0.0948, max mem: 5909.0, experiment: run, epoch: 43, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 707ms, time_since_start: 01h 04m 46s 307ms, eta: 02h 45m 55s 971ms
[32m2021-03-04T01:40:44 | mmf.trainers.callbacks.logistics: [0mprogress: 5700/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.0936, train/total_loss: 0.0023, train/total_loss/avg: 0.0936, max mem: 5909.0, experiment: run, epoch: 43, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00004, ups: 2.00, time: 50s 695ms, time_since_start: 01h 05m 37s 003ms, eta: 02h 17m 43s 439ms
[32m2021-03-04T01:41:44 | mmf.trainers.callbacks.logistics: [0mprogress: 5800/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.0922, train/total_loss: 0.0023, train/total_loss/avg: 0.0922, max mem: 5909.0, experiment: run, epoch: 44, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00004, ups: 1.69, time: 59s 993ms, time_since_start: 01h 06m 36s 996ms, eta: 02h 41m 58s 875ms
[32m2021-03-04T01:42:45 | mmf.trainers.callbacks.logistics: [0mprogress: 5900/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.0906, train/total_loss: 0.0012, train/total_loss/avg: 0.0906, max mem: 5909.0, experiment: run, epoch: 45, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 326ms, time_since_start: 01h 07m 37s 323ms, eta: 02h 41m 52s 562ms
[32m2021-03-04T01:43:46 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T01:43:46 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T01:43:46 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T01:43:46 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T01:43:48 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T01:43:58 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T01:43:58 | mmf.trainers.callbacks.logistics: [0mprogress: 6000/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0891, train/total_loss: 0.0013, train/total_loss/avg: 0.0891, max mem: 5909.0, experiment: run, epoch: 46, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00004, ups: 1.37, time: 01m 13s 714ms, time_since_start: 01h 08m 51s 037ms, eta: 03h 16m 34s 269ms
[32m2021-03-04T01:43:58 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T01:44:09 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T01:44:09 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T01:44:09 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T01:44:09 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T01:44:19 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T01:44:28 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T01:44:28 | mmf.trainers.callbacks.logistics: [0mprogress: 6000/22000, val/hateful_memes/cross_entropy: 2.0785, val/total_loss: 2.0785, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4468, val/hateful_memes/roc_auc: 0.7054, num_updates: 6000, epoch: 46, iterations: 6000, max_updates: 22000, val_time: 29s 528ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T01:45:18 | mmf.trainers.callbacks.logistics: [0mprogress: 6100/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0877, train/total_loss: 0.0015, train/total_loss/avg: 0.0877, max mem: 5909.0, experiment: run, epoch: 46, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00004, ups: 2.00, time: 50s 293ms, time_since_start: 01h 10m 10s 861ms, eta: 02h 13m 16s 704ms
[32m2021-03-04T01:46:20 | mmf.trainers.callbacks.logistics: [0mprogress: 6200/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0864, train/total_loss: 0.0015, train/total_loss/avg: 0.0864, max mem: 5909.0, experiment: run, epoch: 47, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00004, ups: 1.64, time: 01m 01s 625ms, time_since_start: 01h 11m 12s 487ms, eta: 02h 42m 16s 891ms
[32m2021-03-04T01:47:22 | mmf.trainers.callbacks.logistics: [0mprogress: 6300/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0850, train/total_loss: 0.0015, train/total_loss/avg: 0.0850, max mem: 5909.0, experiment: run, epoch: 48, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00004, ups: 1.64, time: 01m 01s 642ms, time_since_start: 01h 12m 14s 129ms, eta: 02h 41m 17s 837ms
[32m2021-03-04T01:48:23 | mmf.trainers.callbacks.logistics: [0mprogress: 6400/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0837, train/total_loss: 0.0015, train/total_loss/avg: 0.0837, max mem: 5909.0, experiment: run, epoch: 49, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00004, ups: 1.64, time: 01m 01s 263ms, time_since_start: 01h 13m 15s 393ms, eta: 02h 39m 17s 157ms
[32m2021-03-04T01:49:12 | mmf.trainers.callbacks.logistics: [0mprogress: 6500/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0824, train/total_loss: 0.0013, train/total_loss/avg: 0.0824, max mem: 5909.0, experiment: run, epoch: 49, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00004, ups: 2.04, time: 49s 538ms, time_since_start: 01h 14m 04s 931ms, eta: 02h 07m 58s 411ms
[32m2021-03-04T01:50:13 | mmf.trainers.callbacks.logistics: [0mprogress: 6600/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0812, train/total_loss: 0.0015, train/total_loss/avg: 0.0812, max mem: 5909.0, experiment: run, epoch: 50, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 609ms, time_since_start: 01h 15m 05s 541ms, eta: 02h 35m 33s 864ms
[32m2021-03-04T01:51:14 | mmf.trainers.callbacks.logistics: [0mprogress: 6700/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0800, train/total_loss: 0.0013, train/total_loss/avg: 0.0800, max mem: 5909.0, experiment: run, epoch: 51, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 580ms, time_since_start: 01h 16m 06s 122ms, eta: 02h 34m 28s 861ms
[32m2021-03-04T01:52:14 | mmf.trainers.callbacks.logistics: [0mprogress: 6800/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0788, train/total_loss: 0.0013, train/total_loss/avg: 0.0788, max mem: 5909.0, experiment: run, epoch: 52, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 718ms, time_since_start: 01h 17m 06s 840ms, eta: 02h 33m 49s 251ms
[32m2021-03-04T01:53:04 | mmf.trainers.callbacks.logistics: [0mprogress: 6900/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0779, train/total_loss: 0.0013, train/total_loss/avg: 0.0779, max mem: 5909.0, experiment: run, epoch: 52, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00004, ups: 2.00, time: 50s 152ms, time_since_start: 01h 17m 56s 993ms, eta: 02h 06m 13s 046ms
[32m2021-03-04T01:54:04 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T01:54:04 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T01:54:04 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T01:54:04 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T01:54:07 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T01:54:17 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T01:54:18 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.0767, train/total_loss: 0.0012, train/total_loss/avg: 0.0767, max mem: 5909.0, experiment: run, epoch: 53, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00004, ups: 1.37, time: 01m 13s 126ms, time_since_start: 01h 19m 10s 119ms, eta: 03h 02m 48s 936ms
[32m2021-03-04T01:54:18 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T01:54:28 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T01:54:28 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, val/hateful_memes/cross_entropy: 2.0283, val/total_loss: 2.0283, val/hateful_memes/accuracy: 0.7037, val/hateful_memes/binary_f1: 0.5022, val/hateful_memes/roc_auc: 0.6944, num_updates: 7000, epoch: 53, iterations: 7000, max_updates: 22000, val_time: 10s 885ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T01:55:31 | mmf.trainers.callbacks.logistics: [0mprogress: 7100/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0757, train/total_loss: 0.0013, train/total_loss/avg: 0.0757, max mem: 5909.0, experiment: run, epoch: 54, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00004, ups: 1.61, time: 01m 02s 351ms, time_since_start: 01h 20m 23s 357ms, eta: 02h 34m 50s 316ms
[32m2021-03-04T01:56:33 | mmf.trainers.callbacks.logistics: [0mprogress: 7200/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.0747, train/total_loss: 0.0012, train/total_loss/avg: 0.0747, max mem: 5909.0, experiment: run, epoch: 55, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00004, ups: 1.61, time: 01m 02s 447ms, time_since_start: 01h 21m 25s 804ms, eta: 02h 34m 02s 188ms
[32m2021-03-04T01:57:25 | mmf.trainers.callbacks.logistics: [0mprogress: 7300/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0737, train/total_loss: 0.0013, train/total_loss/avg: 0.0737, max mem: 5909.0, experiment: run, epoch: 55, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 119ms, time_since_start: 01h 22m 17s 924ms, eta: 02h 07m 41s 572ms
[32m2021-03-04T01:58:25 | mmf.trainers.callbacks.logistics: [0mprogress: 7400/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.0727, train/total_loss: 0.0012, train/total_loss/avg: 0.0727, max mem: 5909.0, experiment: run, epoch: 56, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 056ms, time_since_start: 01h 23m 17s 980ms, eta: 02h 26m 08s 187ms
[32m2021-03-04T01:59:25 | mmf.trainers.callbacks.logistics: [0mprogress: 7500/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.0718, train/total_loss: 0.0012, train/total_loss/avg: 0.0718, max mem: 5909.0, experiment: run, epoch: 57, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00004, ups: 1.69, time: 59s 969ms, time_since_start: 01h 24m 17s 950ms, eta: 02h 24m 55s 619ms
[32m2021-03-04T02:00:26 | mmf.trainers.callbacks.logistics: [0mprogress: 7600/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0708, train/total_loss: 0.0011, train/total_loss/avg: 0.0708, max mem: 5909.0, experiment: run, epoch: 58, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 284ms, time_since_start: 01h 25m 18s 234ms, eta: 02h 24m 40s 993ms
[32m2021-03-04T02:01:16 | mmf.trainers.callbacks.logistics: [0mprogress: 7700/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0700, train/total_loss: 0.0011, train/total_loss/avg: 0.0700, max mem: 5909.0, experiment: run, epoch: 58, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00004, ups: 2.00, time: 50s 171ms, time_since_start: 01h 26m 08s 406ms, eta: 01h 59m 34s 496ms
[32m2021-03-04T02:02:16 | mmf.trainers.callbacks.logistics: [0mprogress: 7800/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0691, train/total_loss: 0.0010, train/total_loss/avg: 0.0691, max mem: 5909.0, experiment: run, epoch: 59, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 015ms, time_since_start: 01h 27m 08s 421ms, eta: 02h 22m 02s 194ms
[32m2021-03-04T02:03:16 | mmf.trainers.callbacks.logistics: [0mprogress: 7900/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0682, train/total_loss: 0.0011, train/total_loss/avg: 0.0682, max mem: 5909.0, experiment: run, epoch: 60, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00004, ups: 1.67, time: 01m 115ms, time_since_start: 01h 28m 08s 537ms, eta: 02h 21m 16s 292ms
[32m2021-03-04T02:04:17 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T02:04:17 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T02:04:17 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T02:04:17 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T02:04:20 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T02:04:31 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T02:04:31 | mmf.trainers.callbacks.logistics: [0mprogress: 8000/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0675, train/total_loss: 0.0011, train/total_loss/avg: 0.0675, max mem: 5909.0, experiment: run, epoch: 61, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00003, ups: 1.35, time: 01m 14s 737ms, time_since_start: 01h 29m 23s 274ms, eta: 02h 54m 23s 240ms
[32m2021-03-04T02:04:31 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T02:04:42 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T02:04:42 | mmf.trainers.callbacks.logistics: [0mprogress: 8000/22000, val/hateful_memes/cross_entropy: 1.8508, val/total_loss: 1.8508, val/hateful_memes/accuracy: 0.7019, val/hateful_memes/binary_f1: 0.5011, val/hateful_memes/roc_auc: 0.6924, num_updates: 8000, epoch: 61, iterations: 8000, max_updates: 22000, val_time: 11s 684ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T02:05:34 | mmf.trainers.callbacks.logistics: [0mprogress: 8100/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0668, train/total_loss: 0.0011, train/total_loss/avg: 0.0668, max mem: 5909.0, experiment: run, epoch: 61, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 779ms, time_since_start: 01h 30m 26s 740ms, eta: 01h 59m 57s 328ms
[32m2021-03-04T02:06:35 | mmf.trainers.callbacks.logistics: [0mprogress: 8200/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0665, train/total_loss: 0.0011, train/total_loss/avg: 0.0665, max mem: 5909.0, experiment: run, epoch: 62, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 760ms, time_since_start: 01h 31m 27s 501ms, eta: 02h 19m 44s 998ms
[32m2021-03-04T02:07:36 | mmf.trainers.callbacks.logistics: [0mprogress: 8300/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0658, train/total_loss: 0.0016, train/total_loss/avg: 0.0658, max mem: 5909.0, experiment: run, epoch: 63, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00003, ups: 1.64, time: 01m 01s 302ms, time_since_start: 01h 32m 28s 803ms, eta: 02h 19m 58s 383ms
[32m2021-03-04T02:08:38 | mmf.trainers.callbacks.logistics: [0mprogress: 8400/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0650, train/total_loss: 0.0011, train/total_loss/avg: 0.0650, max mem: 5909.0, experiment: run, epoch: 64, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00003, ups: 1.64, time: 01m 01s 736ms, time_since_start: 01h 33m 30s 539ms, eta: 02h 19m 56s 101ms
[32m2021-03-04T02:09:30 | mmf.trainers.callbacks.logistics: [0mprogress: 8500/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0653, train/total_loss: 0.0016, train/total_loss/avg: 0.0653, max mem: 5909.0, experiment: run, epoch: 64, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 964ms, time_since_start: 01h 34m 22s 504ms, eta: 01h 56m 55s 161ms
[32m2021-03-04T02:10:32 | mmf.trainers.callbacks.logistics: [0mprogress: 8600/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0646, train/total_loss: 0.0011, train/total_loss/avg: 0.0646, max mem: 5909.0, experiment: run, epoch: 65, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00003, ups: 1.61, time: 01m 02s 186ms, time_since_start: 01h 35m 24s 690ms, eta: 02h 18m 53s 039ms
[32m2021-03-04T02:11:33 | mmf.trainers.callbacks.logistics: [0mprogress: 8700/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0639, train/total_loss: 0.0011, train/total_loss/avg: 0.0639, max mem: 5909.0, experiment: run, epoch: 66, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00003, ups: 1.64, time: 01m 01s 200ms, time_since_start: 01h 36m 25s 891ms, eta: 02h 15m 39s 650ms
[32m2021-03-04T02:12:34 | mmf.trainers.callbacks.logistics: [0mprogress: 8800/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0631, train/total_loss: 0.0011, train/total_loss/avg: 0.0631, max mem: 5909.0, experiment: run, epoch: 67, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 501ms, time_since_start: 01h 37m 26s 393ms, eta: 02h 13m 06s 241ms
[32m2021-03-04T02:13:24 | mmf.trainers.callbacks.logistics: [0mprogress: 8900/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0624, train/total_loss: 0.0008, train/total_loss/avg: 0.0624, max mem: 5909.0, experiment: run, epoch: 67, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00003, ups: 2.00, time: 50s 203ms, time_since_start: 01h 38m 16s 596ms, eta: 01h 49m 36s 607ms
[32m2021-03-04T02:14:24 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T02:14:24 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T02:14:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T02:14:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T02:14:27 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T02:14:37 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T02:14:37 | mmf.trainers.callbacks.logistics: [0mprogress: 9000/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0617, train/total_loss: 0.0008, train/total_loss/avg: 0.0617, max mem: 5909.0, experiment: run, epoch: 68, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00003, ups: 1.37, time: 01m 13s 277ms, time_since_start: 01h 39m 29s 874ms, eta: 02h 38m 46s 140ms
[32m2021-03-04T02:14:37 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T02:14:51 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T02:14:51 | mmf.trainers.callbacks.logistics: [0mprogress: 9000/22000, val/hateful_memes/cross_entropy: 1.9897, val/total_loss: 1.9897, val/hateful_memes/accuracy: 0.6944, val/hateful_memes/binary_f1: 0.5358, val/hateful_memes/roc_auc: 0.7003, num_updates: 9000, epoch: 68, iterations: 9000, max_updates: 22000, val_time: 13s 424ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T02:15:51 | mmf.trainers.callbacks.logistics: [0mprogress: 9100/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0611, train/total_loss: 0.0007, train/total_loss/avg: 0.0611, max mem: 5909.0, experiment: run, epoch: 69, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 209ms, time_since_start: 01h 40m 43s 510ms, eta: 02h 09m 27s 058ms
[32m2021-03-04T02:16:51 | mmf.trainers.callbacks.logistics: [0mprogress: 9200/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0605, train/total_loss: 0.0008, train/total_loss/avg: 0.0605, max mem: 5909.0, experiment: run, epoch: 70, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 327ms, time_since_start: 01h 41m 43s 838ms, eta: 02h 08m 41s 982ms
[32m2021-03-04T02:17:41 | mmf.trainers.callbacks.logistics: [0mprogress: 9300/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0599, train/total_loss: 0.0007, train/total_loss/avg: 0.0599, max mem: 5909.0, experiment: run, epoch: 70, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00003, ups: 2.04, time: 49s 723ms, time_since_start: 01h 42m 33s 561ms, eta: 01h 45m 14s 861ms
[32m2021-03-04T02:18:43 | mmf.trainers.callbacks.logistics: [0mprogress: 9400/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0593, train/total_loss: 0.0008, train/total_loss/avg: 0.0593, max mem: 5909.0, experiment: run, epoch: 71, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00003, ups: 1.64, time: 01m 01s 683ms, time_since_start: 01h 43m 35s 245ms, eta: 02h 09m 32s 182ms
[32m2021-03-04T02:19:44 | mmf.trainers.callbacks.logistics: [0mprogress: 9500/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0587, train/total_loss: 0.0009, train/total_loss/avg: 0.0587, max mem: 5909.0, experiment: run, epoch: 72, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00003, ups: 1.64, time: 01m 01s 445ms, time_since_start: 01h 44m 36s 691ms, eta: 02h 08m 752ms
[32m2021-03-04T02:20:46 | mmf.trainers.callbacks.logistics: [0mprogress: 9600/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0581, train/total_loss: 0.0008, train/total_loss/avg: 0.0581, max mem: 5909.0, experiment: run, epoch: 73, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00003, ups: 1.64, time: 01m 01s 747ms, time_since_start: 01h 45m 38s 439ms, eta: 02h 07m 36s 746ms
[32m2021-03-04T02:21:39 | mmf.trainers.callbacks.logistics: [0mprogress: 9700/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0575, train/total_loss: 0.0008, train/total_loss/avg: 0.0575, max mem: 5909.0, experiment: run, epoch: 73, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 936ms, time_since_start: 01h 46m 31s 375ms, eta: 01h 48m 31s 139ms
[32m2021-03-04T02:22:40 | mmf.trainers.callbacks.logistics: [0mprogress: 9800/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0570, train/total_loss: 0.0008, train/total_loss/avg: 0.0570, max mem: 5909.0, experiment: run, epoch: 74, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00003, ups: 1.64, time: 01m 01s 301ms, time_since_start: 01h 47m 32s 677ms, eta: 02h 04m 38s 778ms
[32m2021-03-04T02:23:41 | mmf.trainers.callbacks.logistics: [0mprogress: 9900/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0564, train/total_loss: 0.0008, train/total_loss/avg: 0.0564, max mem: 5909.0, experiment: run, epoch: 75, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00003, ups: 1.64, time: 01m 01s 085ms, time_since_start: 01h 48m 33s 763ms, eta: 02h 03m 11s 363ms
[32m2021-03-04T02:24:42 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T02:24:42 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T02:24:42 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T02:24:42 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T02:24:45 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T02:24:55 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T02:24:55 | mmf.trainers.callbacks.logistics: [0mprogress: 10000/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0558, train/total_loss: 0.0006, train/total_loss/avg: 0.0558, max mem: 5909.0, experiment: run, epoch: 76, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00003, ups: 1.35, time: 01m 14s 311ms, time_since_start: 01h 49m 48s 074ms, eta: 02h 28m 37s 398ms
[32m2021-03-04T02:24:55 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T02:25:07 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T02:25:07 | mmf.trainers.callbacks.logistics: [0mprogress: 10000/22000, val/hateful_memes/cross_entropy: 2.0898, val/total_loss: 2.0898, val/hateful_memes/accuracy: 0.6944, val/hateful_memes/binary_f1: 0.4723, val/hateful_memes/roc_auc: 0.6993, num_updates: 10000, epoch: 76, iterations: 10000, max_updates: 22000, val_time: 11s 639ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T02:25:54 | mmf.trainers.callbacks.logistics: [0mprogress: 10100/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0553, train/total_loss: 0.0005, train/total_loss/avg: 0.0553, max mem: 5909.0, experiment: run, epoch: 76, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00003, ups: 2.13, time: 47s 352ms, time_since_start: 01h 50m 47s 068ms, eta: 01h 33m 54s 909ms
[32m2021-03-04T02:26:54 | mmf.trainers.callbacks.logistics: [0mprogress: 10200/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0547, train/total_loss: 0.0005, train/total_loss/avg: 0.0547, max mem: 5909.0, experiment: run, epoch: 77, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00003, ups: 1.69, time: 59s 577ms, time_since_start: 01h 51m 46s 645ms, eta: 01h 57m 10s 094ms
[32m2021-03-04T02:27:55 | mmf.trainers.callbacks.logistics: [0mprogress: 10300/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0542, train/total_loss: 0.0005, train/total_loss/avg: 0.0542, max mem: 5909.0, experiment: run, epoch: 78, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 635ms, time_since_start: 01h 52m 47s 281ms, eta: 01h 58m 14s 401ms
[32m2021-03-04T02:28:56 | mmf.trainers.callbacks.logistics: [0mprogress: 10400/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0540, train/total_loss: 0.0005, train/total_loss/avg: 0.0540, max mem: 5909.0, experiment: run, epoch: 79, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00003, ups: 1.64, time: 01m 01s 698ms, time_since_start: 01h 53m 48s 979ms, eta: 01h 59m 16s 985ms
[32m2021-03-04T02:29:48 | mmf.trainers.callbacks.logistics: [0mprogress: 10500/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0535, train/total_loss: 0.0004, train/total_loss/avg: 0.0535, max mem: 5909.0, experiment: run, epoch: 79, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 128ms, time_since_start: 01h 54m 41s 108ms, eta: 01h 39m 54s 817ms
[32m2021-03-04T02:30:50 | mmf.trainers.callbacks.logistics: [0mprogress: 10600/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0530, train/total_loss: 0.0004, train/total_loss/avg: 0.0530, max mem: 5909.0, experiment: run, epoch: 80, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00003, ups: 1.64, time: 01m 01s 083ms, time_since_start: 01h 55m 42s 191ms, eta: 01h 56m 03s 552ms
[32m2021-03-04T02:31:50 | mmf.trainers.callbacks.logistics: [0mprogress: 10700/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0525, train/total_loss: 0.0004, train/total_loss/avg: 0.0525, max mem: 5909.0, experiment: run, epoch: 81, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 536ms, time_since_start: 01h 56m 42s 727ms, eta: 01h 54m 574ms
[32m2021-03-04T02:32:51 | mmf.trainers.callbacks.logistics: [0mprogress: 10800/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0520, train/total_loss: 0.0004, train/total_loss/avg: 0.0520, max mem: 5909.0, experiment: run, epoch: 82, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 979ms, time_since_start: 01h 57m 43s 707ms, eta: 01h 53m 49s 695ms
[32m2021-03-04T02:33:43 | mmf.trainers.callbacks.logistics: [0mprogress: 10900/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0515, train/total_loss: 0.0004, train/total_loss/avg: 0.0515, max mem: 5909.0, experiment: run, epoch: 82, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 776ms, time_since_start: 01h 58m 35s 483ms, eta: 01h 35m 47s 187ms
[32m2021-03-04T02:34:41 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T02:34:41 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T02:34:41 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T02:34:41 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T02:34:44 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T02:34:54 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T02:34:54 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0516, train/total_loss: 0.0004, train/total_loss/avg: 0.0516, max mem: 5909.0, experiment: run, epoch: 83, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00003, ups: 1.41, time: 01m 11s 490ms, time_since_start: 01h 59m 46s 974ms, eta: 02h 11m 03s 964ms
[32m2021-03-04T02:34:54 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T02:35:05 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T02:35:05 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, val/hateful_memes/cross_entropy: 2.0813, val/total_loss: 2.0813, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.5303, val/hateful_memes/roc_auc: 0.6893, num_updates: 11000, epoch: 83, iterations: 11000, max_updates: 22000, val_time: 10s 321ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T02:36:03 | mmf.trainers.callbacks.logistics: [0mprogress: 11100/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0512, train/total_loss: 0.0004, train/total_loss/avg: 0.0512, max mem: 5909.0, experiment: run, epoch: 84, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00003, ups: 1.72, time: 58s 452ms, time_since_start: 02h 55s 750ms, eta: 01h 46m 11s 305ms
[32m2021-03-04T02:37:04 | mmf.trainers.callbacks.logistics: [0mprogress: 11200/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0508, train/total_loss: 0.0004, train/total_loss/avg: 0.0508, max mem: 5909.0, experiment: run, epoch: 85, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 669ms, time_since_start: 02h 01m 56s 420ms, eta: 01h 49m 12s 317ms
[32m2021-03-04T02:37:55 | mmf.trainers.callbacks.logistics: [0mprogress: 11300/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0503, train/total_loss: 0.0004, train/total_loss/avg: 0.0503, max mem: 5909.0, experiment: run, epoch: 85, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 018ms, time_since_start: 02h 02m 47s 439ms, eta: 01h 30m 59s 030ms
[32m2021-03-04T02:38:56 | mmf.trainers.callbacks.logistics: [0mprogress: 11400/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0499, train/total_loss: 0.0004, train/total_loss/avg: 0.0499, max mem: 5909.0, experiment: run, epoch: 86, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 925ms, time_since_start: 02h 03m 48s 364ms, eta: 01h 47m 38s 081ms
[32m2021-03-04T02:39:56 | mmf.trainers.callbacks.logistics: [0mprogress: 11500/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0494, train/total_loss: 0.0004, train/total_loss/avg: 0.0494, max mem: 5909.0, experiment: run, epoch: 87, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 406ms, time_since_start: 02h 04m 48s 771ms, eta: 01h 45m 42s 714ms
[32m2021-03-04T02:40:57 | mmf.trainers.callbacks.logistics: [0mprogress: 11600/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0490, train/total_loss: 0.0004, train/total_loss/avg: 0.0490, max mem: 5909.0, experiment: run, epoch: 88, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 860ms, time_since_start: 02h 05m 49s 632ms, eta: 01h 45m 29s 523ms
[32m2021-03-04T02:41:48 | mmf.trainers.callbacks.logistics: [0mprogress: 11700/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0486, train/total_loss: 0.0004, train/total_loss/avg: 0.0486, max mem: 5909.0, experiment: run, epoch: 88, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00003, ups: 2.00, time: 50s 823ms, time_since_start: 02h 06m 40s 455ms, eta: 01h 27m 14s 835ms
[32m2021-03-04T02:42:48 | mmf.trainers.callbacks.logistics: [0mprogress: 11800/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0482, train/total_loss: 0.0004, train/total_loss/avg: 0.0482, max mem: 5909.0, experiment: run, epoch: 89, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 190ms, time_since_start: 02h 07m 40s 646ms, eta: 01h 42m 19s 442ms
[32m2021-03-04T02:43:49 | mmf.trainers.callbacks.logistics: [0mprogress: 11900/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0478, train/total_loss: 0.0003, train/total_loss/avg: 0.0478, max mem: 5909.0, experiment: run, epoch: 90, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00003, ups: 1.67, time: 01m 743ms, time_since_start: 02h 08m 41s 389ms, eta: 01h 42m 15s 085ms
[32m2021-03-04T02:44:50 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T02:44:50 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T02:44:50 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T02:44:50 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T02:44:52 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T02:45:03 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T02:45:03 | mmf.trainers.callbacks.logistics: [0mprogress: 12000/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0474, train/total_loss: 0.0003, train/total_loss/avg: 0.0474, max mem: 5909.0, experiment: run, epoch: 91, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00003, ups: 1.35, time: 01m 14s 681ms, time_since_start: 02h 09m 56s 071ms, eta: 02h 04m 28s 199ms
[32m2021-03-04T02:45:03 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T02:45:16 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T02:45:16 | mmf.trainers.callbacks.logistics: [0mprogress: 12000/22000, val/hateful_memes/cross_entropy: 2.5790, val/total_loss: 2.5790, val/hateful_memes/accuracy: 0.6685, val/hateful_memes/binary_f1: 0.5342, val/hateful_memes/roc_auc: 0.6668, num_updates: 12000, epoch: 91, iterations: 12000, max_updates: 22000, val_time: 12s 568ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T02:46:06 | mmf.trainers.callbacks.logistics: [0mprogress: 12100/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0472, train/total_loss: 0.0003, train/total_loss/avg: 0.0472, max mem: 5909.0, experiment: run, epoch: 91, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0.00002, ups: 2.00, time: 50s 214ms, time_since_start: 02h 10m 58s 857ms, eta: 01h 22m 51s 225ms
[32m2021-03-04T02:47:05 | mmf.trainers.callbacks.logistics: [0mprogress: 12200/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0468, train/total_loss: 0.0003, train/total_loss/avg: 0.0468, max mem: 5909.0, experiment: run, epoch: 92, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0.00002, ups: 1.72, time: 58s 953ms, time_since_start: 02h 11m 57s 810ms, eta: 01h 36m 17s 408ms
[32m2021-03-04T02:48:04 | mmf.trainers.callbacks.logistics: [0mprogress: 12300/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0464, train/total_loss: 0.0003, train/total_loss/avg: 0.0464, max mem: 5909.0, experiment: run, epoch: 93, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0.00002, ups: 1.69, time: 59s 046ms, time_since_start: 02h 12m 56s 856ms, eta: 01h 35m 27s 475ms
[32m2021-03-04T02:49:04 | mmf.trainers.callbacks.logistics: [0mprogress: 12400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0460, train/total_loss: 0.0002, train/total_loss/avg: 0.0460, max mem: 5909.0, experiment: run, epoch: 94, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 222ms, time_since_start: 02h 13m 57s 079ms, eta: 01h 36m 21s 393ms
[32m2021-03-04T02:49:55 | mmf.trainers.callbacks.logistics: [0mprogress: 12500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0457, train/total_loss: 0.0002, train/total_loss/avg: 0.0457, max mem: 5909.0, experiment: run, epoch: 94, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0.00002, ups: 2.00, time: 50s 823ms, time_since_start: 02h 14m 47s 903ms, eta: 01h 20m 28s 232ms
[32m2021-03-04T02:50:56 | mmf.trainers.callbacks.logistics: [0mprogress: 12600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0453, train/total_loss: 0.0001, train/total_loss/avg: 0.0453, max mem: 5909.0, experiment: run, epoch: 95, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 213ms, time_since_start: 02h 15m 48s 116ms, eta: 01h 34m 20s 078ms
[32m2021-03-04T02:51:56 | mmf.trainers.callbacks.logistics: [0mprogress: 12700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0450, train/total_loss: 0.0002, train/total_loss/avg: 0.0450, max mem: 5909.0, experiment: run, epoch: 96, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 632ms, time_since_start: 02h 16m 48s 749ms, eta: 01h 33m 58s 802ms
[32m2021-03-04T02:52:57 | mmf.trainers.callbacks.logistics: [0mprogress: 12800/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0449, train/total_loss: 0.0003, train/total_loss/avg: 0.0449, max mem: 5909.0, experiment: run, epoch: 97, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0.00002, ups: 1.64, time: 01m 01s 222ms, time_since_start: 02h 17m 49s 971ms, eta: 01h 33m 52s 430ms
[32m2021-03-04T02:53:48 | mmf.trainers.callbacks.logistics: [0mprogress: 12900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0446, train/total_loss: 0.0002, train/total_loss/avg: 0.0446, max mem: 5909.0, experiment: run, epoch: 97, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0.00002, ups: 2.00, time: 50s 755ms, time_since_start: 02h 18m 40s 727ms, eta: 01h 16m 58s 778ms
[32m2021-03-04T02:54:50 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T02:54:50 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T02:54:50 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T02:54:50 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T02:54:53 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T02:55:03 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T02:55:03 | mmf.trainers.callbacks.logistics: [0mprogress: 13000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0442, train/total_loss: 0.0001, train/total_loss/avg: 0.0442, max mem: 5909.0, experiment: run, epoch: 98, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0.00002, ups: 1.33, time: 01m 15s 370ms, time_since_start: 02h 19m 56s 097ms, eta: 01h 53m 03s 337ms
[32m2021-03-04T02:55:03 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T02:55:16 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T02:55:16 | mmf.trainers.callbacks.logistics: [0mprogress: 13000/22000, val/hateful_memes/cross_entropy: 2.5930, val/total_loss: 2.5930, val/hateful_memes/accuracy: 0.7167, val/hateful_memes/binary_f1: 0.5257, val/hateful_memes/roc_auc: 0.6976, num_updates: 13000, epoch: 98, iterations: 13000, max_updates: 22000, val_time: 12s 187ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T02:56:16 | mmf.trainers.callbacks.logistics: [0mprogress: 13100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0439, train/total_loss: 0.0001, train/total_loss/avg: 0.0439, max mem: 5909.0, experiment: run, epoch: 99, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 195ms, time_since_start: 02h 21m 08s 482ms, eta: 01h 29m 17s 445ms
[32m2021-03-04T02:57:17 | mmf.trainers.callbacks.logistics: [0mprogress: 13200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0436, train/total_loss: 0.0001, train/total_loss/avg: 0.0436, max mem: 5909.0, experiment: run, epoch: 100, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 703ms, time_since_start: 02h 22m 09s 185ms, eta: 01h 29m 01s 899ms
[32m2021-03-04T02:58:07 | mmf.trainers.callbacks.logistics: [0mprogress: 13300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0433, train/total_loss: 0.0001, train/total_loss/avg: 0.0433, max mem: 5909.0, experiment: run, epoch: 100, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0.00002, ups: 2.00, time: 50s 915ms, time_since_start: 02h 23m 100ms, eta: 01h 13m 49s 618ms
[32m2021-03-04T02:59:10 | mmf.trainers.callbacks.logistics: [0mprogress: 13400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0430, train/total_loss: 0.0001, train/total_loss/avg: 0.0430, max mem: 5909.0, experiment: run, epoch: 101, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0.00002, ups: 1.61, time: 01m 02s 128ms, time_since_start: 02h 24m 02s 229ms, eta: 01h 29m 03s 073ms
[32m2021-03-04T03:00:10 | mmf.trainers.callbacks.logistics: [0mprogress: 13500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0427, train/total_loss: 0.0000, train/total_loss/avg: 0.0427, max mem: 5909.0, experiment: run, epoch: 102, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 626ms, time_since_start: 02h 25m 02s 856ms, eta: 01h 25m 53s 234ms
[32m2021-03-04T03:01:11 | mmf.trainers.callbacks.logistics: [0mprogress: 13600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0424, train/total_loss: 0.0000, train/total_loss/avg: 0.0424, max mem: 5909.0, experiment: run, epoch: 103, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 898ms, time_since_start: 02h 26m 03s 754ms, eta: 01h 25m 15s 501ms
[32m2021-03-04T03:02:12 | mmf.trainers.callbacks.logistics: [0mprogress: 13700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0421, train/total_loss: 0.0000, train/total_loss/avg: 0.0421, max mem: 5909.0, experiment: run, epoch: 104, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0.00002, ups: 1.64, time: 01m 01s 125ms, time_since_start: 02h 27m 04s 880ms, eta: 01h 24m 33s 418ms
[32m2021-03-04T03:03:01 | mmf.trainers.callbacks.logistics: [0mprogress: 13800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0418, train/total_loss: 0.0000, train/total_loss/avg: 0.0418, max mem: 5909.0, experiment: run, epoch: 104, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0.00002, ups: 2.08, time: 48s 954ms, time_since_start: 02h 27m 53s 834ms, eta: 01h 06m 54s 262ms
[32m2021-03-04T03:04:01 | mmf.trainers.callbacks.logistics: [0mprogress: 13900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0415, train/total_loss: 0.0001, train/total_loss/avg: 0.0415, max mem: 5909.0, experiment: run, epoch: 105, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 264ms, time_since_start: 02h 28m 54s 099ms, eta: 01h 21m 21s 444ms
[32m2021-03-04T03:05:02 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T03:05:02 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T03:05:02 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T03:05:02 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T03:05:05 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T03:05:15 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T03:05:15 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0412, train/total_loss: 0.0001, train/total_loss/avg: 0.0412, max mem: 5909.0, experiment: run, epoch: 106, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0.00002, ups: 1.37, time: 01m 13s 690ms, time_since_start: 02h 30m 07s 790ms, eta: 01h 38m 15s 224ms
[32m2021-03-04T03:05:15 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T03:05:25 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T03:05:25 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, val/hateful_memes/cross_entropy: 2.2051, val/total_loss: 2.2051, val/hateful_memes/accuracy: 0.6944, val/hateful_memes/binary_f1: 0.5121, val/hateful_memes/roc_auc: 0.6961, num_updates: 14000, epoch: 106, iterations: 14000, max_updates: 22000, val_time: 10s 298ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T03:06:25 | mmf.trainers.callbacks.logistics: [0mprogress: 14100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0409, train/total_loss: 0.0001, train/total_loss/avg: 0.0409, max mem: 5909.0, experiment: run, epoch: 107, num_updates: 14100, iterations: 14100, max_updates: 22000, lr: 0.00002, ups: 1.69, time: 59s 915ms, time_since_start: 02h 31m 18s 005ms, eta: 01h 18m 53s 330ms
[32m2021-03-04T03:07:16 | mmf.trainers.callbacks.logistics: [0mprogress: 14200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0406, train/total_loss: 0.0001, train/total_loss/avg: 0.0406, max mem: 5909.0, experiment: run, epoch: 107, num_updates: 14200, iterations: 14200, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 046ms, time_since_start: 02h 32m 09s 052ms, eta: 01h 06m 21s 640ms
[32m2021-03-04T03:08:17 | mmf.trainers.callbacks.logistics: [0mprogress: 14300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0403, train/total_loss: 0.0001, train/total_loss/avg: 0.0403, max mem: 5909.0, experiment: run, epoch: 108, num_updates: 14300, iterations: 14300, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 232ms, time_since_start: 02h 33m 09s 285ms, eta: 01h 17m 17s 905ms
[32m2021-03-04T03:09:17 | mmf.trainers.callbacks.logistics: [0mprogress: 14400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0401, train/total_loss: 0.0001, train/total_loss/avg: 0.0401, max mem: 5909.0, experiment: run, epoch: 109, num_updates: 14400, iterations: 14400, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 202ms, time_since_start: 02h 34m 09s 487ms, eta: 01h 16m 15s 371ms
[32m2021-03-04T03:10:18 | mmf.trainers.callbacks.logistics: [0mprogress: 14500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0398, train/total_loss: 0.0000, train/total_loss/avg: 0.0398, max mem: 5909.0, experiment: run, epoch: 110, num_updates: 14500, iterations: 14500, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 873ms, time_since_start: 02h 35m 10s 361ms, eta: 01h 16m 05s 536ms
[32m2021-03-04T03:11:09 | mmf.trainers.callbacks.logistics: [0mprogress: 14600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0395, train/total_loss: 0.0000, train/total_loss/avg: 0.0395, max mem: 5909.0, experiment: run, epoch: 110, num_updates: 14600, iterations: 14600, max_updates: 22000, lr: 0.00002, ups: 2.00, time: 50s 966ms, time_since_start: 02h 36m 01s 328ms, eta: 01h 02m 51s 544ms
[32m2021-03-04T03:12:10 | mmf.trainers.callbacks.logistics: [0mprogress: 14700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0392, train/total_loss: 0.0000, train/total_loss/avg: 0.0392, max mem: 5909.0, experiment: run, epoch: 111, num_updates: 14700, iterations: 14700, max_updates: 22000, lr: 0.00002, ups: 1.64, time: 01m 01s 374ms, time_since_start: 02h 37m 02s 702ms, eta: 01h 14m 40s 304ms
[32m2021-03-04T03:13:11 | mmf.trainers.callbacks.logistics: [0mprogress: 14800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0390, train/total_loss: 0.0000, train/total_loss/avg: 0.0390, max mem: 5909.0, experiment: run, epoch: 112, num_updates: 14800, iterations: 14800, max_updates: 22000, lr: 0.00002, ups: 1.64, time: 01m 01s 267ms, time_since_start: 02h 38m 03s 969ms, eta: 01h 13m 31s 280ms
[32m2021-03-04T03:14:13 | mmf.trainers.callbacks.logistics: [0mprogress: 14900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0387, train/total_loss: 0.0000, train/total_loss/avg: 0.0387, max mem: 5909.0, experiment: run, epoch: 113, num_updates: 14900, iterations: 14900, max_updates: 22000, lr: 0.00002, ups: 1.64, time: 01m 01s 173ms, time_since_start: 02h 39m 05s 143ms, eta: 01h 12m 23s 317ms
[32m2021-03-04T03:15:02 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T03:15:02 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T03:15:02 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T03:15:02 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T03:15:05 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T03:15:16 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T03:15:16 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0385, train/total_loss: 0.0000, train/total_loss/avg: 0.0385, max mem: 5909.0, experiment: run, epoch: 113, num_updates: 15000, iterations: 15000, max_updates: 22000, lr: 0.00002, ups: 1.59, time: 01m 03s 181ms, time_since_start: 02h 40m 08s 325ms, eta: 01h 13m 42s 736ms
[32m2021-03-04T03:15:16 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T03:15:26 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T03:15:26 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, val/hateful_memes/cross_entropy: 2.5716, val/total_loss: 2.5716, val/hateful_memes/accuracy: 0.7037, val/hateful_memes/binary_f1: 0.4790, val/hateful_memes/roc_auc: 0.6848, num_updates: 15000, epoch: 113, iterations: 15000, max_updates: 22000, val_time: 10s 388ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T03:16:25 | mmf.trainers.callbacks.logistics: [0mprogress: 15100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0382, train/total_loss: 0.0001, train/total_loss/avg: 0.0382, max mem: 5909.0, experiment: run, epoch: 114, num_updates: 15100, iterations: 15100, max_updates: 22000, lr: 0.00002, ups: 1.69, time: 59s 305ms, time_since_start: 02h 41m 18s 021ms, eta: 01h 08m 12s 065ms
[32m2021-03-04T03:17:26 | mmf.trainers.callbacks.logistics: [0mprogress: 15200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0380, train/total_loss: 0.0001, train/total_loss/avg: 0.0380, max mem: 5909.0, experiment: run, epoch: 115, num_updates: 15200, iterations: 15200, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 742ms, time_since_start: 02h 42m 18s 763ms, eta: 01h 08m 50s 470ms
[32m2021-03-04T03:18:27 | mmf.trainers.callbacks.logistics: [0mprogress: 15300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0377, train/total_loss: 0.0001, train/total_loss/avg: 0.0377, max mem: 5909.0, experiment: run, epoch: 116, num_updates: 15300, iterations: 15300, max_updates: 22000, lr: 0.00002, ups: 1.64, time: 01m 01s 266ms, time_since_start: 02h 43m 20s 030ms, eta: 01h 08m 24s 889ms
[32m2021-03-04T03:19:20 | mmf.trainers.callbacks.logistics: [0mprogress: 15400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0375, train/total_loss: 0.0001, train/total_loss/avg: 0.0375, max mem: 5909.0, experiment: run, epoch: 116, num_updates: 15400, iterations: 15400, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 954ms, time_since_start: 02h 44m 12s 985ms, eta: 58m 15s 027ms
[32m2021-03-04T03:20:21 | mmf.trainers.callbacks.logistics: [0mprogress: 15500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0372, train/total_loss: 0.0001, train/total_loss/avg: 0.0372, max mem: 5909.0, experiment: run, epoch: 117, num_updates: 15500, iterations: 15500, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 310ms, time_since_start: 02h 45m 13s 296ms, eta: 01h 05m 20s 208ms
[32m2021-03-04T03:21:21 | mmf.trainers.callbacks.logistics: [0mprogress: 15600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0370, train/total_loss: 0.0001, train/total_loss/avg: 0.0370, max mem: 5909.0, experiment: run, epoch: 118, num_updates: 15600, iterations: 15600, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 144ms, time_since_start: 02h 46m 13s 440ms, eta: 01h 04m 09s 256ms
[32m2021-03-04T03:22:22 | mmf.trainers.callbacks.logistics: [0mprogress: 15700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0368, train/total_loss: 0.0001, train/total_loss/avg: 0.0368, max mem: 5909.0, experiment: run, epoch: 119, num_updates: 15700, iterations: 15700, max_updates: 22000, lr: 0.00002, ups: 1.64, time: 01m 01s 290ms, time_since_start: 02h 47m 14s 731ms, eta: 01h 04m 21s 299ms
[32m2021-03-04T03:23:13 | mmf.trainers.callbacks.logistics: [0mprogress: 15800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0365, train/total_loss: 0.0001, train/total_loss/avg: 0.0365, max mem: 5909.0, experiment: run, epoch: 119, num_updates: 15800, iterations: 15800, max_updates: 22000, lr: 0.00002, ups: 2.00, time: 50s 603ms, time_since_start: 02h 48m 05s 335ms, eta: 52m 17s 443ms
[32m2021-03-04T03:24:13 | mmf.trainers.callbacks.logistics: [0mprogress: 15900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0363, train/total_loss: 0.0001, train/total_loss/avg: 0.0363, max mem: 5909.0, experiment: run, epoch: 120, num_updates: 15900, iterations: 15900, max_updates: 22000, lr: 0.00002, ups: 1.67, time: 01m 689ms, time_since_start: 02h 49m 06s 025ms, eta: 01h 01m 42s 066ms
[32m2021-03-04T03:25:14 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T03:25:14 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T03:25:14 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T03:25:14 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T03:25:17 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T03:25:27 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T03:25:27 | mmf.trainers.callbacks.logistics: [0mprogress: 16000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0361, train/total_loss: 0.0001, train/total_loss/avg: 0.0361, max mem: 5909.0, experiment: run, epoch: 121, num_updates: 16000, iterations: 16000, max_updates: 22000, lr: 0.00002, ups: 1.37, time: 01m 13s 850ms, time_since_start: 02h 50m 19s 875ms, eta: 01h 13m 51s 024ms
[32m2021-03-04T03:25:27 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T03:25:38 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T03:25:38 | mmf.trainers.callbacks.logistics: [0mprogress: 16000/22000, val/hateful_memes/cross_entropy: 2.4290, val/total_loss: 2.4290, val/hateful_memes/accuracy: 0.6944, val/hateful_memes/binary_f1: 0.5063, val/hateful_memes/roc_auc: 0.6951, num_updates: 16000, epoch: 121, iterations: 16000, max_updates: 22000, val_time: 10s 441ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T03:26:37 | mmf.trainers.callbacks.logistics: [0mprogress: 16100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0358, train/total_loss: 0.0001, train/total_loss/avg: 0.0358, max mem: 5909.0, experiment: run, epoch: 122, num_updates: 16100, iterations: 16100, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 270ms, time_since_start: 02h 51m 29s 589ms, eta: 58m 16s 988ms
[32m2021-03-04T03:27:26 | mmf.trainers.callbacks.logistics: [0mprogress: 16200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0356, train/total_loss: 0.0001, train/total_loss/avg: 0.0356, max mem: 5909.0, experiment: run, epoch: 122, num_updates: 16200, iterations: 16200, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 256ms, time_since_start: 02h 52m 18s 846ms, eta: 47m 36s 868ms
[32m2021-03-04T03:28:27 | mmf.trainers.callbacks.logistics: [0mprogress: 16300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0354, train/total_loss: 0.0001, train/total_loss/avg: 0.0354, max mem: 5909.0, experiment: run, epoch: 123, num_updates: 16300, iterations: 16300, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 472ms, time_since_start: 02h 53m 19s 318ms, eta: 57m 26s 937ms
[32m2021-03-04T03:29:28 | mmf.trainers.callbacks.logistics: [0mprogress: 16400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0352, train/total_loss: 0.0001, train/total_loss/avg: 0.0352, max mem: 5909.0, experiment: run, epoch: 124, num_updates: 16400, iterations: 16400, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 570ms, time_since_start: 02h 54m 20s 889ms, eta: 57m 27s 941ms
[32m2021-03-04T03:30:30 | mmf.trainers.callbacks.logistics: [0mprogress: 16500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0350, train/total_loss: 0.0001, train/total_loss/avg: 0.0350, max mem: 5909.0, experiment: run, epoch: 125, num_updates: 16500, iterations: 16500, max_updates: 22000, lr: 0.00001, ups: 1.61, time: 01m 02s 126ms, time_since_start: 02h 55m 23s 015ms, eta: 56m 56s 961ms
[32m2021-03-04T03:31:20 | mmf.trainers.callbacks.logistics: [0mprogress: 16600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0348, train/total_loss: 0.0001, train/total_loss/avg: 0.0348, max mem: 5909.0, experiment: run, epoch: 125, num_updates: 16600, iterations: 16600, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 955ms, time_since_start: 02h 56m 12s 971ms, eta: 44m 57s 587ms
[32m2021-03-04T03:32:21 | mmf.trainers.callbacks.logistics: [0mprogress: 16700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0346, train/total_loss: 0.0001, train/total_loss/avg: 0.0346, max mem: 5909.0, experiment: run, epoch: 126, num_updates: 16700, iterations: 16700, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 607ms, time_since_start: 02h 57m 13s 578ms, eta: 53m 32s 204ms
[32m2021-03-04T03:33:22 | mmf.trainers.callbacks.logistics: [0mprogress: 16800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0344, train/total_loss: 0.0001, train/total_loss/avg: 0.0344, max mem: 5909.0, experiment: run, epoch: 127, num_updates: 16800, iterations: 16800, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 726ms, time_since_start: 02h 58m 14s 305ms, eta: 52m 37s 795ms
[32m2021-03-04T03:34:22 | mmf.trainers.callbacks.logistics: [0mprogress: 16900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0342, train/total_loss: 0.0001, train/total_loss/avg: 0.0342, max mem: 5909.0, experiment: run, epoch: 128, num_updates: 16900, iterations: 16900, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 771ms, time_since_start: 02h 59m 15s 076ms, eta: 51m 39s 324ms
[32m2021-03-04T03:35:14 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T03:35:14 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T03:35:14 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T03:35:14 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T03:35:17 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T03:35:28 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T03:35:28 | mmf.trainers.callbacks.logistics: [0mprogress: 17000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0340, train/total_loss: 0.0001, train/total_loss/avg: 0.0340, max mem: 5909.0, experiment: run, epoch: 128, num_updates: 17000, iterations: 17000, max_updates: 22000, lr: 0.00001, ups: 1.54, time: 01m 05s 132ms, time_since_start: 03h 20s 209ms, eta: 54m 16s 635ms
[32m2021-03-04T03:35:28 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T03:35:38 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T03:35:38 | mmf.trainers.callbacks.logistics: [0mprogress: 17000/22000, val/hateful_memes/cross_entropy: 2.6267, val/total_loss: 2.6267, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4864, val/hateful_memes/roc_auc: 0.6921, num_updates: 17000, epoch: 128, iterations: 17000, max_updates: 22000, val_time: 10s 442ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T03:36:38 | mmf.trainers.callbacks.logistics: [0mprogress: 17100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0338, train/total_loss: 0.0001, train/total_loss/avg: 0.0338, max mem: 5909.0, experiment: run, epoch: 129, num_updates: 17100, iterations: 17100, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 382ms, time_since_start: 03h 01m 31s 036ms, eta: 49m 18s 744ms
[32m2021-03-04T03:37:40 | mmf.trainers.callbacks.logistics: [0mprogress: 17200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0336, train/total_loss: 0.0001, train/total_loss/avg: 0.0336, max mem: 5909.0, experiment: run, epoch: 130, num_updates: 17200, iterations: 17200, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 129ms, time_since_start: 03h 02m 32s 165ms, eta: 48m 54s 204ms
[32m2021-03-04T03:38:41 | mmf.trainers.callbacks.logistics: [0mprogress: 17300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0334, train/total_loss: 0.0001, train/total_loss/avg: 0.0334, max mem: 5909.0, experiment: run, epoch: 131, num_updates: 17300, iterations: 17300, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 300ms, time_since_start: 03h 03m 33s 466ms, eta: 48m 01s 121ms
[32m2021-03-04T03:39:31 | mmf.trainers.callbacks.logistics: [0mprogress: 17400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0332, train/total_loss: 0.0000, train/total_loss/avg: 0.0332, max mem: 5909.0, experiment: run, epoch: 131, num_updates: 17400, iterations: 17400, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 622ms, time_since_start: 03h 04m 24s 089ms, eta: 38m 48s 653ms
[32m2021-03-04T03:40:33 | mmf.trainers.callbacks.logistics: [0mprogress: 17500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0330, train/total_loss: 0.0000, train/total_loss/avg: 0.0330, max mem: 5909.0, experiment: run, epoch: 132, num_updates: 17500, iterations: 17500, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 708ms, time_since_start: 03h 05m 25s 798ms, eta: 46m 16s 887ms
[32m2021-03-04T03:41:35 | mmf.trainers.callbacks.logistics: [0mprogress: 17600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0328, train/total_loss: 0.0000, train/total_loss/avg: 0.0328, max mem: 5909.0, experiment: run, epoch: 133, num_updates: 17600, iterations: 17600, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 485ms, time_since_start: 03h 06m 27s 283ms, eta: 45m 05s 358ms
[32m2021-03-04T03:42:36 | mmf.trainers.callbacks.logistics: [0mprogress: 17700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0326, train/total_loss: 0.0000, train/total_loss/avg: 0.0326, max mem: 5909.0, experiment: run, epoch: 134, num_updates: 17700, iterations: 17700, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 581ms, time_since_start: 03h 07m 28s 865ms, eta: 44m 08s 024ms
[32m2021-03-04T03:43:28 | mmf.trainers.callbacks.logistics: [0mprogress: 17800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0324, train/total_loss: 0.0000, train/total_loss/avg: 0.0324, max mem: 5909.0, experiment: run, epoch: 134, num_updates: 17800, iterations: 17800, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 328ms, time_since_start: 03h 08m 20s 193ms, eta: 35m 55s 780ms
[32m2021-03-04T03:44:29 | mmf.trainers.callbacks.logistics: [0mprogress: 17900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0322, train/total_loss: 0.0000, train/total_loss/avg: 0.0322, max mem: 5909.0, experiment: run, epoch: 135, num_updates: 17900, iterations: 17900, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 648ms, time_since_start: 03h 09m 21s 842ms, eta: 42m 07s 591ms
[32m2021-03-04T03:45:30 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T03:45:30 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T03:45:30 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T03:45:30 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T03:45:32 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T03:45:43 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T03:45:43 | mmf.trainers.callbacks.logistics: [0mprogress: 18000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0321, train/total_loss: 0.0000, train/total_loss/avg: 0.0321, max mem: 5909.0, experiment: run, epoch: 136, num_updates: 18000, iterations: 18000, max_updates: 22000, lr: 0.00001, ups: 1.37, time: 01m 13s 399ms, time_since_start: 03h 10m 35s 241ms, eta: 48m 55s 966ms
[32m2021-03-04T03:45:43 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T03:45:53 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T03:45:53 | mmf.trainers.callbacks.logistics: [0mprogress: 18000/22000, val/hateful_memes/cross_entropy: 2.9723, val/total_loss: 2.9723, val/hateful_memes/accuracy: 0.6944, val/hateful_memes/binary_f1: 0.4790, val/hateful_memes/roc_auc: 0.6895, num_updates: 18000, epoch: 136, iterations: 18000, max_updates: 22000, val_time: 10s 248ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T03:46:52 | mmf.trainers.callbacks.logistics: [0mprogress: 18100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0319, train/total_loss: 0.0000, train/total_loss/avg: 0.0319, max mem: 5909.0, experiment: run, epoch: 137, num_updates: 18100, iterations: 18100, max_updates: 22000, lr: 0.00001, ups: 1.72, time: 58s 747ms, time_since_start: 03h 11m 44s 239ms, eta: 38m 11s 140ms
[32m2021-03-04T03:47:42 | mmf.trainers.callbacks.logistics: [0mprogress: 18200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0317, train/total_loss: 0.0000, train/total_loss/avg: 0.0317, max mem: 5909.0, experiment: run, epoch: 137, num_updates: 18200, iterations: 18200, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 980ms, time_since_start: 03h 12m 34s 219ms, eta: 31m 39s 255ms
[32m2021-03-04T03:48:41 | mmf.trainers.callbacks.logistics: [0mprogress: 18300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0315, train/total_loss: 0.0000, train/total_loss/avg: 0.0315, max mem: 5909.0, experiment: run, epoch: 138, num_updates: 18300, iterations: 18300, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 122ms, time_since_start: 03h 13m 33s 342ms, eta: 36m 27s 542ms
[32m2021-03-04T03:49:40 | mmf.trainers.callbacks.logistics: [0mprogress: 18400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0314, train/total_loss: 0.0000, train/total_loss/avg: 0.0314, max mem: 5909.0, experiment: run, epoch: 139, num_updates: 18400, iterations: 18400, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 546ms, time_since_start: 03h 14m 32s 889ms, eta: 35m 43s 684ms
[32m2021-03-04T03:50:41 | mmf.trainers.callbacks.logistics: [0mprogress: 18500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0312, train/total_loss: 0.0000, train/total_loss/avg: 0.0312, max mem: 5909.0, experiment: run, epoch: 140, num_updates: 18500, iterations: 18500, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 565ms, time_since_start: 03h 15m 33s 454ms, eta: 35m 19s 779ms
[32m2021-03-04T03:51:30 | mmf.trainers.callbacks.logistics: [0mprogress: 18600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0310, train/total_loss: 0.0000, train/total_loss/avg: 0.0310, max mem: 5909.0, experiment: run, epoch: 140, num_updates: 18600, iterations: 18600, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 929ms, time_since_start: 03h 16m 22s 384ms, eta: 27m 43s 612ms
[32m2021-03-04T03:52:29 | mmf.trainers.callbacks.logistics: [0mprogress: 18700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0309, train/total_loss: 0.0000, train/total_loss/avg: 0.0309, max mem: 5909.0, experiment: run, epoch: 141, num_updates: 18700, iterations: 18700, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 478ms, time_since_start: 03h 17m 21s 862ms, eta: 32m 42s 787ms
[32m2021-03-04T03:53:31 | mmf.trainers.callbacks.logistics: [0mprogress: 18800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0307, train/total_loss: 0.0000, train/total_loss/avg: 0.0307, max mem: 5909.0, experiment: run, epoch: 142, num_updates: 18800, iterations: 18800, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 321ms, time_since_start: 03h 18m 23s 183ms, eta: 32m 42s 274ms
[32m2021-03-04T03:54:33 | mmf.trainers.callbacks.logistics: [0mprogress: 18900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0305, train/total_loss: 0.0000, train/total_loss/avg: 0.0305, max mem: 5909.0, experiment: run, epoch: 143, num_updates: 18900, iterations: 18900, max_updates: 22000, lr: 0.00001, ups: 1.61, time: 01m 02s 584ms, time_since_start: 03h 19m 25s 767ms, eta: 32m 20s 110ms
[32m2021-03-04T03:55:24 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T03:55:24 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T03:55:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T03:55:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T03:55:27 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T03:55:37 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T03:55:37 | mmf.trainers.callbacks.logistics: [0mprogress: 19000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0304, train/total_loss: 0.0000, train/total_loss/avg: 0.0304, max mem: 5909.0, experiment: run, epoch: 143, num_updates: 19000, iterations: 19000, max_updates: 22000, lr: 0.00001, ups: 1.56, time: 01m 04s 261ms, time_since_start: 03h 20m 30s 029ms, eta: 32m 07s 848ms
[32m2021-03-04T03:55:37 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T03:55:48 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T03:55:48 | mmf.trainers.callbacks.logistics: [0mprogress: 19000/22000, val/hateful_memes/cross_entropy: 3.0760, val/total_loss: 3.0760, val/hateful_memes/accuracy: 0.7019, val/hateful_memes/binary_f1: 0.5112, val/hateful_memes/roc_auc: 0.6892, num_updates: 19000, epoch: 143, iterations: 19000, max_updates: 22000, val_time: 10s 423ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T03:56:47 | mmf.trainers.callbacks.logistics: [0mprogress: 19100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0302, train/total_loss: 0.0000, train/total_loss/avg: 0.0302, max mem: 5909.0, experiment: run, epoch: 144, num_updates: 19100, iterations: 19100, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 470ms, time_since_start: 03h 21m 39s 925ms, eta: 28m 44s 650ms
[32m2021-03-04T03:57:48 | mmf.trainers.callbacks.logistics: [0mprogress: 19200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0301, train/total_loss: 0.0000, train/total_loss/avg: 0.0301, max mem: 5909.0, experiment: run, epoch: 145, num_updates: 19200, iterations: 19200, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 358ms, time_since_start: 03h 22m 40s 283ms, eta: 28m 10s 030ms
[32m2021-03-04T03:58:49 | mmf.trainers.callbacks.logistics: [0mprogress: 19300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0299, train/total_loss: 0.0000, train/total_loss/avg: 0.0299, max mem: 5909.0, experiment: run, epoch: 146, num_updates: 19300, iterations: 19300, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 119ms, time_since_start: 03h 23m 41s 402ms, eta: 27m 30s 216ms
[32m2021-03-04T03:59:39 | mmf.trainers.callbacks.logistics: [0mprogress: 19400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0297, train/total_loss: 0.0000, train/total_loss/avg: 0.0297, max mem: 5909.0, experiment: run, epoch: 146, num_updates: 19400, iterations: 19400, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 165ms, time_since_start: 03h 24m 31s 568ms, eta: 21m 44s 316ms
[32m2021-03-04T04:00:40 | mmf.trainers.callbacks.logistics: [0mprogress: 19500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0296, train/total_loss: 0.0000, train/total_loss/avg: 0.0296, max mem: 5909.0, experiment: run, epoch: 147, num_updates: 19500, iterations: 19500, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 603ms, time_since_start: 03h 25m 32s 172ms, eta: 25m 15s 083ms
[32m2021-03-04T04:01:40 | mmf.trainers.callbacks.logistics: [0mprogress: 19600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0294, train/total_loss: 0.0000, train/total_loss/avg: 0.0294, max mem: 5909.0, experiment: run, epoch: 148, num_updates: 19600, iterations: 19600, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 468ms, time_since_start: 03h 26m 32s 641ms, eta: 24m 11s 252ms
[32m2021-03-04T04:02:40 | mmf.trainers.callbacks.logistics: [0mprogress: 19700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0293, train/total_loss: 0.0000, train/total_loss/avg: 0.0293, max mem: 5909.0, experiment: run, epoch: 149, num_updates: 19700, iterations: 19700, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 176ms, time_since_start: 03h 27m 32s 817ms, eta: 23m 04s 049ms
[32m2021-03-04T04:03:30 | mmf.trainers.callbacks.logistics: [0mprogress: 19800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0291, train/total_loss: 0.0000, train/total_loss/avg: 0.0291, max mem: 5909.0, experiment: run, epoch: 149, num_updates: 19800, iterations: 19800, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 432ms, time_since_start: 03h 28m 22s 249ms, eta: 18m 07s 513ms
[32m2021-03-04T04:04:29 | mmf.trainers.callbacks.logistics: [0mprogress: 19900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0290, train/total_loss: 0.0000, train/total_loss/avg: 0.0290, max mem: 5909.0, experiment: run, epoch: 150, num_updates: 19900, iterations: 19900, max_updates: 22000, lr: 0.00001, ups: 1.72, time: 58s 976ms, time_since_start: 03h 29m 21s 226ms, eta: 20m 38s 502ms
[32m2021-03-04T04:05:29 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T04:05:29 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T04:05:29 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T04:05:29 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T04:05:32 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T04:05:43 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T04:05:43 | mmf.trainers.callbacks.logistics: [0mprogress: 20000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0289, train/total_loss: 0.0000, train/total_loss/avg: 0.0289, max mem: 5909.0, experiment: run, epoch: 151, num_updates: 20000, iterations: 20000, max_updates: 22000, lr: 0.00001, ups: 1.37, time: 01m 13s 913ms, time_since_start: 03h 30m 35s 139ms, eta: 24m 38s 271ms
[32m2021-03-04T04:05:43 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T04:05:53 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T04:05:53 | mmf.trainers.callbacks.logistics: [0mprogress: 20000/22000, val/hateful_memes/cross_entropy: 3.1735, val/total_loss: 3.1735, val/hateful_memes/accuracy: 0.7019, val/hateful_memes/binary_f1: 0.5092, val/hateful_memes/roc_auc: 0.6906, num_updates: 20000, epoch: 151, iterations: 20000, max_updates: 22000, val_time: 10s 474ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T04:06:54 | mmf.trainers.callbacks.logistics: [0mprogress: 20100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0287, train/total_loss: 0.0000, train/total_loss/avg: 0.0287, max mem: 5909.0, experiment: run, epoch: 152, num_updates: 20100, iterations: 20100, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 957ms, time_since_start: 03h 31m 46s 573ms, eta: 19m 18s 194ms
[32m2021-03-04T04:07:43 | mmf.trainers.callbacks.logistics: [0mprogress: 20200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0286, train/total_loss: 0.0000, train/total_loss/avg: 0.0286, max mem: 5909.0, experiment: run, epoch: 152, num_updates: 20200, iterations: 20200, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 945ms, time_since_start: 03h 32m 35s 518ms, eta: 14m 41s 017ms
[32m2021-03-04T04:08:43 | mmf.trainers.callbacks.logistics: [0mprogress: 20300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0284, train/total_loss: 0.0000, train/total_loss/avg: 0.0284, max mem: 5909.0, experiment: run, epoch: 153, num_updates: 20300, iterations: 20300, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 302ms, time_since_start: 03h 33m 35s 820ms, eta: 17m 05s 137ms
[32m2021-03-04T04:09:44 | mmf.trainers.callbacks.logistics: [0mprogress: 20400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0283, train/total_loss: 0.0000, train/total_loss/avg: 0.0283, max mem: 5909.0, experiment: run, epoch: 154, num_updates: 20400, iterations: 20400, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 440ms, time_since_start: 03h 34m 36s 261ms, eta: 16m 07s 045ms
[32m2021-03-04T04:10:44 | mmf.trainers.callbacks.logistics: [0mprogress: 20500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0282, train/total_loss: 0.0000, train/total_loss/avg: 0.0282, max mem: 5909.0, experiment: run, epoch: 155, num_updates: 20500, iterations: 20500, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 422ms, time_since_start: 03h 35m 36s 683ms, eta: 15m 06s 333ms
[32m2021-03-04T04:11:34 | mmf.trainers.callbacks.logistics: [0mprogress: 20600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0280, train/total_loss: 0.0000, train/total_loss/avg: 0.0280, max mem: 5909.0, experiment: run, epoch: 155, num_updates: 20600, iterations: 20600, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 904ms, time_since_start: 03h 36m 26s 588ms, eta: 11m 38s 669ms
[32m2021-03-04T04:12:33 | mmf.trainers.callbacks.logistics: [0mprogress: 20700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0279, train/total_loss: 0.0000, train/total_loss/avg: 0.0279, max mem: 5909.0, experiment: run, epoch: 156, num_updates: 20700, iterations: 20700, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 146ms, time_since_start: 03h 37m 25s 734ms, eta: 12m 48s 898ms
[32m2021-03-04T04:13:34 | mmf.trainers.callbacks.logistics: [0mprogress: 20800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0277, train/total_loss: 0.0000, train/total_loss/avg: 0.0277, max mem: 5909.0, experiment: run, epoch: 157, num_updates: 20800, iterations: 20800, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 397ms, time_since_start: 03h 38m 26s 131ms, eta: 12m 04s 764ms
[32m2021-03-04T04:14:35 | mmf.trainers.callbacks.logistics: [0mprogress: 20900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0276, train/total_loss: 0.0000, train/total_loss/avg: 0.0276, max mem: 5909.0, experiment: run, epoch: 158, num_updates: 20900, iterations: 20900, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 201ms, time_since_start: 03h 39m 27s 333ms, eta: 11m 13s 218ms
[32m2021-03-04T04:15:25 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T04:15:25 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T04:15:25 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T04:15:25 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T04:15:27 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T04:15:38 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T04:15:38 | mmf.trainers.callbacks.logistics: [0mprogress: 21000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0275, train/total_loss: 0.0000, train/total_loss/avg: 0.0275, max mem: 5909.0, experiment: run, epoch: 158, num_updates: 21000, iterations: 21000, max_updates: 22000, lr: 0., ups: 1.59, time: 01m 03s 286ms, time_since_start: 03h 40m 30s 619ms, eta: 10m 32s 864ms
[32m2021-03-04T04:15:38 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T04:15:48 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T04:15:48 | mmf.trainers.callbacks.logistics: [0mprogress: 21000/22000, val/hateful_memes/cross_entropy: 3.2458, val/total_loss: 3.2458, val/hateful_memes/accuracy: 0.7000, val/hateful_memes/binary_f1: 0.5077, val/hateful_memes/roc_auc: 0.6891, num_updates: 21000, epoch: 158, iterations: 21000, max_updates: 22000, val_time: 10s 433ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T04:16:49 | mmf.trainers.callbacks.logistics: [0mprogress: 21100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0273, train/total_loss: 0.0000, train/total_loss/avg: 0.0273, max mem: 5909.0, experiment: run, epoch: 159, num_updates: 21100, iterations: 21100, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 487ms, time_since_start: 03h 41m 41s 542ms, eta: 09m 04s 389ms
[32m2021-03-04T04:17:49 | mmf.trainers.callbacks.logistics: [0mprogress: 21200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0272, train/total_loss: 0.0000, train/total_loss/avg: 0.0272, max mem: 5909.0, experiment: run, epoch: 160, num_updates: 21200, iterations: 21200, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 706ms, time_since_start: 03h 42m 41s 249ms, eta: 07m 57s 648ms
[32m2021-03-04T04:18:49 | mmf.trainers.callbacks.logistics: [0mprogress: 21300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0271, train/total_loss: 0.0000, train/total_loss/avg: 0.0271, max mem: 5909.0, experiment: run, epoch: 161, num_updates: 21300, iterations: 21300, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 256ms, time_since_start: 03h 43m 41s 505ms, eta: 07m 01s 793ms
[32m2021-03-04T04:19:40 | mmf.trainers.callbacks.logistics: [0mprogress: 21400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0270, train/total_loss: 0.0000, train/total_loss/avg: 0.0270, max mem: 5909.0, experiment: run, epoch: 161, num_updates: 21400, iterations: 21400, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 682ms, time_since_start: 03h 44m 32s 187ms, eta: 05m 04s 095ms
[32m2021-03-04T04:20:40 | mmf.trainers.callbacks.logistics: [0mprogress: 21500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0268, train/total_loss: 0.0000, train/total_loss/avg: 0.0268, max mem: 5909.0, experiment: run, epoch: 162, num_updates: 21500, iterations: 21500, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 402ms, time_since_start: 03h 45m 32s 590ms, eta: 05m 02s 014ms
[32m2021-03-04T04:21:40 | mmf.trainers.callbacks.logistics: [0mprogress: 21600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0267, train/total_loss: 0.0000, train/total_loss/avg: 0.0267, max mem: 5909.0, experiment: run, epoch: 163, num_updates: 21600, iterations: 21600, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 604ms, time_since_start: 03h 46m 32s 195ms, eta: 03m 58s 417ms
[32m2021-03-04T04:22:39 | mmf.trainers.callbacks.logistics: [0mprogress: 21700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0266, train/total_loss: 0.0000, train/total_loss/avg: 0.0266, max mem: 5909.0, experiment: run, epoch: 164, num_updates: 21700, iterations: 21700, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 606ms, time_since_start: 03h 47m 31s 802ms, eta: 02m 58s 820ms
[32m2021-03-04T04:23:30 | mmf.trainers.callbacks.logistics: [0mprogress: 21800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0265, train/total_loss: 0.0000, train/total_loss/avg: 0.0265, max mem: 5909.0, experiment: run, epoch: 164, num_updates: 21800, iterations: 21800, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 860ms, time_since_start: 03h 48m 22s 662ms, eta: 01m 41s 721ms
[32m2021-03-04T04:24:30 | mmf.trainers.callbacks.logistics: [0mprogress: 21900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0263, train/total_loss: 0.0000, train/total_loss/avg: 0.0263, max mem: 5909.0, experiment: run, epoch: 165, num_updates: 21900, iterations: 21900, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 156ms, time_since_start: 03h 49m 22s 819ms, eta: 01m 156ms
[32m2021-03-04T04:25:30 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T04:25:30 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T04:25:30 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T04:25:30 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T04:25:32 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T04:25:43 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T04:25:43 | mmf.trainers.callbacks.logistics: [0mprogress: 22000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0262, train/total_loss: 0.0000, train/total_loss/avg: 0.0262, max mem: 5909.0, experiment: run, epoch: 166, num_updates: 22000, iterations: 22000, max_updates: 22000, lr: 0., ups: 1.39, time: 01m 12s 826ms, time_since_start: 03h 50m 35s 645ms, eta: 0ms
[32m2021-03-04T04:25:43 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T04:25:53 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T04:25:53 | mmf.trainers.callbacks.logistics: [0mprogress: 22000/22000, val/hateful_memes/cross_entropy: 3.2863, val/total_loss: 3.2863, val/hateful_memes/accuracy: 0.7111, val/hateful_memes/binary_f1: 0.4961, val/hateful_memes/roc_auc: 0.6872, num_updates: 22000, epoch: 166, iterations: 22000, max_updates: 22000, val_time: 10s 350ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.708355
[32m2021-03-04T04:25:54 | mmf.trainers.core.training_loop: [0mStepping into final validation check
[32m2021-03-04T04:25:54 | mmf.utils.checkpoint: [0mRestoring checkpoint
[32m2021-03-04T04:25:54 | mmf.utils.checkpoint: [0mLoading checkpoint
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.position_ids from model.bert.embeddings.position_ids
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.token_type_embeddings_visual.weight from model.bert.embeddings.token_type_embeddings_visual.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.position_embeddings_visual.weight from model.bert.embeddings.position_embeddings_visual.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.projection.weight from model.bert.embeddings.projection.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.projection.bias from model.bert.embeddings.projection.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.pooler.dense.weight from model.bert.pooler.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.bert.pooler.dense.bias from model.bert.pooler.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.dense.weight from model.classifier.0.dense.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.dense.bias from model.classifier.0.dense.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.LayerNorm.weight from model.classifier.0.LayerNorm.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.LayerNorm.bias from model.classifier.0.LayerNorm.bias
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.1.weight from model.classifier.1.weight
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.1.bias from model.classifier.1.bias
[5m[31mWARNING[0m [32m2021-03-04T04:26:03 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T04:26:03 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mCheckpoint loaded.
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mCurrent num updates: 2000
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mCurrent iteration: 2000
[32m2021-03-04T04:26:03 | mmf.utils.checkpoint: [0mCurrent epoch: 16
[32m2021-03-04T04:26:03 | mmf.trainers.mmf_trainer: [0mStarting inference on val set
  0%|          | 0/34 [00:00<?, ?it/s]  3%|â–Ž         | 1/34 [00:09<05:22,  9.76s/it]  6%|â–Œ         | 2/34 [00:09<02:11,  4.09s/it]  9%|â–‰         | 3/34 [00:10<01:10,  2.28s/it] 12%|â–ˆâ–        | 4/34 [00:10<00:42,  1.43s/it] 15%|â–ˆâ–        | 5/34 [00:10<00:27,  1.05it/s] 18%|â–ˆâ–Š        | 6/34 [00:10<00:18,  1.49it/s] 21%|â–ˆâ–ˆ        | 7/34 [00:10<00:13,  2.04it/s] 24%|â–ˆâ–ˆâ–Ž       | 8/34 [00:10<00:09,  2.68it/s] 26%|â–ˆâ–ˆâ–‹       | 9/34 [00:10<00:07,  3.40it/s] 26%|â–ˆâ–ˆâ–‹       | 9/34 [00:11<00:30,  1.23s/it][32m2021-03-04T04:26:15 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T04:26:15 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, val/hateful_memes/cross_entropy: 1.5278, val/total_loss: 1.5278, val/hateful_memes/accuracy: 0.7000, val/hateful_memes/binary_f1: 0.4160, val/hateful_memes/roc_auc: 0.7084
[32m2021-03-04T04:26:15 | mmf.trainers.callbacks.logistics: [0mFinished run in 03h 51m 07s 195ms

Training VISUAL_BERT_COCO complete
********************************************************************
Training VILBERT_CC
[32m2021-03-04T04:26:20 | mmf.utils.configuration: [0mOverriding option config to projects/hateful_memes/configs/vilbert/from_cc.yaml
[32m2021-03-04T04:26:20 | mmf.utils.configuration: [0mOverriding option model to vilbert
[32m2021-03-04T04:26:20 | mmf.utils.configuration: [0mOverriding option datasets to hateful_memes
[32m2021-03-04T04:26:20 | mmf.utils.configuration: [0mOverriding option run_type to train_val
[32m2021-03-04T04:26:20 | mmf.utils.configuration: [0mOverriding option checkpoint.max_to_keep to 3
[32m2021-03-04T04:26:22 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T04:26:22 | mmf.utils.distributed: [0mDistributed Init (Rank 1): tcp://localhost:16607
[32m2021-03-04T04:26:22 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T04:26:22 | mmf.utils.distributed: [0mDistributed Init (Rank 3): tcp://localhost:16607
[32m2021-03-04T04:26:22 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T04:26:22 | mmf.utils.distributed: [0mDistributed Init (Rank 0): tcp://localhost:16607
[32m2021-03-04T04:26:22 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T04:26:22 | mmf.utils.distributed: [0mDistributed Init (Rank 2): tcp://localhost:16607
[32m2021-03-04T04:26:22 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 2
[32m2021-03-04T04:26:23 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 1
[32m2021-03-04T04:26:23 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 3
[32m2021-03-04T04:26:23 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 0
[32m2021-03-04T04:26:26 | mmf: [0mLogging to: /scratch/sagarsj42/save/train.log
[32m2021-03-04T04:26:26 | mmf_cli.run: [0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/vilbert/from_cc.yaml', 'model=vilbert', 'dataset=hateful_memes', 'run_type=train_val', 'checkpoint.max_to_keep=3'])
[32m2021-03-04T04:26:26 | mmf_cli.run: [0mTorch version: 1.6.0
[32m2021-03-04T04:26:26 | mmf.utils.general: [0mCUDA Device 0 is: GeForce GTX 1080 Ti
[32m2021-03-04T04:26:26 | mmf_cli.run: [0mUsing seed 26346095
[32m2021-03-04T04:26:26 | mmf.trainers.mmf_trainer: [0mLoading datasets
[32m2021-03-04T04:26:32 | mmf.trainers.mmf_trainer: [0mLoading model
Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.v_embeddings.image_embeddings.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[32m2021-03-04T04:26:38 | mmf.trainers.mmf_trainer: [0mLoading optimizer
[32m2021-03-04T04:26:38 | mmf.trainers.mmf_trainer: [0mLoading metrics
[5m[31mWARNING[0m [32m2021-03-04T04:26:38 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.
Use OmegaConf.to_yaml(cfg)

  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T04:26:38 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.
Use OmegaConf.to_yaml(cfg)

  builtin_warn(*args, **kwargs)

[32m2021-03-04T04:26:38 | mmf.utils.checkpoint: [0mLoading checkpoint
Downloading vilbert.pretrained.cc_original.tar.gz: 0.00B [00:00, ?B/s]Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.v_embeddings.image_embeddings.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.v_embeddings.image_embeddings.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.v_embeddings.image_embeddings.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Downloading vilbert.pretrained.cc_original.tar.gz:   0%|          | 32.8k/918M [00:01<11:16:38, 22.6kB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   0%|          | 65.5k/918M [00:01<5:26:18, 46.9kB/s] Downloading vilbert.pretrained.cc_original.tar.gz:   0%|          | 164k/918M [00:01<1:52:02, 137kB/s]  Downloading vilbert.pretrained.cc_original.tar.gz:   0%|          | 328k/918M [00:01<51:32, 297kB/s]  Downloading vilbert.pretrained.cc_original.tar.gz:   0%|          | 623k/918M [00:02<25:09, 608kB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   0%|          | 1.28M/918M [00:02<11:10, 1.37MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   0%|          | 1.93M/918M [00:02<07:04, 2.16MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   0%|          | 3.28M/918M [00:02<03:41, 4.13MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   1%|          | 4.62M/918M [00:02<02:35, 5.88MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   1%|          | 5.80M/918M [00:02<02:11, 6.93MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   1%|          | 7.18M/918M [00:02<01:50, 8.23MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   1%|          | 8.29M/918M [00:03<01:45, 8.60MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   1%|          | 9.27M/918M [00:03<02:00, 7.56MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   1%|          | 10.1M/918M [00:03<02:00, 7.55MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   1%|â–         | 12.4M/918M [00:03<01:23, 10.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   2%|â–         | 14.4M/918M [00:03<01:12, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   2%|â–         | 16.4M/918M [00:03<01:04, 13.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   2%|â–         | 17.9M/918M [00:03<01:08, 13.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   2%|â–         | 19.3M/918M [00:03<01:18, 11.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   2%|â–         | 20.5M/918M [00:04<01:19, 11.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   2%|â–         | 22.4M/918M [00:04<01:10, 12.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   3%|â–Ž         | 24.4M/918M [00:04<01:04, 13.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   3%|â–Ž         | 25.8M/918M [00:04<01:08, 13.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   3%|â–Ž         | 27.2M/918M [00:04<01:19, 11.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   3%|â–Ž         | 28.5M/918M [00:04<01:27, 10.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   3%|â–Ž         | 30.6M/918M [00:04<01:22, 10.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   4%|â–Ž         | 32.5M/918M [00:05<01:22, 10.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   4%|â–Ž         | 34.4M/918M [00:05<01:21, 10.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   4%|â–         | 36.4M/918M [00:05<01:19, 11.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   4%|â–         | 38.4M/918M [00:05<01:10, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   4%|â–         | 39.7M/918M [00:05<01:13, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   4%|â–         | 41.0M/918M [00:05<01:14, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   5%|â–         | 42.6M/918M [00:05<01:20, 10.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   5%|â–         | 44.4M/918M [00:06<01:21, 10.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   5%|â–Œ         | 46.4M/918M [00:06<01:18, 11.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   5%|â–Œ         | 48.5M/918M [00:06<01:16, 11.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   6%|â–Œ         | 50.6M/918M [00:06<01:15, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   6%|â–Œ         | 52.7M/918M [00:06<01:14, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   6%|â–Œ         | 54.7M/918M [00:07<01:13, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   6%|â–Œ         | 56.8M/918M [00:07<01:13, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   6%|â–‹         | 58.8M/918M [00:07<01:13, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   7%|â–‹         | 60.1M/918M [00:07<01:15, 11.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   7%|â–‹         | 62.9M/918M [00:07<01:12, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   7%|â–‹         | 65.0M/918M [00:07<01:12, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   7%|â–‹         | 67.0M/918M [00:08<01:12, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   8%|â–Š         | 69.1M/918M [00:08<01:11, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   8%|â–Š         | 71.2M/918M [00:08<01:07, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   8%|â–Š         | 73.3M/918M [00:08<01:08, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   8%|â–Š         | 75.2M/918M [00:08<01:10, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   8%|â–Š         | 77.3M/918M [00:08<01:10, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   9%|â–Š         | 79.4M/918M [00:09<01:10, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   9%|â–‰         | 81.5M/918M [00:09<01:09, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   9%|â–‰         | 83.6M/918M [00:09<01:09, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:   9%|â–‰         | 85.6M/918M [00:09<01:10, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  10%|â–‰         | 87.7M/918M [00:09<01:09, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  10%|â–‰         | 89.8M/918M [00:09<01:09, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  10%|â–ˆ         | 91.8M/918M [00:10<01:09, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  10%|â–ˆ         | 93.9M/918M [00:10<01:09, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  10%|â–ˆ         | 95.9M/918M [00:10<01:09, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  11%|â–ˆ         | 98.0M/918M [00:10<01:09, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  11%|â–ˆ         | 99.9M/918M [00:10<01:01, 13.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  11%|â–ˆ         | 101M/918M [00:10<01:03, 12.8MB/s] Downloading vilbert.pretrained.cc_original.tar.gz:  11%|â–ˆ         | 103M/918M [00:11<01:12, 11.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  11%|â–ˆâ–        | 104M/918M [00:11<01:11, 11.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  12%|â–ˆâ–        | 106M/918M [00:11<01:10, 11.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  12%|â–ˆâ–        | 108M/918M [00:11<01:11, 11.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  12%|â–ˆâ–        | 110M/918M [00:11<01:10, 11.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  12%|â–ˆâ–        | 112M/918M [00:11<01:09, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  12%|â–ˆâ–        | 114M/918M [00:12<01:08, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  13%|â–ˆâ–Ž        | 116M/918M [00:12<01:08, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  13%|â–ˆâ–Ž        | 118M/918M [00:12<01:13, 10.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  13%|â–ˆâ–Ž        | 120M/918M [00:12<01:01, 13.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  13%|â–ˆâ–Ž        | 121M/918M [00:12<01:04, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  13%|â–ˆâ–Ž        | 123M/918M [00:12<01:07, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  14%|â–ˆâ–Ž        | 125M/918M [00:12<01:08, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  14%|â–ˆâ–        | 127M/918M [00:13<00:58, 13.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  14%|â–ˆâ–        | 128M/918M [00:13<01:01, 12.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  14%|â–ˆâ–        | 129M/918M [00:13<01:09, 11.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  14%|â–ˆâ–        | 131M/918M [00:13<01:13, 10.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  14%|â–ˆâ–        | 133M/918M [00:13<01:10, 11.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  15%|â–ˆâ–        | 135M/918M [00:13<01:09, 11.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  15%|â–ˆâ–        | 137M/918M [00:13<01:07, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  15%|â–ˆâ–Œ        | 139M/918M [00:14<01:00, 13.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  15%|â–ˆâ–Œ        | 140M/918M [00:14<01:02, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  15%|â–ˆâ–Œ        | 141M/918M [00:14<01:06, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  16%|â–ˆâ–Œ        | 143M/918M [00:14<01:09, 11.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  16%|â–ˆâ–Œ        | 145M/918M [00:14<00:59, 13.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  16%|â–ˆâ–Œ        | 146M/918M [00:14<01:01, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  16%|â–ˆâ–Œ        | 148M/918M [00:14<01:10, 10.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  16%|â–ˆâ–‹        | 149M/918M [00:14<01:05, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  16%|â–ˆâ–‹        | 151M/918M [00:15<01:01, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  17%|â–ˆâ–‹        | 152M/918M [00:15<01:04, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  17%|â–ˆâ–‹        | 154M/918M [00:15<01:09, 11.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  17%|â–ˆâ–‹        | 155M/918M [00:15<01:03, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  17%|â–ˆâ–‹        | 157M/918M [00:15<01:00, 12.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  17%|â–ˆâ–‹        | 159M/918M [00:15<01:03, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  17%|â–ˆâ–‹        | 160M/918M [00:15<01:09, 10.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  18%|â–ˆâ–Š        | 162M/918M [00:16<01:02, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  18%|â–ˆâ–Š        | 163M/918M [00:16<01:00, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  18%|â–ˆâ–Š        | 165M/918M [00:16<01:03, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  18%|â–ˆâ–Š        | 166M/918M [00:16<01:03, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  18%|â–ˆâ–Š        | 167M/918M [00:16<01:01, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  18%|â–ˆâ–Š        | 169M/918M [00:16<01:05, 11.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  19%|â–ˆâ–Š        | 170M/918M [00:16<01:07, 11.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  19%|â–ˆâ–Š        | 172M/918M [00:16<01:00, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  19%|â–ˆâ–‰        | 174M/918M [00:17<01:01, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  19%|â–ˆâ–‰        | 175M/918M [00:17<01:03, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  19%|â–ˆâ–‰        | 176M/918M [00:17<01:02, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  19%|â–ˆâ–‰        | 178M/918M [00:17<01:01, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  19%|â–ˆâ–‰        | 179M/918M [00:17<01:03, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  20%|â–ˆâ–‰        | 180M/918M [00:17<01:02, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  20%|â–ˆâ–‰        | 182M/918M [00:17<01:00, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  20%|â–ˆâ–‰        | 183M/918M [00:17<01:03, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  20%|â–ˆâ–ˆ        | 184M/918M [00:17<01:01, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  20%|â–ˆâ–ˆ        | 186M/918M [00:18<01:00, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  20%|â–ˆâ–ˆ        | 187M/918M [00:18<01:02, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  21%|â–ˆâ–ˆ        | 189M/918M [00:18<01:02, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  21%|â–ˆâ–ˆ        | 190M/918M [00:18<00:59, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  21%|â–ˆâ–ˆ        | 191M/918M [00:18<01:01, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  21%|â–ˆâ–ˆ        | 193M/918M [00:18<01:01, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  21%|â–ˆâ–ˆ        | 194M/918M [00:18<00:58, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  21%|â–ˆâ–ˆâ–       | 196M/918M [00:18<01:01, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  21%|â–ˆâ–ˆâ–       | 197M/918M [00:18<01:01, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  22%|â–ˆâ–ˆâ–       | 198M/918M [00:19<00:59, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  22%|â–ˆâ–ˆâ–       | 200M/918M [00:19<01:02, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  22%|â–ˆâ–ˆâ–       | 201M/918M [00:19<01:00, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  22%|â–ˆâ–ˆâ–       | 203M/918M [00:19<01:21, 8.78MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  22%|â–ˆâ–ˆâ–       | 204M/918M [00:19<01:32, 7.74MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  22%|â–ˆâ–ˆâ–       | 205M/918M [00:19<01:16, 9.32MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  23%|â–ˆâ–ˆâ–Ž       | 209M/918M [00:20<00:46, 15.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  23%|â–ˆâ–ˆâ–Ž       | 211M/918M [00:20<00:48, 14.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  23%|â–ˆâ–ˆâ–Ž       | 213M/918M [00:20<00:50, 14.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  23%|â–ˆâ–ˆâ–Ž       | 214M/918M [00:20<00:56, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  23%|â–ˆâ–ˆâ–Ž       | 215M/918M [00:20<00:56, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  24%|â–ˆâ–ˆâ–Ž       | 217M/918M [00:20<00:54, 12.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  24%|â–ˆâ–ˆâ–       | 218M/918M [00:20<00:57, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  24%|â–ˆâ–ˆâ–       | 220M/918M [00:20<00:57, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  24%|â–ˆâ–ˆâ–       | 221M/918M [00:21<00:56, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  24%|â–ˆâ–ˆâ–       | 222M/918M [00:21<00:59, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  24%|â–ˆâ–ˆâ–       | 224M/918M [00:21<00:58, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  25%|â–ˆâ–ˆâ–       | 225M/918M [00:21<00:56, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  25%|â–ˆâ–ˆâ–       | 227M/918M [00:21<00:58, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  25%|â–ˆâ–ˆâ–       | 228M/918M [00:21<00:58, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  25%|â–ˆâ–ˆâ–       | 230M/918M [00:21<00:55, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  25%|â–ˆâ–ˆâ–Œ       | 231M/918M [00:21<00:58, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  25%|â–ˆâ–ˆâ–Œ       | 232M/918M [00:21<00:57, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  25%|â–ˆâ–ˆâ–Œ       | 234M/918M [00:22<00:55, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  26%|â–ˆâ–ˆâ–Œ       | 235M/918M [00:22<00:58, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  26%|â–ˆâ–ˆâ–Œ       | 236M/918M [00:22<00:58, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  26%|â–ˆâ–ˆâ–Œ       | 238M/918M [00:22<00:51, 13.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  26%|â–ˆâ–ˆâ–Œ       | 239M/918M [00:22<00:58, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  26%|â–ˆâ–ˆâ–Œ       | 240M/918M [00:22<01:01, 11.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  26%|â–ˆâ–ˆâ–‹       | 242M/918M [00:22<00:58, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  27%|â–ˆâ–ˆâ–‹       | 244M/918M [00:22<00:50, 13.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  27%|â–ˆâ–ˆâ–‹       | 245M/918M [00:23<00:57, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  27%|â–ˆâ–ˆâ–‹       | 247M/918M [00:23<00:56, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  27%|â–ˆâ–ˆâ–‹       | 248M/918M [00:23<00:54, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  27%|â–ˆâ–ˆâ–‹       | 250M/918M [00:23<00:57, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  27%|â–ˆâ–ˆâ–‹       | 251M/918M [00:23<00:56, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  27%|â–ˆâ–ˆâ–‹       | 252M/918M [00:23<00:54, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  28%|â–ˆâ–ˆâ–Š       | 254M/918M [00:23<00:57, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  28%|â–ˆâ–ˆâ–Š       | 255M/918M [00:23<00:57, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  28%|â–ˆâ–ˆâ–Š       | 257M/918M [00:23<00:53, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  28%|â–ˆâ–ˆâ–Š       | 258M/918M [00:24<00:56, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  28%|â–ˆâ–ˆâ–Š       | 259M/918M [00:24<00:56, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  28%|â–ˆâ–ˆâ–Š       | 261M/918M [00:24<00:52, 12.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  29%|â–ˆâ–ˆâ–Š       | 262M/918M [00:24<00:55, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  29%|â–ˆâ–ˆâ–Š       | 263M/918M [00:24<00:55, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  29%|â–ˆâ–ˆâ–‰       | 265M/918M [00:24<00:50, 13.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  29%|â–ˆâ–ˆâ–‰       | 266M/918M [00:24<00:56, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  29%|â–ˆâ–ˆâ–‰       | 267M/918M [00:24<01:00, 10.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  29%|â–ˆâ–ˆâ–‰       | 269M/918M [00:25<00:55, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  30%|â–ˆâ–ˆâ–‰       | 271M/918M [00:25<00:49, 13.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  30%|â–ˆâ–ˆâ–‰       | 272M/918M [00:25<00:54, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  30%|â–ˆâ–ˆâ–‰       | 274M/918M [00:25<00:59, 10.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  30%|â–ˆâ–ˆâ–ˆ       | 276M/918M [00:25<00:54, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  30%|â–ˆâ–ˆâ–ˆ       | 277M/918M [00:25<00:49, 12.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  30%|â–ˆâ–ˆâ–ˆ       | 278M/918M [00:25<00:55, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  30%|â–ˆâ–ˆâ–ˆ       | 280M/918M [00:25<00:54, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  31%|â–ˆâ–ˆâ–ˆ       | 281M/918M [00:26<00:49, 12.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  31%|â–ˆâ–ˆâ–ˆ       | 283M/918M [00:26<01:06, 9.55MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  31%|â–ˆâ–ˆâ–ˆ       | 285M/918M [00:26<00:50, 12.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  31%|â–ˆâ–ˆâ–ˆ       | 286M/918M [00:26<00:52, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  31%|â–ˆâ–ˆâ–ˆâ–      | 288M/918M [00:26<00:51, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  32%|â–ˆâ–ˆâ–ˆâ–      | 290M/918M [00:26<00:48, 13.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  32%|â–ˆâ–ˆâ–ˆâ–      | 291M/918M [00:26<00:52, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  32%|â–ˆâ–ˆâ–ˆâ–      | 292M/918M [00:27<00:56, 11.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  32%|â–ˆâ–ˆâ–ˆâ–      | 294M/918M [00:27<00:47, 13.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  32%|â–ˆâ–ˆâ–ˆâ–      | 296M/918M [00:27<00:50, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  32%|â–ˆâ–ˆâ–ˆâ–      | 297M/918M [00:27<00:56, 11.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  32%|â–ˆâ–ˆâ–ˆâ–      | 298M/918M [00:27<00:53, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 300M/918M [00:27<00:47, 13.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 301M/918M [00:27<00:52, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 303M/918M [00:27<00:51, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 304M/918M [00:27<00:49, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 306M/918M [00:28<00:52, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 307M/918M [00:28<00:52, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 308M/918M [00:28<00:49, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 310M/918M [00:28<00:52, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  34%|â–ˆâ–ˆâ–ˆâ–      | 311M/918M [00:28<00:52, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  34%|â–ˆâ–ˆâ–ˆâ–      | 313M/918M [00:28<00:48, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  34%|â–ˆâ–ˆâ–ˆâ–      | 314M/918M [00:28<00:51, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  34%|â–ˆâ–ˆâ–ˆâ–      | 315M/918M [00:28<00:51, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  34%|â–ˆâ–ˆâ–ˆâ–      | 317M/918M [00:29<00:47, 12.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  35%|â–ˆâ–ˆâ–ˆâ–      | 318M/918M [00:29<00:53, 11.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  35%|â–ˆâ–ˆâ–ˆâ–      | 319M/918M [00:29<00:50, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  35%|â–ˆâ–ˆâ–ˆâ–      | 321M/918M [00:29<00:48, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 322M/918M [00:29<00:50, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 323M/918M [00:29<00:51, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 325M/918M [00:29<00:48, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 326M/918M [00:29<00:51, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 327M/918M [00:29<00:50, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 329M/918M [00:30<00:47, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 330M/918M [00:30<00:51, 11.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 332M/918M [00:30<00:49, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 333M/918M [00:30<00:47, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 334M/918M [00:30<00:50, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 336M/918M [00:30<00:48, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 337M/918M [00:30<00:46, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 338M/918M [00:30<00:49, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 340M/918M [00:30<00:48, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 341M/918M [00:31<00:47, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 343M/918M [00:31<00:49, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 344M/918M [00:31<00:48, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 345M/918M [00:31<00:47, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 347M/918M [00:31<00:49, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 348M/918M [00:31<00:48, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 349M/918M [00:31<00:47, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 351M/918M [00:31<00:49, 11.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 352M/918M [00:32<00:46, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 354M/918M [00:32<00:46, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 355M/918M [00:32<00:48, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 357M/918M [00:32<00:46, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 358M/918M [00:32<00:46, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 359M/918M [00:32<00:48, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 361M/918M [00:32<00:46, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 362M/918M [00:32<00:45, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 363M/918M [00:32<00:48, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 365M/918M [00:33<00:45, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 366M/918M [00:33<00:45, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 367M/918M [00:33<00:47, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 369M/918M [00:33<00:45, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 370M/918M [00:33<00:44, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 372M/918M [00:33<00:47, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 373M/918M [00:33<00:45, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 374M/918M [00:33<00:45, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 376M/918M [00:33<00:47, 11.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 377M/918M [00:34<00:46, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 378M/918M [00:34<00:45, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 380M/918M [00:34<00:45, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 381M/918M [00:34<00:45, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 383M/918M [00:34<00:44, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 384M/918M [00:34<00:45, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 385M/918M [00:34<00:44, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 387M/918M [00:34<00:44, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 388M/918M [00:35<00:44, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 390M/918M [00:35<00:44, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 391M/918M [00:35<00:42, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 392M/918M [00:35<00:44, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 394M/918M [00:35<00:44, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 395M/918M [00:35<00:42, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 396M/918M [00:35<00:44, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 398M/918M [00:35<00:43, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 399M/918M [00:35<00:42, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 401M/918M [00:36<00:44, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 402M/918M [00:36<00:43, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 403M/918M [00:36<00:42, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 405M/918M [00:36<00:43, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 406M/918M [00:36<00:43, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 408M/918M [00:36<00:42, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 409M/918M [00:36<00:43, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 410M/918M [00:36<00:42, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 412M/918M [00:37<00:41, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 413M/918M [00:37<00:42, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 415M/918M [00:37<00:42, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 416M/918M [00:37<00:40, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 417M/918M [00:37<00:42, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 419M/918M [00:37<00:41, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 420M/918M [00:37<00:40, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 421M/918M [00:37<00:42, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 423M/918M [00:37<00:41, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 424M/918M [00:38<00:40, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 426M/918M [00:38<00:42, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 427M/918M [00:38<00:42, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 428M/918M [00:38<00:40, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 430M/918M [00:38<00:41, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 431M/918M [00:38<00:41, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 433M/918M [00:38<00:39, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 434M/918M [00:38<00:40, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 435M/918M [00:39<00:41, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 437M/918M [00:39<00:38, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 438M/918M [00:39<00:40, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 439M/918M [00:39<00:40, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 441M/918M [00:39<00:38, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 442M/918M [00:39<00:40, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 444M/918M [00:39<00:40, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 445M/918M [00:39<00:38, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 446M/918M [00:39<00:40, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 448M/918M [00:40<00:39, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 449M/918M [00:40<00:37, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 451M/918M [00:40<01:05, 7.10MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 452M/918M [00:40<01:02, 7.44MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 454M/918M [00:40<00:43, 10.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 458M/918M [00:40<00:28, 15.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 460M/918M [00:41<00:30, 15.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 461M/918M [00:41<00:33, 13.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 463M/918M [00:41<00:35, 13.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 464M/918M [00:41<00:35, 12.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 466M/918M [00:41<00:34, 13.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 467M/918M [00:41<00:37, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 469M/918M [00:41<00:36, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 470M/918M [00:41<00:35, 12.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 471M/918M [00:42<00:38, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 473M/918M [00:42<00:37, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 474M/918M [00:42<00:35, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 475M/918M [00:42<00:37, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 477M/918M [00:42<00:36, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 478M/918M [00:42<00:36, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 479M/918M [00:42<00:37, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 481M/918M [00:42<00:35, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 482M/918M [00:42<00:36, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 483M/918M [00:43<00:36, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 485M/918M [00:43<00:35, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 486M/918M [00:43<00:37, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 487M/918M [00:43<00:36, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 489M/918M [00:43<00:36, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 490M/918M [00:43<00:37, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 491M/918M [00:43<00:33, 12.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 493M/918M [00:43<00:35, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 494M/918M [00:43<00:36, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 496M/918M [00:44<00:33, 12.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 497M/918M [00:44<00:34, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 498M/918M [00:44<00:34, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 499M/918M [00:44<00:35, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 501M/918M [00:44<00:35, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 502M/918M [00:44<00:35, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 503M/918M [00:44<00:35, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 504M/918M [00:44<00:35, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 506M/918M [00:44<00:32, 12.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 507M/918M [00:45<00:34, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 509M/918M [00:45<00:35, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 510M/918M [00:45<00:32, 12.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 511M/918M [00:45<00:33, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 513M/918M [00:45<00:33, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 514M/918M [00:45<00:34, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 515M/918M [00:45<00:33, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 516M/918M [00:45<00:34, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 518M/918M [00:45<00:33, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 519M/918M [00:46<00:34, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 520M/918M [00:46<00:31, 12.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 522M/918M [00:46<00:32, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 523M/918M [00:46<00:32, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 524M/918M [00:46<00:33, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 525M/918M [00:46<00:33, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 527M/918M [00:46<00:33, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 528M/918M [00:46<00:32, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 529M/918M [00:46<00:33, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 531M/918M [00:46<00:29, 12.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 532M/918M [00:47<00:32, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 534M/918M [00:47<00:33, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 535M/918M [00:47<00:32, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 536M/918M [00:47<00:31, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 537M/918M [00:47<00:36, 10.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 539M/918M [00:47<00:30, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 541M/918M [00:47<00:30, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 542M/918M [00:47<00:32, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 544M/918M [00:48<00:30, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 545M/918M [00:48<00:30, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 546M/918M [00:48<00:31, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 548M/918M [00:48<00:30, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 549M/918M [00:48<00:30, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 550M/918M [00:48<00:31, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 552M/918M [00:48<00:29, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 553M/918M [00:48<00:29, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 554M/918M [00:48<00:30, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 555M/918M [00:49<00:30, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 557M/918M [00:49<00:30, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 558M/918M [00:49<00:29, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 559M/918M [00:49<00:30, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 560M/918M [00:49<00:30, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 562M/918M [00:49<00:29, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 563M/918M [00:49<00:30, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 564M/918M [00:49<00:29, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 565M/918M [00:49<00:29, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 567M/918M [00:49<00:29, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 568M/918M [00:50<00:29, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 569M/918M [00:50<00:29, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 570M/918M [00:50<00:28, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 572M/918M [00:50<00:28, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 573M/918M [00:50<00:29, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 574M/918M [00:50<00:28, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 575M/918M [00:50<00:29, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 577M/918M [00:50<00:29, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 578M/918M [00:50<00:27, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 579M/918M [00:51<00:28, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 581M/918M [00:51<00:29, 11.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 582M/918M [00:51<00:27, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 583M/918M [00:51<00:27, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 585M/918M [00:51<00:27, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 586M/918M [00:51<00:27, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 587M/918M [00:51<00:27, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 589M/918M [00:51<00:27, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 590M/918M [00:51<00:27, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 591M/918M [00:52<00:27, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 592M/918M [00:52<00:26, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 594M/918M [00:52<00:27, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 595M/918M [00:52<00:26, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 596M/918M [00:52<00:26, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 598M/918M [00:52<00:27, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 599M/918M [00:52<00:26, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 600M/918M [00:52<00:27, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 601M/918M [00:52<00:26, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 603M/918M [00:53<00:25, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 604M/918M [00:53<00:26, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 605M/918M [00:53<00:26, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 606M/918M [00:53<00:27, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 608M/918M [00:53<00:25, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 609M/918M [00:53<00:25, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 610M/918M [00:53<00:25, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 612M/918M [00:53<00:25, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 613M/918M [00:54<00:46, 6.59MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 614M/918M [00:54<00:42, 7.24MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 618M/918M [00:54<00:22, 13.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 620M/918M [00:54<00:19, 15.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 622M/918M [00:54<00:20, 14.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 624M/918M [00:54<00:21, 13.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 625M/918M [00:54<00:22, 12.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 627M/918M [00:55<00:22, 12.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 628M/918M [00:55<00:23, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 629M/918M [00:55<00:23, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 631M/918M [00:55<00:22, 12.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 632M/918M [00:55<00:23, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 633M/918M [00:55<00:24, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 635M/918M [00:55<00:22, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 636M/918M [00:55<00:22, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 637M/918M [00:55<00:23, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 639M/918M [00:56<00:23, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 640M/918M [00:56<00:23, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 641M/918M [00:56<00:22, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 642M/918M [00:56<00:22, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 644M/918M [00:56<00:23, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 645M/918M [00:56<00:23, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 646M/918M [00:56<00:22, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 647M/918M [00:56<00:22, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 649M/918M [00:56<00:22, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 650M/918M [00:56<00:22, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 651M/918M [00:57<00:22, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 652M/918M [00:57<00:22, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 654M/918M [00:57<00:22, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 655M/918M [00:57<00:21, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 656M/918M [00:57<00:22, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 658M/918M [00:57<00:21, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 659M/918M [00:57<00:21, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 660M/918M [00:57<00:22, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 662M/918M [00:57<00:20, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 663M/918M [00:58<00:21, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 664M/918M [00:58<00:20, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 665M/918M [00:58<00:21, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 667M/918M [00:58<00:21, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 668M/918M [00:58<00:20, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 669M/918M [00:58<00:20, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 670M/918M [00:58<00:21, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 672M/918M [00:58<00:20, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 673M/918M [00:58<00:21, 11.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 674M/918M [00:59<00:19, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 676M/918M [00:59<00:20, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 677M/918M [00:59<00:20, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 678M/918M [00:59<00:19, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 680M/918M [00:59<00:19, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 681M/918M [00:59<00:20, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 682M/918M [00:59<00:19, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 684M/918M [00:59<00:20, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 685M/918M [00:59<00:18, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 686M/918M [01:00<00:19, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 687M/918M [01:00<00:19, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 689M/918M [01:00<00:18, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 690M/918M [01:00<00:18, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 691M/918M [01:00<00:19, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 693M/918M [01:00<00:18, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 694M/918M [01:00<00:19, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 695M/918M [01:00<00:17, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 697M/918M [01:00<00:18, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 698M/918M [01:00<00:19, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 699M/918M [01:01<00:18, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 700M/918M [01:01<00:17, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 702M/918M [01:01<00:17, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 703M/918M [01:01<00:18, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 704M/918M [01:01<00:18, 11.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 706M/918M [01:01<00:17, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 707M/918M [01:01<00:17, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 708M/918M [01:01<00:18, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 710M/918M [01:01<00:17, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 711M/918M [01:02<00:17, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 712M/918M [01:02<00:17, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 713M/918M [01:02<00:17, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 715M/918M [01:02<00:17, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 716M/918M [01:02<00:16, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 717M/918M [01:02<00:16, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 719M/918M [01:02<00:17, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 720M/918M [01:02<00:16, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 721M/918M [01:02<00:16, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 723M/918M [01:03<00:16, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 724M/918M [01:03<00:16, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 725M/918M [01:03<00:16, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 726M/918M [01:03<00:15, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 728M/918M [01:03<00:15, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 729M/918M [01:03<00:15, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 730M/918M [01:03<00:15, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 732M/918M [01:03<00:16, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 733M/918M [01:03<00:15, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 734M/918M [01:04<00:15, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 736M/918M [01:04<00:15, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 737M/918M [01:04<00:14, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 738M/918M [01:04<00:28, 6.34MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 741M/918M [01:04<00:18, 9.53MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 745M/918M [01:04<00:11, 15.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 747M/918M [01:05<00:12, 14.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 749M/918M [01:05<00:12, 13.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 751M/918M [01:05<00:12, 13.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 752M/918M [01:05<00:13, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 754M/918M [01:05<00:12, 12.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 755M/918M [01:05<00:12, 12.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 756M/918M [01:05<00:13, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 758M/918M [01:05<00:13, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 759M/918M [01:06<00:12, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 760M/918M [01:06<00:13, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 762M/918M [01:06<00:12, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 763M/918M [01:06<00:13, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 764M/918M [01:06<00:12, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 766M/918M [01:06<00:12, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 767M/918M [01:06<00:13, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 768M/918M [01:06<00:12, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 770M/918M [01:06<00:12, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 771M/918M [01:07<00:12, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 772M/918M [01:07<00:12, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 773M/918M [01:07<00:13, 11.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 775M/918M [01:07<00:11, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 776M/918M [01:07<00:11, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 777M/918M [01:07<00:12, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 779M/918M [01:07<00:11, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 780M/918M [01:07<00:11, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 781M/918M [01:07<00:11, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 783M/918M [01:08<00:11, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 784M/918M [01:08<00:11, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 785M/918M [01:08<00:11, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 787M/918M [01:08<00:10, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 788M/918M [01:08<00:11, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 789M/918M [01:08<00:10, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 790M/918M [01:08<00:10, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 792M/918M [01:08<00:10, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 793M/918M [01:08<00:10, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 794M/918M [01:09<00:10, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 795M/918M [01:09<00:10, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 797M/918M [01:09<00:11, 10.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 799M/918M [01:09<00:09, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 800M/918M [01:09<00:09, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 801M/918M [01:09<00:09, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 802M/918M [01:09<00:09, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 804M/918M [01:09<00:09, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 805M/918M [01:09<00:09, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 806M/918M [01:10<00:09, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 808M/918M [01:10<00:09, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 809M/918M [01:10<00:11, 9.68MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 811M/918M [01:10<00:08, 12.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 813M/918M [01:10<00:08, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 814M/918M [01:10<00:08, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 816M/918M [01:10<00:08, 12.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 817M/918M [01:10<00:08, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 818M/918M [01:11<00:08, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 820M/918M [01:11<00:08, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 821M/918M [01:11<00:07, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 822M/918M [01:11<00:07, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 823M/918M [01:11<00:08, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 825M/918M [01:11<00:07, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 826M/918M [01:11<00:07, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 827M/918M [01:11<00:07, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 828M/918M [01:11<00:07, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 829M/918M [01:11<00:07, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 831M/918M [01:12<00:07, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 832M/918M [01:12<00:07, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 833M/918M [01:12<00:07, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 835M/918M [01:12<00:06, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 836M/918M [01:12<00:06, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 837M/918M [01:12<00:07, 10.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 839M/918M [01:12<00:06, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 840M/918M [01:12<00:06, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 841M/918M [01:12<00:06, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 843M/918M [01:13<00:06, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 844M/918M [01:13<00:06, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 845M/918M [01:13<00:05, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 847M/918M [01:13<00:05, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 848M/918M [01:13<00:05, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 849M/918M [01:13<00:05, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 850M/918M [01:13<00:05, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 852M/918M [01:13<00:05, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 853M/918M [01:13<00:05, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 854M/918M [01:14<00:05, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 855M/918M [01:14<00:05, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 857M/918M [01:14<00:05, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 858M/918M [01:14<00:04, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 859M/918M [01:14<00:05, 11.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 860M/918M [01:14<00:04, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 862M/918M [01:14<00:04, 12.5MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 863M/918M [01:14<00:04, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 864M/918M [01:14<00:04, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 866M/918M [01:15<00:04, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 867M/918M [01:15<00:04, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 868M/918M [01:15<00:04, 12.3MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 870M/918M [01:15<00:04, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 871M/918M [01:15<00:04, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 872M/918M [01:15<00:03, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 873M/918M [01:15<00:03, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 875M/918M [01:15<00:03, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 876M/918M [01:15<00:03, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 877M/918M [01:15<00:03, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 878M/918M [01:16<00:03, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 880M/918M [01:16<00:03, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 881M/918M [01:16<00:03, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 882M/918M [01:16<00:03, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 883M/918M [01:16<00:02, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 885M/918M [01:16<00:02, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 886M/918M [01:16<00:02, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 887M/918M [01:16<00:02, 12.4MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 888M/918M [01:16<00:02, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 890M/918M [01:17<00:02, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 891M/918M [01:17<00:02, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 892M/918M [01:17<00:02, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 893M/918M [01:17<00:02, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 895M/918M [01:17<00:02, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 896M/918M [01:17<00:01, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 897M/918M [01:17<00:01, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 898M/918M [01:17<00:01, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 900M/918M [01:17<00:01, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 901M/918M [01:17<00:01, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 902M/918M [01:18<00:01, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 904M/918M [01:18<00:01, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 905M/918M [01:18<00:01, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 906M/918M [01:18<00:01, 11.8MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 907M/918M [01:18<00:00, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 908M/918M [01:18<00:00, 11.7MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 910M/918M [01:18<00:00, 12.1MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 911M/918M [01:18<00:00, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 912M/918M [01:18<00:00, 12.0MB/s]Downloading vilbert.pretrained.cc_original.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 913M/918M [01:19<00:00, 11.9MB/s]Downloading vilbert.pretrained.cc_original.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 915M/918M [01:19<00:00, 11.6MB/s]Downloading vilbert.pretrained.cc_original.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 916M/918M [01:19<00:00, 12.2MB/s]Downloading vilbert.pretrained.cc_original.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 917M/918M [01:19<00:00, 6.44MB/s]Downloading vilbert.pretrained.cc_original.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 918M/918M [01:19<00:00, 11.5MB/s][ Downloading: https://dl.fbaipublicfiles.com/mmf/data/models/vilbert/vilbert.pretrained.cc_original.tar.gz to /scratch/sagarsj42/data/models/vilbert.pretrained.cc.original/vilbert.pretrained.cc_original.tar.gz ]
[ Starting checksum for vilbert.pretrained.cc_original.tar.gz]
[ Checksum successful for vilbert.pretrained.cc_original.tar.gz]
Unpacking vilbert.pretrained.cc_original.tar.gz
[5m[31mWARNING[0m [32m2021-03-04T04:28:10 | mmf: [0mKey data_parallel is not present in registry, returning default value of None
[5m[31mWARNING[0m [32m2021-03-04T04:28:10 | mmf: [0mKey distributed is not present in registry, returning default value of None
[5m[31mWARNING[0m [32m2021-03-04T04:28:10 | mmf: [0mKey data_parallel is not present in registry, returning default value of None
[5m[31mWARNING[0m [32m2021-03-04T04:28:10 | mmf: [0mKey distributed is not present in registry, returning default value of None
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.v_embeddings.image_embeddings.weight from model.bert.v_embeddings.image_embeddings.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.v_embeddings.image_embeddings.bias from model.bert.v_embeddings.image_embeddings.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.v_embeddings.image_location_embeddings.weight from model.bert.v_embeddings.image_location_embeddings.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.v_embeddings.image_location_embeddings.bias from model.bert.v_embeddings.image_location_embeddings.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.v_embeddings.LayerNorm.weight from model.bert.v_embeddings.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.v_embeddings.LayerNorm.bias from model.bert.v_embeddings.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.attention.self.query.weight from model.bert.encoder.v_layer.0.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.attention.self.query.bias from model.bert.encoder.v_layer.0.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.attention.self.key.weight from model.bert.encoder.v_layer.0.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.attention.self.key.bias from model.bert.encoder.v_layer.0.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.attention.self.value.weight from model.bert.encoder.v_layer.0.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.attention.self.value.bias from model.bert.encoder.v_layer.0.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.attention.output.dense.weight from model.bert.encoder.v_layer.0.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.attention.output.dense.bias from model.bert.encoder.v_layer.0.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.0.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.0.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.intermediate.dense.weight from model.bert.encoder.v_layer.0.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.intermediate.dense.bias from model.bert.encoder.v_layer.0.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.output.dense.weight from model.bert.encoder.v_layer.0.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.output.dense.bias from model.bert.encoder.v_layer.0.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.output.LayerNorm.weight from model.bert.encoder.v_layer.0.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.0.output.LayerNorm.bias from model.bert.encoder.v_layer.0.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.attention.self.query.weight from model.bert.encoder.v_layer.1.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.attention.self.query.bias from model.bert.encoder.v_layer.1.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.attention.self.key.weight from model.bert.encoder.v_layer.1.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.attention.self.key.bias from model.bert.encoder.v_layer.1.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.attention.self.value.weight from model.bert.encoder.v_layer.1.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.attention.self.value.bias from model.bert.encoder.v_layer.1.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.attention.output.dense.weight from model.bert.encoder.v_layer.1.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.attention.output.dense.bias from model.bert.encoder.v_layer.1.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.1.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.1.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.intermediate.dense.weight from model.bert.encoder.v_layer.1.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.intermediate.dense.bias from model.bert.encoder.v_layer.1.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.output.dense.weight from model.bert.encoder.v_layer.1.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.output.dense.bias from model.bert.encoder.v_layer.1.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.output.LayerNorm.weight from model.bert.encoder.v_layer.1.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.1.output.LayerNorm.bias from model.bert.encoder.v_layer.1.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.attention.self.query.weight from model.bert.encoder.v_layer.2.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.attention.self.query.bias from model.bert.encoder.v_layer.2.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.attention.self.key.weight from model.bert.encoder.v_layer.2.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.attention.self.key.bias from model.bert.encoder.v_layer.2.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.attention.self.value.weight from model.bert.encoder.v_layer.2.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.attention.self.value.bias from model.bert.encoder.v_layer.2.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.attention.output.dense.weight from model.bert.encoder.v_layer.2.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.attention.output.dense.bias from model.bert.encoder.v_layer.2.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.2.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.2.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.intermediate.dense.weight from model.bert.encoder.v_layer.2.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.intermediate.dense.bias from model.bert.encoder.v_layer.2.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.output.dense.weight from model.bert.encoder.v_layer.2.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.output.dense.bias from model.bert.encoder.v_layer.2.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.output.LayerNorm.weight from model.bert.encoder.v_layer.2.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.2.output.LayerNorm.bias from model.bert.encoder.v_layer.2.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.attention.self.query.weight from model.bert.encoder.v_layer.3.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.attention.self.query.bias from model.bert.encoder.v_layer.3.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.attention.self.key.weight from model.bert.encoder.v_layer.3.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.attention.self.key.bias from model.bert.encoder.v_layer.3.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.attention.self.value.weight from model.bert.encoder.v_layer.3.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.attention.self.value.bias from model.bert.encoder.v_layer.3.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.attention.output.dense.weight from model.bert.encoder.v_layer.3.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.attention.output.dense.bias from model.bert.encoder.v_layer.3.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.3.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.3.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.intermediate.dense.weight from model.bert.encoder.v_layer.3.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.intermediate.dense.bias from model.bert.encoder.v_layer.3.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.output.dense.weight from model.bert.encoder.v_layer.3.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.output.dense.bias from model.bert.encoder.v_layer.3.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.output.LayerNorm.weight from model.bert.encoder.v_layer.3.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.3.output.LayerNorm.bias from model.bert.encoder.v_layer.3.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.attention.self.query.weight from model.bert.encoder.v_layer.4.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.attention.self.query.bias from model.bert.encoder.v_layer.4.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.attention.self.key.weight from model.bert.encoder.v_layer.4.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.attention.self.key.bias from model.bert.encoder.v_layer.4.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.attention.self.value.weight from model.bert.encoder.v_layer.4.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.attention.self.value.bias from model.bert.encoder.v_layer.4.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.attention.output.dense.weight from model.bert.encoder.v_layer.4.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.attention.output.dense.bias from model.bert.encoder.v_layer.4.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.4.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.4.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.intermediate.dense.weight from model.bert.encoder.v_layer.4.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.intermediate.dense.bias from model.bert.encoder.v_layer.4.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.output.dense.weight from model.bert.encoder.v_layer.4.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.output.dense.bias from model.bert.encoder.v_layer.4.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.output.LayerNorm.weight from model.bert.encoder.v_layer.4.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.4.output.LayerNorm.bias from model.bert.encoder.v_layer.4.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.attention.self.query.weight from model.bert.encoder.v_layer.5.attention.self.query.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.attention.self.query.bias from model.bert.encoder.v_layer.5.attention.self.query.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.attention.self.key.weight from model.bert.encoder.v_layer.5.attention.self.key.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.attention.self.key.bias from model.bert.encoder.v_layer.5.attention.self.key.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.attention.self.value.weight from model.bert.encoder.v_layer.5.attention.self.value.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.attention.self.value.bias from model.bert.encoder.v_layer.5.attention.self.value.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.attention.output.dense.weight from model.bert.encoder.v_layer.5.attention.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.attention.output.dense.bias from model.bert.encoder.v_layer.5.attention.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.5.attention.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.5.attention.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.intermediate.dense.weight from model.bert.encoder.v_layer.5.intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.intermediate.dense.bias from model.bert.encoder.v_layer.5.intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.output.dense.weight from model.bert.encoder.v_layer.5.output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.output.dense.bias from model.bert.encoder.v_layer.5.output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.output.LayerNorm.weight from model.bert.encoder.v_layer.5.output.LayerNorm.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.v_layer.5.output.LayerNorm.bias from model.bert.encoder.v_layer.5.output.LayerNorm.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biattention.query1.weight from model.bert.encoder.c_layer.0.biattention.query1.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biattention.query1.bias from model.bert.encoder.c_layer.0.biattention.query1.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biattention.key1.weight from model.bert.encoder.c_layer.0.biattention.key1.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biattention.key1.bias from model.bert.encoder.c_layer.0.biattention.key1.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biattention.value1.weight from model.bert.encoder.c_layer.0.biattention.value1.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biattention.value1.bias from model.bert.encoder.c_layer.0.biattention.value1.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biattention.query2.weight from model.bert.encoder.c_layer.0.biattention.query2.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biattention.query2.bias from model.bert.encoder.c_layer.0.biattention.query2.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biattention.key2.weight from model.bert.encoder.c_layer.0.biattention.key2.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biattention.key2.bias from model.bert.encoder.c_layer.0.biattention.key2.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biattention.value2.weight from model.bert.encoder.c_layer.0.biattention.value2.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biattention.value2.bias from model.bert.encoder.c_layer.0.biattention.value2.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biOutput.dense1.weight from model.bert.encoder.c_layer.0.biOutput.dense1.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biOutput.dense1.bias from model.bert.encoder.c_layer.0.biOutput.dense1.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.0.biOutput.LayerNorm1.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.0.biOutput.LayerNorm1.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biOutput.q_dense1.weight from model.bert.encoder.c_layer.0.biOutput.q_dense1.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biOutput.q_dense1.bias from model.bert.encoder.c_layer.0.biOutput.q_dense1.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biOutput.dense2.weight from model.bert.encoder.c_layer.0.biOutput.dense2.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biOutput.dense2.bias from model.bert.encoder.c_layer.0.biOutput.dense2.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.0.biOutput.LayerNorm2.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.0.biOutput.LayerNorm2.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biOutput.q_dense2.weight from model.bert.encoder.c_layer.0.biOutput.q_dense2.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.biOutput.q_dense2.bias from model.bert.encoder.c_layer.0.biOutput.q_dense2.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.v_intermediate.dense.weight from model.bert.encoder.c_layer.0.v_intermediate.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.v_intermediate.dense.bias from model.bert.encoder.c_layer.0.v_intermediate.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.v_output.dense.weight from model.bert.encoder.c_layer.0.v_output.dense.weight
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.v_output.dense.bias from model.bert.encoder.c_layer.0.v_output.dense.bias
[32m2021-03-04T04:28:10 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.v_output.LayerNorm.weight from model.bert.encoder.c_layer.0.v_output.LayerNorm.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.v_output.LayerNorm.bias from model.bert.encoder.c_layer.0.v_output.LayerNorm.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.t_intermediate.dense.weight from model.bert.encoder.c_layer.0.t_intermediate.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.t_intermediate.dense.bias from model.bert.encoder.c_layer.0.t_intermediate.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.t_output.dense.weight from model.bert.encoder.c_layer.0.t_output.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.t_output.dense.bias from model.bert.encoder.c_layer.0.t_output.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.t_output.LayerNorm.weight from model.bert.encoder.c_layer.0.t_output.LayerNorm.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.0.t_output.LayerNorm.bias from model.bert.encoder.c_layer.0.t_output.LayerNorm.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biattention.query1.weight from model.bert.encoder.c_layer.1.biattention.query1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biattention.query1.bias from model.bert.encoder.c_layer.1.biattention.query1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biattention.key1.weight from model.bert.encoder.c_layer.1.biattention.key1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biattention.key1.bias from model.bert.encoder.c_layer.1.biattention.key1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biattention.value1.weight from model.bert.encoder.c_layer.1.biattention.value1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biattention.value1.bias from model.bert.encoder.c_layer.1.biattention.value1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biattention.query2.weight from model.bert.encoder.c_layer.1.biattention.query2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biattention.query2.bias from model.bert.encoder.c_layer.1.biattention.query2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biattention.key2.weight from model.bert.encoder.c_layer.1.biattention.key2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biattention.key2.bias from model.bert.encoder.c_layer.1.biattention.key2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biattention.value2.weight from model.bert.encoder.c_layer.1.biattention.value2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biattention.value2.bias from model.bert.encoder.c_layer.1.biattention.value2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biOutput.dense1.weight from model.bert.encoder.c_layer.1.biOutput.dense1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biOutput.dense1.bias from model.bert.encoder.c_layer.1.biOutput.dense1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.1.biOutput.LayerNorm1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.1.biOutput.LayerNorm1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biOutput.q_dense1.weight from model.bert.encoder.c_layer.1.biOutput.q_dense1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biOutput.q_dense1.bias from model.bert.encoder.c_layer.1.biOutput.q_dense1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biOutput.dense2.weight from model.bert.encoder.c_layer.1.biOutput.dense2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biOutput.dense2.bias from model.bert.encoder.c_layer.1.biOutput.dense2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.1.biOutput.LayerNorm2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.1.biOutput.LayerNorm2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biOutput.q_dense2.weight from model.bert.encoder.c_layer.1.biOutput.q_dense2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.biOutput.q_dense2.bias from model.bert.encoder.c_layer.1.biOutput.q_dense2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.v_intermediate.dense.weight from model.bert.encoder.c_layer.1.v_intermediate.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.v_intermediate.dense.bias from model.bert.encoder.c_layer.1.v_intermediate.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.v_output.dense.weight from model.bert.encoder.c_layer.1.v_output.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.v_output.dense.bias from model.bert.encoder.c_layer.1.v_output.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.v_output.LayerNorm.weight from model.bert.encoder.c_layer.1.v_output.LayerNorm.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.v_output.LayerNorm.bias from model.bert.encoder.c_layer.1.v_output.LayerNorm.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.t_intermediate.dense.weight from model.bert.encoder.c_layer.1.t_intermediate.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.t_intermediate.dense.bias from model.bert.encoder.c_layer.1.t_intermediate.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.t_output.dense.weight from model.bert.encoder.c_layer.1.t_output.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.t_output.dense.bias from model.bert.encoder.c_layer.1.t_output.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.t_output.LayerNorm.weight from model.bert.encoder.c_layer.1.t_output.LayerNorm.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.1.t_output.LayerNorm.bias from model.bert.encoder.c_layer.1.t_output.LayerNorm.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biattention.query1.weight from model.bert.encoder.c_layer.2.biattention.query1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biattention.query1.bias from model.bert.encoder.c_layer.2.biattention.query1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biattention.key1.weight from model.bert.encoder.c_layer.2.biattention.key1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biattention.key1.bias from model.bert.encoder.c_layer.2.biattention.key1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biattention.value1.weight from model.bert.encoder.c_layer.2.biattention.value1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biattention.value1.bias from model.bert.encoder.c_layer.2.biattention.value1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biattention.query2.weight from model.bert.encoder.c_layer.2.biattention.query2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biattention.query2.bias from model.bert.encoder.c_layer.2.biattention.query2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biattention.key2.weight from model.bert.encoder.c_layer.2.biattention.key2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biattention.key2.bias from model.bert.encoder.c_layer.2.biattention.key2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biattention.value2.weight from model.bert.encoder.c_layer.2.biattention.value2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biattention.value2.bias from model.bert.encoder.c_layer.2.biattention.value2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biOutput.dense1.weight from model.bert.encoder.c_layer.2.biOutput.dense1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biOutput.dense1.bias from model.bert.encoder.c_layer.2.biOutput.dense1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.2.biOutput.LayerNorm1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.2.biOutput.LayerNorm1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biOutput.q_dense1.weight from model.bert.encoder.c_layer.2.biOutput.q_dense1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biOutput.q_dense1.bias from model.bert.encoder.c_layer.2.biOutput.q_dense1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biOutput.dense2.weight from model.bert.encoder.c_layer.2.biOutput.dense2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biOutput.dense2.bias from model.bert.encoder.c_layer.2.biOutput.dense2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.2.biOutput.LayerNorm2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.2.biOutput.LayerNorm2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biOutput.q_dense2.weight from model.bert.encoder.c_layer.2.biOutput.q_dense2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.biOutput.q_dense2.bias from model.bert.encoder.c_layer.2.biOutput.q_dense2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.v_intermediate.dense.weight from model.bert.encoder.c_layer.2.v_intermediate.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.v_intermediate.dense.bias from model.bert.encoder.c_layer.2.v_intermediate.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.v_output.dense.weight from model.bert.encoder.c_layer.2.v_output.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.v_output.dense.bias from model.bert.encoder.c_layer.2.v_output.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.v_output.LayerNorm.weight from model.bert.encoder.c_layer.2.v_output.LayerNorm.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.v_output.LayerNorm.bias from model.bert.encoder.c_layer.2.v_output.LayerNorm.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.t_intermediate.dense.weight from model.bert.encoder.c_layer.2.t_intermediate.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.t_intermediate.dense.bias from model.bert.encoder.c_layer.2.t_intermediate.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.t_output.dense.weight from model.bert.encoder.c_layer.2.t_output.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.t_output.dense.bias from model.bert.encoder.c_layer.2.t_output.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.t_output.LayerNorm.weight from model.bert.encoder.c_layer.2.t_output.LayerNorm.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.2.t_output.LayerNorm.bias from model.bert.encoder.c_layer.2.t_output.LayerNorm.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biattention.query1.weight from model.bert.encoder.c_layer.3.biattention.query1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biattention.query1.bias from model.bert.encoder.c_layer.3.biattention.query1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biattention.key1.weight from model.bert.encoder.c_layer.3.biattention.key1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biattention.key1.bias from model.bert.encoder.c_layer.3.biattention.key1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biattention.value1.weight from model.bert.encoder.c_layer.3.biattention.value1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biattention.value1.bias from model.bert.encoder.c_layer.3.biattention.value1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biattention.query2.weight from model.bert.encoder.c_layer.3.biattention.query2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biattention.query2.bias from model.bert.encoder.c_layer.3.biattention.query2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biattention.key2.weight from model.bert.encoder.c_layer.3.biattention.key2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biattention.key2.bias from model.bert.encoder.c_layer.3.biattention.key2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biattention.value2.weight from model.bert.encoder.c_layer.3.biattention.value2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biattention.value2.bias from model.bert.encoder.c_layer.3.biattention.value2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biOutput.dense1.weight from model.bert.encoder.c_layer.3.biOutput.dense1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biOutput.dense1.bias from model.bert.encoder.c_layer.3.biOutput.dense1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.3.biOutput.LayerNorm1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.3.biOutput.LayerNorm1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biOutput.q_dense1.weight from model.bert.encoder.c_layer.3.biOutput.q_dense1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biOutput.q_dense1.bias from model.bert.encoder.c_layer.3.biOutput.q_dense1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biOutput.dense2.weight from model.bert.encoder.c_layer.3.biOutput.dense2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biOutput.dense2.bias from model.bert.encoder.c_layer.3.biOutput.dense2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.3.biOutput.LayerNorm2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.3.biOutput.LayerNorm2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biOutput.q_dense2.weight from model.bert.encoder.c_layer.3.biOutput.q_dense2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.biOutput.q_dense2.bias from model.bert.encoder.c_layer.3.biOutput.q_dense2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.v_intermediate.dense.weight from model.bert.encoder.c_layer.3.v_intermediate.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.v_intermediate.dense.bias from model.bert.encoder.c_layer.3.v_intermediate.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.v_output.dense.weight from model.bert.encoder.c_layer.3.v_output.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.v_output.dense.bias from model.bert.encoder.c_layer.3.v_output.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.v_output.LayerNorm.weight from model.bert.encoder.c_layer.3.v_output.LayerNorm.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.v_output.LayerNorm.bias from model.bert.encoder.c_layer.3.v_output.LayerNorm.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.t_intermediate.dense.weight from model.bert.encoder.c_layer.3.t_intermediate.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.t_intermediate.dense.bias from model.bert.encoder.c_layer.3.t_intermediate.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.t_output.dense.weight from model.bert.encoder.c_layer.3.t_output.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.t_output.dense.bias from model.bert.encoder.c_layer.3.t_output.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.t_output.LayerNorm.weight from model.bert.encoder.c_layer.3.t_output.LayerNorm.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.3.t_output.LayerNorm.bias from model.bert.encoder.c_layer.3.t_output.LayerNorm.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biattention.query1.weight from model.bert.encoder.c_layer.4.biattention.query1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biattention.query1.bias from model.bert.encoder.c_layer.4.biattention.query1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biattention.key1.weight from model.bert.encoder.c_layer.4.biattention.key1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biattention.key1.bias from model.bert.encoder.c_layer.4.biattention.key1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biattention.value1.weight from model.bert.encoder.c_layer.4.biattention.value1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biattention.value1.bias from model.bert.encoder.c_layer.4.biattention.value1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biattention.query2.weight from model.bert.encoder.c_layer.4.biattention.query2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biattention.query2.bias from model.bert.encoder.c_layer.4.biattention.query2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biattention.key2.weight from model.bert.encoder.c_layer.4.biattention.key2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biattention.key2.bias from model.bert.encoder.c_layer.4.biattention.key2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biattention.value2.weight from model.bert.encoder.c_layer.4.biattention.value2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biattention.value2.bias from model.bert.encoder.c_layer.4.biattention.value2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biOutput.dense1.weight from model.bert.encoder.c_layer.4.biOutput.dense1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biOutput.dense1.bias from model.bert.encoder.c_layer.4.biOutput.dense1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.4.biOutput.LayerNorm1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.4.biOutput.LayerNorm1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biOutput.q_dense1.weight from model.bert.encoder.c_layer.4.biOutput.q_dense1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biOutput.q_dense1.bias from model.bert.encoder.c_layer.4.biOutput.q_dense1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biOutput.dense2.weight from model.bert.encoder.c_layer.4.biOutput.dense2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biOutput.dense2.bias from model.bert.encoder.c_layer.4.biOutput.dense2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.4.biOutput.LayerNorm2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.4.biOutput.LayerNorm2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biOutput.q_dense2.weight from model.bert.encoder.c_layer.4.biOutput.q_dense2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.biOutput.q_dense2.bias from model.bert.encoder.c_layer.4.biOutput.q_dense2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.v_intermediate.dense.weight from model.bert.encoder.c_layer.4.v_intermediate.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.v_intermediate.dense.bias from model.bert.encoder.c_layer.4.v_intermediate.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.v_output.dense.weight from model.bert.encoder.c_layer.4.v_output.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.v_output.dense.bias from model.bert.encoder.c_layer.4.v_output.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.v_output.LayerNorm.weight from model.bert.encoder.c_layer.4.v_output.LayerNorm.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.v_output.LayerNorm.bias from model.bert.encoder.c_layer.4.v_output.LayerNorm.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.t_intermediate.dense.weight from model.bert.encoder.c_layer.4.t_intermediate.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.t_intermediate.dense.bias from model.bert.encoder.c_layer.4.t_intermediate.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.t_output.dense.weight from model.bert.encoder.c_layer.4.t_output.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.t_output.dense.bias from model.bert.encoder.c_layer.4.t_output.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.t_output.LayerNorm.weight from model.bert.encoder.c_layer.4.t_output.LayerNorm.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.4.t_output.LayerNorm.bias from model.bert.encoder.c_layer.4.t_output.LayerNorm.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biattention.query1.weight from model.bert.encoder.c_layer.5.biattention.query1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biattention.query1.bias from model.bert.encoder.c_layer.5.biattention.query1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biattention.key1.weight from model.bert.encoder.c_layer.5.biattention.key1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biattention.key1.bias from model.bert.encoder.c_layer.5.biattention.key1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biattention.value1.weight from model.bert.encoder.c_layer.5.biattention.value1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biattention.value1.bias from model.bert.encoder.c_layer.5.biattention.value1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biattention.query2.weight from model.bert.encoder.c_layer.5.biattention.query2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biattention.query2.bias from model.bert.encoder.c_layer.5.biattention.query2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biattention.key2.weight from model.bert.encoder.c_layer.5.biattention.key2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biattention.key2.bias from model.bert.encoder.c_layer.5.biattention.key2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biattention.value2.weight from model.bert.encoder.c_layer.5.biattention.value2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biattention.value2.bias from model.bert.encoder.c_layer.5.biattention.value2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biOutput.dense1.weight from model.bert.encoder.c_layer.5.biOutput.dense1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biOutput.dense1.bias from model.bert.encoder.c_layer.5.biOutput.dense1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.5.biOutput.LayerNorm1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.5.biOutput.LayerNorm1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biOutput.q_dense1.weight from model.bert.encoder.c_layer.5.biOutput.q_dense1.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biOutput.q_dense1.bias from model.bert.encoder.c_layer.5.biOutput.q_dense1.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biOutput.dense2.weight from model.bert.encoder.c_layer.5.biOutput.dense2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biOutput.dense2.bias from model.bert.encoder.c_layer.5.biOutput.dense2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.5.biOutput.LayerNorm2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.5.biOutput.LayerNorm2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biOutput.q_dense2.weight from model.bert.encoder.c_layer.5.biOutput.q_dense2.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.biOutput.q_dense2.bias from model.bert.encoder.c_layer.5.biOutput.q_dense2.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.v_intermediate.dense.weight from model.bert.encoder.c_layer.5.v_intermediate.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.v_intermediate.dense.bias from model.bert.encoder.c_layer.5.v_intermediate.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.v_output.dense.weight from model.bert.encoder.c_layer.5.v_output.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.v_output.dense.bias from model.bert.encoder.c_layer.5.v_output.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.v_output.LayerNorm.weight from model.bert.encoder.c_layer.5.v_output.LayerNorm.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.v_output.LayerNorm.bias from model.bert.encoder.c_layer.5.v_output.LayerNorm.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.t_intermediate.dense.weight from model.bert.encoder.c_layer.5.t_intermediate.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.t_intermediate.dense.bias from model.bert.encoder.c_layer.5.t_intermediate.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.t_output.dense.weight from model.bert.encoder.c_layer.5.t_output.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.t_output.dense.bias from model.bert.encoder.c_layer.5.t_output.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.t_output.LayerNorm.weight from model.bert.encoder.c_layer.5.t_output.LayerNorm.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.encoder.c_layer.5.t_output.LayerNorm.bias from model.bert.encoder.c_layer.5.t_output.LayerNorm.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.t_pooler.dense.weight from model.bert.t_pooler.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.t_pooler.dense.bias from model.bert.t_pooler.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.v_pooler.dense.weight from model.bert.v_pooler.dense.weight
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCopying model.bert.v_pooler.dense.bias from model.bert.v_pooler.dense.bias
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mPretrained model loaded
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCheckpoint loaded.
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCurrent num updates: 0
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCurrent iteration: 0
[32m2021-03-04T04:28:11 | mmf.utils.checkpoint: [0mCurrent epoch: 0
[32m2021-03-04T04:28:11 | mmf.trainers.mmf_trainer: [0m===== Model =====
[32m2021-03-04T04:28:11 | mmf.trainers.mmf_trainer: [0mDistributedDataParallel(
  (module): ViLBERT(
    (model): ViLBERTForClassification(
      (bert): ViLBERTBase(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_embeddings): BertImageFeatureEmbeddings(
          (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)
          (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)
          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (v_layer): ModuleList(
            (0): BertImageLayer(
              (attention): BertImageAttention(
                (self): BertImageSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertImageSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertImageLayer(
              (attention): BertImageAttention(
                (self): BertImageSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertImageSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertImageLayer(
              (attention): BertImageAttention(
                (self): BertImageSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertImageSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertImageLayer(
              (attention): BertImageAttention(
                (self): BertImageSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertImageSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertImageLayer(
              (attention): BertImageAttention(
                (self): BertImageSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertImageSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertImageLayer(
              (attention): BertImageAttention(
                (self): BertImageSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertImageSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (c_layer): ModuleList(
            (0): BertConnectionLayer(
              (biattention): BertBiAttention(
                (query1): Linear(in_features=1024, out_features=1024, bias=True)
                (key1): Linear(in_features=1024, out_features=1024, bias=True)
                (value1): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (query2): Linear(in_features=768, out_features=1024, bias=True)
                (key2): Linear(in_features=768, out_features=1024, bias=True)
                (value2): Linear(in_features=768, out_features=1024, bias=True)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
              (biOutput): BertBiOutput(
                (dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (q_dropout1): Dropout(p=0.1, inplace=False)
                (dense2): Linear(in_features=1024, out_features=768, bias=True)
                (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout2): Dropout(p=0.1, inplace=False)
                (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
                (q_dropout2): Dropout(p=0.1, inplace=False)
              )
              (v_intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (v_output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (t_intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (t_output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertConnectionLayer(
              (biattention): BertBiAttention(
                (query1): Linear(in_features=1024, out_features=1024, bias=True)
                (key1): Linear(in_features=1024, out_features=1024, bias=True)
                (value1): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (query2): Linear(in_features=768, out_features=1024, bias=True)
                (key2): Linear(in_features=768, out_features=1024, bias=True)
                (value2): Linear(in_features=768, out_features=1024, bias=True)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
              (biOutput): BertBiOutput(
                (dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (q_dropout1): Dropout(p=0.1, inplace=False)
                (dense2): Linear(in_features=1024, out_features=768, bias=True)
                (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout2): Dropout(p=0.1, inplace=False)
                (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
                (q_dropout2): Dropout(p=0.1, inplace=False)
              )
              (v_intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (v_output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (t_intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (t_output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertConnectionLayer(
              (biattention): BertBiAttention(
                (query1): Linear(in_features=1024, out_features=1024, bias=True)
                (key1): Linear(in_features=1024, out_features=1024, bias=True)
                (value1): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (query2): Linear(in_features=768, out_features=1024, bias=True)
                (key2): Linear(in_features=768, out_features=1024, bias=True)
                (value2): Linear(in_features=768, out_features=1024, bias=True)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
              (biOutput): BertBiOutput(
                (dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (q_dropout1): Dropout(p=0.1, inplace=False)
                (dense2): Linear(in_features=1024, out_features=768, bias=True)
                (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout2): Dropout(p=0.1, inplace=False)
                (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
                (q_dropout2): Dropout(p=0.1, inplace=False)
              )
              (v_intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (v_output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (t_intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (t_output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertConnectionLayer(
              (biattention): BertBiAttention(
                (query1): Linear(in_features=1024, out_features=1024, bias=True)
                (key1): Linear(in_features=1024, out_features=1024, bias=True)
                (value1): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (query2): Linear(in_features=768, out_features=1024, bias=True)
                (key2): Linear(in_features=768, out_features=1024, bias=True)
                (value2): Linear(in_features=768, out_features=1024, bias=True)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
              (biOutput): BertBiOutput(
                (dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (q_dropout1): Dropout(p=0.1, inplace=False)
                (dense2): Linear(in_features=1024, out_features=768, bias=True)
                (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout2): Dropout(p=0.1, inplace=False)
                (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
                (q_dropout2): Dropout(p=0.1, inplace=False)
              )
              (v_intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (v_output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (t_intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (t_output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertConnectionLayer(
              (biattention): BertBiAttention(
                (query1): Linear(in_features=1024, out_features=1024, bias=True)
                (key1): Linear(in_features=1024, out_features=1024, bias=True)
                (value1): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (query2): Linear(in_features=768, out_features=1024, bias=True)
                (key2): Linear(in_features=768, out_features=1024, bias=True)
                (value2): Linear(in_features=768, out_features=1024, bias=True)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
              (biOutput): BertBiOutput(
                (dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (q_dropout1): Dropout(p=0.1, inplace=False)
                (dense2): Linear(in_features=1024, out_features=768, bias=True)
                (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout2): Dropout(p=0.1, inplace=False)
                (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
                (q_dropout2): Dropout(p=0.1, inplace=False)
              )
              (v_intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (v_output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (t_intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (t_output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertConnectionLayer(
              (biattention): BertBiAttention(
                (query1): Linear(in_features=1024, out_features=1024, bias=True)
                (key1): Linear(in_features=1024, out_features=1024, bias=True)
                (value1): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (query2): Linear(in_features=768, out_features=1024, bias=True)
                (key2): Linear(in_features=768, out_features=1024, bias=True)
                (value2): Linear(in_features=768, out_features=1024, bias=True)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
              (biOutput): BertBiOutput(
                (dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (q_dropout1): Dropout(p=0.1, inplace=False)
                (dense2): Linear(in_features=1024, out_features=768, bias=True)
                (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout2): Dropout(p=0.1, inplace=False)
                (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
                (q_dropout2): Dropout(p=0.1, inplace=False)
              )
              (v_intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (v_output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (t_intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (t_output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (t_pooler): BertTextPooler(
          (dense): Linear(in_features=768, out_features=1024, bias=True)
          (activation): ReLU()
        )
        (v_pooler): BertImagePooler(
          (dense): Linear(in_features=1024, out_features=1024, bias=True)
          (activation): ReLU()
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
      (classifier): Sequential(
        (0): BertPredictionHeadTransform(
          (dense): Linear(in_features=1024, out_features=1024, bias=True)
          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        )
        (1): Linear(in_features=1024, out_features=2, bias=True)
      )
    )
    (losses): Losses(
      (losses): ModuleList(
        (0): MMFLoss(
          (loss_criterion): CrossEntropyLoss(
            (loss_fn): CrossEntropyLoss()
          )
        )
      )
    )
  )
)
[32m2021-03-04T04:28:11 | mmf.utils.general: [0mTotal Parameters: 247780354. Trained Parameters: 247780354
[32m2021-03-04T04:28:11 | mmf.trainers.core.training_loop: [0mStarting training...

[32m2021-03-04T04:29:12 | mmf.trainers.callbacks.logistics: [0mprogress: 100/22000, train/hateful_memes/cross_entropy: 0.7386, train/hateful_memes/cross_entropy/avg: 0.7386, train/total_loss: 0.7386, train/total_loss/avg: 0.7386, max mem: 6431.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 578ms, time_since_start: 02m 34s 160ms, eta: 03h 45m 12s 589ms
[32m2021-03-04T04:30:02 | mmf.trainers.callbacks.logistics: [0mprogress: 200/22000, train/hateful_memes/cross_entropy: 0.7386, train/hateful_memes/cross_entropy/avg: 0.7808, train/total_loss: 0.7386, train/total_loss/avg: 0.7808, max mem: 6431.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 272ms, time_since_start: 03m 23s 433ms, eta: 02h 59m 22s 990ms
[32m2021-03-04T04:31:03 | mmf.trainers.callbacks.logistics: [0mprogress: 300/22000, train/hateful_memes/cross_entropy: 0.7386, train/hateful_memes/cross_entropy/avg: 0.7306, train/total_loss: 0.7386, train/total_loss/avg: 0.7306, max mem: 6431.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 014ms, time_since_start: 04m 24s 447ms, eta: 03h 41m 06s 648ms
[32m2021-03-04T04:31:52 | mmf.trainers.callbacks.logistics: [0mprogress: 400/22000, train/hateful_memes/cross_entropy: 0.7386, train/hateful_memes/cross_entropy/avg: 0.7343, train/total_loss: 0.7386, train/total_loss/avg: 0.7343, max mem: 6431.0, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 476ms, time_since_start: 05m 13s 924ms, eta: 02h 58m 28s 255ms
[32m2021-03-04T04:32:42 | mmf.trainers.callbacks.logistics: [0mprogress: 500/22000, train/hateful_memes/cross_entropy: 0.7386, train/hateful_memes/cross_entropy/avg: 0.6853, train/total_loss: 0.7386, train/total_loss/avg: 0.6853, max mem: 6431.0, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 666ms, time_since_start: 06m 03s 590ms, eta: 02h 58m 19s 694ms
[32m2021-03-04T04:33:42 | mmf.trainers.callbacks.logistics: [0mprogress: 600/22000, train/hateful_memes/cross_entropy: 0.6303, train/hateful_memes/cross_entropy/avg: 0.6540, train/total_loss: 0.6303, train/total_loss/avg: 0.6540, max mem: 6431.0, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 313ms, time_since_start: 07m 03s 904ms, eta: 03h 35m 32s 937ms
[32m2021-03-04T04:34:32 | mmf.trainers.callbacks.logistics: [0mprogress: 700/22000, train/hateful_memes/cross_entropy: 0.6303, train/hateful_memes/cross_entropy/avg: 0.6482, train/total_loss: 0.6303, train/total_loss/avg: 0.6482, max mem: 6431.0, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 891ms, time_since_start: 07m 53s 795ms, eta: 02h 57m 28s 045ms
[32m2021-03-04T04:35:33 | mmf.trainers.callbacks.logistics: [0mprogress: 800/22000, train/hateful_memes/cross_entropy: 0.6132, train/hateful_memes/cross_entropy/avg: 0.6389, train/total_loss: 0.6132, train/total_loss/avg: 0.6389, max mem: 6431.0, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 840ms, time_since_start: 08m 54s 636ms, eta: 03h 35m 23s 993ms
[32m2021-03-04T04:36:22 | mmf.trainers.callbacks.logistics: [0mprogress: 900/22000, train/hateful_memes/cross_entropy: 0.6132, train/hateful_memes/cross_entropy/avg: 0.6253, train/total_loss: 0.6132, train/total_loss/avg: 0.6253, max mem: 6431.0, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 762ms, time_since_start: 09m 43s 399ms, eta: 02h 51m 49s 535ms
[32m2021-03-04T04:37:11 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T04:37:11 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T04:37:11 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T04:37:11 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T04:37:17 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T04:37:49 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T04:37:49 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, train/hateful_memes/cross_entropy: 0.5738, train/hateful_memes/cross_entropy/avg: 0.6055, train/total_loss: 0.5738, train/total_loss/avg: 0.6055, max mem: 6431.0, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00001, ups: 1.15, time: 01m 27s 746ms, time_since_start: 11m 11s 145ms, eta: 05h 07m 43s 533ms
[32m2021-03-04T04:37:49 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T04:38:07 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T04:38:07 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T04:38:07 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T04:38:07 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T04:38:29 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T04:38:52 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T04:39:14 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T04:39:14 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, val/hateful_memes/cross_entropy: 0.7880, val/total_loss: 0.7880, val/hateful_memes/accuracy: 0.6315, val/hateful_memes/binary_f1: 0.3261, val/hateful_memes/roc_auc: 0.6046, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 22000, val_time: 01m 24s 906ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.604615
[32m2021-03-04T04:40:15 | mmf.trainers.callbacks.logistics: [0mprogress: 1100/22000, train/hateful_memes/cross_entropy: 0.5738, train/hateful_memes/cross_entropy/avg: 0.5848, train/total_loss: 0.5738, train/total_loss/avg: 0.5848, max mem: 6431.0, experiment: run, epoch: 5, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 585ms, time_since_start: 13m 36s 657ms, eta: 03h 31m 27s 691ms
[32m2021-03-04T04:41:05 | mmf.trainers.callbacks.logistics: [0mprogress: 1200/22000, train/hateful_memes/cross_entropy: 0.5168, train/hateful_memes/cross_entropy/avg: 0.5528, train/total_loss: 0.5168, train/total_loss/avg: 0.5528, max mem: 6431.0, experiment: run, epoch: 5, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 879ms, time_since_start: 14m 26s 537ms, eta: 02h 53m 15s 665ms
[32m2021-03-04T04:41:55 | mmf.trainers.callbacks.logistics: [0mprogress: 1300/22000, train/hateful_memes/cross_entropy: 0.5168, train/hateful_memes/cross_entropy/avg: 0.5321, train/total_loss: 0.5168, train/total_loss/avg: 0.5321, max mem: 6431.0, experiment: run, epoch: 5, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 956ms, time_since_start: 15m 16s 493ms, eta: 02h 52m 41s 591ms
[32m2021-03-04T04:42:54 | mmf.trainers.callbacks.logistics: [0mprogress: 1400/22000, train/hateful_memes/cross_entropy: 0.4975, train/hateful_memes/cross_entropy/avg: 0.5139, train/total_loss: 0.4975, train/total_loss/avg: 0.5139, max mem: 6431.0, experiment: run, epoch: 6, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 098ms, time_since_start: 16m 15s 591ms, eta: 03h 23m 18s 620ms
[32m2021-03-04T04:43:42 | mmf.trainers.callbacks.logistics: [0mprogress: 1500/22000, train/hateful_memes/cross_entropy: 0.4975, train/hateful_memes/cross_entropy/avg: 0.5027, train/total_loss: 0.4975, train/total_loss/avg: 0.5027, max mem: 6431.0, experiment: run, epoch: 6, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 370ms, time_since_start: 17m 03s 962ms, eta: 02h 45m 35s 752ms
[32m2021-03-04T04:44:41 | mmf.trainers.callbacks.logistics: [0mprogress: 1600/22000, train/hateful_memes/cross_entropy: 0.4896, train/hateful_memes/cross_entropy/avg: 0.4832, train/total_loss: 0.4896, train/total_loss/avg: 0.4832, max mem: 6431.0, experiment: run, epoch: 7, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00001, ups: 1.72, time: 58s 878ms, time_since_start: 18m 02s 840ms, eta: 03h 20m 35s 261ms
[32m2021-03-04T04:45:29 | mmf.trainers.callbacks.logistics: [0mprogress: 1700/22000, train/hateful_memes/cross_entropy: 0.4896, train/hateful_memes/cross_entropy/avg: 0.4606, train/total_loss: 0.4896, train/total_loss/avg: 0.4606, max mem: 6431.0, experiment: run, epoch: 7, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 005ms, time_since_start: 18m 50s 845ms, eta: 02h 42m 44s 543ms
[32m2021-03-04T04:46:17 | mmf.trainers.callbacks.logistics: [0mprogress: 1800/22000, train/hateful_memes/cross_entropy: 0.4271, train/hateful_memes/cross_entropy/avg: 0.4493, train/total_loss: 0.4271, train/total_loss/avg: 0.4493, max mem: 6431.0, experiment: run, epoch: 7, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 295ms, time_since_start: 19m 39s 141ms, eta: 02h 42m 55s 304ms
[32m2021-03-04T04:47:16 | mmf.trainers.callbacks.logistics: [0mprogress: 1900/22000, train/hateful_memes/cross_entropy: 0.4271, train/hateful_memes/cross_entropy/avg: 0.4296, train/total_loss: 0.4271, train/total_loss/avg: 0.4296, max mem: 6431.0, experiment: run, epoch: 8, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00001, ups: 1.72, time: 58s 968ms, time_since_start: 20m 38s 110ms, eta: 03h 17m 56s 318ms
[32m2021-03-04T04:48:05 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T04:48:05 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T04:48:05 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T04:48:05 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T04:48:11 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T04:48:40 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T04:48:40 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, train/hateful_memes/cross_entropy: 0.3776, train/hateful_memes/cross_entropy/avg: 0.4233, train/total_loss: 0.3776, train/total_loss/avg: 0.4233, max mem: 6431.0, experiment: run, epoch: 8, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00001, ups: 1.20, time: 01m 23s 651ms, time_since_start: 22m 01s 762ms, eta: 04h 39m 23s 853ms
[32m2021-03-04T04:48:40 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T04:48:57 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T04:48:57 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T04:48:57 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T04:48:57 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T04:49:20 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T04:49:43 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T04:50:06 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T04:50:06 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, val/hateful_memes/cross_entropy: 1.0219, val/total_loss: 1.0219, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.4477, val/hateful_memes/roc_auc: 0.6845, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 22000, val_time: 01m 25s 611ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.684480
[32m2021-03-04T04:50:55 | mmf.trainers.callbacks.logistics: [0mprogress: 2100/22000, train/hateful_memes/cross_entropy: 0.3458, train/hateful_memes/cross_entropy/avg: 0.4146, train/total_loss: 0.3458, train/total_loss/avg: 0.4146, max mem: 6431.0, experiment: run, epoch: 8, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 098ms, time_since_start: 24m 16s 489ms, eta: 02h 43m 10s 062ms
[32m2021-03-04T04:51:55 | mmf.trainers.callbacks.logistics: [0mprogress: 2200/22000, train/hateful_memes/cross_entropy: 0.3033, train/hateful_memes/cross_entropy/avg: 0.3993, train/total_loss: 0.3033, train/total_loss/avg: 0.3993, max mem: 6431.0, experiment: run, epoch: 9, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 310ms, time_since_start: 25m 16s 800ms, eta: 03h 19m 25s 336ms
[32m2021-03-04T04:52:45 | mmf.trainers.callbacks.logistics: [0mprogress: 2300/22000, train/hateful_memes/cross_entropy: 0.2840, train/hateful_memes/cross_entropy/avg: 0.3853, train/total_loss: 0.2840, train/total_loss/avg: 0.3853, max mem: 6431.0, experiment: run, epoch: 9, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 536ms, time_since_start: 26m 06s 336ms, eta: 02h 42m 58s 142ms
[32m2021-03-04T04:53:44 | mmf.trainers.callbacks.logistics: [0mprogress: 2400/22000, train/hateful_memes/cross_entropy: 0.2771, train/hateful_memes/cross_entropy/avg: 0.3700, train/total_loss: 0.2771, train/total_loss/avg: 0.3700, max mem: 6431.0, experiment: run, epoch: 10, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 824ms, time_since_start: 27m 06s 161ms, eta: 03h 15m 49s 081ms
[32m2021-03-04T04:54:33 | mmf.trainers.callbacks.logistics: [0mprogress: 2500/22000, train/hateful_memes/cross_entropy: 0.2566, train/hateful_memes/cross_entropy/avg: 0.3574, train/total_loss: 0.2566, train/total_loss/avg: 0.3574, max mem: 6431.0, experiment: run, epoch: 10, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 208ms, time_since_start: 27m 54s 369ms, eta: 02h 36m 59s 368ms
[32m2021-03-04T04:55:21 | mmf.trainers.callbacks.logistics: [0mprogress: 2600/22000, train/hateful_memes/cross_entropy: 0.2398, train/hateful_memes/cross_entropy/avg: 0.3450, train/total_loss: 0.2398, train/total_loss/avg: 0.3450, max mem: 6431.0, experiment: run, epoch: 10, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 376ms, time_since_start: 28m 42s 746ms, eta: 02h 36m 43s 872ms
[32m2021-03-04T04:56:20 | mmf.trainers.callbacks.logistics: [0mprogress: 2700/22000, train/hateful_memes/cross_entropy: 0.2010, train/hateful_memes/cross_entropy/avg: 0.3330, train/total_loss: 0.2010, train/total_loss/avg: 0.3330, max mem: 6431.0, experiment: run, epoch: 11, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 355ms, time_since_start: 29m 42s 101ms, eta: 03h 11m 18s 459ms
[32m2021-03-04T04:57:10 | mmf.trainers.callbacks.logistics: [0mprogress: 2800/22000, train/hateful_memes/cross_entropy: 0.1900, train/hateful_memes/cross_entropy/avg: 0.3214, train/total_loss: 0.1900, train/total_loss/avg: 0.3214, max mem: 6431.0, experiment: run, epoch: 11, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 315ms, time_since_start: 30m 31s 417ms, eta: 02h 38m 07s 594ms
[32m2021-03-04T04:57:59 | mmf.trainers.callbacks.logistics: [0mprogress: 2900/22000, train/hateful_memes/cross_entropy: 0.1204, train/hateful_memes/cross_entropy/avg: 0.3145, train/total_loss: 0.1204, train/total_loss/avg: 0.3145, max mem: 6431.0, experiment: run, epoch: 11, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 437ms, time_since_start: 31m 20s 854ms, eta: 02h 37m 41s 367ms
[32m2021-03-04T04:58:59 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T04:58:59 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T04:58:59 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T04:58:59 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T04:59:04 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T04:59:41 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T04:59:41 | mmf.trainers.callbacks.logistics: [0mprogress: 3000/22000, train/hateful_memes/cross_entropy: 0.1006, train/hateful_memes/cross_entropy/avg: 0.3048, train/total_loss: 0.1006, train/total_loss/avg: 0.3048, max mem: 6431.0, experiment: run, epoch: 12, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00001, ups: 0.99, time: 01m 41s 610ms, time_since_start: 33m 02s 464ms, eta: 05h 22m 24s 586ms
[32m2021-03-04T04:59:41 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T04:59:58 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T04:59:58 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T04:59:58 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T04:59:58 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T05:00:21 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T05:00:44 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T05:00:44 | mmf.trainers.callbacks.logistics: [0mprogress: 3000/22000, val/hateful_memes/cross_entropy: 1.5030, val/total_loss: 1.5030, val/hateful_memes/accuracy: 0.6704, val/hateful_memes/binary_f1: 0.4383, val/hateful_memes/roc_auc: 0.6832, num_updates: 3000, epoch: 12, iterations: 3000, max_updates: 22000, val_time: 01m 03s 313ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.684480
[32m2021-03-04T05:01:33 | mmf.trainers.callbacks.logistics: [0mprogress: 3100/22000, train/hateful_memes/cross_entropy: 0.0784, train/hateful_memes/cross_entropy/avg: 0.2952, train/total_loss: 0.0784, train/total_loss/avg: 0.2952, max mem: 6431.0, experiment: run, epoch: 12, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 598ms, time_since_start: 34m 54s 393ms, eta: 02h 33m 23s 503ms
[32m2021-03-04T05:02:33 | mmf.trainers.callbacks.logistics: [0mprogress: 3200/22000, train/hateful_memes/cross_entropy: 0.0777, train/hateful_memes/cross_entropy/avg: 0.2863, train/total_loss: 0.0777, train/total_loss/avg: 0.2863, max mem: 6431.0, experiment: run, epoch: 13, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 026ms, time_since_start: 35m 54s 419ms, eta: 03h 08m 27s 568ms
[32m2021-03-04T05:03:24 | mmf.trainers.callbacks.logistics: [0mprogress: 3300/22000, train/hateful_memes/cross_entropy: 0.0749, train/hateful_memes/cross_entropy/avg: 0.2778, train/total_loss: 0.0749, train/total_loss/avg: 0.2778, max mem: 6431.0, experiment: run, epoch: 13, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 791ms, time_since_start: 36m 46s 210ms, eta: 02h 41m 44s 329ms
[32m2021-03-04T05:04:16 | mmf.trainers.callbacks.logistics: [0mprogress: 3400/22000, train/hateful_memes/cross_entropy: 0.0565, train/hateful_memes/cross_entropy/avg: 0.2698, train/total_loss: 0.0565, train/total_loss/avg: 0.2698, max mem: 6431.0, experiment: run, epoch: 13, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 997ms, time_since_start: 37m 38s 208ms, eta: 02h 41m 30s 824ms
[32m2021-03-04T05:05:18 | mmf.trainers.callbacks.logistics: [0mprogress: 3500/22000, train/hateful_memes/cross_entropy: 0.0353, train/hateful_memes/cross_entropy/avg: 0.2622, train/total_loss: 0.0353, train/total_loss/avg: 0.2622, max mem: 6431.0, experiment: run, epoch: 14, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 310ms, time_since_start: 38m 39s 518ms, eta: 03h 09m 25s 089ms
[32m2021-03-04T05:06:07 | mmf.trainers.callbacks.logistics: [0mprogress: 3600/22000, train/hateful_memes/cross_entropy: 0.0218, train/hateful_memes/cross_entropy/avg: 0.2550, train/total_loss: 0.0218, train/total_loss/avg: 0.2550, max mem: 6431.0, experiment: run, epoch: 14, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 034ms, time_since_start: 39m 28s 553ms, eta: 02h 30m 40s 464ms
[32m2021-03-04T05:06:56 | mmf.trainers.callbacks.logistics: [0mprogress: 3700/22000, train/hateful_memes/cross_entropy: 0.0198, train/hateful_memes/cross_entropy/avg: 0.2482, train/total_loss: 0.0198, train/total_loss/avg: 0.2482, max mem: 6431.0, experiment: run, epoch: 14, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 254ms, time_since_start: 40m 17s 808ms, eta: 02h 30m 31s 662ms
[32m2021-03-04T05:07:56 | mmf.trainers.callbacks.logistics: [0mprogress: 3800/22000, train/hateful_memes/cross_entropy: 0.0177, train/hateful_memes/cross_entropy/avg: 0.2420, train/total_loss: 0.0177, train/total_loss/avg: 0.2420, max mem: 6431.0, experiment: run, epoch: 15, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 782ms, time_since_start: 41m 17s 591ms, eta: 03h 01m 42s 259ms
[32m2021-03-04T05:08:45 | mmf.trainers.callbacks.logistics: [0mprogress: 3900/22000, train/hateful_memes/cross_entropy: 0.0117, train/hateful_memes/cross_entropy/avg: 0.2359, train/total_loss: 0.0117, train/total_loss/avg: 0.2359, max mem: 6431.0, experiment: run, epoch: 15, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 276ms, time_since_start: 42m 06s 867ms, eta: 02h 28m 56s 860ms
[32m2021-03-04T05:09:45 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T05:09:45 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T05:09:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T05:09:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T05:09:51 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T05:10:27 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T05:10:27 | mmf.trainers.callbacks.logistics: [0mprogress: 4000/22000, train/hateful_memes/cross_entropy: 0.0102, train/hateful_memes/cross_entropy/avg: 0.2300, train/total_loss: 0.0102, train/total_loss/avg: 0.2300, max mem: 6431.0, experiment: run, epoch: 16, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00001, ups: 0.98, time: 01m 42s 300ms, time_since_start: 43m 49s 167ms, eta: 05h 07m 30s 837ms
[32m2021-03-04T05:10:27 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T05:10:44 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T05:10:44 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T05:10:44 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T05:10:44 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T05:11:08 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T05:11:30 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T05:11:53 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T05:11:53 | mmf.trainers.callbacks.logistics: [0mprogress: 4000/22000, val/hateful_memes/cross_entropy: 1.6220, val/total_loss: 1.6220, val/hateful_memes/accuracy: 0.6796, val/hateful_memes/binary_f1: 0.4930, val/hateful_memes/roc_auc: 0.6948, num_updates: 4000, epoch: 16, iterations: 4000, max_updates: 22000, val_time: 01m 25s 240ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.694761
[32m2021-03-04T05:12:42 | mmf.trainers.callbacks.logistics: [0mprogress: 4100/22000, train/hateful_memes/cross_entropy: 0.0102, train/hateful_memes/cross_entropy/avg: 0.2249, train/total_loss: 0.0102, train/total_loss/avg: 0.2249, max mem: 6431.0, experiment: run, epoch: 16, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 606ms, time_since_start: 46m 04s 032ms, eta: 02h 28m 17s 336ms
[32m2021-03-04T05:13:32 | mmf.trainers.callbacks.logistics: [0mprogress: 4200/22000, train/hateful_memes/cross_entropy: 0.0093, train/hateful_memes/cross_entropy/avg: 0.2196, train/total_loss: 0.0093, train/total_loss/avg: 0.2196, max mem: 6431.0, experiment: run, epoch: 16, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 395ms, time_since_start: 46m 53s 428ms, eta: 02h 26m 50s 038ms
[32m2021-03-04T05:14:32 | mmf.trainers.callbacks.logistics: [0mprogress: 4300/22000, train/hateful_memes/cross_entropy: 0.0093, train/hateful_memes/cross_entropy/avg: 0.2161, train/total_loss: 0.0093, train/total_loss/avg: 0.2161, max mem: 6431.0, experiment: run, epoch: 17, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 509ms, time_since_start: 47m 53s 937ms, eta: 02h 58m 51s 636ms
[32m2021-03-04T05:15:22 | mmf.trainers.callbacks.logistics: [0mprogress: 4400/22000, train/hateful_memes/cross_entropy: 0.0092, train/hateful_memes/cross_entropy/avg: 0.2112, train/total_loss: 0.0092, train/total_loss/avg: 0.2112, max mem: 6431.0, experiment: run, epoch: 17, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 445ms, time_since_start: 48m 43s 383ms, eta: 02h 25m 19s 748ms
[32m2021-03-04T05:16:11 | mmf.trainers.callbacks.logistics: [0mprogress: 4500/22000, train/hateful_memes/cross_entropy: 0.0068, train/hateful_memes/cross_entropy/avg: 0.2066, train/total_loss: 0.0068, train/total_loss/avg: 0.2066, max mem: 6431.0, experiment: run, epoch: 17, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 355ms, time_since_start: 49m 32s 738ms, eta: 02h 24m 14s 540ms
[32m2021-03-04T05:17:11 | mmf.trainers.callbacks.logistics: [0mprogress: 4600/22000, train/hateful_memes/cross_entropy: 0.0060, train/hateful_memes/cross_entropy/avg: 0.2021, train/total_loss: 0.0060, train/total_loss/avg: 0.2021, max mem: 6431.0, experiment: run, epoch: 18, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 756ms, time_since_start: 50m 32s 495ms, eta: 02h 53m 38s 472ms
[32m2021-03-04T05:18:00 | mmf.trainers.callbacks.logistics: [0mprogress: 4700/22000, train/hateful_memes/cross_entropy: 0.0053, train/hateful_memes/cross_entropy/avg: 0.1979, train/total_loss: 0.0053, train/total_loss/avg: 0.1979, max mem: 6431.0, experiment: run, epoch: 18, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 963ms, time_since_start: 51m 21s 459ms, eta: 02h 21m 27s 653ms
[32m2021-03-04T05:18:59 | mmf.trainers.callbacks.logistics: [0mprogress: 4800/22000, train/hateful_memes/cross_entropy: 0.0053, train/hateful_memes/cross_entropy/avg: 0.1941, train/total_loss: 0.0053, train/total_loss/avg: 0.1941, max mem: 6431.0, experiment: run, epoch: 19, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 661ms, time_since_start: 52m 21s 121ms, eta: 02h 51m 22s 361ms
[32m2021-03-04T05:19:48 | mmf.trainers.callbacks.logistics: [0mprogress: 4900/22000, train/hateful_memes/cross_entropy: 0.0053, train/hateful_memes/cross_entropy/avg: 0.1906, train/total_loss: 0.0053, train/total_loss/avg: 0.1906, max mem: 6431.0, experiment: run, epoch: 19, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 128ms, time_since_start: 53m 10s 249ms, eta: 02h 20m 17s 775ms
[32m2021-03-04T05:20:38 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T05:20:38 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T05:20:38 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T05:20:38 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T05:20:43 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T05:21:20 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T05:21:20 | mmf.trainers.callbacks.logistics: [0mprogress: 5000/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1868, train/total_loss: 0.0047, train/total_loss/avg: 0.1868, max mem: 6431.0, experiment: run, epoch: 19, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00001, ups: 1.10, time: 01m 31s 416ms, time_since_start: 54m 41s 666ms, eta: 04h 19m 31s 913ms
[32m2021-03-04T05:21:20 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T05:21:37 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T05:21:37 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T05:21:37 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T05:21:37 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T05:22:00 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T05:22:23 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T05:22:23 | mmf.trainers.callbacks.logistics: [0mprogress: 5000/22000, val/hateful_memes/cross_entropy: 1.9264, val/total_loss: 1.9264, val/hateful_memes/accuracy: 0.6648, val/hateful_memes/binary_f1: 0.4136, val/hateful_memes/roc_auc: 0.6779, num_updates: 5000, epoch: 19, iterations: 5000, max_updates: 22000, val_time: 01m 03s 004ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.694761
[32m2021-03-04T05:23:24 | mmf.trainers.callbacks.logistics: [0mprogress: 5100/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1836, train/total_loss: 0.0047, train/total_loss/avg: 0.1836, max mem: 6431.0, experiment: run, epoch: 20, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 431ms, time_since_start: 56m 46s 119ms, eta: 02h 53m 22s 714ms
[32m2021-03-04T05:24:15 | mmf.trainers.callbacks.logistics: [0mprogress: 5200/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1802, train/total_loss: 0.0047, train/total_loss/avg: 0.1802, max mem: 6431.0, experiment: run, epoch: 20, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 975ms, time_since_start: 57m 37s 095ms, eta: 02h 23m 01s 068ms
[32m2021-03-04T05:25:06 | mmf.trainers.callbacks.logistics: [0mprogress: 5300/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1769, train/total_loss: 0.0047, train/total_loss/avg: 0.1769, max mem: 6431.0, experiment: run, epoch: 20, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 890ms, time_since_start: 58m 27s 985ms, eta: 02h 21m 55s 642ms
[32m2021-03-04T05:26:06 | mmf.trainers.callbacks.logistics: [0mprogress: 5400/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1737, train/total_loss: 0.0047, train/total_loss/avg: 0.1737, max mem: 6431.0, experiment: run, epoch: 21, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 796ms, time_since_start: 59m 27s 781ms, eta: 02h 45m 46s 067ms
[32m2021-03-04T05:26:55 | mmf.trainers.callbacks.logistics: [0mprogress: 5500/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1706, train/total_loss: 0.0047, train/total_loss/avg: 0.1706, max mem: 6431.0, experiment: run, epoch: 21, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 384ms, time_since_start: 01h 17s 166ms, eta: 02h 16m 04s 742ms
[32m2021-03-04T05:27:55 | mmf.trainers.callbacks.logistics: [0mprogress: 5600/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1676, train/total_loss: 0.0047, train/total_loss/avg: 0.1676, max mem: 6431.0, experiment: run, epoch: 22, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 967ms, time_since_start: 01h 01m 17s 134ms, eta: 02h 44m 14s 378ms
[32m2021-03-04T05:28:44 | mmf.trainers.callbacks.logistics: [0mprogress: 5700/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1647, train/total_loss: 0.0047, train/total_loss/avg: 0.1647, max mem: 6431.0, experiment: run, epoch: 22, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 843ms, time_since_start: 01h 02m 05s 977ms, eta: 02h 12m 57s 434ms
[32m2021-03-04T05:29:33 | mmf.trainers.callbacks.logistics: [0mprogress: 5800/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1620, train/total_loss: 0.0047, train/total_loss/avg: 0.1620, max mem: 6431.0, experiment: run, epoch: 22, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 888ms, time_since_start: 01h 02m 54s 866ms, eta: 02h 12m 15s 834ms
[32m2021-03-04T05:30:33 | mmf.trainers.callbacks.logistics: [0mprogress: 5900/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1594, train/total_loss: 0.0047, train/total_loss/avg: 0.1594, max mem: 6431.0, experiment: run, epoch: 23, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 613ms, time_since_start: 01h 03m 54s 479ms, eta: 02h 40m 16s 910ms
[32m2021-03-04T05:31:22 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T05:31:22 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T05:31:22 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T05:31:22 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T05:31:28 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T05:32:05 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T05:32:05 | mmf.trainers.callbacks.logistics: [0mprogress: 6000/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1570, train/total_loss: 0.0047, train/total_loss/avg: 0.1570, max mem: 6431.0, experiment: run, epoch: 23, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00001, ups: 1.09, time: 01m 32s 155ms, time_since_start: 01h 05m 26s 635ms, eta: 04h 06m 14s 345ms
[32m2021-03-04T05:32:05 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T05:32:22 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T05:32:22 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T05:32:22 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T05:32:22 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T05:32:46 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T05:33:09 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T05:33:09 | mmf.trainers.callbacks.logistics: [0mprogress: 6000/22000, val/hateful_memes/cross_entropy: 2.0407, val/total_loss: 2.0407, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.3806, val/hateful_memes/roc_auc: 0.6718, num_updates: 6000, epoch: 23, iterations: 6000, max_updates: 22000, val_time: 01m 03s 956ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.694761
[32m2021-03-04T05:33:58 | mmf.trainers.callbacks.logistics: [0mprogress: 6100/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1544, train/total_loss: 0.0047, train/total_loss/avg: 0.1544, max mem: 6431.0, experiment: run, epoch: 23, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 642ms, time_since_start: 01h 07m 20s 246ms, eta: 02h 11m 48s 978ms
[32m2021-03-04T05:35:00 | mmf.trainers.callbacks.logistics: [0mprogress: 6200/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1522, train/total_loss: 0.0047, train/total_loss/avg: 0.1522, max mem: 6431.0, experiment: run, epoch: 24, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 390ms, time_since_start: 01h 08m 21s 636ms, eta: 02h 41m 59s 068ms
[32m2021-03-04T05:35:50 | mmf.trainers.callbacks.logistics: [0mprogress: 6300/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1500, train/total_loss: 0.0047, train/total_loss/avg: 0.1500, max mem: 6431.0, experiment: run, epoch: 24, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 176ms, time_since_start: 01h 09m 11s 812ms, eta: 02h 11m 33s 414ms
[32m2021-03-04T05:36:50 | mmf.trainers.callbacks.logistics: [0mprogress: 6400/22000, train/hateful_memes/cross_entropy: 0.0053, train/hateful_memes/cross_entropy/avg: 0.1478, train/total_loss: 0.0053, train/total_loss/avg: 0.1478, max mem: 6431.0, experiment: run, epoch: 25, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 456ms, time_since_start: 01h 10m 12s 269ms, eta: 02h 37m 30s 035ms
[32m2021-03-04T05:37:39 | mmf.trainers.callbacks.logistics: [0mprogress: 6500/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1455, train/total_loss: 0.0047, train/total_loss/avg: 0.1455, max mem: 6431.0, experiment: run, epoch: 25, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 853ms, time_since_start: 01h 11m 01s 122ms, eta: 02h 06m 27s 392ms
[32m2021-03-04T05:38:28 | mmf.trainers.callbacks.logistics: [0mprogress: 6600/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1433, train/total_loss: 0.0047, train/total_loss/avg: 0.1433, max mem: 6431.0, experiment: run, epoch: 25, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 017ms, time_since_start: 01h 11m 50s 140ms, eta: 02h 06m 03s 836ms
[32m2021-03-04T05:39:28 | mmf.trainers.callbacks.logistics: [0mprogress: 6700/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1412, train/total_loss: 0.0047, train/total_loss/avg: 0.1412, max mem: 6431.0, experiment: run, epoch: 26, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 589ms, time_since_start: 01h 12m 49s 729ms, eta: 02h 32m 15s 479ms
[32m2021-03-04T05:40:17 | mmf.trainers.callbacks.logistics: [0mprogress: 6800/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1391, train/total_loss: 0.0047, train/total_loss/avg: 0.1391, max mem: 6431.0, experiment: run, epoch: 26, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 184ms, time_since_start: 01h 13m 38s 914ms, eta: 02h 04m 50s 934ms
[32m2021-03-04T05:41:07 | mmf.trainers.callbacks.logistics: [0mprogress: 6900/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1375, train/total_loss: 0.0047, train/total_loss/avg: 0.1375, max mem: 6431.0, experiment: run, epoch: 26, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 546ms, time_since_start: 01h 14m 28s 460ms, eta: 02h 04m 56s 413ms
[32m2021-03-04T05:42:06 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T05:42:06 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T05:42:06 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T05:42:06 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T05:42:11 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T05:42:45 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T05:42:45 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1356, train/total_loss: 0.0047, train/total_loss/avg: 0.1356, max mem: 6431.0, experiment: run, epoch: 27, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 689ms, time_since_start: 01h 16m 07s 149ms, eta: 04h 07m 13s 024ms
[32m2021-03-04T05:42:45 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T05:43:08 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T05:43:08 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T05:43:08 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T05:43:08 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T05:43:32 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T05:43:54 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T05:43:54 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, val/hateful_memes/cross_entropy: 2.0290, val/total_loss: 2.0290, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.4702, val/hateful_memes/roc_auc: 0.6752, num_updates: 7000, epoch: 27, iterations: 7000, max_updates: 22000, val_time: 01m 08s 996ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.694761
[32m2021-03-04T05:44:43 | mmf.trainers.callbacks.logistics: [0mprogress: 7100/22000, train/hateful_memes/cross_entropy: 0.0042, train/hateful_memes/cross_entropy/avg: 0.1337, train/total_loss: 0.0042, train/total_loss/avg: 0.1337, max mem: 6431.0, experiment: run, epoch: 27, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 060ms, time_since_start: 01h 18m 05s 224ms, eta: 02h 02m 04s 685ms
[32m2021-03-04T05:45:43 | mmf.trainers.callbacks.logistics: [0mprogress: 7200/22000, train/hateful_memes/cross_entropy: 0.0040, train/hateful_memes/cross_entropy/avg: 0.1318, train/total_loss: 0.0040, train/total_loss/avg: 0.1318, max mem: 6431.0, experiment: run, epoch: 28, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 950ms, time_since_start: 01h 19m 05s 174ms, eta: 02h 28m 10s 368ms
[32m2021-03-04T05:46:32 | mmf.trainers.callbacks.logistics: [0mprogress: 7300/22000, train/hateful_memes/cross_entropy: 0.0036, train/hateful_memes/cross_entropy/avg: 0.1300, train/total_loss: 0.0036, train/total_loss/avg: 0.1300, max mem: 6431.0, experiment: run, epoch: 28, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 103ms, time_since_start: 01h 19m 53s 277ms, eta: 01h 58m 05s 312ms
[32m2021-03-04T05:47:20 | mmf.trainers.callbacks.logistics: [0mprogress: 7400/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.1283, train/total_loss: 0.0017, train/total_loss/avg: 0.1283, max mem: 6431.0, experiment: run, epoch: 28, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 187ms, time_since_start: 01h 20m 41s 465ms, eta: 01h 57m 29s 441ms
[32m2021-03-04T05:48:19 | mmf.trainers.callbacks.logistics: [0mprogress: 7500/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1266, train/total_loss: 0.0016, train/total_loss/avg: 0.1266, max mem: 6431.0, experiment: run, epoch: 29, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 158ms, time_since_start: 01h 21m 40s 623ms, eta: 02h 23m 15s 148ms
[32m2021-03-04T05:49:07 | mmf.trainers.callbacks.logistics: [0mprogress: 7600/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1250, train/total_loss: 0.0016, train/total_loss/avg: 0.1250, max mem: 6431.0, experiment: run, epoch: 29, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 266ms, time_since_start: 01h 22m 28s 889ms, eta: 01h 56m 04s 223ms
[32m2021-03-04T05:49:56 | mmf.trainers.callbacks.logistics: [0mprogress: 7700/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1234, train/total_loss: 0.0016, train/total_loss/avg: 0.1234, max mem: 6431.0, experiment: run, epoch: 29, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 416ms, time_since_start: 01h 23m 17s 306ms, eta: 01h 55m 37s 472ms
[32m2021-03-04T05:50:55 | mmf.trainers.callbacks.logistics: [0mprogress: 7800/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1218, train/total_loss: 0.0015, train/total_loss/avg: 0.1218, max mem: 6431.0, experiment: run, epoch: 30, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 123ms, time_since_start: 01h 24m 16s 430ms, eta: 02h 20m 12s 364ms
[32m2021-03-04T05:51:43 | mmf.trainers.callbacks.logistics: [0mprogress: 7900/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1203, train/total_loss: 0.0015, train/total_loss/avg: 0.1203, max mem: 6431.0, experiment: run, epoch: 30, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 556ms, time_since_start: 01h 25m 04s 987ms, eta: 01h 54m 20s 215ms
[32m2021-03-04T05:52:42 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T05:52:42 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T05:52:42 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T05:52:42 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T05:52:48 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T05:53:14 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T05:53:14 | mmf.trainers.callbacks.logistics: [0mprogress: 8000/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1207, train/total_loss: 0.0015, train/total_loss/avg: 0.1207, max mem: 6431.0, experiment: run, epoch: 31, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00001, ups: 1.11, time: 01m 30s 397ms, time_since_start: 01h 26m 35s 385ms, eta: 03h 31m 21s 001ms
[32m2021-03-04T05:53:14 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T05:53:26 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T05:53:26 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T05:53:26 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T05:53:26 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T05:53:50 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T05:54:13 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T05:54:13 | mmf.trainers.callbacks.logistics: [0mprogress: 8000/22000, val/hateful_memes/cross_entropy: 2.2415, val/total_loss: 2.2415, val/hateful_memes/accuracy: 0.6630, val/hateful_memes/binary_f1: 0.4375, val/hateful_memes/roc_auc: 0.6770, num_updates: 8000, epoch: 31, iterations: 8000, max_updates: 22000, val_time: 59s 645ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.694761
[32m2021-03-04T05:55:03 | mmf.trainers.callbacks.logistics: [0mprogress: 8100/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1194, train/total_loss: 0.0015, train/total_loss/avg: 0.1194, max mem: 6431.0, experiment: run, epoch: 31, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 390ms, time_since_start: 01h 28m 24s 438ms, eta: 01h 54m 38s 944ms
[32m2021-03-04T05:55:52 | mmf.trainers.callbacks.logistics: [0mprogress: 8200/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1179, train/total_loss: 0.0014, train/total_loss/avg: 0.1179, max mem: 6431.0, experiment: run, epoch: 31, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 444ms, time_since_start: 01h 29m 13s 883ms, eta: 01h 53m 57s 018ms
[32m2021-03-04T05:56:53 | mmf.trainers.callbacks.logistics: [0mprogress: 8300/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1165, train/total_loss: 0.0014, train/total_loss/avg: 0.1165, max mem: 6431.0, experiment: run, epoch: 32, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 350ms, time_since_start: 01h 30m 15s 233ms, eta: 02h 20m 21s 872ms
[32m2021-03-04T05:57:44 | mmf.trainers.callbacks.logistics: [0mprogress: 8400/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1152, train/total_loss: 0.0013, train/total_loss/avg: 0.1152, max mem: 6431.0, experiment: run, epoch: 32, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 456ms, time_since_start: 01h 31m 05s 690ms, eta: 01h 54m 35s 826ms
[32m2021-03-04T05:58:35 | mmf.trainers.callbacks.logistics: [0mprogress: 8500/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1138, train/total_loss: 0.0014, train/total_loss/avg: 0.1138, max mem: 6431.0, experiment: run, epoch: 32, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 592ms, time_since_start: 01h 31m 56s 283ms, eta: 01h 54m 03s 667ms
[32m2021-03-04T05:59:34 | mmf.trainers.callbacks.logistics: [0mprogress: 8600/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1126, train/total_loss: 0.0015, train/total_loss/avg: 0.1126, max mem: 6431.0, experiment: run, epoch: 33, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 528ms, time_since_start: 01h 32m 55s 811ms, eta: 02h 13m 12s 741ms
[32m2021-03-04T06:00:23 | mmf.trainers.callbacks.logistics: [0mprogress: 8700/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1113, train/total_loss: 0.0015, train/total_loss/avg: 0.1113, max mem: 6431.0, experiment: run, epoch: 33, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 996ms, time_since_start: 01h 33m 44s 808ms, eta: 01h 48m 49s 592ms
[32m2021-03-04T06:01:23 | mmf.trainers.callbacks.logistics: [0mprogress: 8800/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1100, train/total_loss: 0.0015, train/total_loss/avg: 0.1100, max mem: 6431.0, experiment: run, epoch: 34, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 729ms, time_since_start: 01h 34m 44s 538ms, eta: 02h 11m 40s 099ms
[32m2021-03-04T06:02:12 | mmf.trainers.callbacks.logistics: [0mprogress: 8900/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1088, train/total_loss: 0.0014, train/total_loss/avg: 0.1088, max mem: 6431.0, experiment: run, epoch: 34, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 042ms, time_since_start: 01h 35m 33s 580ms, eta: 01h 47m 17s 391ms
[32m2021-03-04T06:03:01 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T06:03:01 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T06:03:01 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T06:03:01 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T06:03:06 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T06:03:30 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T06:03:30 | mmf.trainers.callbacks.logistics: [0mprogress: 9000/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1076, train/total_loss: 0.0013, train/total_loss/avg: 0.1076, max mem: 6431.0, experiment: run, epoch: 34, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00001, ups: 1.30, time: 01m 17s 931ms, time_since_start: 01h 36m 51s 511ms, eta: 02h 49m 11s 357ms
[32m2021-03-04T06:03:30 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T06:03:41 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T06:03:41 | mmf.trainers.callbacks.logistics: [0mprogress: 9000/22000, val/hateful_memes/cross_entropy: 2.3800, val/total_loss: 2.3800, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.4566, val/hateful_memes/roc_auc: 0.6830, num_updates: 9000, epoch: 34, iterations: 9000, max_updates: 22000, val_time: 11s 078ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.694761
[32m2021-03-04T06:04:41 | mmf.trainers.callbacks.logistics: [0mprogress: 9100/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1064, train/total_loss: 0.0006, train/total_loss/avg: 0.1064, max mem: 6431.0, experiment: run, epoch: 35, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 652ms, time_since_start: 01h 38m 03s 252ms, eta: 02h 10m 39s 831ms
[32m2021-03-04T06:05:30 | mmf.trainers.callbacks.logistics: [0mprogress: 9200/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1052, train/total_loss: 0.0006, train/total_loss/avg: 0.1052, max mem: 6431.0, experiment: run, epoch: 35, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 587ms, time_since_start: 01h 38m 51s 840ms, eta: 01h 43m 51s 678ms
[32m2021-03-04T06:06:19 | mmf.trainers.callbacks.logistics: [0mprogress: 9300/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1042, train/total_loss: 0.0013, train/total_loss/avg: 0.1042, max mem: 6431.0, experiment: run, epoch: 35, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 881ms, time_since_start: 01h 39m 40s 721ms, eta: 01h 43m 40s 311ms
[32m2021-03-04T06:07:18 | mmf.trainers.callbacks.logistics: [0mprogress: 9400/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1031, train/total_loss: 0.0006, train/total_loss/avg: 0.1031, max mem: 6431.0, experiment: run, epoch: 36, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 391ms, time_since_start: 01h 40m 40s 113ms, eta: 02h 04m 58s 351ms
[32m2021-03-04T06:08:07 | mmf.trainers.callbacks.logistics: [0mprogress: 9500/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1021, train/total_loss: 0.0006, train/total_loss/avg: 0.1021, max mem: 6431.0, experiment: run, epoch: 36, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 723ms, time_since_start: 01h 41m 28s 836ms, eta: 01h 41m 42s 576ms
[32m2021-03-04T06:09:07 | mmf.trainers.callbacks.logistics: [0mprogress: 9600/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1010, train/total_loss: 0.0006, train/total_loss/avg: 0.1010, max mem: 6431.0, experiment: run, epoch: 37, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 650ms, time_since_start: 01h 42m 28s 487ms, eta: 02h 03m 31s 491ms
[32m2021-03-04T06:09:56 | mmf.trainers.callbacks.logistics: [0mprogress: 9700/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1000, train/total_loss: 0.0006, train/total_loss/avg: 0.1000, max mem: 6431.0, experiment: run, epoch: 37, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 451ms, time_since_start: 01h 43m 17s 938ms, eta: 01h 41m 34s 649ms
[32m2021-03-04T06:10:46 | mmf.trainers.callbacks.logistics: [0mprogress: 9800/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0990, train/total_loss: 0.0006, train/total_loss/avg: 0.0990, max mem: 6431.0, experiment: run, epoch: 37, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 375ms, time_since_start: 01h 44m 07s 314ms, eta: 01h 40m 35s 892ms
[32m2021-03-04T06:11:45 | mmf.trainers.callbacks.logistics: [0mprogress: 9900/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0980, train/total_loss: 0.0006, train/total_loss/avg: 0.0980, max mem: 6431.0, experiment: run, epoch: 38, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 668ms, time_since_start: 01h 45m 06s 982ms, eta: 02h 34s 283ms
[32m2021-03-04T06:12:34 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T06:12:34 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T06:12:34 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T06:12:34 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T06:12:39 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T06:13:03 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T06:13:03 | mmf.trainers.callbacks.logistics: [0mprogress: 10000/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0970, train/total_loss: 0.0006, train/total_loss/avg: 0.0970, max mem: 6431.0, experiment: run, epoch: 38, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00001, ups: 1.30, time: 01m 17s 640ms, time_since_start: 01h 46m 24s 623ms, eta: 02h 35m 35s 532ms
[32m2021-03-04T06:13:03 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T06:13:15 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T06:13:15 | mmf.trainers.callbacks.logistics: [0mprogress: 10000/22000, val/hateful_memes/cross_entropy: 2.2677, val/total_loss: 2.2677, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.4467, val/hateful_memes/roc_auc: 0.6841, num_updates: 10000, epoch: 38, iterations: 10000, max_updates: 22000, val_time: 12s 108ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.694761
[32m2021-03-04T06:14:04 | mmf.trainers.callbacks.logistics: [0mprogress: 10100/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0961, train/total_loss: 0.0006, train/total_loss/avg: 0.0961, max mem: 6431.0, experiment: run, epoch: 38, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 692ms, time_since_start: 01h 47m 25s 431ms, eta: 01h 36m 46s 043ms
[32m2021-03-04T06:15:04 | mmf.trainers.callbacks.logistics: [0mprogress: 10200/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0956, train/total_loss: 0.0006, train/total_loss/avg: 0.0956, max mem: 6431.0, experiment: run, epoch: 39, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 282ms, time_since_start: 01h 48m 25s 714ms, eta: 01h 58m 47s 601ms
[32m2021-03-04T06:15:54 | mmf.trainers.callbacks.logistics: [0mprogress: 10300/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0947, train/total_loss: 0.0006, train/total_loss/avg: 0.0947, max mem: 6431.0, experiment: run, epoch: 39, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 904ms, time_since_start: 01h 49m 15s 618ms, eta: 01h 37m 30s 489ms
[32m2021-03-04T06:16:54 | mmf.trainers.callbacks.logistics: [0mprogress: 10400/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0938, train/total_loss: 0.0006, train/total_loss/avg: 0.0938, max mem: 6431.0, experiment: run, epoch: 40, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 265ms, time_since_start: 01h 50m 15s 883ms, eta: 01h 56m 44s 728ms
[32m2021-03-04T06:17:43 | mmf.trainers.callbacks.logistics: [0mprogress: 10500/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0933, train/total_loss: 0.0006, train/total_loss/avg: 0.0933, max mem: 6431.0, experiment: run, epoch: 40, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 939ms, time_since_start: 01h 51m 04s 823ms, eta: 01h 33m 59s 338ms
[32m2021-03-04T06:18:32 | mmf.trainers.callbacks.logistics: [0mprogress: 10600/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0925, train/total_loss: 0.0006, train/total_loss/avg: 0.0925, max mem: 6431.0, experiment: run, epoch: 40, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 040ms, time_since_start: 01h 51m 53s 864ms, eta: 01h 33m 21s 781ms
[32m2021-03-04T06:19:32 | mmf.trainers.callbacks.logistics: [0mprogress: 10700/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0916, train/total_loss: 0.0006, train/total_loss/avg: 0.0916, max mem: 6431.0, experiment: run, epoch: 41, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 319ms, time_since_start: 01h 52m 54s 183ms, eta: 01h 53m 49s 749ms
[32m2021-03-04T06:20:23 | mmf.trainers.callbacks.logistics: [0mprogress: 10800/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0908, train/total_loss: 0.0006, train/total_loss/avg: 0.0908, max mem: 6431.0, experiment: run, epoch: 41, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 188ms, time_since_start: 01h 53m 44s 372ms, eta: 01h 33m 52s 388ms
[32m2021-03-04T06:21:13 | mmf.trainers.callbacks.logistics: [0mprogress: 10900/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0900, train/total_loss: 0.0006, train/total_loss/avg: 0.0900, max mem: 6431.0, experiment: run, epoch: 41, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 265ms, time_since_start: 01h 54m 34s 637ms, eta: 01h 33m 10s 588ms
[32m2021-03-04T06:22:12 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T06:22:12 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T06:22:12 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T06:22:12 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T06:22:18 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T06:22:55 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T06:22:55 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0892, train/total_loss: 0.0006, train/total_loss/avg: 0.0892, max mem: 6431.0, experiment: run, epoch: 42, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00001, ups: 0.98, time: 01m 42s 526ms, time_since_start: 01h 56m 17s 163ms, eta: 03h 08m 20s 424ms
[32m2021-03-04T06:22:55 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T06:23:13 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T06:23:13 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, val/hateful_memes/cross_entropy: 2.3175, val/total_loss: 2.3175, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4383, val/hateful_memes/roc_auc: 0.6935, num_updates: 11000, epoch: 42, iterations: 11000, max_updates: 22000, val_time: 17s 305ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.694761
[32m2021-03-04T06:24:02 | mmf.trainers.callbacks.logistics: [0mprogress: 11100/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0884, train/total_loss: 0.0006, train/total_loss/avg: 0.0884, max mem: 6431.0, experiment: run, epoch: 42, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 067ms, time_since_start: 01h 57m 23s 552ms, eta: 01h 29m 19s 023ms
[32m2021-03-04T06:25:03 | mmf.trainers.callbacks.logistics: [0mprogress: 11200/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0876, train/total_loss: 0.0006, train/total_loss/avg: 0.0876, max mem: 6431.0, experiment: run, epoch: 43, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 091ms, time_since_start: 01h 58m 24s 644ms, eta: 01h 50m 11s 124ms
[32m2021-03-04T06:25:54 | mmf.trainers.callbacks.logistics: [0mprogress: 11300/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0868, train/total_loss: 0.0006, train/total_loss/avg: 0.0868, max mem: 6431.0, experiment: run, epoch: 43, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 464ms, time_since_start: 01h 59m 16s 108ms, eta: 01h 31m 57s 681ms
[32m2021-03-04T06:26:46 | mmf.trainers.callbacks.logistics: [0mprogress: 11400/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0861, train/total_loss: 0.0006, train/total_loss/avg: 0.0861, max mem: 6431.0, experiment: run, epoch: 43, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 871ms, time_since_start: 02h 07s 979ms, eta: 01h 31m 49s 346ms
[32m2021-03-04T06:27:47 | mmf.trainers.callbacks.logistics: [0mprogress: 11500/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0853, train/total_loss: 0.0004, train/total_loss/avg: 0.0853, max mem: 6431.0, experiment: run, epoch: 44, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 297ms, time_since_start: 02h 01m 08s 277ms, eta: 01h 45m 43s 952ms
[32m2021-03-04T06:28:35 | mmf.trainers.callbacks.logistics: [0mprogress: 11600/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0846, train/total_loss: 0.0004, train/total_loss/avg: 0.0846, max mem: 6431.0, experiment: run, epoch: 44, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 716ms, time_since_start: 02h 01m 56s 994ms, eta: 01h 24m 36s 691ms
[32m2021-03-04T06:29:24 | mmf.trainers.callbacks.logistics: [0mprogress: 11700/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0839, train/total_loss: 0.0004, train/total_loss/avg: 0.0839, max mem: 6431.0, experiment: run, epoch: 44, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 060ms, time_since_start: 02h 02m 46s 055ms, eta: 01h 24m 23s 326ms
[32m2021-03-04T06:30:24 | mmf.trainers.callbacks.logistics: [0mprogress: 11800/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0831, train/total_loss: 0.0004, train/total_loss/avg: 0.0831, max mem: 6431.0, experiment: run, epoch: 45, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 022ms, time_since_start: 02h 03m 46s 077ms, eta: 01h 42m 14s 518ms
[32m2021-03-04T06:31:14 | mmf.trainers.callbacks.logistics: [0mprogress: 11900/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0824, train/total_loss: 0.0004, train/total_loss/avg: 0.0824, max mem: 6431.0, experiment: run, epoch: 45, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 329ms, time_since_start: 02h 04m 35s 406ms, eta: 01h 23m 12s 200ms
[32m2021-03-04T06:32:14 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T06:32:14 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T06:32:14 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T06:32:14 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T06:32:20 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T06:32:57 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T06:32:57 | mmf.trainers.callbacks.logistics: [0mprogress: 12000/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0818, train/total_loss: 0.0003, train/total_loss/avg: 0.0818, max mem: 6431.0, experiment: run, epoch: 46, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00001, ups: 0.97, time: 01m 43s 368ms, time_since_start: 02h 06m 18s 774ms, eta: 02h 52m 37s 515ms
[32m2021-03-04T06:32:57 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T06:33:20 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T06:33:20 | mmf.trainers.callbacks.logistics: [0mprogress: 12000/22000, val/hateful_memes/cross_entropy: 2.5830, val/total_loss: 2.5830, val/hateful_memes/accuracy: 0.6741, val/hateful_memes/binary_f1: 0.3829, val/hateful_memes/roc_auc: 0.6922, num_updates: 12000, epoch: 46, iterations: 12000, max_updates: 22000, val_time: 22s 843ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.694761
[32m2021-03-04T06:34:10 | mmf.trainers.callbacks.logistics: [0mprogress: 12100/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0811, train/total_loss: 0.0003, train/total_loss/avg: 0.0811, max mem: 6431.0, experiment: run, epoch: 46, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 047ms, time_since_start: 02h 07m 31s 682ms, eta: 01h 22m 44s 608ms
[32m2021-03-04T06:35:00 | mmf.trainers.callbacks.logistics: [0mprogress: 12200/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0804, train/total_loss: 0.0003, train/total_loss/avg: 0.0804, max mem: 6431.0, experiment: run, epoch: 46, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 966ms, time_since_start: 02h 08m 21s 649ms, eta: 01h 21m 46s 485ms
[32m2021-03-04T06:36:01 | mmf.trainers.callbacks.logistics: [0mprogress: 12300/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0798, train/total_loss: 0.0002, train/total_loss/avg: 0.0798, max mem: 6431.0, experiment: run, epoch: 47, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 734ms, time_since_start: 02h 09m 22s 383ms, eta: 01h 38m 23s 033ms
[32m2021-03-04T06:36:50 | mmf.trainers.callbacks.logistics: [0mprogress: 12400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0791, train/total_loss: 0.0002, train/total_loss/avg: 0.0791, max mem: 6431.0, experiment: run, epoch: 47, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 480ms, time_since_start: 02h 10m 11s 863ms, eta: 01h 19m 19s 603ms
[32m2021-03-04T06:37:40 | mmf.trainers.callbacks.logistics: [0mprogress: 12500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0785, train/total_loss: 0.0002, train/total_loss/avg: 0.0785, max mem: 6431.0, experiment: run, epoch: 47, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 423ms, time_since_start: 02h 11m 01s 287ms, eta: 01h 18m 24s 660ms
[32m2021-03-04T06:38:40 | mmf.trainers.callbacks.logistics: [0mprogress: 12600/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0779, train/total_loss: 0.0002, train/total_loss/avg: 0.0779, max mem: 6431.0, experiment: run, epoch: 48, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 496ms, time_since_start: 02h 12m 01s 784ms, eta: 01h 34m 58s 009ms
[32m2021-03-04T06:39:30 | mmf.trainers.callbacks.logistics: [0mprogress: 12700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0773, train/total_loss: 0.0002, train/total_loss/avg: 0.0773, max mem: 6431.0, experiment: run, epoch: 48, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 627ms, time_since_start: 02h 12m 51s 411ms, eta: 01h 17m 04s 559ms
[32m2021-03-04T06:40:30 | mmf.trainers.callbacks.logistics: [0mprogress: 12800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0767, train/total_loss: 0.0002, train/total_loss/avg: 0.0767, max mem: 6431.0, experiment: run, epoch: 49, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 026ms, time_since_start: 02h 13m 51s 437ms, eta: 01h 32m 13s 447ms
[32m2021-03-04T06:41:19 | mmf.trainers.callbacks.logistics: [0mprogress: 12900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0761, train/total_loss: 0.0002, train/total_loss/avg: 0.0761, max mem: 6431.0, experiment: run, epoch: 49, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 127ms, time_since_start: 02h 14m 40s 565ms, eta: 01h 14m 39s 588ms
[32m2021-03-04T06:42:08 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T06:42:08 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T06:42:08 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T06:42:08 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T06:42:14 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T06:42:55 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T06:42:55 | mmf.trainers.callbacks.logistics: [0mprogress: 13000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0756, train/total_loss: 0.0002, train/total_loss/avg: 0.0756, max mem: 6431.0, experiment: run, epoch: 49, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 330ms, time_since_start: 02h 16m 16s 895ms, eta: 02h 24m 47s 082ms
[32m2021-03-04T06:42:55 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T06:43:19 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T06:43:19 | mmf.trainers.callbacks.logistics: [0mprogress: 13000/22000, val/hateful_memes/cross_entropy: 2.4514, val/total_loss: 2.4514, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.4437, val/hateful_memes/roc_auc: 0.6835, num_updates: 13000, epoch: 49, iterations: 13000, max_updates: 22000, val_time: 23s 539ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.694761
[32m2021-03-04T06:44:21 | mmf.trainers.callbacks.logistics: [0mprogress: 13100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0750, train/total_loss: 0.0002, train/total_loss/avg: 0.0750, max mem: 6431.0, experiment: run, epoch: 50, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0., ups: 1.61, time: 01m 02s 305ms, time_since_start: 02h 17m 42s 757ms, eta: 01h 32m 36s 301ms
[32m2021-03-04T06:45:12 | mmf.trainers.callbacks.logistics: [0mprogress: 13200/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0744, train/total_loss: 0.0002, train/total_loss/avg: 0.0744, max mem: 6431.0, experiment: run, epoch: 50, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 160ms, time_since_start: 02h 18m 33s 917ms, eta: 01h 15m 11s 096ms
[32m2021-03-04T06:46:03 | mmf.trainers.callbacks.logistics: [0mprogress: 13300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0741, train/total_loss: 0.0001, train/total_loss/avg: 0.0741, max mem: 6431.0, experiment: run, epoch: 50, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 139ms, time_since_start: 02h 19m 25s 057ms, eta: 01h 14m 18s 073ms
[32m2021-03-04T06:47:03 | mmf.trainers.callbacks.logistics: [0mprogress: 13400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0736, train/total_loss: 0.0002, train/total_loss/avg: 0.0736, max mem: 6431.0, experiment: run, epoch: 51, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 516ms, time_since_start: 02h 20m 24s 574ms, eta: 01h 25m 28s 654ms
[32m2021-03-04T06:47:51 | mmf.trainers.callbacks.logistics: [0mprogress: 13500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0731, train/total_loss: 0.0002, train/total_loss/avg: 0.0731, max mem: 6431.0, experiment: run, epoch: 51, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 503ms, time_since_start: 02h 21m 13s 077ms, eta: 01h 08m 51s 053ms
[32m2021-03-04T06:48:51 | mmf.trainers.callbacks.logistics: [0mprogress: 13600/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0725, train/total_loss: 0.0002, train/total_loss/avg: 0.0725, max mem: 6431.0, experiment: run, epoch: 52, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 557ms, time_since_start: 02h 22m 12s 634ms, eta: 01h 23m 32s 795ms
[32m2021-03-04T06:49:41 | mmf.trainers.callbacks.logistics: [0mprogress: 13700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0720, train/total_loss: 0.0001, train/total_loss/avg: 0.0720, max mem: 6431.0, experiment: run, epoch: 52, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 744ms, time_since_start: 02h 23m 02s 379ms, eta: 01h 08m 57s 014ms
[32m2021-03-04T06:50:31 | mmf.trainers.callbacks.logistics: [0mprogress: 13800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0715, train/total_loss: 0.0002, train/total_loss/avg: 0.0715, max mem: 6431.0, experiment: run, epoch: 52, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 966ms, time_since_start: 02h 23m 52s 345ms, eta: 01h 08m 25s 468ms
[32m2021-03-04T06:51:30 | mmf.trainers.callbacks.logistics: [0mprogress: 13900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0710, train/total_loss: 0.0002, train/total_loss/avg: 0.0710, max mem: 6431.0, experiment: run, epoch: 53, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 886ms, time_since_start: 02h 24m 52s 232ms, eta: 01h 21m 548ms
[32m2021-03-04T06:52:20 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T06:52:20 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T06:52:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T06:52:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T06:52:26 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T06:52:57 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T06:52:57 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0705, train/total_loss: 0.0002, train/total_loss/avg: 0.0705, max mem: 6431.0, experiment: run, epoch: 53, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0., ups: 1.16, time: 01m 26s 463ms, time_since_start: 02h 26m 18s 696ms, eta: 01h 55m 30s 886ms
[32m2021-03-04T06:52:57 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T06:53:15 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T06:53:15 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T06:53:15 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T06:53:15 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T06:53:38 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T06:54:00 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T06:54:23 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T06:54:23 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, val/hateful_memes/cross_entropy: 2.5702, val/total_loss: 2.5702, val/hateful_memes/accuracy: 0.6667, val/hateful_memes/binary_f1: 0.4058, val/hateful_memes/roc_auc: 0.6949, num_updates: 14000, epoch: 53, iterations: 14000, max_updates: 22000, val_time: 01m 25s 995ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.694852
[32m2021-03-04T06:55:24 | mmf.trainers.callbacks.logistics: [0mprogress: 14100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0700, train/total_loss: 0.0002, train/total_loss/avg: 0.0700, max mem: 6431.0, experiment: run, epoch: 54, num_updates: 14100, iterations: 14100, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 552ms, time_since_start: 02h 28m 46s 262ms, eta: 01h 21m 12s 379ms
[32m2021-03-04T06:56:16 | mmf.trainers.callbacks.logistics: [0mprogress: 14200/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0695, train/total_loss: 0.0002, train/total_loss/avg: 0.0695, max mem: 6431.0, experiment: run, epoch: 54, num_updates: 14200, iterations: 14200, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 472ms, time_since_start: 02h 29m 37s 734ms, eta: 01h 07m 02s 912ms
[32m2021-03-04T06:57:08 | mmf.trainers.callbacks.logistics: [0mprogress: 14300/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0690, train/total_loss: 0.0002, train/total_loss/avg: 0.0690, max mem: 6431.0, experiment: run, epoch: 54, num_updates: 14300, iterations: 14300, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 684ms, time_since_start: 02h 30m 29s 419ms, eta: 01h 06m 27s 684ms
[32m2021-03-04T06:58:09 | mmf.trainers.callbacks.logistics: [0mprogress: 14400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0685, train/total_loss: 0.0002, train/total_loss/avg: 0.0685, max mem: 6431.0, experiment: run, epoch: 55, num_updates: 14400, iterations: 14400, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 220ms, time_since_start: 02h 31m 30s 639ms, eta: 01h 17m 42s 033ms
[32m2021-03-04T06:58:58 | mmf.trainers.callbacks.logistics: [0mprogress: 14500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0681, train/total_loss: 0.0002, train/total_loss/avg: 0.0681, max mem: 6431.0, experiment: run, epoch: 55, num_updates: 14500, iterations: 14500, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 645ms, time_since_start: 02h 32m 19s 285ms, eta: 01h 55s 739ms
[32m2021-03-04T06:59:47 | mmf.trainers.callbacks.logistics: [0mprogress: 14600/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0677, train/total_loss: 0.0003, train/total_loss/avg: 0.0677, max mem: 6431.0, experiment: run, epoch: 55, num_updates: 14600, iterations: 14600, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 019ms, time_since_start: 02h 33m 08s 305ms, eta: 01h 34s 708ms
[32m2021-03-04T07:00:47 | mmf.trainers.callbacks.logistics: [0mprogress: 14700/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0673, train/total_loss: 0.0003, train/total_loss/avg: 0.0673, max mem: 6431.0, experiment: run, epoch: 56, num_updates: 14700, iterations: 14700, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 042ms, time_since_start: 02h 34m 08s 347ms, eta: 01h 13m 11s 834ms
[32m2021-03-04T07:01:36 | mmf.trainers.callbacks.logistics: [0mprogress: 14800/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0669, train/total_loss: 0.0003, train/total_loss/avg: 0.0669, max mem: 6431.0, experiment: run, epoch: 56, num_updates: 14800, iterations: 14800, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 466ms, time_since_start: 02h 34m 57s 814ms, eta: 59m 28s 746ms
[32m2021-03-04T07:02:36 | mmf.trainers.callbacks.logistics: [0mprogress: 14900/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0664, train/total_loss: 0.0003, train/total_loss/avg: 0.0664, max mem: 6431.0, experiment: run, epoch: 57, num_updates: 14900, iterations: 14900, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 059ms, time_since_start: 02h 35m 57s 873ms, eta: 01h 11m 12s 730ms
[32m2021-03-04T07:03:25 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T07:03:25 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T07:03:25 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T07:03:25 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T07:03:32 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T07:03:58 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T07:03:58 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0660, train/total_loss: 0.0002, train/total_loss/avg: 0.0660, max mem: 6431.0, experiment: run, epoch: 57, num_updates: 15000, iterations: 15000, max_updates: 22000, lr: 0., ups: 1.23, time: 01m 21s 597ms, time_since_start: 02h 37m 19s 471ms, eta: 01h 35m 23s 265ms
[32m2021-03-04T07:03:58 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T07:04:22 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T07:04:22 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T07:04:22 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T07:04:22 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T07:04:46 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T07:05:09 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T07:05:31 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T07:05:31 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, val/hateful_memes/cross_entropy: 2.5364, val/total_loss: 2.5364, val/hateful_memes/accuracy: 0.6889, val/hateful_memes/binary_f1: 0.4488, val/hateful_memes/roc_auc: 0.7019, num_updates: 15000, epoch: 57, iterations: 15000, max_updates: 22000, val_time: 01m 33s 645ms, best_update: 15000, best_iteration: 15000, best_val/hateful_memes/roc_auc: 0.701934
[32m2021-03-04T07:06:21 | mmf.trainers.callbacks.logistics: [0mprogress: 15100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0655, train/total_loss: 0.0002, train/total_loss/avg: 0.0655, max mem: 6431.0, experiment: run, epoch: 57, num_updates: 15100, iterations: 15100, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 481ms, time_since_start: 02h 39m 42s 606ms, eta: 57m 01s 051ms
[32m2021-03-04T07:07:22 | mmf.trainers.callbacks.logistics: [0mprogress: 15200/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0651, train/total_loss: 0.0002, train/total_loss/avg: 0.0651, max mem: 6431.0, experiment: run, epoch: 58, num_updates: 15200, iterations: 15200, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 200ms, time_since_start: 02h 40m 43s 806ms, eta: 01h 09m 29s 946ms
[32m2021-03-04T07:08:12 | mmf.trainers.callbacks.logistics: [0mprogress: 15300/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0647, train/total_loss: 0.0002, train/total_loss/avg: 0.0647, max mem: 6431.0, experiment: run, epoch: 58, num_updates: 15300, iterations: 15300, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 373ms, time_since_start: 02h 41m 34s 180ms, eta: 56m 21s 766ms
[32m2021-03-04T07:09:03 | mmf.trainers.callbacks.logistics: [0mprogress: 15400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0643, train/total_loss: 0.0002, train/total_loss/avg: 0.0643, max mem: 6431.0, experiment: run, epoch: 58, num_updates: 15400, iterations: 15400, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 592ms, time_since_start: 02h 42m 24s 772ms, eta: 55m 45s 787ms
[32m2021-03-04T07:10:03 | mmf.trainers.callbacks.logistics: [0mprogress: 15500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0638, train/total_loss: 0.0001, train/total_loss/avg: 0.0638, max mem: 6431.0, experiment: run, epoch: 59, num_updates: 15500, iterations: 15500, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 525ms, time_since_start: 02h 43m 24s 298ms, eta: 01h 04m 36s 919ms
[32m2021-03-04T07:10:51 | mmf.trainers.callbacks.logistics: [0mprogress: 15600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0634, train/total_loss: 0.0001, train/total_loss/avg: 0.0634, max mem: 6431.0, experiment: run, epoch: 59, num_updates: 15600, iterations: 15600, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 857ms, time_since_start: 02h 44m 13s 156ms, eta: 52m 13s 152ms
[32m2021-03-04T07:11:51 | mmf.trainers.callbacks.logistics: [0mprogress: 15700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0630, train/total_loss: 0.0001, train/total_loss/avg: 0.0630, max mem: 6431.0, experiment: run, epoch: 60, num_updates: 15700, iterations: 15700, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 686ms, time_since_start: 02h 45m 12s 843ms, eta: 01h 02m 47s 794ms
[32m2021-03-04T07:12:40 | mmf.trainers.callbacks.logistics: [0mprogress: 15800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0626, train/total_loss: 0.0001, train/total_loss/avg: 0.0626, max mem: 6431.0, experiment: run, epoch: 60, num_updates: 15800, iterations: 15800, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 740ms, time_since_start: 02h 46m 01s 583ms, eta: 50m 27s 937ms
[32m2021-03-04T07:13:29 | mmf.trainers.callbacks.logistics: [0mprogress: 15900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0622, train/total_loss: 0.0001, train/total_loss/avg: 0.0622, max mem: 6431.0, experiment: run, epoch: 60, num_updates: 15900, iterations: 15900, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 015ms, time_since_start: 02h 46m 50s 598ms, eta: 49m 55s 910ms
[32m2021-03-04T07:14:29 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T07:14:29 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T07:14:29 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T07:14:29 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T07:14:34 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T07:14:58 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T07:14:58 | mmf.trainers.callbacks.logistics: [0mprogress: 16000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0618, train/total_loss: 0.0001, train/total_loss/avg: 0.0618, max mem: 6431.0, experiment: run, epoch: 61, num_updates: 16000, iterations: 16000, max_updates: 22000, lr: 0., ups: 1.12, time: 01m 29s 557ms, time_since_start: 02h 48m 20s 155ms, eta: 01h 29m 44s 171ms
[32m2021-03-04T07:14:58 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T07:15:16 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T07:15:16 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T07:15:16 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T07:15:16 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T07:15:41 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T07:16:04 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T07:16:04 | mmf.trainers.callbacks.logistics: [0mprogress: 16000/22000, val/hateful_memes/cross_entropy: 2.6136, val/total_loss: 2.6136, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4436, val/hateful_memes/roc_auc: 0.7003, num_updates: 16000, epoch: 61, iterations: 16000, max_updates: 22000, val_time: 01m 05s 267ms, best_update: 15000, best_iteration: 15000, best_val/hateful_memes/roc_auc: 0.701934
[32m2021-03-04T07:16:54 | mmf.trainers.callbacks.logistics: [0mprogress: 16100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0615, train/total_loss: 0.0001, train/total_loss/avg: 0.0615, max mem: 6431.0, experiment: run, epoch: 61, num_updates: 16100, iterations: 16100, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 004ms, time_since_start: 02h 50m 15s 432ms, eta: 49m 16s 167ms
[32m2021-03-04T07:17:44 | mmf.trainers.callbacks.logistics: [0mprogress: 16200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0611, train/total_loss: 0.0001, train/total_loss/avg: 0.0611, max mem: 6431.0, experiment: run, epoch: 61, num_updates: 16200, iterations: 16200, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 950ms, time_since_start: 02h 51m 05s 383ms, eta: 48m 22s 936ms
[32m2021-03-04T07:18:45 | mmf.trainers.callbacks.logistics: [0mprogress: 16300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0607, train/total_loss: 0.0001, train/total_loss/avg: 0.0607, max mem: 6431.0, experiment: run, epoch: 62, num_updates: 16300, iterations: 16300, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 991ms, time_since_start: 02h 52m 06s 375ms, eta: 58m 03s 479ms
[32m2021-03-04T07:19:35 | mmf.trainers.callbacks.logistics: [0mprogress: 16400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0603, train/total_loss: 0.0001, train/total_loss/avg: 0.0603, max mem: 6431.0, experiment: run, epoch: 62, num_updates: 16400, iterations: 16400, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 971ms, time_since_start: 02h 52m 56s 346ms, eta: 46m 43s 978ms
[32m2021-03-04T07:20:35 | mmf.trainers.callbacks.logistics: [0mprogress: 16500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0600, train/total_loss: 0.0001, train/total_loss/avg: 0.0600, max mem: 6431.0, experiment: run, epoch: 63, num_updates: 16500, iterations: 16500, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 632ms, time_since_start: 02h 53m 56s 978ms, eta: 55m 41s 448ms
[32m2021-03-04T07:21:25 | mmf.trainers.callbacks.logistics: [0mprogress: 16600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0596, train/total_loss: 0.0001, train/total_loss/avg: 0.0596, max mem: 6431.0, experiment: run, epoch: 63, num_updates: 16600, iterations: 16600, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 038ms, time_since_start: 02h 54m 47s 017ms, eta: 45m 07s 488ms
[32m2021-03-04T07:22:15 | mmf.trainers.callbacks.logistics: [0mprogress: 16700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0592, train/total_loss: 0.0001, train/total_loss/avg: 0.0592, max mem: 6431.0, experiment: run, epoch: 63, num_updates: 16700, iterations: 16700, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 121ms, time_since_start: 02h 55m 37s 139ms, eta: 44m 21s 772ms
[32m2021-03-04T07:23:16 | mmf.trainers.callbacks.logistics: [0mprogress: 16800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0589, train/total_loss: 0.0001, train/total_loss/avg: 0.0589, max mem: 6431.0, experiment: run, epoch: 64, num_updates: 16800, iterations: 16800, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 169ms, time_since_start: 02h 56m 37s 308ms, eta: 52m 15s 068ms
[32m2021-03-04T07:24:05 | mmf.trainers.callbacks.logistics: [0mprogress: 16900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0586, train/total_loss: 0.0001, train/total_loss/avg: 0.0586, max mem: 6431.0, experiment: run, epoch: 64, num_updates: 16900, iterations: 16900, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 966ms, time_since_start: 02h 57m 26s 275ms, eta: 41m 42s 307ms
[32m2021-03-04T07:24:53 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T07:24:53 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T07:24:53 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T07:24:53 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T07:24:59 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T07:25:26 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T07:25:26 | mmf.trainers.callbacks.logistics: [0mprogress: 17000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0582, train/total_loss: 0.0000, train/total_loss/avg: 0.0582, max mem: 6431.0, experiment: run, epoch: 64, num_updates: 17000, iterations: 17000, max_updates: 22000, lr: 0., ups: 1.23, time: 01m 21s 458ms, time_since_start: 02h 58m 47s 734ms, eta: 01h 08m 01s 096ms
[32m2021-03-04T07:25:26 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T07:25:49 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T07:25:49 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T07:25:49 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T07:25:49 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T07:26:13 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T07:26:36 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T07:26:36 | mmf.trainers.callbacks.logistics: [0mprogress: 17000/22000, val/hateful_memes/cross_entropy: 2.9346, val/total_loss: 2.9346, val/hateful_memes/accuracy: 0.6667, val/hateful_memes/binary_f1: 0.3605, val/hateful_memes/roc_auc: 0.6878, num_updates: 17000, epoch: 64, iterations: 17000, max_updates: 22000, val_time: 01m 10s 333ms, best_update: 15000, best_iteration: 15000, best_val/hateful_memes/roc_auc: 0.701934
[32m2021-03-04T07:27:37 | mmf.trainers.callbacks.logistics: [0mprogress: 17100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0579, train/total_loss: 0.0000, train/total_loss/avg: 0.0579, max mem: 6431.0, experiment: run, epoch: 65, num_updates: 17100, iterations: 17100, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 538ms, time_since_start: 03h 58s 623ms, eta: 49m 32s 303ms
[32m2021-03-04T07:28:26 | mmf.trainers.callbacks.logistics: [0mprogress: 17200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0575, train/total_loss: 0.0000, train/total_loss/avg: 0.0575, max mem: 6431.0, experiment: run, epoch: 65, num_updates: 17200, iterations: 17200, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 482ms, time_since_start: 03h 01m 48s 105ms, eta: 39m 39s 893ms
[32m2021-03-04T07:29:27 | mmf.trainers.callbacks.logistics: [0mprogress: 17300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0572, train/total_loss: 0.0000, train/total_loss/avg: 0.0572, max mem: 6431.0, experiment: run, epoch: 66, num_updates: 17300, iterations: 17300, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 253ms, time_since_start: 03h 02m 48s 359ms, eta: 47m 17s 574ms
[32m2021-03-04T07:30:16 | mmf.trainers.callbacks.logistics: [0mprogress: 17400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0569, train/total_loss: 0.0000, train/total_loss/avg: 0.0569, max mem: 6431.0, experiment: run, epoch: 66, num_updates: 17400, iterations: 17400, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 644ms, time_since_start: 03h 03m 38s 003ms, eta: 38m 08s 216ms
[32m2021-03-04T07:31:06 | mmf.trainers.callbacks.logistics: [0mprogress: 17500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0566, train/total_loss: 0.0000, train/total_loss/avg: 0.0566, max mem: 6431.0, experiment: run, epoch: 66, num_updates: 17500, iterations: 17500, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 929ms, time_since_start: 03h 04m 27s 933ms, eta: 37m 31s 319ms
[32m2021-03-04T07:32:06 | mmf.trainers.callbacks.logistics: [0mprogress: 17600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0562, train/total_loss: 0.0000, train/total_loss/avg: 0.0562, max mem: 6431.0, experiment: run, epoch: 67, num_updates: 17600, iterations: 17600, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 668ms, time_since_start: 03h 05m 27s 602ms, eta: 43m 50s 681ms
[32m2021-03-04T07:32:54 | mmf.trainers.callbacks.logistics: [0mprogress: 17700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0559, train/total_loss: 0.0000, train/total_loss/avg: 0.0559, max mem: 6431.0, experiment: run, epoch: 67, num_updates: 17700, iterations: 17700, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 186ms, time_since_start: 03h 06m 15s 788ms, eta: 34m 36s 177ms
[32m2021-03-04T07:33:42 | mmf.trainers.callbacks.logistics: [0mprogress: 17800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0556, train/total_loss: 0.0000, train/total_loss/avg: 0.0556, max mem: 6431.0, experiment: run, epoch: 67, num_updates: 17800, iterations: 17800, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 314ms, time_since_start: 03h 07m 04s 103ms, eta: 33m 53s 254ms
[32m2021-03-04T07:34:43 | mmf.trainers.callbacks.logistics: [0mprogress: 17900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0553, train/total_loss: 0.0000, train/total_loss/avg: 0.0553, max mem: 6431.0, experiment: run, epoch: 68, num_updates: 17900, iterations: 17900, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 234ms, time_since_start: 03h 08m 04s 337ms, eta: 41m 14s 550ms
[32m2021-03-04T07:35:33 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T07:35:33 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T07:35:33 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T07:35:33 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T07:35:38 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T07:36:03 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T07:36:03 | mmf.trainers.callbacks.logistics: [0mprogress: 18000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0550, train/total_loss: 0.0000, train/total_loss/avg: 0.0550, max mem: 6431.0, experiment: run, epoch: 68, num_updates: 18000, iterations: 18000, max_updates: 22000, lr: 0., ups: 1.25, time: 01m 20s 278ms, time_since_start: 03h 09m 24s 616ms, eta: 53m 37s 569ms
[32m2021-03-04T07:36:03 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T07:36:20 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T07:36:20 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T07:36:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T07:36:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T07:36:44 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T07:37:07 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T07:37:07 | mmf.trainers.callbacks.logistics: [0mprogress: 18000/22000, val/hateful_memes/cross_entropy: 2.6181, val/total_loss: 2.6181, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4420, val/hateful_memes/roc_auc: 0.6977, num_updates: 18000, epoch: 68, iterations: 18000, max_updates: 22000, val_time: 01m 04s 605ms, best_update: 15000, best_iteration: 15000, best_val/hateful_memes/roc_auc: 0.701934
[32m2021-03-04T07:38:08 | mmf.trainers.callbacks.logistics: [0mprogress: 18100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0547, train/total_loss: 0.0000, train/total_loss/avg: 0.0547, max mem: 6431.0, experiment: run, epoch: 69, num_updates: 18100, iterations: 18100, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 906ms, time_since_start: 03h 11m 30s 144ms, eta: 39m 40s 094ms
[32m2021-03-04T07:38:58 | mmf.trainers.callbacks.logistics: [0mprogress: 18200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0544, train/total_loss: 0.0000, train/total_loss/avg: 0.0544, max mem: 6431.0, experiment: run, epoch: 69, num_updates: 18200, iterations: 18200, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 783ms, time_since_start: 03h 12m 19s 927ms, eta: 31m 35s 541ms
[32m2021-03-04T07:39:48 | mmf.trainers.callbacks.logistics: [0mprogress: 18300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0541, train/total_loss: 0.0000, train/total_loss/avg: 0.0541, max mem: 6431.0, experiment: run, epoch: 69, num_updates: 18300, iterations: 18300, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 819ms, time_since_start: 03h 13m 09s 747ms, eta: 30m 47s 023ms
[32m2021-03-04T07:40:48 | mmf.trainers.callbacks.logistics: [0mprogress: 18400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0538, train/total_loss: 0.0000, train/total_loss/avg: 0.0538, max mem: 6431.0, experiment: run, epoch: 70, num_updates: 18400, iterations: 18400, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 461ms, time_since_start: 03h 14m 10s 209ms, eta: 36m 20s 977ms
[32m2021-03-04T07:41:38 | mmf.trainers.callbacks.logistics: [0mprogress: 18500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0535, train/total_loss: 0.0000, train/total_loss/avg: 0.0535, max mem: 6431.0, experiment: run, epoch: 70, num_updates: 18500, iterations: 18500, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 407ms, time_since_start: 03h 14m 59s 617ms, eta: 28m 52s 736ms
[32m2021-03-04T07:42:27 | mmf.trainers.callbacks.logistics: [0mprogress: 18600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0532, train/total_loss: 0.0000, train/total_loss/avg: 0.0532, max mem: 6431.0, experiment: run, epoch: 70, num_updates: 18600, iterations: 18600, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 568ms, time_since_start: 03h 15m 49s 185ms, eta: 28m 08s 684ms
[32m2021-03-04T07:43:26 | mmf.trainers.callbacks.logistics: [0mprogress: 18700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0529, train/total_loss: 0.0000, train/total_loss/avg: 0.0529, max mem: 6431.0, experiment: run, epoch: 71, num_updates: 18700, iterations: 18700, max_updates: 22000, lr: 0., ups: 1.72, time: 58s 914ms, time_since_start: 03h 16m 48s 100ms, eta: 32m 28s 079ms
[32m2021-03-04T07:44:15 | mmf.trainers.callbacks.logistics: [0mprogress: 18800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0526, train/total_loss: 0.0000, train/total_loss/avg: 0.0526, max mem: 6431.0, experiment: run, epoch: 71, num_updates: 18800, iterations: 18800, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 173ms, time_since_start: 03h 17m 36s 274ms, eta: 25m 44s 647ms
[32m2021-03-04T07:45:13 | mmf.trainers.callbacks.logistics: [0mprogress: 18900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0524, train/total_loss: 0.0000, train/total_loss/avg: 0.0524, max mem: 6431.0, experiment: run, epoch: 72, num_updates: 18900, iterations: 18900, max_updates: 22000, lr: 0., ups: 1.72, time: 58s 931ms, time_since_start: 03h 18m 35s 205ms, eta: 30m 30s 518ms
[32m2021-03-04T07:46:02 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T07:46:02 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T07:46:02 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T07:46:02 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T07:46:07 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T07:46:31 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T07:46:31 | mmf.trainers.callbacks.logistics: [0mprogress: 19000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0521, train/total_loss: 0.0000, train/total_loss/avg: 0.0521, max mem: 6431.0, experiment: run, epoch: 72, num_updates: 19000, iterations: 19000, max_updates: 22000, lr: 0., ups: 1.30, time: 01m 17s 373ms, time_since_start: 03h 19m 52s 579ms, eta: 38m 45s 856ms
[32m2021-03-04T07:46:31 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T07:46:42 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T07:46:42 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T07:46:42 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T07:46:42 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T07:47:06 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T07:47:30 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T07:47:30 | mmf.trainers.callbacks.logistics: [0mprogress: 19000/22000, val/hateful_memes/cross_entropy: 2.5428, val/total_loss: 2.5428, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.4824, val/hateful_memes/roc_auc: 0.7004, num_updates: 19000, epoch: 72, iterations: 19000, max_updates: 22000, val_time: 58s 955ms, best_update: 15000, best_iteration: 15000, best_val/hateful_memes/roc_auc: 0.701934
[32m2021-03-04T07:48:18 | mmf.trainers.callbacks.logistics: [0mprogress: 19100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0518, train/total_loss: 0.0000, train/total_loss/avg: 0.0518, max mem: 6431.0, experiment: run, epoch: 72, num_updates: 19100, iterations: 19100, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 522ms, time_since_start: 03h 21m 40s 065ms, eta: 23m 29s 977ms
[32m2021-03-04T07:49:18 | mmf.trainers.callbacks.logistics: [0mprogress: 19200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0515, train/total_loss: 0.0000, train/total_loss/avg: 0.0515, max mem: 6431.0, experiment: run, epoch: 73, num_updates: 19200, iterations: 19200, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 842ms, time_since_start: 03h 22m 39s 908ms, eta: 27m 58s 948ms
[32m2021-03-04T07:50:07 | mmf.trainers.callbacks.logistics: [0mprogress: 19300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0513, train/total_loss: 0.0000, train/total_loss/avg: 0.0513, max mem: 6431.0, experiment: run, epoch: 73, num_updates: 19300, iterations: 19300, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 839ms, time_since_start: 03h 23m 28s 747ms, eta: 22m 01s 299ms
[32m2021-03-04T07:50:56 | mmf.trainers.callbacks.logistics: [0mprogress: 19400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0510, train/total_loss: 0.0000, train/total_loss/avg: 0.0510, max mem: 6431.0, experiment: run, epoch: 73, num_updates: 19400, iterations: 19400, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 922ms, time_since_start: 03h 24m 17s 669ms, eta: 21m 14s 524ms
[32m2021-03-04T07:51:56 | mmf.trainers.callbacks.logistics: [0mprogress: 19500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0507, train/total_loss: 0.0000, train/total_loss/avg: 0.0507, max mem: 6431.0, experiment: run, epoch: 74, num_updates: 19500, iterations: 19500, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 601ms, time_since_start: 03h 25m 17s 271ms, eta: 24m 53s 021ms
[32m2021-03-04T07:52:44 | mmf.trainers.callbacks.logistics: [0mprogress: 19600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0505, train/total_loss: 0.0000, train/total_loss/avg: 0.0505, max mem: 6431.0, experiment: run, epoch: 74, num_updates: 19600, iterations: 19600, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 689ms, time_since_start: 03h 26m 05s 961ms, eta: 19m 30s 887ms
[32m2021-03-04T07:53:43 | mmf.trainers.callbacks.logistics: [0mprogress: 19700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0502, train/total_loss: 0.0000, train/total_loss/avg: 0.0502, max mem: 6431.0, experiment: run, epoch: 75, num_updates: 19700, iterations: 19700, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 296ms, time_since_start: 03h 27m 05s 257ms, eta: 22m 46s 552ms
[32m2021-03-04T07:54:33 | mmf.trainers.callbacks.logistics: [0mprogress: 19800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0500, train/total_loss: 0.0000, train/total_loss/avg: 0.0500, max mem: 6431.0, experiment: run, epoch: 75, num_updates: 19800, iterations: 19800, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 246ms, time_since_start: 03h 27m 54s 504ms, eta: 18m 05s 593ms
[32m2021-03-04T07:55:22 | mmf.trainers.callbacks.logistics: [0mprogress: 19900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0497, train/total_loss: 0.0000, train/total_loss/avg: 0.0497, max mem: 6431.0, experiment: run, epoch: 75, num_updates: 19900, iterations: 19900, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 431ms, time_since_start: 03h 28m 43s 935ms, eta: 17m 20s 130ms
[32m2021-03-04T07:56:23 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T07:56:23 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T07:56:23 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T07:56:23 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T07:56:47 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T07:57:10 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T07:57:10 | mmf.trainers.callbacks.logistics: [0mprogress: 20000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0495, train/total_loss: 0.0000, train/total_loss/avg: 0.0495, max mem: 6431.0, experiment: run, epoch: 76, num_updates: 20000, iterations: 20000, max_updates: 22000, lr: 0., ups: 0.93, time: 01m 47s 863ms, time_since_start: 03h 30m 31s 799ms, eta: 36m 01s 580ms
[32m2021-03-04T07:57:10 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T07:57:21 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T07:57:21 | mmf.trainers.callbacks.logistics: [0mprogress: 20000/22000, val/hateful_memes/cross_entropy: 2.7275, val/total_loss: 2.7275, val/hateful_memes/accuracy: 0.6852, val/hateful_memes/binary_f1: 0.4378, val/hateful_memes/roc_auc: 0.6999, num_updates: 20000, epoch: 76, iterations: 20000, max_updates: 22000, val_time: 11s 265ms, best_update: 15000, best_iteration: 15000, best_val/hateful_memes/roc_auc: 0.701934
[32m2021-03-04T07:58:12 | mmf.trainers.callbacks.logistics: [0mprogress: 20100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0492, train/total_loss: 0.0000, train/total_loss/avg: 0.0492, max mem: 6431.0, experiment: run, epoch: 76, num_updates: 20100, iterations: 20100, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 533ms, time_since_start: 03h 31m 33s 603ms, eta: 16m 02s 064ms
[32m2021-03-04T07:59:03 | mmf.trainers.callbacks.logistics: [0mprogress: 20200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0490, train/total_loss: 0.0000, train/total_loss/avg: 0.0490, max mem: 6431.0, experiment: run, epoch: 76, num_updates: 20200, iterations: 20200, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 680ms, time_since_start: 03h 32m 24s 283ms, eta: 15m 14s 073ms
[32m2021-03-04T08:00:02 | mmf.trainers.callbacks.logistics: [0mprogress: 20300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0487, train/total_loss: 0.0000, train/total_loss/avg: 0.0487, max mem: 6431.0, experiment: run, epoch: 77, num_updates: 20300, iterations: 20300, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 841ms, time_since_start: 03h 33m 24s 125ms, eta: 16m 59s 343ms
[32m2021-03-04T08:00:51 | mmf.trainers.callbacks.logistics: [0mprogress: 20400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0485, train/total_loss: 0.0000, train/total_loss/avg: 0.0485, max mem: 6431.0, experiment: run, epoch: 77, num_updates: 20400, iterations: 20400, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 044ms, time_since_start: 03h 34m 13s 169ms, eta: 13m 06s 275ms
[32m2021-03-04T08:01:51 | mmf.trainers.callbacks.logistics: [0mprogress: 20500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0483, train/total_loss: 0.0000, train/total_loss/avg: 0.0483, max mem: 6431.0, experiment: run, epoch: 78, num_updates: 20500, iterations: 20500, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 869ms, time_since_start: 03h 35m 13s 039ms, eta: 14m 59s 841ms
[32m2021-03-04T08:02:41 | mmf.trainers.callbacks.logistics: [0mprogress: 20600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0480, train/total_loss: 0.0000, train/total_loss/avg: 0.0480, max mem: 6431.0, experiment: run, epoch: 78, num_updates: 20600, iterations: 20600, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 568ms, time_since_start: 03h 36m 02s 608ms, eta: 11m 35s 351ms
[32m2021-03-04T08:03:30 | mmf.trainers.callbacks.logistics: [0mprogress: 20700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0478, train/total_loss: 0.0000, train/total_loss/avg: 0.0478, max mem: 6431.0, experiment: run, epoch: 78, num_updates: 20700, iterations: 20700, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 568ms, time_since_start: 03h 36m 52s 176ms, eta: 10m 45s 682ms
[32m2021-03-04T08:04:30 | mmf.trainers.callbacks.logistics: [0mprogress: 20800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0476, train/total_loss: 0.0000, train/total_loss/avg: 0.0476, max mem: 6431.0, experiment: run, epoch: 79, num_updates: 20800, iterations: 20800, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 985ms, time_since_start: 03h 37m 52s 162ms, eta: 12m 01s 265ms
[32m2021-03-04T08:05:20 | mmf.trainers.callbacks.logistics: [0mprogress: 20900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0473, train/total_loss: 0.0000, train/total_loss/avg: 0.0473, max mem: 6431.0, experiment: run, epoch: 79, num_updates: 20900, iterations: 20900, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 704ms, time_since_start: 03h 38m 41s 866ms, eta: 09m 07s 838ms
[32m2021-03-04T08:06:10 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T08:06:10 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T08:06:10 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T08:06:10 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T08:06:40 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T08:07:03 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T08:07:03 | mmf.trainers.callbacks.logistics: [0mprogress: 21000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0471, train/total_loss: 0.0000, train/total_loss/avg: 0.0471, max mem: 6431.0, experiment: run, epoch: 79, num_updates: 21000, iterations: 21000, max_updates: 22000, lr: 0., ups: 0.97, time: 01m 43s 093ms, time_since_start: 03h 40m 24s 960ms, eta: 17m 12s 998ms
[32m2021-03-04T08:07:03 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T08:07:18 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T08:07:18 | mmf.trainers.callbacks.logistics: [0mprogress: 21000/22000, val/hateful_memes/cross_entropy: 2.7758, val/total_loss: 2.7758, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4613, val/hateful_memes/roc_auc: 0.6987, num_updates: 21000, epoch: 79, iterations: 21000, max_updates: 22000, val_time: 15s 066ms, best_update: 15000, best_iteration: 15000, best_val/hateful_memes/roc_auc: 0.701934
[32m2021-03-04T08:08:20 | mmf.trainers.callbacks.logistics: [0mprogress: 21100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0469, train/total_loss: 0.0000, train/total_loss/avg: 0.0469, max mem: 6431.0, experiment: run, epoch: 80, num_updates: 21100, iterations: 21100, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 423ms, time_since_start: 03h 41m 41s 458ms, eta: 09m 13s 919ms
[32m2021-03-04T08:09:10 | mmf.trainers.callbacks.logistics: [0mprogress: 21200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0467, train/total_loss: 0.0000, train/total_loss/avg: 0.0467, max mem: 6431.0, experiment: run, epoch: 80, num_updates: 21200, iterations: 21200, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 671ms, time_since_start: 03h 42m 32s 129ms, eta: 06m 46s 184ms
[32m2021-03-04T08:10:11 | mmf.trainers.callbacks.logistics: [0mprogress: 21300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0465, train/total_loss: 0.0000, train/total_loss/avg: 0.0465, max mem: 6431.0, experiment: run, epoch: 81, num_updates: 21300, iterations: 21300, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 018ms, time_since_start: 03h 43m 33s 147ms, eta: 07m 07s 981ms
[32m2021-03-04T08:11:01 | mmf.trainers.callbacks.logistics: [0mprogress: 21400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0462, train/total_loss: 0.0000, train/total_loss/avg: 0.0462, max mem: 6431.0, experiment: run, epoch: 81, num_updates: 21400, iterations: 21400, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 514ms, time_since_start: 03h 44m 22s 662ms, eta: 04m 57s 681ms
[32m2021-03-04T08:11:51 | mmf.trainers.callbacks.logistics: [0mprogress: 21500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0460, train/total_loss: 0.0000, train/total_loss/avg: 0.0460, max mem: 6431.0, experiment: run, epoch: 81, num_updates: 21500, iterations: 21500, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 678ms, time_since_start: 03h 45m 12s 340ms, eta: 04m 08s 888ms
[32m2021-03-04T08:12:51 | mmf.trainers.callbacks.logistics: [0mprogress: 21600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0458, train/total_loss: 0.0000, train/total_loss/avg: 0.0458, max mem: 6431.0, experiment: run, epoch: 82, num_updates: 21600, iterations: 21600, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 064ms, time_since_start: 03h 46m 12s 405ms, eta: 04m 739ms
[32m2021-03-04T08:13:40 | mmf.trainers.callbacks.logistics: [0mprogress: 21700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0456, train/total_loss: 0.0000, train/total_loss/avg: 0.0456, max mem: 6431.0, experiment: run, epoch: 82, num_updates: 21700, iterations: 21700, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 599ms, time_since_start: 03h 47m 02s 005ms, eta: 02m 29s 096ms
[32m2021-03-04T08:14:30 | mmf.trainers.callbacks.logistics: [0mprogress: 21800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0454, train/total_loss: 0.0000, train/total_loss/avg: 0.0454, max mem: 6431.0, experiment: run, epoch: 82, num_updates: 21800, iterations: 21800, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 544ms, time_since_start: 03h 47m 51s 549ms, eta: 01m 39s 287ms
[32m2021-03-04T08:15:29 | mmf.trainers.callbacks.logistics: [0mprogress: 21900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0452, train/total_loss: 0.0000, train/total_loss/avg: 0.0452, max mem: 6431.0, experiment: run, epoch: 83, num_updates: 21900, iterations: 21900, max_updates: 22000, lr: 0., ups: 1.72, time: 58s 877ms, time_since_start: 03h 48m 50s 427ms, eta: 58s 995ms
[32m2021-03-04T08:16:17 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T08:16:17 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T08:16:17 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T08:16:17 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T08:16:40 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T08:17:03 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T08:17:03 | mmf.trainers.callbacks.logistics: [0mprogress: 22000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0450, train/total_loss: 0.0000, train/total_loss/avg: 0.0450, max mem: 6431.0, experiment: run, epoch: 83, num_updates: 22000, iterations: 22000, max_updates: 22000, lr: 0., ups: 1.08, time: 01m 33s 865ms, time_since_start: 03h 50m 24s 293ms, eta: 0ms
[32m2021-03-04T08:17:03 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T08:17:20 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T08:17:20 | mmf.trainers.callbacks.logistics: [0mprogress: 22000/22000, val/hateful_memes/cross_entropy: 2.8487, val/total_loss: 2.8487, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4412, val/hateful_memes/roc_auc: 0.6970, num_updates: 22000, epoch: 83, iterations: 22000, max_updates: 22000, val_time: 17s 077ms, best_update: 15000, best_iteration: 15000, best_val/hateful_memes/roc_auc: 0.701934
[32m2021-03-04T08:17:20 | mmf.trainers.core.training_loop: [0mStepping into final validation check
[32m2021-03-04T08:17:20 | mmf.utils.checkpoint: [0mRestoring checkpoint
[32m2021-03-04T08:17:20 | mmf.utils.checkpoint: [0mLoading checkpoint
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.position_ids from model.bert.embeddings.position_ids
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_embeddings.image_embeddings.weight from model.bert.v_embeddings.image_embeddings.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_embeddings.image_embeddings.bias from model.bert.v_embeddings.image_embeddings.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_embeddings.image_location_embeddings.weight from model.bert.v_embeddings.image_location_embeddings.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_embeddings.image_location_embeddings.bias from model.bert.v_embeddings.image_location_embeddings.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_embeddings.LayerNorm.weight from model.bert.v_embeddings.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_embeddings.LayerNorm.bias from model.bert.v_embeddings.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.self.query.weight from model.bert.encoder.v_layer.0.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.self.query.bias from model.bert.encoder.v_layer.0.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.self.key.weight from model.bert.encoder.v_layer.0.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.self.key.bias from model.bert.encoder.v_layer.0.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.self.value.weight from model.bert.encoder.v_layer.0.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.self.value.bias from model.bert.encoder.v_layer.0.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.output.dense.weight from model.bert.encoder.v_layer.0.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.output.dense.bias from model.bert.encoder.v_layer.0.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.0.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.0.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.intermediate.dense.weight from model.bert.encoder.v_layer.0.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.intermediate.dense.bias from model.bert.encoder.v_layer.0.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.output.dense.weight from model.bert.encoder.v_layer.0.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.output.dense.bias from model.bert.encoder.v_layer.0.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.output.LayerNorm.weight from model.bert.encoder.v_layer.0.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.output.LayerNorm.bias from model.bert.encoder.v_layer.0.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.self.query.weight from model.bert.encoder.v_layer.1.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.self.query.bias from model.bert.encoder.v_layer.1.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.self.key.weight from model.bert.encoder.v_layer.1.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.self.key.bias from model.bert.encoder.v_layer.1.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.self.value.weight from model.bert.encoder.v_layer.1.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.self.value.bias from model.bert.encoder.v_layer.1.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.output.dense.weight from model.bert.encoder.v_layer.1.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.output.dense.bias from model.bert.encoder.v_layer.1.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.1.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.1.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.intermediate.dense.weight from model.bert.encoder.v_layer.1.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.intermediate.dense.bias from model.bert.encoder.v_layer.1.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.output.dense.weight from model.bert.encoder.v_layer.1.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.output.dense.bias from model.bert.encoder.v_layer.1.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.output.LayerNorm.weight from model.bert.encoder.v_layer.1.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.output.LayerNorm.bias from model.bert.encoder.v_layer.1.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.self.query.weight from model.bert.encoder.v_layer.2.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.self.query.bias from model.bert.encoder.v_layer.2.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.self.key.weight from model.bert.encoder.v_layer.2.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.self.key.bias from model.bert.encoder.v_layer.2.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.self.value.weight from model.bert.encoder.v_layer.2.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.self.value.bias from model.bert.encoder.v_layer.2.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.output.dense.weight from model.bert.encoder.v_layer.2.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.output.dense.bias from model.bert.encoder.v_layer.2.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.2.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.2.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.intermediate.dense.weight from model.bert.encoder.v_layer.2.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.intermediate.dense.bias from model.bert.encoder.v_layer.2.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.output.dense.weight from model.bert.encoder.v_layer.2.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.output.dense.bias from model.bert.encoder.v_layer.2.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.output.LayerNorm.weight from model.bert.encoder.v_layer.2.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.output.LayerNorm.bias from model.bert.encoder.v_layer.2.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.self.query.weight from model.bert.encoder.v_layer.3.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.self.query.bias from model.bert.encoder.v_layer.3.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.self.key.weight from model.bert.encoder.v_layer.3.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.self.key.bias from model.bert.encoder.v_layer.3.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.self.value.weight from model.bert.encoder.v_layer.3.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.self.value.bias from model.bert.encoder.v_layer.3.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.output.dense.weight from model.bert.encoder.v_layer.3.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.output.dense.bias from model.bert.encoder.v_layer.3.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.3.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.3.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.intermediate.dense.weight from model.bert.encoder.v_layer.3.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.intermediate.dense.bias from model.bert.encoder.v_layer.3.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.output.dense.weight from model.bert.encoder.v_layer.3.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.output.dense.bias from model.bert.encoder.v_layer.3.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.output.LayerNorm.weight from model.bert.encoder.v_layer.3.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.output.LayerNorm.bias from model.bert.encoder.v_layer.3.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.self.query.weight from model.bert.encoder.v_layer.4.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.self.query.bias from model.bert.encoder.v_layer.4.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.self.key.weight from model.bert.encoder.v_layer.4.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.self.key.bias from model.bert.encoder.v_layer.4.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.self.value.weight from model.bert.encoder.v_layer.4.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.self.value.bias from model.bert.encoder.v_layer.4.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.output.dense.weight from model.bert.encoder.v_layer.4.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.output.dense.bias from model.bert.encoder.v_layer.4.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.4.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.4.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.intermediate.dense.weight from model.bert.encoder.v_layer.4.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.intermediate.dense.bias from model.bert.encoder.v_layer.4.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.output.dense.weight from model.bert.encoder.v_layer.4.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.output.dense.bias from model.bert.encoder.v_layer.4.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.output.LayerNorm.weight from model.bert.encoder.v_layer.4.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.output.LayerNorm.bias from model.bert.encoder.v_layer.4.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.self.query.weight from model.bert.encoder.v_layer.5.attention.self.query.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.self.query.bias from model.bert.encoder.v_layer.5.attention.self.query.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.self.key.weight from model.bert.encoder.v_layer.5.attention.self.key.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.self.key.bias from model.bert.encoder.v_layer.5.attention.self.key.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.self.value.weight from model.bert.encoder.v_layer.5.attention.self.value.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.self.value.bias from model.bert.encoder.v_layer.5.attention.self.value.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.output.dense.weight from model.bert.encoder.v_layer.5.attention.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.output.dense.bias from model.bert.encoder.v_layer.5.attention.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.5.attention.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.5.attention.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.intermediate.dense.weight from model.bert.encoder.v_layer.5.intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.intermediate.dense.bias from model.bert.encoder.v_layer.5.intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.output.dense.weight from model.bert.encoder.v_layer.5.output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.output.dense.bias from model.bert.encoder.v_layer.5.output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.output.LayerNorm.weight from model.bert.encoder.v_layer.5.output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.output.LayerNorm.bias from model.bert.encoder.v_layer.5.output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.query1.weight from model.bert.encoder.c_layer.0.biattention.query1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.query1.bias from model.bert.encoder.c_layer.0.biattention.query1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.key1.weight from model.bert.encoder.c_layer.0.biattention.key1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.key1.bias from model.bert.encoder.c_layer.0.biattention.key1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.value1.weight from model.bert.encoder.c_layer.0.biattention.value1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.value1.bias from model.bert.encoder.c_layer.0.biattention.value1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.query2.weight from model.bert.encoder.c_layer.0.biattention.query2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.query2.bias from model.bert.encoder.c_layer.0.biattention.query2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.key2.weight from model.bert.encoder.c_layer.0.biattention.key2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.key2.bias from model.bert.encoder.c_layer.0.biattention.key2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.value2.weight from model.bert.encoder.c_layer.0.biattention.value2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.value2.bias from model.bert.encoder.c_layer.0.biattention.value2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.dense1.weight from model.bert.encoder.c_layer.0.biOutput.dense1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.dense1.bias from model.bert.encoder.c_layer.0.biOutput.dense1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.0.biOutput.LayerNorm1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.0.biOutput.LayerNorm1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.q_dense1.weight from model.bert.encoder.c_layer.0.biOutput.q_dense1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.q_dense1.bias from model.bert.encoder.c_layer.0.biOutput.q_dense1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.dense2.weight from model.bert.encoder.c_layer.0.biOutput.dense2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.dense2.bias from model.bert.encoder.c_layer.0.biOutput.dense2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.0.biOutput.LayerNorm2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.0.biOutput.LayerNorm2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.q_dense2.weight from model.bert.encoder.c_layer.0.biOutput.q_dense2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.q_dense2.bias from model.bert.encoder.c_layer.0.biOutput.q_dense2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.v_intermediate.dense.weight from model.bert.encoder.c_layer.0.v_intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.v_intermediate.dense.bias from model.bert.encoder.c_layer.0.v_intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.v_output.dense.weight from model.bert.encoder.c_layer.0.v_output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.v_output.dense.bias from model.bert.encoder.c_layer.0.v_output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.v_output.LayerNorm.weight from model.bert.encoder.c_layer.0.v_output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.v_output.LayerNorm.bias from model.bert.encoder.c_layer.0.v_output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.t_intermediate.dense.weight from model.bert.encoder.c_layer.0.t_intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.t_intermediate.dense.bias from model.bert.encoder.c_layer.0.t_intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.t_output.dense.weight from model.bert.encoder.c_layer.0.t_output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.t_output.dense.bias from model.bert.encoder.c_layer.0.t_output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.t_output.LayerNorm.weight from model.bert.encoder.c_layer.0.t_output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.t_output.LayerNorm.bias from model.bert.encoder.c_layer.0.t_output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.query1.weight from model.bert.encoder.c_layer.1.biattention.query1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.query1.bias from model.bert.encoder.c_layer.1.biattention.query1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.key1.weight from model.bert.encoder.c_layer.1.biattention.key1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.key1.bias from model.bert.encoder.c_layer.1.biattention.key1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.value1.weight from model.bert.encoder.c_layer.1.biattention.value1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.value1.bias from model.bert.encoder.c_layer.1.biattention.value1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.query2.weight from model.bert.encoder.c_layer.1.biattention.query2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.query2.bias from model.bert.encoder.c_layer.1.biattention.query2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.key2.weight from model.bert.encoder.c_layer.1.biattention.key2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.key2.bias from model.bert.encoder.c_layer.1.biattention.key2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.value2.weight from model.bert.encoder.c_layer.1.biattention.value2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.value2.bias from model.bert.encoder.c_layer.1.biattention.value2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.dense1.weight from model.bert.encoder.c_layer.1.biOutput.dense1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.dense1.bias from model.bert.encoder.c_layer.1.biOutput.dense1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.1.biOutput.LayerNorm1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.1.biOutput.LayerNorm1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.q_dense1.weight from model.bert.encoder.c_layer.1.biOutput.q_dense1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.q_dense1.bias from model.bert.encoder.c_layer.1.biOutput.q_dense1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.dense2.weight from model.bert.encoder.c_layer.1.biOutput.dense2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.dense2.bias from model.bert.encoder.c_layer.1.biOutput.dense2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.1.biOutput.LayerNorm2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.1.biOutput.LayerNorm2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.q_dense2.weight from model.bert.encoder.c_layer.1.biOutput.q_dense2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.q_dense2.bias from model.bert.encoder.c_layer.1.biOutput.q_dense2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.v_intermediate.dense.weight from model.bert.encoder.c_layer.1.v_intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.v_intermediate.dense.bias from model.bert.encoder.c_layer.1.v_intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.v_output.dense.weight from model.bert.encoder.c_layer.1.v_output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.v_output.dense.bias from model.bert.encoder.c_layer.1.v_output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.v_output.LayerNorm.weight from model.bert.encoder.c_layer.1.v_output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.v_output.LayerNorm.bias from model.bert.encoder.c_layer.1.v_output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.t_intermediate.dense.weight from model.bert.encoder.c_layer.1.t_intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.t_intermediate.dense.bias from model.bert.encoder.c_layer.1.t_intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.t_output.dense.weight from model.bert.encoder.c_layer.1.t_output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.t_output.dense.bias from model.bert.encoder.c_layer.1.t_output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.t_output.LayerNorm.weight from model.bert.encoder.c_layer.1.t_output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.t_output.LayerNorm.bias from model.bert.encoder.c_layer.1.t_output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.query1.weight from model.bert.encoder.c_layer.2.biattention.query1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.query1.bias from model.bert.encoder.c_layer.2.biattention.query1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.key1.weight from model.bert.encoder.c_layer.2.biattention.key1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.key1.bias from model.bert.encoder.c_layer.2.biattention.key1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.value1.weight from model.bert.encoder.c_layer.2.biattention.value1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.value1.bias from model.bert.encoder.c_layer.2.biattention.value1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.query2.weight from model.bert.encoder.c_layer.2.biattention.query2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.query2.bias from model.bert.encoder.c_layer.2.biattention.query2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.key2.weight from model.bert.encoder.c_layer.2.biattention.key2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.key2.bias from model.bert.encoder.c_layer.2.biattention.key2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.value2.weight from model.bert.encoder.c_layer.2.biattention.value2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.value2.bias from model.bert.encoder.c_layer.2.biattention.value2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.dense1.weight from model.bert.encoder.c_layer.2.biOutput.dense1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.dense1.bias from model.bert.encoder.c_layer.2.biOutput.dense1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.2.biOutput.LayerNorm1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.2.biOutput.LayerNorm1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.q_dense1.weight from model.bert.encoder.c_layer.2.biOutput.q_dense1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.q_dense1.bias from model.bert.encoder.c_layer.2.biOutput.q_dense1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.dense2.weight from model.bert.encoder.c_layer.2.biOutput.dense2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.dense2.bias from model.bert.encoder.c_layer.2.biOutput.dense2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.2.biOutput.LayerNorm2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.2.biOutput.LayerNorm2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.q_dense2.weight from model.bert.encoder.c_layer.2.biOutput.q_dense2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.q_dense2.bias from model.bert.encoder.c_layer.2.biOutput.q_dense2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.v_intermediate.dense.weight from model.bert.encoder.c_layer.2.v_intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.v_intermediate.dense.bias from model.bert.encoder.c_layer.2.v_intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.v_output.dense.weight from model.bert.encoder.c_layer.2.v_output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.v_output.dense.bias from model.bert.encoder.c_layer.2.v_output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.v_output.LayerNorm.weight from model.bert.encoder.c_layer.2.v_output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.v_output.LayerNorm.bias from model.bert.encoder.c_layer.2.v_output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.t_intermediate.dense.weight from model.bert.encoder.c_layer.2.t_intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.t_intermediate.dense.bias from model.bert.encoder.c_layer.2.t_intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.t_output.dense.weight from model.bert.encoder.c_layer.2.t_output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.t_output.dense.bias from model.bert.encoder.c_layer.2.t_output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.t_output.LayerNorm.weight from model.bert.encoder.c_layer.2.t_output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.t_output.LayerNorm.bias from model.bert.encoder.c_layer.2.t_output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.query1.weight from model.bert.encoder.c_layer.3.biattention.query1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.query1.bias from model.bert.encoder.c_layer.3.biattention.query1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.key1.weight from model.bert.encoder.c_layer.3.biattention.key1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.key1.bias from model.bert.encoder.c_layer.3.biattention.key1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.value1.weight from model.bert.encoder.c_layer.3.biattention.value1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.value1.bias from model.bert.encoder.c_layer.3.biattention.value1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.query2.weight from model.bert.encoder.c_layer.3.biattention.query2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.query2.bias from model.bert.encoder.c_layer.3.biattention.query2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.key2.weight from model.bert.encoder.c_layer.3.biattention.key2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.key2.bias from model.bert.encoder.c_layer.3.biattention.key2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.value2.weight from model.bert.encoder.c_layer.3.biattention.value2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.value2.bias from model.bert.encoder.c_layer.3.biattention.value2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.dense1.weight from model.bert.encoder.c_layer.3.biOutput.dense1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.dense1.bias from model.bert.encoder.c_layer.3.biOutput.dense1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.3.biOutput.LayerNorm1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.3.biOutput.LayerNorm1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.q_dense1.weight from model.bert.encoder.c_layer.3.biOutput.q_dense1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.q_dense1.bias from model.bert.encoder.c_layer.3.biOutput.q_dense1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.dense2.weight from model.bert.encoder.c_layer.3.biOutput.dense2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.dense2.bias from model.bert.encoder.c_layer.3.biOutput.dense2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.3.biOutput.LayerNorm2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.3.biOutput.LayerNorm2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.q_dense2.weight from model.bert.encoder.c_layer.3.biOutput.q_dense2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.q_dense2.bias from model.bert.encoder.c_layer.3.biOutput.q_dense2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.v_intermediate.dense.weight from model.bert.encoder.c_layer.3.v_intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.v_intermediate.dense.bias from model.bert.encoder.c_layer.3.v_intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.v_output.dense.weight from model.bert.encoder.c_layer.3.v_output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.v_output.dense.bias from model.bert.encoder.c_layer.3.v_output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.v_output.LayerNorm.weight from model.bert.encoder.c_layer.3.v_output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.v_output.LayerNorm.bias from model.bert.encoder.c_layer.3.v_output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.t_intermediate.dense.weight from model.bert.encoder.c_layer.3.t_intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.t_intermediate.dense.bias from model.bert.encoder.c_layer.3.t_intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.t_output.dense.weight from model.bert.encoder.c_layer.3.t_output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.t_output.dense.bias from model.bert.encoder.c_layer.3.t_output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.t_output.LayerNorm.weight from model.bert.encoder.c_layer.3.t_output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.t_output.LayerNorm.bias from model.bert.encoder.c_layer.3.t_output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.query1.weight from model.bert.encoder.c_layer.4.biattention.query1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.query1.bias from model.bert.encoder.c_layer.4.biattention.query1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.key1.weight from model.bert.encoder.c_layer.4.biattention.key1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.key1.bias from model.bert.encoder.c_layer.4.biattention.key1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.value1.weight from model.bert.encoder.c_layer.4.biattention.value1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.value1.bias from model.bert.encoder.c_layer.4.biattention.value1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.query2.weight from model.bert.encoder.c_layer.4.biattention.query2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.query2.bias from model.bert.encoder.c_layer.4.biattention.query2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.key2.weight from model.bert.encoder.c_layer.4.biattention.key2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.key2.bias from model.bert.encoder.c_layer.4.biattention.key2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.value2.weight from model.bert.encoder.c_layer.4.biattention.value2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.value2.bias from model.bert.encoder.c_layer.4.biattention.value2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.dense1.weight from model.bert.encoder.c_layer.4.biOutput.dense1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.dense1.bias from model.bert.encoder.c_layer.4.biOutput.dense1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.4.biOutput.LayerNorm1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.4.biOutput.LayerNorm1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.q_dense1.weight from model.bert.encoder.c_layer.4.biOutput.q_dense1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.q_dense1.bias from model.bert.encoder.c_layer.4.biOutput.q_dense1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.dense2.weight from model.bert.encoder.c_layer.4.biOutput.dense2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.dense2.bias from model.bert.encoder.c_layer.4.biOutput.dense2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.4.biOutput.LayerNorm2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.4.biOutput.LayerNorm2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.q_dense2.weight from model.bert.encoder.c_layer.4.biOutput.q_dense2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.q_dense2.bias from model.bert.encoder.c_layer.4.biOutput.q_dense2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.v_intermediate.dense.weight from model.bert.encoder.c_layer.4.v_intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.v_intermediate.dense.bias from model.bert.encoder.c_layer.4.v_intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.v_output.dense.weight from model.bert.encoder.c_layer.4.v_output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.v_output.dense.bias from model.bert.encoder.c_layer.4.v_output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.v_output.LayerNorm.weight from model.bert.encoder.c_layer.4.v_output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.v_output.LayerNorm.bias from model.bert.encoder.c_layer.4.v_output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.t_intermediate.dense.weight from model.bert.encoder.c_layer.4.t_intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.t_intermediate.dense.bias from model.bert.encoder.c_layer.4.t_intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.t_output.dense.weight from model.bert.encoder.c_layer.4.t_output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.t_output.dense.bias from model.bert.encoder.c_layer.4.t_output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.t_output.LayerNorm.weight from model.bert.encoder.c_layer.4.t_output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.t_output.LayerNorm.bias from model.bert.encoder.c_layer.4.t_output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.query1.weight from model.bert.encoder.c_layer.5.biattention.query1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.query1.bias from model.bert.encoder.c_layer.5.biattention.query1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.key1.weight from model.bert.encoder.c_layer.5.biattention.key1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.key1.bias from model.bert.encoder.c_layer.5.biattention.key1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.value1.weight from model.bert.encoder.c_layer.5.biattention.value1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.value1.bias from model.bert.encoder.c_layer.5.biattention.value1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.query2.weight from model.bert.encoder.c_layer.5.biattention.query2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.query2.bias from model.bert.encoder.c_layer.5.biattention.query2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.key2.weight from model.bert.encoder.c_layer.5.biattention.key2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.key2.bias from model.bert.encoder.c_layer.5.biattention.key2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.value2.weight from model.bert.encoder.c_layer.5.biattention.value2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.value2.bias from model.bert.encoder.c_layer.5.biattention.value2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.dense1.weight from model.bert.encoder.c_layer.5.biOutput.dense1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.dense1.bias from model.bert.encoder.c_layer.5.biOutput.dense1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.5.biOutput.LayerNorm1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.5.biOutput.LayerNorm1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.q_dense1.weight from model.bert.encoder.c_layer.5.biOutput.q_dense1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.q_dense1.bias from model.bert.encoder.c_layer.5.biOutput.q_dense1.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.dense2.weight from model.bert.encoder.c_layer.5.biOutput.dense2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.dense2.bias from model.bert.encoder.c_layer.5.biOutput.dense2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.5.biOutput.LayerNorm2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.5.biOutput.LayerNorm2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.q_dense2.weight from model.bert.encoder.c_layer.5.biOutput.q_dense2.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.q_dense2.bias from model.bert.encoder.c_layer.5.biOutput.q_dense2.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.v_intermediate.dense.weight from model.bert.encoder.c_layer.5.v_intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.v_intermediate.dense.bias from model.bert.encoder.c_layer.5.v_intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.v_output.dense.weight from model.bert.encoder.c_layer.5.v_output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.v_output.dense.bias from model.bert.encoder.c_layer.5.v_output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.v_output.LayerNorm.weight from model.bert.encoder.c_layer.5.v_output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.v_output.LayerNorm.bias from model.bert.encoder.c_layer.5.v_output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.t_intermediate.dense.weight from model.bert.encoder.c_layer.5.t_intermediate.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.t_intermediate.dense.bias from model.bert.encoder.c_layer.5.t_intermediate.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.t_output.dense.weight from model.bert.encoder.c_layer.5.t_output.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.t_output.dense.bias from model.bert.encoder.c_layer.5.t_output.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.t_output.LayerNorm.weight from model.bert.encoder.c_layer.5.t_output.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.t_output.LayerNorm.bias from model.bert.encoder.c_layer.5.t_output.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.t_pooler.dense.weight from model.bert.t_pooler.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.t_pooler.dense.bias from model.bert.t_pooler.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_pooler.dense.weight from model.bert.v_pooler.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_pooler.dense.bias from model.bert.v_pooler.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.dense.weight from model.classifier.0.dense.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.dense.bias from model.classifier.0.dense.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.LayerNorm.weight from model.classifier.0.LayerNorm.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.LayerNorm.bias from model.classifier.0.LayerNorm.bias
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.1.weight from model.classifier.1.weight
[32m2021-03-04T08:17:46 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.1.bias from model.classifier.1.bias
[5m[31mWARNING[0m [32m2021-03-04T08:17:47 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T08:17:47 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T08:17:47 | mmf.utils.checkpoint: [0mCheckpoint loaded.
[32m2021-03-04T08:17:47 | mmf.utils.checkpoint: [0mCurrent num updates: 15000
[32m2021-03-04T08:17:47 | mmf.utils.checkpoint: [0mCurrent iteration: 15000
[32m2021-03-04T08:17:47 | mmf.utils.checkpoint: [0mCurrent epoch: 57
[32m2021-03-04T08:17:48 | mmf.trainers.mmf_trainer: [0mStarting inference on val set
  0%|          | 0/68 [00:00<?, ?it/s]  1%|â–         | 1/68 [00:10<11:30, 10.31s/it]  4%|â–         | 3/68 [00:10<02:58,  2.74s/it]  7%|â–‹         | 5/68 [00:10<01:26,  1.37s/it] 10%|â–ˆ         | 7/68 [00:10<00:50,  1.21it/s] 13%|â–ˆâ–Ž        | 9/68 [00:10<00:32,  1.84it/s] 16%|â–ˆâ–Œ        | 11/68 [00:11<00:22,  2.57it/s] 19%|â–ˆâ–‰        | 13/68 [00:11<00:15,  3.54it/s] 22%|â–ˆâ–ˆâ–       | 15/68 [00:11<00:11,  4.63it/s] 25%|â–ˆâ–ˆâ–Œ       | 17/68 [00:11<00:08,  5.79it/s] 25%|â–ˆâ–ˆâ–Œ       | 17/68 [00:12<00:36,  1.42it/s][32m2021-03-04T08:18:00 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T08:18:00 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, val/hateful_memes/cross_entropy: 2.5364, val/total_loss: 2.5364, val/hateful_memes/accuracy: 0.6889, val/hateful_memes/binary_f1: 0.4488, val/hateful_memes/roc_auc: 0.7019
[32m2021-03-04T08:18:00 | mmf.trainers.callbacks.logistics: [0mFinished run in 03h 51m 22s 030ms

Training VILBERT_CC complete
********************************************************************
Training VISUAL_BERT_DIRECT
[32m2021-03-04T08:18:07 | mmf.utils.configuration: [0mOverriding option config to projects/hateful_memes/configs/visual_bert/direct.yaml
[32m2021-03-04T08:18:07 | mmf.utils.configuration: [0mOverriding option model to visual_bert
[32m2021-03-04T08:18:07 | mmf.utils.configuration: [0mOverriding option datasets to hateful_memes
[32m2021-03-04T08:18:07 | mmf.utils.configuration: [0mOverriding option run_type to train_val
[32m2021-03-04T08:18:07 | mmf.utils.configuration: [0mOverriding option checkpoint.max_to_keep to 3
[32m2021-03-04T08:18:09 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T08:18:09 | mmf.utils.distributed: [0mDistributed Init (Rank 0): tcp://localhost:17044
[32m2021-03-04T08:18:10 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T08:18:10 | mmf.utils.distributed: [0mDistributed Init (Rank 3): tcp://localhost:17044
[32m2021-03-04T08:18:10 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 3
[32m2021-03-04T08:18:10 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T08:18:10 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T08:18:10 | mmf.utils.distributed: [0mDistributed Init (Rank 1): tcp://localhost:17044
[32m2021-03-04T08:18:10 | mmf.utils.distributed: [0mDistributed Init (Rank 2): tcp://localhost:17044
[32m2021-03-04T08:18:10 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 1
[32m2021-03-04T08:18:10 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 2
[32m2021-03-04T08:18:10 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 0
[32m2021-03-04T08:18:17 | mmf: [0mLogging to: /scratch/sagarsj42/save/train.log
[32m2021-03-04T08:18:17 | mmf_cli.run: [0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/visual_bert/direct.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=train_val', 'checkpoint.max_to_keep=3'])
[32m2021-03-04T08:18:17 | mmf_cli.run: [0mTorch version: 1.6.0
[32m2021-03-04T08:18:17 | mmf.utils.general: [0mCUDA Device 0 is: GeForce GTX 1080 Ti
[32m2021-03-04T08:18:17 | mmf_cli.run: [0mUsing seed 17488407
[32m2021-03-04T08:18:17 | mmf.trainers.mmf_trainer: [0mLoading datasets
[32m2021-03-04T08:18:23 | mmf.trainers.mmf_trainer: [0mLoading model
Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[32m2021-03-04T08:18:28 | mmf.trainers.mmf_trainer: [0mLoading optimizer
[32m2021-03-04T08:18:28 | mmf.trainers.mmf_trainer: [0mLoading metrics
[5m[31mWARNING[0m [32m2021-03-04T08:18:28 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.
Use OmegaConf.to_yaml(cfg)

  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T08:18:28 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.
Use OmegaConf.to_yaml(cfg)

  builtin_warn(*args, **kwargs)

Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[32m2021-03-04T08:18:32 | mmf.trainers.mmf_trainer: [0m===== Model =====
[32m2021-03-04T08:18:32 | mmf.trainers.mmf_trainer: [0mDistributedDataParallel(
  (module): VisualBERT(
    (model): VisualBERTForClassification(
      (bert): VisualBERTBase(
        (embeddings): BertVisioLinguisticEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (token_type_embeddings_visual): Embedding(2, 768)
          (position_embeddings_visual): Embedding(512, 768)
          (projection): Linear(in_features=2048, out_features=768, bias=True)
        )
        (encoder): BertEncoderJit(
          (layer): ModuleList(
            (0): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayerJit(
              (attention): BertAttentionJit(
                (self): BertSelfAttentionJit(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
      (classifier): Sequential(
        (0): BertPredictionHeadTransform(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (1): Linear(in_features=768, out_features=2, bias=True)
      )
    )
    (losses): Losses(
      (losses): ModuleList(
        (0): MMFLoss(
          (loss_criterion): CrossEntropyLoss(
            (loss_fn): CrossEntropyLoss()
          )
        )
      )
    )
  )
)
[32m2021-03-04T08:18:32 | mmf.utils.general: [0mTotal Parameters: 112044290. Trained Parameters: 112044290
[32m2021-03-04T08:18:32 | mmf.trainers.core.training_loop: [0mStarting training...
[32m2021-03-04T08:20:28 | mmf.trainers.callbacks.logistics: [0mprogress: 100/22000, train/hateful_memes/cross_entropy: 0.6416, train/hateful_memes/cross_entropy/avg: 0.6416, train/total_loss: 0.6416, train/total_loss/avg: 0.6416, max mem: 9603.0, experiment: run, epoch: 2, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 0.86, time: 01m 56s 330ms, time_since_start: 02m 101ms, eta: 07h 04m 36s 492ms
[32m2021-03-04T08:22:02 | mmf.trainers.callbacks.logistics: [0mprogress: 200/22000, train/hateful_memes/cross_entropy: 0.6119, train/hateful_memes/cross_entropy/avg: 0.6267, train/total_loss: 0.6119, train/total_loss/avg: 0.6267, max mem: 9603.0, experiment: run, epoch: 3, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0.00001, ups: 1.08, time: 01m 33s 965ms, time_since_start: 03m 34s 066ms, eta: 05h 41m 24s 384ms
[32m2021-03-04T08:23:47 | mmf.trainers.callbacks.logistics: [0mprogress: 300/22000, train/hateful_memes/cross_entropy: 0.6119, train/hateful_memes/cross_entropy/avg: 0.5988, train/total_loss: 0.6119, train/total_loss/avg: 0.5988, max mem: 9603.0, experiment: run, epoch: 5, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0.00001, ups: 0.95, time: 01m 45s 410ms, time_since_start: 05m 19s 477ms, eta: 06h 21m 14s 179ms
[32m2021-03-04T08:25:21 | mmf.trainers.callbacks.logistics: [0mprogress: 400/22000, train/hateful_memes/cross_entropy: 0.5429, train/hateful_memes/cross_entropy/avg: 0.5555, train/total_loss: 0.5429, train/total_loss/avg: 0.5555, max mem: 9603.0, experiment: run, epoch: 6, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0.00001, ups: 1.08, time: 01m 33s 570ms, time_since_start: 06m 53s 047ms, eta: 05h 36m 51s 254ms
[32m2021-03-04T08:27:07 | mmf.trainers.callbacks.logistics: [0mprogress: 500/22000, train/hateful_memes/cross_entropy: 0.5429, train/hateful_memes/cross_entropy/avg: 0.5125, train/total_loss: 0.5429, train/total_loss/avg: 0.5125, max mem: 9603.0, experiment: run, epoch: 8, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0.00001, ups: 0.94, time: 01m 46s 516ms, time_since_start: 08m 39s 564ms, eta: 06h 21m 40s 987ms
[32m2021-03-04T08:28:44 | mmf.trainers.callbacks.logistics: [0mprogress: 600/22000, train/hateful_memes/cross_entropy: 0.4258, train/hateful_memes/cross_entropy/avg: 0.4763, train/total_loss: 0.4258, train/total_loss/avg: 0.4763, max mem: 9603.0, experiment: run, epoch: 9, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0.00002, ups: 1.04, time: 01m 36s 312ms, time_since_start: 10m 15s 876ms, eta: 05h 43m 30s 806ms
[32m2021-03-04T08:30:28 | mmf.trainers.callbacks.logistics: [0mprogress: 700/22000, train/hateful_memes/cross_entropy: 0.4258, train/hateful_memes/cross_entropy/avg: 0.4328, train/total_loss: 0.4258, train/total_loss/avg: 0.4328, max mem: 9603.0, experiment: run, epoch: 11, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0.00002, ups: 0.97, time: 01m 43s 864ms, time_since_start: 11m 59s 741ms, eta: 06h 08m 43s 193ms
[32m2021-03-04T08:32:01 | mmf.trainers.callbacks.logistics: [0mprogress: 800/22000, train/hateful_memes/cross_entropy: 0.3403, train/hateful_memes/cross_entropy/avg: 0.3968, train/total_loss: 0.3403, train/total_loss/avg: 0.3968, max mem: 9603.0, experiment: run, epoch: 12, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0.00002, ups: 1.08, time: 01m 33s 800ms, time_since_start: 13m 33s 541ms, eta: 05h 31m 25s 683ms
[32m2021-03-04T08:33:46 | mmf.trainers.callbacks.logistics: [0mprogress: 900/22000, train/hateful_memes/cross_entropy: 0.3403, train/hateful_memes/cross_entropy/avg: 0.3633, train/total_loss: 0.3403, train/total_loss/avg: 0.3633, max mem: 9603.0, experiment: run, epoch: 14, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0.00002, ups: 0.96, time: 01m 44s 789ms, time_since_start: 15m 18s 331ms, eta: 06h 08m 30s 574ms
[32m2021-03-04T08:35:20 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T08:35:20 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T08:35:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T08:35:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T08:35:24 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T08:35:45 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T08:35:45 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, train/hateful_memes/cross_entropy: 0.2951, train/hateful_memes/cross_entropy/avg: 0.3353, train/total_loss: 0.2951, train/total_loss/avg: 0.3353, max mem: 9603.0, experiment: run, epoch: 15, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00003, ups: 0.84, time: 01m 59s 120ms, time_since_start: 17m 17s 451ms, eta: 06h 56m 55s 370ms
[32m2021-03-04T08:35:45 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T08:36:02 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T08:36:02 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T08:36:02 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T08:36:02 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T08:36:13 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T08:36:23 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T08:36:34 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T08:36:34 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, val/hateful_memes/cross_entropy: 1.1819, val/total_loss: 1.1819, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.3990, val/hateful_memes/roc_auc: 0.7096, num_updates: 1000, epoch: 15, iterations: 1000, max_updates: 22000, val_time: 48s 304ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T08:38:17 | mmf.trainers.callbacks.logistics: [0mprogress: 1100/22000, train/hateful_memes/cross_entropy: 0.2951, train/hateful_memes/cross_entropy/avg: 0.3152, train/total_loss: 0.2951, train/total_loss/avg: 0.3152, max mem: 9622.0, experiment: run, epoch: 17, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00003, ups: 0.97, time: 01m 43s 692ms, time_since_start: 19m 49s 462ms, eta: 06h 01m 11s 646ms
[32m2021-03-04T08:39:52 | mmf.trainers.callbacks.logistics: [0mprogress: 1200/22000, train/hateful_memes/cross_entropy: 0.1722, train/hateful_memes/cross_entropy/avg: 0.2924, train/total_loss: 0.1722, train/total_loss/avg: 0.2924, max mem: 9622.0, experiment: run, epoch: 18, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00003, ups: 1.06, time: 01m 34s 527ms, time_since_start: 21m 23s 990ms, eta: 05h 27m 41s 766ms
[32m2021-03-04T08:41:35 | mmf.trainers.callbacks.logistics: [0mprogress: 1300/22000, train/hateful_memes/cross_entropy: 0.1722, train/hateful_memes/cross_entropy/avg: 0.2727, train/total_loss: 0.1722, train/total_loss/avg: 0.2727, max mem: 9622.0, experiment: run, epoch: 20, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00003, ups: 0.97, time: 01m 43s 244ms, time_since_start: 23m 07s 234ms, eta: 05h 56m 11s 596ms
[32m2021-03-04T08:43:08 | mmf.trainers.callbacks.logistics: [0mprogress: 1400/22000, train/hateful_memes/cross_entropy: 0.1446, train/hateful_memes/cross_entropy/avg: 0.2551, train/total_loss: 0.1446, train/total_loss/avg: 0.2551, max mem: 9622.0, experiment: run, epoch: 21, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00003, ups: 1.08, time: 01m 33s 374ms, time_since_start: 24m 40s 609ms, eta: 05h 20m 35s 231ms
[32m2021-03-04T08:44:54 | mmf.trainers.callbacks.logistics: [0mprogress: 1500/22000, train/hateful_memes/cross_entropy: 0.1446, train/hateful_memes/cross_entropy/avg: 0.2415, train/total_loss: 0.1446, train/total_loss/avg: 0.2415, max mem: 9622.0, experiment: run, epoch: 23, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00004, ups: 0.95, time: 01m 45s 471ms, time_since_start: 26m 26s 081ms, eta: 06h 21s 683ms
[32m2021-03-04T08:46:30 | mmf.trainers.callbacks.logistics: [0mprogress: 1600/22000, train/hateful_memes/cross_entropy: 0.1136, train/hateful_memes/cross_entropy/avg: 0.2274, train/total_loss: 0.1136, train/total_loss/avg: 0.2274, max mem: 9622.0, experiment: run, epoch: 24, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00004, ups: 1.05, time: 01m 35s 688ms, time_since_start: 28m 01s 770ms, eta: 05h 25m 20s 551ms
[32m2021-03-04T08:48:15 | mmf.trainers.callbacks.logistics: [0mprogress: 1700/22000, train/hateful_memes/cross_entropy: 0.1136, train/hateful_memes/cross_entropy/avg: 0.2173, train/total_loss: 0.1136, train/total_loss/avg: 0.2173, max mem: 9622.0, experiment: run, epoch: 26, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00004, ups: 0.96, time: 01m 44s 936ms, time_since_start: 29m 46s 706ms, eta: 05h 55m 02s 059ms
[32m2021-03-04T08:49:50 | mmf.trainers.callbacks.logistics: [0mprogress: 1800/22000, train/hateful_memes/cross_entropy: 0.0956, train/hateful_memes/cross_entropy/avg: 0.2066, train/total_loss: 0.0956, train/total_loss/avg: 0.2066, max mem: 9622.0, experiment: run, epoch: 27, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00005, ups: 1.05, time: 01m 35s 422ms, time_since_start: 31m 22s 129ms, eta: 05h 21m 15s 369ms
[32m2021-03-04T08:51:35 | mmf.trainers.callbacks.logistics: [0mprogress: 1900/22000, train/hateful_memes/cross_entropy: 0.0956, train/hateful_memes/cross_entropy/avg: 0.1968, train/total_loss: 0.0956, train/total_loss/avg: 0.1968, max mem: 9622.0, experiment: run, epoch: 29, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00005, ups: 0.96, time: 01m 44s 950ms, time_since_start: 33m 07s 079ms, eta: 05h 51m 35s 010ms
[32m2021-03-04T08:53:10 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T08:53:10 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T08:53:10 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T08:53:10 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T08:53:13 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T08:53:23 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T08:53:23 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, train/hateful_memes/cross_entropy: 0.0834, train/hateful_memes/cross_entropy/avg: 0.1877, train/total_loss: 0.0834, train/total_loss/avg: 0.1877, max mem: 9622.0, experiment: run, epoch: 30, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00005, ups: 0.93, time: 01m 48s 211ms, time_since_start: 34m 55s 291ms, eta: 06h 42s 340ms
[32m2021-03-04T08:53:23 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T08:53:40 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T08:53:40 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T08:53:40 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T08:53:40 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T08:53:51 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T08:54:01 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T08:54:01 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, val/hateful_memes/cross_entropy: 1.7290, val/total_loss: 1.7290, val/hateful_memes/accuracy: 0.6704, val/hateful_memes/binary_f1: 0.4730, val/hateful_memes/roc_auc: 0.6835, num_updates: 2000, epoch: 30, iterations: 2000, max_updates: 22000, val_time: 37s 937ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T08:55:46 | mmf.trainers.callbacks.logistics: [0mprogress: 2100/22000, train/hateful_memes/cross_entropy: 0.0556, train/hateful_memes/cross_entropy/avg: 0.1795, train/total_loss: 0.0556, train/total_loss/avg: 0.1795, max mem: 9622.0, experiment: run, epoch: 32, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00005, ups: 0.95, time: 01m 45s 272ms, time_since_start: 37m 18s 503ms, eta: 05h 49m 09s 290ms
[32m2021-03-04T08:57:20 | mmf.trainers.callbacks.logistics: [0mprogress: 2200/22000, train/hateful_memes/cross_entropy: 0.0514, train/hateful_memes/cross_entropy/avg: 0.1720, train/total_loss: 0.0514, train/total_loss/avg: 0.1720, max mem: 9622.0, experiment: run, epoch: 33, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00005, ups: 1.06, time: 01m 34s 044ms, time_since_start: 38m 52s 547ms, eta: 05h 10m 20s 808ms
[32m2021-03-04T08:59:05 | mmf.trainers.callbacks.logistics: [0mprogress: 2300/22000, train/hateful_memes/cross_entropy: 0.0514, train/hateful_memes/cross_entropy/avg: 0.1668, train/total_loss: 0.0514, train/total_loss/avg: 0.1668, max mem: 9622.0, experiment: run, epoch: 35, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00005, ups: 0.96, time: 01m 44s 630ms, time_since_start: 40m 37s 178ms, eta: 05h 43m 32s 183ms
[32m2021-03-04T09:00:40 | mmf.trainers.callbacks.logistics: [0mprogress: 2400/22000, train/hateful_memes/cross_entropy: 0.0423, train/hateful_memes/cross_entropy/avg: 0.1600, train/total_loss: 0.0423, train/total_loss/avg: 0.1600, max mem: 9622.0, experiment: run, epoch: 36, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00005, ups: 1.06, time: 01m 34s 644ms, time_since_start: 42m 11s 822ms, eta: 05h 09m 10s 361ms
[32m2021-03-04T09:02:24 | mmf.trainers.callbacks.logistics: [0mprogress: 2500/22000, train/hateful_memes/cross_entropy: 0.0363, train/hateful_memes/cross_entropy/avg: 0.1537, train/total_loss: 0.0363, train/total_loss/avg: 0.1537, max mem: 9622.0, experiment: run, epoch: 38, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00005, ups: 0.96, time: 01m 44s 227ms, time_since_start: 43m 56s 050ms, eta: 05h 38m 44s 363ms
[32m2021-03-04T09:04:00 | mmf.trainers.callbacks.logistics: [0mprogress: 2600/22000, train/hateful_memes/cross_entropy: 0.0257, train/hateful_memes/cross_entropy/avg: 0.1482, train/total_loss: 0.0257, train/total_loss/avg: 0.1482, max mem: 9622.0, experiment: run, epoch: 39, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00005, ups: 1.04, time: 01m 36s 012ms, time_since_start: 45m 32s 062ms, eta: 05h 10m 26s 430ms
[32m2021-03-04T09:05:44 | mmf.trainers.callbacks.logistics: [0mprogress: 2700/22000, train/hateful_memes/cross_entropy: 0.0241, train/hateful_memes/cross_entropy/avg: 0.1435, train/total_loss: 0.0241, train/total_loss/avg: 0.1435, max mem: 9622.0, experiment: run, epoch: 41, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00005, ups: 0.97, time: 01m 43s 643ms, time_since_start: 47m 15s 706ms, eta: 05h 33m 23s 115ms
[32m2021-03-04T09:07:19 | mmf.trainers.callbacks.logistics: [0mprogress: 2800/22000, train/hateful_memes/cross_entropy: 0.0207, train/hateful_memes/cross_entropy/avg: 0.1386, train/total_loss: 0.0207, train/total_loss/avg: 0.1386, max mem: 9622.0, experiment: run, epoch: 42, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00005, ups: 1.05, time: 01m 35s 068ms, time_since_start: 48m 50s 774ms, eta: 05h 04m 13s 097ms
[32m2021-03-04T09:09:04 | mmf.trainers.callbacks.logistics: [0mprogress: 2900/22000, train/hateful_memes/cross_entropy: 0.0205, train/hateful_memes/cross_entropy/avg: 0.1343, train/total_loss: 0.0205, train/total_loss/avg: 0.1343, max mem: 9622.0, experiment: run, epoch: 44, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00005, ups: 0.95, time: 01m 45s 308ms, time_since_start: 50m 36s 082ms, eta: 05h 35m 13s 936ms
[32m2021-03-04T09:10:42 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T09:10:42 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T09:10:42 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T09:10:42 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T09:10:45 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T09:10:56 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T09:10:56 | mmf.trainers.callbacks.logistics: [0mprogress: 3000/22000, train/hateful_memes/cross_entropy: 0.0163, train/hateful_memes/cross_entropy/avg: 0.1300, train/total_loss: 0.0163, train/total_loss/avg: 0.1300, max mem: 9622.0, experiment: run, epoch: 45, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00005, ups: 0.89, time: 01m 52s 315ms, time_since_start: 52m 28s 398ms, eta: 05h 55m 40s 027ms
[32m2021-03-04T09:10:56 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T09:11:09 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T09:11:09 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T09:11:09 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T09:11:09 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T09:11:21 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T09:11:31 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T09:11:31 | mmf.trainers.callbacks.logistics: [0mprogress: 3000/22000, val/hateful_memes/cross_entropy: 1.7335, val/total_loss: 1.7335, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4820, val/hateful_memes/roc_auc: 0.7085, num_updates: 3000, epoch: 45, iterations: 3000, max_updates: 22000, val_time: 34s 673ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T09:13:15 | mmf.trainers.callbacks.logistics: [0mprogress: 3100/22000, train/hateful_memes/cross_entropy: 0.0156, train/hateful_memes/cross_entropy/avg: 0.1262, train/total_loss: 0.0156, train/total_loss/avg: 0.1262, max mem: 9622.0, experiment: run, epoch: 47, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00005, ups: 0.96, time: 01m 44s 188ms, time_since_start: 54m 47s 263ms, eta: 05h 28m 11s 681ms
[32m2021-03-04T09:14:50 | mmf.trainers.callbacks.logistics: [0mprogress: 3200/22000, train/hateful_memes/cross_entropy: 0.0156, train/hateful_memes/cross_entropy/avg: 0.1238, train/total_loss: 0.0156, train/total_loss/avg: 0.1238, max mem: 9622.0, experiment: run, epoch: 48, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00005, ups: 1.06, time: 01m 34s 677ms, time_since_start: 56m 21s 940ms, eta: 04h 56m 39s 290ms
[32m2021-03-04T09:16:34 | mmf.trainers.callbacks.logistics: [0mprogress: 3300/22000, train/hateful_memes/cross_entropy: 0.0156, train/hateful_memes/cross_entropy/avg: 0.1208, train/total_loss: 0.0156, train/total_loss/avg: 0.1208, max mem: 9622.0, experiment: run, epoch: 50, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00005, ups: 0.97, time: 01m 43s 868ms, time_since_start: 58m 05s 809ms, eta: 05h 23m 43s 331ms
[32m2021-03-04T09:18:09 | mmf.trainers.callbacks.logistics: [0mprogress: 3400/22000, train/hateful_memes/cross_entropy: 0.0152, train/hateful_memes/cross_entropy/avg: 0.1173, train/total_loss: 0.0152, train/total_loss/avg: 0.1173, max mem: 9622.0, experiment: run, epoch: 51, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00005, ups: 1.05, time: 01m 35s 569ms, time_since_start: 59m 41s 379ms, eta: 04h 56m 16s 004ms
[32m2021-03-04T09:19:53 | mmf.trainers.callbacks.logistics: [0mprogress: 3500/22000, train/hateful_memes/cross_entropy: 0.0148, train/hateful_memes/cross_entropy/avg: 0.1140, train/total_loss: 0.0148, train/total_loss/avg: 0.1140, max mem: 9622.0, experiment: run, epoch: 53, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00005, ups: 0.97, time: 01m 43s 291ms, time_since_start: 01h 01m 24s 670ms, eta: 05h 18m 28s 981ms
[32m2021-03-04T09:21:27 | mmf.trainers.callbacks.logistics: [0mprogress: 3600/22000, train/hateful_memes/cross_entropy: 0.0148, train/hateful_memes/cross_entropy/avg: 0.1118, train/total_loss: 0.0148, train/total_loss/avg: 0.1118, max mem: 9622.0, experiment: run, epoch: 54, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00005, ups: 1.06, time: 01m 34s 886ms, time_since_start: 01h 02m 59s 557ms, eta: 04h 50m 59s 087ms
[32m2021-03-04T09:23:11 | mmf.trainers.callbacks.logistics: [0mprogress: 3700/22000, train/hateful_memes/cross_entropy: 0.0146, train/hateful_memes/cross_entropy/avg: 0.1088, train/total_loss: 0.0146, train/total_loss/avg: 0.1088, max mem: 9622.0, experiment: run, epoch: 56, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00005, ups: 0.97, time: 01m 43s 445ms, time_since_start: 01h 04m 43s 002ms, eta: 05h 15m 30s 525ms
[32m2021-03-04T09:24:46 | mmf.trainers.callbacks.logistics: [0mprogress: 3800/22000, train/hateful_memes/cross_entropy: 0.0134, train/hateful_memes/cross_entropy/avg: 0.1060, train/total_loss: 0.0134, train/total_loss/avg: 0.1060, max mem: 9622.0, experiment: run, epoch: 57, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00005, ups: 1.05, time: 01m 35s 204ms, time_since_start: 01h 06m 18s 206ms, eta: 04h 48m 47s 139ms
[32m2021-03-04T09:26:32 | mmf.trainers.callbacks.logistics: [0mprogress: 3900/22000, train/hateful_memes/cross_entropy: 0.0134, train/hateful_memes/cross_entropy/avg: 0.1037, train/total_loss: 0.0134, train/total_loss/avg: 0.1037, max mem: 9622.0, experiment: run, epoch: 59, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00005, ups: 0.95, time: 01m 45s 575ms, time_since_start: 01h 08m 03s 782ms, eta: 05h 18m 29s 245ms
[32m2021-03-04T09:28:06 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T09:28:06 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T09:28:06 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T09:28:06 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T09:28:09 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T09:28:19 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T09:28:19 | mmf.trainers.callbacks.logistics: [0mprogress: 4000/22000, train/hateful_memes/cross_entropy: 0.0106, train/hateful_memes/cross_entropy/avg: 0.1011, train/total_loss: 0.0106, train/total_loss/avg: 0.1011, max mem: 9622.0, experiment: run, epoch: 60, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00005, ups: 0.93, time: 01m 47s 786ms, time_since_start: 01h 09m 51s 569ms, eta: 05h 23m 21s 591ms
[32m2021-03-04T09:28:19 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T09:28:30 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T09:28:30 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T09:28:30 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T09:28:30 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T09:28:41 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T09:28:51 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T09:28:51 | mmf.trainers.callbacks.logistics: [0mprogress: 4000/22000, val/hateful_memes/cross_entropy: 2.2339, val/total_loss: 2.2339, val/hateful_memes/accuracy: 0.6704, val/hateful_memes/binary_f1: 0.4806, val/hateful_memes/roc_auc: 0.6778, num_updates: 4000, epoch: 60, iterations: 4000, max_updates: 22000, val_time: 31s 574ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T09:30:35 | mmf.trainers.callbacks.logistics: [0mprogress: 4100/22000, train/hateful_memes/cross_entropy: 0.0065, train/hateful_memes/cross_entropy/avg: 0.0988, train/total_loss: 0.0065, train/total_loss/avg: 0.0988, max mem: 9622.0, experiment: run, epoch: 62, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00004, ups: 0.97, time: 01m 43s 918ms, time_since_start: 01h 12m 07s 064ms, eta: 05h 10m 01s 441ms
[32m2021-03-04T09:32:08 | mmf.trainers.callbacks.logistics: [0mprogress: 4200/22000, train/hateful_memes/cross_entropy: 0.0065, train/hateful_memes/cross_entropy/avg: 0.0967, train/total_loss: 0.0065, train/total_loss/avg: 0.0967, max mem: 9622.0, experiment: run, epoch: 63, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00004, ups: 1.08, time: 01m 33s 495ms, time_since_start: 01h 13m 40s 560ms, eta: 04h 37m 22s 146ms
[32m2021-03-04T09:33:53 | mmf.trainers.callbacks.logistics: [0mprogress: 4300/22000, train/hateful_memes/cross_entropy: 0.0061, train/hateful_memes/cross_entropy/avg: 0.0945, train/total_loss: 0.0061, train/total_loss/avg: 0.0945, max mem: 9622.0, experiment: run, epoch: 65, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00004, ups: 0.96, time: 01m 44s 860ms, time_since_start: 01h 15m 25s 420ms, eta: 05h 09m 20s 305ms
[32m2021-03-04T09:35:29 | mmf.trainers.callbacks.logistics: [0mprogress: 4400/22000, train/hateful_memes/cross_entropy: 0.0061, train/hateful_memes/cross_entropy/avg: 0.0924, train/total_loss: 0.0061, train/total_loss/avg: 0.0924, max mem: 9622.0, experiment: run, epoch: 66, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00004, ups: 1.05, time: 01m 35s 523ms, time_since_start: 01h 17m 943ms, eta: 04h 40m 12s 056ms
[32m2021-03-04T09:37:12 | mmf.trainers.callbacks.logistics: [0mprogress: 4500/22000, train/hateful_memes/cross_entropy: 0.0065, train/hateful_memes/cross_entropy/avg: 0.0907, train/total_loss: 0.0065, train/total_loss/avg: 0.0907, max mem: 9622.0, experiment: run, epoch: 68, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00004, ups: 0.97, time: 01m 43s 527ms, time_since_start: 01h 18m 44s 470ms, eta: 05h 01m 57s 251ms
[32m2021-03-04T09:38:45 | mmf.trainers.callbacks.logistics: [0mprogress: 4600/22000, train/hateful_memes/cross_entropy: 0.0061, train/hateful_memes/cross_entropy/avg: 0.0887, train/total_loss: 0.0061, train/total_loss/avg: 0.0887, max mem: 9622.0, experiment: run, epoch: 69, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00004, ups: 1.09, time: 01m 32s 920ms, time_since_start: 01h 20m 17s 390ms, eta: 04h 29m 28s 105ms
[32m2021-03-04T09:40:29 | mmf.trainers.callbacks.logistics: [0mprogress: 4700/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0869, train/total_loss: 0.0041, train/total_loss/avg: 0.0869, max mem: 9622.0, experiment: run, epoch: 71, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00004, ups: 0.97, time: 01m 43s 790ms, time_since_start: 01h 22m 01s 181ms, eta: 04h 59m 15s 839ms
[32m2021-03-04T09:42:04 | mmf.trainers.callbacks.logistics: [0mprogress: 4800/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0852, train/total_loss: 0.0041, train/total_loss/avg: 0.0852, max mem: 9622.0, experiment: run, epoch: 72, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00004, ups: 1.06, time: 01m 34s 502ms, time_since_start: 01h 23m 35s 684ms, eta: 04h 30m 54s 392ms
[32m2021-03-04T09:43:48 | mmf.trainers.callbacks.logistics: [0mprogress: 4900/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0838, train/total_loss: 0.0041, train/total_loss/avg: 0.0838, max mem: 9622.0, experiment: run, epoch: 74, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00004, ups: 0.96, time: 01m 44s 661ms, time_since_start: 01h 25m 20s 345ms, eta: 04h 58m 17s 065ms
[32m2021-03-04T09:45:21 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T09:45:21 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T09:45:21 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T09:45:21 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T09:45:24 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T09:45:34 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T09:45:34 | mmf.trainers.callbacks.logistics: [0mprogress: 5000/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0822, train/total_loss: 0.0041, train/total_loss/avg: 0.0822, max mem: 9622.0, experiment: run, epoch: 75, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00004, ups: 0.94, time: 01m 46s 133ms, time_since_start: 01h 27m 06s 479ms, eta: 05h 42s 781ms
[32m2021-03-04T09:45:34 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T09:45:45 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T09:45:45 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T09:45:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T09:45:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T09:45:55 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T09:46:05 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T09:46:05 | mmf.trainers.callbacks.logistics: [0mprogress: 5000/22000, val/hateful_memes/cross_entropy: 2.2815, val/total_loss: 2.2815, val/hateful_memes/accuracy: 0.6926, val/hateful_memes/binary_f1: 0.4854, val/hateful_memes/roc_auc: 0.6868, num_updates: 5000, epoch: 75, iterations: 5000, max_updates: 22000, val_time: 31s 048ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T09:47:49 | mmf.trainers.callbacks.logistics: [0mprogress: 5100/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0806, train/total_loss: 0.0041, train/total_loss/avg: 0.0806, max mem: 9622.0, experiment: run, epoch: 77, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00004, ups: 0.97, time: 01m 43s 529ms, time_since_start: 01h 29m 21s 059ms, eta: 04h 51m 36s 514ms
[32m2021-03-04T09:49:24 | mmf.trainers.callbacks.logistics: [0mprogress: 5200/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0792, train/total_loss: 0.0041, train/total_loss/avg: 0.0792, max mem: 9622.0, experiment: run, epoch: 78, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00004, ups: 1.05, time: 01m 35s 161ms, time_since_start: 01h 30m 56s 221ms, eta: 04h 26m 27s 090ms
[32m2021-03-04T09:51:09 | mmf.trainers.callbacks.logistics: [0mprogress: 5300/22000, train/hateful_memes/cross_entropy: 0.0039, train/hateful_memes/cross_entropy/avg: 0.0778, train/total_loss: 0.0039, train/total_loss/avg: 0.0778, max mem: 9622.0, experiment: run, epoch: 80, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00004, ups: 0.96, time: 01m 44s 463ms, time_since_start: 01h 32m 40s 684ms, eta: 04h 50m 45s 398ms
[32m2021-03-04T09:52:43 | mmf.trainers.callbacks.logistics: [0mprogress: 5400/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0767, train/total_loss: 0.0041, train/total_loss/avg: 0.0767, max mem: 9622.0, experiment: run, epoch: 81, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00004, ups: 1.06, time: 01m 34s 063ms, time_since_start: 01h 34m 14s 748ms, eta: 04h 20m 14s 537ms
[32m2021-03-04T09:54:27 | mmf.trainers.callbacks.logistics: [0mprogress: 5500/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0754, train/total_loss: 0.0041, train/total_loss/avg: 0.0754, max mem: 9622.0, experiment: run, epoch: 83, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00004, ups: 0.96, time: 01m 44s 566ms, time_since_start: 01h 35m 59s 314ms, eta: 04h 47m 33s 518ms
[32m2021-03-04T09:56:02 | mmf.trainers.callbacks.logistics: [0mprogress: 5600/22000, train/hateful_memes/cross_entropy: 0.0039, train/hateful_memes/cross_entropy/avg: 0.0740, train/total_loss: 0.0039, train/total_loss/avg: 0.0740, max mem: 9622.0, experiment: run, epoch: 84, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00004, ups: 1.06, time: 01m 34s 593ms, time_since_start: 01h 37m 33s 908ms, eta: 04h 18m 33s 265ms
[32m2021-03-04T09:57:45 | mmf.trainers.callbacks.logistics: [0mprogress: 5700/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0728, train/total_loss: 0.0041, train/total_loss/avg: 0.0728, max mem: 9622.0, experiment: run, epoch: 86, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00004, ups: 0.97, time: 01m 43s 372ms, time_since_start: 01h 39m 17s 280ms, eta: 04h 40m 49s 731ms
[32m2021-03-04T09:59:20 | mmf.trainers.callbacks.logistics: [0mprogress: 5800/22000, train/hateful_memes/cross_entropy: 0.0046, train/hateful_memes/cross_entropy/avg: 0.0717, train/total_loss: 0.0046, train/total_loss/avg: 0.0717, max mem: 9622.0, experiment: run, epoch: 87, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00004, ups: 1.06, time: 01m 34s 869ms, time_since_start: 01h 40m 52s 150ms, eta: 04h 16m 08s 834ms
[32m2021-03-04T10:01:04 | mmf.trainers.callbacks.logistics: [0mprogress: 5900/22000, train/hateful_memes/cross_entropy: 0.0046, train/hateful_memes/cross_entropy/avg: 0.0705, train/total_loss: 0.0046, train/total_loss/avg: 0.0705, max mem: 9622.0, experiment: run, epoch: 89, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00004, ups: 0.96, time: 01m 44s 058ms, time_since_start: 01h 42m 36s 208ms, eta: 04h 39m 13s 408ms
[32m2021-03-04T10:02:38 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T10:02:38 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T10:02:38 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T10:02:38 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T10:02:41 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T10:02:51 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T10:02:51 | mmf.trainers.callbacks.logistics: [0mprogress: 6000/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.0696, train/total_loss: 0.0047, train/total_loss/avg: 0.0696, max mem: 9622.0, experiment: run, epoch: 90, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00004, ups: 0.94, time: 01m 46s 802ms, time_since_start: 01h 44m 23s 011ms, eta: 04h 44m 48s 445ms
[32m2021-03-04T10:02:51 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T10:03:01 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T10:03:01 | mmf.trainers.callbacks.logistics: [0mprogress: 6000/22000, val/hateful_memes/cross_entropy: 2.3351, val/total_loss: 2.3351, val/hateful_memes/accuracy: 0.6611, val/hateful_memes/binary_f1: 0.4837, val/hateful_memes/roc_auc: 0.6897, num_updates: 6000, epoch: 90, iterations: 6000, max_updates: 22000, val_time: 10s 585ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T10:04:45 | mmf.trainers.callbacks.logistics: [0mprogress: 6100/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.0686, train/total_loss: 0.0047, train/total_loss/avg: 0.0686, max mem: 9622.0, experiment: run, epoch: 92, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00004, ups: 0.97, time: 01m 43s 047ms, time_since_start: 01h 46m 16s 646ms, eta: 04h 33m 04s 632ms
[32m2021-03-04T10:06:19 | mmf.trainers.callbacks.logistics: [0mprogress: 6200/22000, train/hateful_memes/cross_entropy: 0.0046, train/hateful_memes/cross_entropy/avg: 0.0675, train/total_loss: 0.0046, train/total_loss/avg: 0.0675, max mem: 9622.0, experiment: run, epoch: 93, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00004, ups: 1.06, time: 01m 34s 141ms, time_since_start: 01h 47m 50s 788ms, eta: 04h 07m 54s 364ms
[32m2021-03-04T10:08:03 | mmf.trainers.callbacks.logistics: [0mprogress: 6300/22000, train/hateful_memes/cross_entropy: 0.0046, train/hateful_memes/cross_entropy/avg: 0.0665, train/total_loss: 0.0046, train/total_loss/avg: 0.0665, max mem: 9622.0, experiment: run, epoch: 95, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00004, ups: 0.96, time: 01m 44s 382ms, time_since_start: 01h 49m 35s 170ms, eta: 04h 33m 07s 989ms
[32m2021-03-04T10:09:37 | mmf.trainers.callbacks.logistics: [0mprogress: 6400/22000, train/hateful_memes/cross_entropy: 0.0046, train/hateful_memes/cross_entropy/avg: 0.0654, train/total_loss: 0.0046, train/total_loss/avg: 0.0654, max mem: 9622.0, experiment: run, epoch: 96, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00004, ups: 1.06, time: 01m 34s 199ms, time_since_start: 01h 51m 09s 370ms, eta: 04h 04m 55s 199ms
[32m2021-03-04T10:11:23 | mmf.trainers.callbacks.logistics: [0mprogress: 6500/22000, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.0644, train/total_loss: 0.0018, train/total_loss/avg: 0.0644, max mem: 9622.0, experiment: run, epoch: 98, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00004, ups: 0.95, time: 01m 45s 345ms, time_since_start: 01h 52m 54s 715ms, eta: 04h 32m 08s 510ms
[32m2021-03-04T10:12:57 | mmf.trainers.callbacks.logistics: [0mprogress: 6600/22000, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.0635, train/total_loss: 0.0018, train/total_loss/avg: 0.0635, max mem: 9622.0, experiment: run, epoch: 99, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00004, ups: 1.08, time: 01m 33s 996ms, time_since_start: 01h 54m 28s 711ms, eta: 04h 01m 15s 404ms
[32m2021-03-04T10:14:30 | mmf.trainers.callbacks.logistics: [0mprogress: 6700/22000, train/hateful_memes/cross_entropy: 0.0027, train/hateful_memes/cross_entropy/avg: 0.0631, train/total_loss: 0.0027, train/total_loss/avg: 0.0631, max mem: 9622.0, experiment: run, epoch: 100, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00004, ups: 1.08, time: 01m 33s 716ms, time_since_start: 01h 56m 02s 428ms, eta: 03h 58m 58s 596ms
[32m2021-03-04T10:16:15 | mmf.trainers.callbacks.logistics: [0mprogress: 6800/22000, train/hateful_memes/cross_entropy: 0.0027, train/hateful_memes/cross_entropy/avg: 0.0624, train/total_loss: 0.0027, train/total_loss/avg: 0.0624, max mem: 9622.0, experiment: run, epoch: 102, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00004, ups: 0.96, time: 01m 44s 276ms, time_since_start: 01h 57m 46s 705ms, eta: 04h 24m 10s 106ms
[32m2021-03-04T10:17:49 | mmf.trainers.callbacks.logistics: [0mprogress: 6900/22000, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.0615, train/total_loss: 0.0018, train/total_loss/avg: 0.0615, max mem: 9622.0, experiment: run, epoch: 103, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00004, ups: 1.06, time: 01m 34s 501ms, time_since_start: 01h 59m 21s 206ms, eta: 03h 57m 49s 711ms
[32m2021-03-04T10:19:34 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T10:19:34 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T10:19:34 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T10:19:34 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T10:19:36 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T10:19:49 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T10:19:49 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, train/hateful_memes/cross_entropy: 0.0027, train/hateful_memes/cross_entropy/avg: 0.0607, train/total_loss: 0.0027, train/total_loss/avg: 0.0607, max mem: 9622.0, experiment: run, epoch: 105, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00004, ups: 0.84, time: 01m 59s 507ms, time_since_start: 02h 01m 20s 714ms, eta: 04h 58m 46s 169ms
[32m2021-03-04T10:19:49 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T10:20:01 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T10:20:01 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, val/hateful_memes/cross_entropy: 1.9693, val/total_loss: 1.9693, val/hateful_memes/accuracy: 0.6704, val/hateful_memes/binary_f1: 0.5007, val/hateful_memes/roc_auc: 0.6733, num_updates: 7000, epoch: 105, iterations: 7000, max_updates: 22000, val_time: 12s 653ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T10:21:37 | mmf.trainers.callbacks.logistics: [0mprogress: 7100/22000, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.0598, train/total_loss: 0.0018, train/total_loss/avg: 0.0598, max mem: 9622.0, experiment: run, epoch: 106, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00004, ups: 1.05, time: 01m 35s 630ms, time_since_start: 02h 03m 09s 000ms, eta: 03h 57m 28s 981ms
[32m2021-03-04T10:23:20 | mmf.trainers.callbacks.logistics: [0mprogress: 7200/22000, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.0593, train/total_loss: 0.0018, train/total_loss/avg: 0.0593, max mem: 9622.0, experiment: run, epoch: 108, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00004, ups: 0.98, time: 01m 42s 752ms, time_since_start: 02h 04m 51s 753ms, eta: 04h 13m 27s 416ms
[32m2021-03-04T10:24:54 | mmf.trainers.callbacks.logistics: [0mprogress: 7300/22000, train/hateful_memes/cross_entropy: 0.0027, train/hateful_memes/cross_entropy/avg: 0.0585, train/total_loss: 0.0027, train/total_loss/avg: 0.0585, max mem: 9622.0, experiment: run, epoch: 109, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00004, ups: 1.06, time: 01m 34s 645ms, time_since_start: 02h 06m 26s 399ms, eta: 03h 51m 52s 947ms
[32m2021-03-04T10:26:39 | mmf.trainers.callbacks.logistics: [0mprogress: 7400/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0578, train/total_loss: 0.0017, train/total_loss/avg: 0.0578, max mem: 9622.0, experiment: run, epoch: 111, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00004, ups: 0.96, time: 01m 44s 261ms, time_since_start: 02h 08m 10s 660ms, eta: 04h 13m 42s 164ms
[32m2021-03-04T10:28:12 | mmf.trainers.callbacks.logistics: [0mprogress: 7500/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0570, train/total_loss: 0.0017, train/total_loss/avg: 0.0570, max mem: 9622.0, experiment: run, epoch: 112, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00004, ups: 1.08, time: 01m 33s 817ms, time_since_start: 02h 09m 44s 477ms, eta: 03h 46m 43s 498ms
[32m2021-03-04T10:29:57 | mmf.trainers.callbacks.logistics: [0mprogress: 7600/22000, train/hateful_memes/cross_entropy: 0.0027, train/hateful_memes/cross_entropy/avg: 0.0563, train/total_loss: 0.0027, train/total_loss/avg: 0.0563, max mem: 9622.0, experiment: run, epoch: 114, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00004, ups: 0.96, time: 01m 44s 430ms, time_since_start: 02h 11m 28s 908ms, eta: 04h 10m 38s 028ms
[32m2021-03-04T10:31:31 | mmf.trainers.callbacks.logistics: [0mprogress: 7700/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0555, train/total_loss: 0.0013, train/total_loss/avg: 0.0555, max mem: 9622.0, experiment: run, epoch: 115, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00004, ups: 1.06, time: 01m 34s 693ms, time_since_start: 02h 13m 03s 602ms, eta: 03h 45m 41s 225ms
[32m2021-03-04T10:33:16 | mmf.trainers.callbacks.logistics: [0mprogress: 7800/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0549, train/total_loss: 0.0013, train/total_loss/avg: 0.0549, max mem: 9622.0, experiment: run, epoch: 117, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00004, ups: 0.96, time: 01m 44s 426ms, time_since_start: 02h 14m 48s 029ms, eta: 04h 07m 08s 585ms
[32m2021-03-04T10:34:52 | mmf.trainers.callbacks.logistics: [0mprogress: 7900/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0542, train/total_loss: 0.0013, train/total_loss/avg: 0.0542, max mem: 9622.0, experiment: run, epoch: 118, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00004, ups: 1.05, time: 01m 35s 870ms, time_since_start: 02h 16m 23s 899ms, eta: 03h 45m 17s 736ms
[32m2021-03-04T10:36:35 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T10:36:35 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T10:36:35 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T10:36:35 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T10:36:38 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T10:36:48 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T10:36:48 | mmf.trainers.callbacks.logistics: [0mprogress: 8000/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0535, train/total_loss: 0.0007, train/total_loss/avg: 0.0535, max mem: 9622.0, experiment: run, epoch: 120, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00003, ups: 0.86, time: 01m 56s 151ms, time_since_start: 02h 18m 20s 051ms, eta: 04h 31m 01s 214ms
[32m2021-03-04T10:36:48 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T10:37:04 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T10:37:04 | mmf.trainers.callbacks.logistics: [0mprogress: 8000/22000, val/hateful_memes/cross_entropy: 2.4153, val/total_loss: 2.4153, val/hateful_memes/accuracy: 0.6611, val/hateful_memes/binary_f1: 0.4756, val/hateful_memes/roc_auc: 0.6696, num_updates: 8000, epoch: 120, iterations: 8000, max_updates: 22000, val_time: 16s 486ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T10:38:40 | mmf.trainers.callbacks.logistics: [0mprogress: 8100/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0529, train/total_loss: 0.0006, train/total_loss/avg: 0.0529, max mem: 9622.0, experiment: run, epoch: 121, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00003, ups: 1.05, time: 01m 35s 825ms, time_since_start: 02h 20m 12s 365ms, eta: 03h 41m 59s 754ms
[32m2021-03-04T10:40:25 | mmf.trainers.callbacks.logistics: [0mprogress: 8200/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0525, train/total_loss: 0.0006, train/total_loss/avg: 0.0525, max mem: 9622.0, experiment: run, epoch: 123, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00003, ups: 0.95, time: 01m 45s 021ms, time_since_start: 02h 21m 57s 386ms, eta: 04h 01m 32s 947ms
[32m2021-03-04T10:42:02 | mmf.trainers.callbacks.logistics: [0mprogress: 8300/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0523, train/total_loss: 0.0007, train/total_loss/avg: 0.0523, max mem: 9622.0, experiment: run, epoch: 124, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00003, ups: 1.03, time: 01m 37s 231ms, time_since_start: 02h 23m 34s 618ms, eta: 03h 42m 756ms
[32m2021-03-04T10:43:47 | mmf.trainers.callbacks.logistics: [0mprogress: 8400/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0518, train/total_loss: 0.0020, train/total_loss/avg: 0.0518, max mem: 9622.0, experiment: run, epoch: 126, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00003, ups: 0.96, time: 01m 44s 436ms, time_since_start: 02h 25m 19s 054ms, eta: 03h 56m 43s 315ms
[32m2021-03-04T10:45:20 | mmf.trainers.callbacks.logistics: [0mprogress: 8500/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0512, train/total_loss: 0.0020, train/total_loss/avg: 0.0512, max mem: 9622.0, experiment: run, epoch: 127, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00003, ups: 1.08, time: 01m 33s 407ms, time_since_start: 02h 26m 52s 462ms, eta: 03h 30m 09s 973ms
[32m2021-03-04T10:47:04 | mmf.trainers.callbacks.logistics: [0mprogress: 8600/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0506, train/total_loss: 0.0020, train/total_loss/avg: 0.0506, max mem: 9622.0, experiment: run, epoch: 129, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00003, ups: 0.97, time: 01m 43s 604ms, time_since_start: 02h 28m 36s 066ms, eta: 03h 51m 23s 018ms
[32m2021-03-04T10:48:38 | mmf.trainers.callbacks.logistics: [0mprogress: 8700/22000, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.0500, train/total_loss: 0.0018, train/total_loss/avg: 0.0500, max mem: 9622.0, experiment: run, epoch: 130, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00003, ups: 1.08, time: 01m 33s 943ms, time_since_start: 02h 30m 10s 009ms, eta: 03h 28m 14s 440ms
[32m2021-03-04T10:50:21 | mmf.trainers.callbacks.logistics: [0mprogress: 8800/22000, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.0495, train/total_loss: 0.0018, train/total_loss/avg: 0.0495, max mem: 9622.0, experiment: run, epoch: 132, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00003, ups: 0.97, time: 01m 43s 103ms, time_since_start: 02h 31m 53s 113ms, eta: 03h 46m 49s 703ms
[32m2021-03-04T10:51:56 | mmf.trainers.callbacks.logistics: [0mprogress: 8900/22000, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.0489, train/total_loss: 0.0018, train/total_loss/avg: 0.0489, max mem: 9622.0, experiment: run, epoch: 133, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00003, ups: 1.05, time: 01m 35s 168ms, time_since_start: 02h 33m 28s 281ms, eta: 03h 27m 47s 029ms
[32m2021-03-04T10:53:39 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T10:53:39 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T10:53:39 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T10:53:39 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T10:53:42 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T10:53:55 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T10:53:55 | mmf.trainers.callbacks.logistics: [0mprogress: 9000/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0484, train/total_loss: 0.0007, train/total_loss/avg: 0.0484, max mem: 9622.0, experiment: run, epoch: 135, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00003, ups: 0.84, time: 01m 59s 231ms, time_since_start: 02h 35m 27s 512ms, eta: 04h 18m 20s 040ms
[32m2021-03-04T10:53:55 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T10:54:07 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T10:54:07 | mmf.trainers.callbacks.logistics: [0mprogress: 9000/22000, val/hateful_memes/cross_entropy: 2.4820, val/total_loss: 2.4820, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4856, val/hateful_memes/roc_auc: 0.6770, num_updates: 9000, epoch: 135, iterations: 9000, max_updates: 22000, val_time: 12s 024ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T10:55:40 | mmf.trainers.callbacks.logistics: [0mprogress: 9100/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0479, train/total_loss: 0.0006, train/total_loss/avg: 0.0479, max mem: 9622.0, experiment: run, epoch: 136, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00003, ups: 1.09, time: 01m 32s 176ms, time_since_start: 02h 37m 11s 715ms, eta: 03h 18m 10s 740ms
[32m2021-03-04T10:57:25 | mmf.trainers.callbacks.logistics: [0mprogress: 9200/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0473, train/total_loss: 0.0005, train/total_loss/avg: 0.0473, max mem: 9622.0, experiment: run, epoch: 138, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00003, ups: 0.96, time: 01m 44s 950ms, time_since_start: 02h 38m 56s 665ms, eta: 03h 43m 53s 634ms
[32m2021-03-04T10:59:00 | mmf.trainers.callbacks.logistics: [0mprogress: 9300/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0468, train/total_loss: 0.0005, train/total_loss/avg: 0.0468, max mem: 9622.0, experiment: run, epoch: 139, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00003, ups: 1.05, time: 01m 35s 607ms, time_since_start: 02h 40m 32s 273ms, eta: 03h 22m 22s 172ms
[32m2021-03-04T11:00:45 | mmf.trainers.callbacks.logistics: [0mprogress: 9400/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0463, train/total_loss: 0.0005, train/total_loss/avg: 0.0463, max mem: 9622.0, experiment: run, epoch: 141, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00003, ups: 0.96, time: 01m 44s 501ms, time_since_start: 02h 42m 16s 775ms, eta: 03h 39m 27s 246ms
[32m2021-03-04T11:02:18 | mmf.trainers.callbacks.logistics: [0mprogress: 9500/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0458, train/total_loss: 0.0004, train/total_loss/avg: 0.0458, max mem: 9622.0, experiment: run, epoch: 142, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00003, ups: 1.08, time: 01m 33s 711ms, time_since_start: 02h 43m 50s 486ms, eta: 03h 15m 13s 936ms
[32m2021-03-04T11:04:01 | mmf.trainers.callbacks.logistics: [0mprogress: 9600/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0454, train/total_loss: 0.0004, train/total_loss/avg: 0.0454, max mem: 9622.0, experiment: run, epoch: 144, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00003, ups: 0.98, time: 01m 42s 748ms, time_since_start: 02h 45m 33s 235ms, eta: 03h 32m 20s 795ms
[32m2021-03-04T11:05:35 | mmf.trainers.callbacks.logistics: [0mprogress: 9700/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0449, train/total_loss: 0.0004, train/total_loss/avg: 0.0449, max mem: 9622.0, experiment: run, epoch: 145, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00003, ups: 1.08, time: 01m 33s 601ms, time_since_start: 02h 47m 06s 836ms, eta: 03h 11m 53s 000ms
[32m2021-03-04T11:07:17 | mmf.trainers.callbacks.logistics: [0mprogress: 9800/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0445, train/total_loss: 0.0003, train/total_loss/avg: 0.0445, max mem: 9622.0, experiment: run, epoch: 147, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00003, ups: 0.98, time: 01m 42s 792ms, time_since_start: 02h 48m 49s 629ms, eta: 03h 29m 721ms
[32m2021-03-04T11:08:52 | mmf.trainers.callbacks.logistics: [0mprogress: 9900/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0440, train/total_loss: 0.0003, train/total_loss/avg: 0.0440, max mem: 9622.0, experiment: run, epoch: 148, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00003, ups: 1.06, time: 01m 34s 399ms, time_since_start: 02h 50m 24s 029ms, eta: 03h 10m 22s 351ms
[32m2021-03-04T11:10:37 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T11:10:37 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T11:10:37 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T11:10:37 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T11:10:40 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T11:10:54 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T11:10:54 | mmf.trainers.callbacks.logistics: [0mprogress: 10000/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0436, train/total_loss: 0.0003, train/total_loss/avg: 0.0436, max mem: 9622.0, experiment: run, epoch: 150, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00003, ups: 0.83, time: 02m 01s 615ms, time_since_start: 02h 52m 25s 645ms, eta: 04h 03m 13s 866ms
[32m2021-03-04T11:10:54 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T11:11:06 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T11:11:06 | mmf.trainers.callbacks.logistics: [0mprogress: 10000/22000, val/hateful_memes/cross_entropy: 2.0258, val/total_loss: 2.0258, val/hateful_memes/accuracy: 0.6648, val/hateful_memes/binary_f1: 0.5031, val/hateful_memes/roc_auc: 0.6790, num_updates: 10000, epoch: 150, iterations: 10000, max_updates: 22000, val_time: 12s 392ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T11:12:40 | mmf.trainers.callbacks.logistics: [0mprogress: 10100/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0431, train/total_loss: 0.0004, train/total_loss/avg: 0.0431, max mem: 9622.0, experiment: run, epoch: 151, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00003, ups: 1.08, time: 01m 33s 630ms, time_since_start: 02h 54m 11s 669ms, eta: 03h 05m 42s 031ms
[32m2021-03-04T11:14:23 | mmf.trainers.callbacks.logistics: [0mprogress: 10200/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0427, train/total_loss: 0.0004, train/total_loss/avg: 0.0427, max mem: 9622.0, experiment: run, epoch: 153, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00003, ups: 0.97, time: 01m 43s 640ms, time_since_start: 02h 55m 55s 310ms, eta: 03h 23m 49s 578ms
[32m2021-03-04T11:15:59 | mmf.trainers.callbacks.logistics: [0mprogress: 10300/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0423, train/total_loss: 0.0003, train/total_loss/avg: 0.0423, max mem: 9622.0, experiment: run, epoch: 154, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00003, ups: 1.05, time: 01m 35s 507ms, time_since_start: 02h 57m 30s 817ms, eta: 03h 06m 14s 351ms
[32m2021-03-04T11:17:43 | mmf.trainers.callbacks.logistics: [0mprogress: 10400/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0419, train/total_loss: 0.0003, train/total_loss/avg: 0.0419, max mem: 9622.0, experiment: run, epoch: 156, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00003, ups: 0.96, time: 01m 44s 726ms, time_since_start: 02h 59m 15s 544ms, eta: 03h 22m 28s 298ms
[32m2021-03-04T11:19:17 | mmf.trainers.callbacks.logistics: [0mprogress: 10500/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0415, train/total_loss: 0.0003, train/total_loss/avg: 0.0415, max mem: 9622.0, experiment: run, epoch: 157, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00003, ups: 1.08, time: 01m 33s 801ms, time_since_start: 03h 49s 345ms, eta: 02h 59m 47s 147ms
[32m2021-03-04T11:21:01 | mmf.trainers.callbacks.logistics: [0mprogress: 10600/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0411, train/total_loss: 0.0003, train/total_loss/avg: 0.0411, max mem: 9622.0, experiment: run, epoch: 159, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00003, ups: 0.97, time: 01m 43s 703ms, time_since_start: 03h 02m 33s 049ms, eta: 03h 17m 02s 214ms
[32m2021-03-04T11:22:34 | mmf.trainers.callbacks.logistics: [0mprogress: 10700/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0407, train/total_loss: 0.0003, train/total_loss/avg: 0.0407, max mem: 9622.0, experiment: run, epoch: 160, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00003, ups: 1.08, time: 01m 33s 183ms, time_since_start: 03h 04m 06s 232ms, eta: 02h 55m 29s 729ms
[32m2021-03-04T11:24:17 | mmf.trainers.callbacks.logistics: [0mprogress: 10800/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0404, train/total_loss: 0.0003, train/total_loss/avg: 0.0404, max mem: 9622.0, experiment: run, epoch: 162, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00003, ups: 0.97, time: 01m 43s 043ms, time_since_start: 03h 05m 49s 276ms, eta: 03h 12m 20s 931ms
[32m2021-03-04T11:25:52 | mmf.trainers.callbacks.logistics: [0mprogress: 10900/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0400, train/total_loss: 0.0003, train/total_loss/avg: 0.0400, max mem: 9622.0, experiment: run, epoch: 163, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00003, ups: 1.06, time: 01m 34s 750ms, time_since_start: 03h 07m 24s 027ms, eta: 02h 55m 17s 301ms
[32m2021-03-04T11:27:35 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T11:27:35 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T11:27:35 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T11:27:35 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T11:27:38 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T11:27:49 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T11:27:49 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0396, train/total_loss: 0.0003, train/total_loss/avg: 0.0396, max mem: 9622.0, experiment: run, epoch: 165, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00003, ups: 0.86, time: 01m 56s 808ms, time_since_start: 03h 09m 20s 835ms, eta: 03h 34m 08s 964ms
[32m2021-03-04T11:27:49 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T11:28:00 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T11:28:00 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, val/hateful_memes/cross_entropy: 2.2865, val/total_loss: 2.2865, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.4797, val/hateful_memes/roc_auc: 0.6767, num_updates: 11000, epoch: 165, iterations: 11000, max_updates: 22000, val_time: 11s 428ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T11:29:34 | mmf.trainers.callbacks.logistics: [0mprogress: 11100/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0393, train/total_loss: 0.0003, train/total_loss/avg: 0.0393, max mem: 9622.0, experiment: run, epoch: 166, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00003, ups: 1.06, time: 01m 34s 209ms, time_since_start: 03h 11m 06s 477ms, eta: 02h 51m 08s 880ms
[32m2021-03-04T11:31:20 | mmf.trainers.callbacks.logistics: [0mprogress: 11200/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0389, train/total_loss: 0.0004, train/total_loss/avg: 0.0389, max mem: 9622.0, experiment: run, epoch: 168, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00003, ups: 0.95, time: 01m 45s 673ms, time_since_start: 03h 12m 52s 151ms, eta: 03h 10m 12s 721ms
[32m2021-03-04T11:32:54 | mmf.trainers.callbacks.logistics: [0mprogress: 11300/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0387, train/total_loss: 0.0005, train/total_loss/avg: 0.0387, max mem: 9622.0, experiment: run, epoch: 169, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00003, ups: 1.06, time: 01m 34s 180ms, time_since_start: 03h 14m 26s 331ms, eta: 02h 47m 57s 321ms
[32m2021-03-04T11:34:37 | mmf.trainers.callbacks.logistics: [0mprogress: 11400/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0384, train/total_loss: 0.0005, train/total_loss/avg: 0.0384, max mem: 9622.0, experiment: run, epoch: 171, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00003, ups: 0.97, time: 01m 43s 218ms, time_since_start: 03h 16m 09s 550ms, eta: 03h 02m 21s 177ms
[32m2021-03-04T11:36:12 | mmf.trainers.callbacks.logistics: [0mprogress: 11500/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0380, train/total_loss: 0.0005, train/total_loss/avg: 0.0380, max mem: 9622.0, experiment: run, epoch: 172, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00003, ups: 1.06, time: 01m 34s 476ms, time_since_start: 03h 17m 44s 027ms, eta: 02h 45m 20s 036ms
[32m2021-03-04T11:37:56 | mmf.trainers.callbacks.logistics: [0mprogress: 11600/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0377, train/total_loss: 0.0005, train/total_loss/avg: 0.0377, max mem: 9622.0, experiment: run, epoch: 174, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00003, ups: 0.96, time: 01m 44s 415ms, time_since_start: 03h 19m 28s 442ms, eta: 03h 59s 198ms
[32m2021-03-04T11:39:28 | mmf.trainers.callbacks.logistics: [0mprogress: 11700/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0374, train/total_loss: 0.0005, train/total_loss/avg: 0.0374, max mem: 9622.0, experiment: run, epoch: 175, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00003, ups: 1.09, time: 01m 32s 074ms, time_since_start: 03h 21m 516ms, eta: 02h 38m 03s 642ms
[32m2021-03-04T11:41:11 | mmf.trainers.callbacks.logistics: [0mprogress: 11800/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0371, train/total_loss: 0.0005, train/total_loss/avg: 0.0371, max mem: 9622.0, experiment: run, epoch: 177, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00003, ups: 0.98, time: 01m 42s 819ms, time_since_start: 03h 22m 43s 336ms, eta: 02h 54m 47s 633ms
[32m2021-03-04T11:42:46 | mmf.trainers.callbacks.logistics: [0mprogress: 11900/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0367, train/total_loss: 0.0005, train/total_loss/avg: 0.0367, max mem: 9622.0, experiment: run, epoch: 178, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00003, ups: 1.06, time: 01m 34s 720ms, time_since_start: 03h 24m 18s 057ms, eta: 02h 39m 26s 759ms
[32m2021-03-04T11:44:31 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T11:44:31 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T11:44:31 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T11:44:31 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T11:44:34 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T11:44:44 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T11:44:44 | mmf.trainers.callbacks.logistics: [0mprogress: 12000/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0364, train/total_loss: 0.0004, train/total_loss/avg: 0.0364, max mem: 9622.0, experiment: run, epoch: 180, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00003, ups: 0.85, time: 01m 58s 277ms, time_since_start: 03h 26m 16s 334ms, eta: 03h 17m 07s 705ms
[32m2021-03-04T11:44:44 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T11:44:55 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T11:44:55 | mmf.trainers.callbacks.logistics: [0mprogress: 12000/22000, val/hateful_memes/cross_entropy: 2.1587, val/total_loss: 2.1587, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.4577, val/hateful_memes/roc_auc: 0.6703, num_updates: 12000, epoch: 180, iterations: 12000, max_updates: 22000, val_time: 10s 414ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T11:46:29 | mmf.trainers.callbacks.logistics: [0mprogress: 12100/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0361, train/total_loss: 0.0003, train/total_loss/avg: 0.0361, max mem: 9622.0, experiment: run, epoch: 181, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0.00002, ups: 1.06, time: 01m 34s 485ms, time_since_start: 03h 28m 01s 236ms, eta: 02h 35m 54s 043ms
[32m2021-03-04T11:48:14 | mmf.trainers.callbacks.logistics: [0mprogress: 12200/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0358, train/total_loss: 0.0003, train/total_loss/avg: 0.0358, max mem: 9622.0, experiment: run, epoch: 183, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0.00002, ups: 0.95, time: 01m 45s 277ms, time_since_start: 03h 29m 46s 514ms, eta: 02h 51m 57s 234ms
[32m2021-03-04T11:49:49 | mmf.trainers.callbacks.logistics: [0mprogress: 12300/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0355, train/total_loss: 0.0003, train/total_loss/avg: 0.0355, max mem: 9622.0, experiment: run, epoch: 184, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0.00002, ups: 1.06, time: 01m 34s 694ms, time_since_start: 03h 31m 21s 208ms, eta: 02h 33m 05s 332ms
[32m2021-03-04T11:51:34 | mmf.trainers.callbacks.logistics: [0mprogress: 12400/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0353, train/total_loss: 0.0003, train/total_loss/avg: 0.0353, max mem: 9622.0, experiment: run, epoch: 186, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0.00002, ups: 0.96, time: 01m 44s 567ms, time_since_start: 03h 33m 05s 775ms, eta: 02h 47m 18s 456ms
[32m2021-03-04T11:53:08 | mmf.trainers.callbacks.logistics: [0mprogress: 12500/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0350, train/total_loss: 0.0003, train/total_loss/avg: 0.0350, max mem: 9622.0, experiment: run, epoch: 187, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0.00002, ups: 1.06, time: 01m 34s 559ms, time_since_start: 03h 34m 40s 334ms, eta: 02h 29m 43s 111ms
[32m2021-03-04T11:54:54 | mmf.trainers.callbacks.logistics: [0mprogress: 12600/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0347, train/total_loss: 0.0002, train/total_loss/avg: 0.0347, max mem: 9622.0, experiment: run, epoch: 189, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0.00002, ups: 0.95, time: 01m 45s 929ms, time_since_start: 03h 36m 26s 264ms, eta: 02h 45m 57s 354ms
[32m2021-03-04T11:56:29 | mmf.trainers.callbacks.logistics: [0mprogress: 12700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0344, train/total_loss: 0.0002, train/total_loss/avg: 0.0344, max mem: 9622.0, experiment: run, epoch: 190, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0.00002, ups: 1.06, time: 01m 34s 945ms, time_since_start: 03h 38m 01s 209ms, eta: 02h 27m 09s 896ms
[32m2021-03-04T11:58:13 | mmf.trainers.callbacks.logistics: [0mprogress: 12800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0342, train/total_loss: 0.0002, train/total_loss/avg: 0.0342, max mem: 9622.0, experiment: run, epoch: 192, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0.00002, ups: 0.97, time: 01m 43s 439ms, time_since_start: 03h 39m 44s 648ms, eta: 02h 38m 36s 418ms
[32m2021-03-04T11:59:45 | mmf.trainers.callbacks.logistics: [0mprogress: 12900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0339, train/total_loss: 0.0001, train/total_loss/avg: 0.0339, max mem: 9622.0, experiment: run, epoch: 193, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0.00002, ups: 1.09, time: 01m 32s 657ms, time_since_start: 03h 41m 17s 306ms, eta: 02h 20m 31s 862ms
[32m2021-03-04T12:01:31 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T12:01:31 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T12:01:31 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T12:01:31 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T12:01:34 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T12:01:44 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T12:01:44 | mmf.trainers.callbacks.logistics: [0mprogress: 13000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0336, train/total_loss: 0.0001, train/total_loss/avg: 0.0336, max mem: 9622.0, experiment: run, epoch: 195, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0.00002, ups: 0.84, time: 01m 59s 004ms, time_since_start: 03h 43m 16s 311ms, eta: 02h 58m 30s 446ms
[32m2021-03-04T12:01:44 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T12:01:54 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T12:01:54 | mmf.trainers.callbacks.logistics: [0mprogress: 13000/22000, val/hateful_memes/cross_entropy: 3.0188, val/total_loss: 3.0188, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4683, val/hateful_memes/roc_auc: 0.6779, num_updates: 13000, epoch: 195, iterations: 13000, max_updates: 22000, val_time: 10s 225ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T12:03:29 | mmf.trainers.callbacks.logistics: [0mprogress: 13100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0335, train/total_loss: 0.0001, train/total_loss/avg: 0.0335, max mem: 9622.0, experiment: run, epoch: 196, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0.00002, ups: 1.06, time: 01m 34s 462ms, time_since_start: 03h 45m 01s 001ms, eta: 02h 20m 07s 149ms
[32m2021-03-04T12:05:14 | mmf.trainers.callbacks.logistics: [0mprogress: 13200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0332, train/total_loss: 0.0001, train/total_loss/avg: 0.0332, max mem: 9622.0, experiment: run, epoch: 198, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0.00002, ups: 0.95, time: 01m 45s 256ms, time_since_start: 03h 46m 46s 257ms, eta: 02h 34m 22s 536ms
[32m2021-03-04T12:06:48 | mmf.trainers.callbacks.logistics: [0mprogress: 13300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0330, train/total_loss: 0.0001, train/total_loss/avg: 0.0330, max mem: 9622.0, experiment: run, epoch: 199, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0.00002, ups: 1.06, time: 01m 34s 251ms, time_since_start: 03h 48m 20s 509ms, eta: 02h 16m 39s 874ms
[32m2021-03-04T12:08:23 | mmf.trainers.callbacks.logistics: [0mprogress: 13400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0329, train/total_loss: 0.0001, train/total_loss/avg: 0.0329, max mem: 9622.0, experiment: run, epoch: 200, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0.00002, ups: 1.06, time: 01m 34s 640ms, time_since_start: 03h 49m 55s 149ms, eta: 02h 15m 39s 090ms
[32m2021-03-04T12:10:08 | mmf.trainers.callbacks.logistics: [0mprogress: 13500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0326, train/total_loss: 0.0001, train/total_loss/avg: 0.0326, max mem: 9622.0, experiment: run, epoch: 202, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0.00002, ups: 0.95, time: 01m 45s 276ms, time_since_start: 03h 51m 40s 426ms, eta: 02h 29m 08s 511ms
[32m2021-03-04T12:11:42 | mmf.trainers.callbacks.logistics: [0mprogress: 13600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0324, train/total_loss: 0.0001, train/total_loss/avg: 0.0324, max mem: 9622.0, experiment: run, epoch: 203, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0.00002, ups: 1.06, time: 01m 34s 116ms, time_since_start: 03h 53m 14s 543ms, eta: 02h 11m 45s 829ms
[32m2021-03-04T12:13:28 | mmf.trainers.callbacks.logistics: [0mprogress: 13700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0322, train/total_loss: 0.0001, train/total_loss/avg: 0.0322, max mem: 9622.0, experiment: run, epoch: 205, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0.00002, ups: 0.95, time: 01m 45s 205ms, time_since_start: 03h 54m 59s 749ms, eta: 02h 25m 32s 095ms
[32m2021-03-04T12:15:03 | mmf.trainers.callbacks.logistics: [0mprogress: 13800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0319, train/total_loss: 0.0001, train/total_loss/avg: 0.0319, max mem: 9622.0, experiment: run, epoch: 206, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0.00002, ups: 1.05, time: 01m 35s 137ms, time_since_start: 03h 56m 34s 886ms, eta: 02h 10m 01s 238ms
[32m2021-03-04T12:16:46 | mmf.trainers.callbacks.logistics: [0mprogress: 13900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0317, train/total_loss: 0.0001, train/total_loss/avg: 0.0317, max mem: 9622.0, experiment: run, epoch: 208, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0.00002, ups: 0.98, time: 01m 42s 917ms, time_since_start: 03h 58m 17s 804ms, eta: 02h 18m 56s 353ms
[32m2021-03-04T12:18:20 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T12:18:20 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T12:18:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T12:18:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T12:18:23 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T12:18:33 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T12:18:33 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0315, train/total_loss: 0.0001, train/total_loss/avg: 0.0315, max mem: 9622.0, experiment: run, epoch: 209, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0.00002, ups: 0.93, time: 01m 47s 218ms, time_since_start: 04h 05s 023ms, eta: 02h 22m 57s 490ms
[32m2021-03-04T12:18:33 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T12:18:43 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T12:18:43 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, val/hateful_memes/cross_entropy: 3.0202, val/total_loss: 3.0202, val/hateful_memes/accuracy: 0.6630, val/hateful_memes/binary_f1: 0.4582, val/hateful_memes/roc_auc: 0.6737, num_updates: 14000, epoch: 209, iterations: 14000, max_updates: 22000, val_time: 10s 279ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T12:20:27 | mmf.trainers.callbacks.logistics: [0mprogress: 14100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0312, train/total_loss: 0.0001, train/total_loss/avg: 0.0312, max mem: 9622.0, experiment: run, epoch: 211, num_updates: 14100, iterations: 14100, max_updates: 22000, lr: 0.00002, ups: 0.96, time: 01m 44s 147ms, time_since_start: 04h 01m 59s 451ms, eta: 02h 17m 07s 616ms
[32m2021-03-04T12:22:02 | mmf.trainers.callbacks.logistics: [0mprogress: 14200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0310, train/total_loss: 0.0001, train/total_loss/avg: 0.0310, max mem: 9622.0, experiment: run, epoch: 212, num_updates: 14200, iterations: 14200, max_updates: 22000, lr: 0.00002, ups: 1.05, time: 01m 35s 033ms, time_since_start: 04h 03m 34s 485ms, eta: 02h 03m 32s 646ms
[32m2021-03-04T12:23:47 | mmf.trainers.callbacks.logistics: [0mprogress: 14300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0308, train/total_loss: 0.0001, train/total_loss/avg: 0.0308, max mem: 9622.0, experiment: run, epoch: 214, num_updates: 14300, iterations: 14300, max_updates: 22000, lr: 0.00002, ups: 0.96, time: 01m 44s 335ms, time_since_start: 04h 05m 18s 821ms, eta: 02h 13m 53s 847ms
[32m2021-03-04T12:25:22 | mmf.trainers.callbacks.logistics: [0mprogress: 14400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0306, train/total_loss: 0.0001, train/total_loss/avg: 0.0306, max mem: 9622.0, experiment: run, epoch: 215, num_updates: 14400, iterations: 14400, max_updates: 22000, lr: 0.00002, ups: 1.05, time: 01m 35s 603ms, time_since_start: 04h 06m 54s 425ms, eta: 02h 01m 05s 866ms
[32m2021-03-04T12:27:07 | mmf.trainers.callbacks.logistics: [0mprogress: 14500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0304, train/total_loss: 0.0001, train/total_loss/avg: 0.0304, max mem: 9622.0, experiment: run, epoch: 217, num_updates: 14500, iterations: 14500, max_updates: 22000, lr: 0.00002, ups: 0.96, time: 01m 44s 232ms, time_since_start: 04h 08m 38s 657ms, eta: 02h 10m 17s 441ms
[32m2021-03-04T12:28:42 | mmf.trainers.callbacks.logistics: [0mprogress: 14600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0302, train/total_loss: 0.0000, train/total_loss/avg: 0.0302, max mem: 9622.0, experiment: run, epoch: 218, num_updates: 14600, iterations: 14600, max_updates: 22000, lr: 0.00002, ups: 1.05, time: 01m 35s 096ms, time_since_start: 04h 10m 13s 754ms, eta: 01h 57m 17s 143ms
[32m2021-03-04T12:30:27 | mmf.trainers.callbacks.logistics: [0mprogress: 14700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0300, train/total_loss: 0.0000, train/total_loss/avg: 0.0300, max mem: 9622.0, experiment: run, epoch: 220, num_updates: 14700, iterations: 14700, max_updates: 22000, lr: 0.00002, ups: 0.95, time: 01m 45s 602ms, time_since_start: 04h 11m 59s 357ms, eta: 02h 08m 29s 007ms
[32m2021-03-04T12:32:04 | mmf.trainers.callbacks.logistics: [0mprogress: 14800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0298, train/total_loss: 0.0001, train/total_loss/avg: 0.0298, max mem: 9622.0, experiment: run, epoch: 221, num_updates: 14800, iterations: 14800, max_updates: 22000, lr: 0.00002, ups: 1.04, time: 01m 36s 299ms, time_since_start: 04h 13m 35s 656ms, eta: 01h 55m 33s 574ms
[32m2021-03-04T12:33:49 | mmf.trainers.callbacks.logistics: [0mprogress: 14900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0296, train/total_loss: 0.0001, train/total_loss/avg: 0.0296, max mem: 9622.0, experiment: run, epoch: 223, num_updates: 14900, iterations: 14900, max_updates: 22000, lr: 0.00002, ups: 0.95, time: 01m 45s 521ms, time_since_start: 04h 15m 21s 178ms, eta: 02h 04m 52s 037ms
[32m2021-03-04T12:35:25 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T12:35:25 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T12:35:25 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T12:35:25 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T12:35:28 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T12:35:38 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T12:35:38 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0294, train/total_loss: 0.0001, train/total_loss/avg: 0.0294, max mem: 9622.0, experiment: run, epoch: 224, num_updates: 15000, iterations: 15000, max_updates: 22000, lr: 0.00002, ups: 0.92, time: 01m 49s 405ms, time_since_start: 04h 17m 10s 583ms, eta: 02h 07m 38s 389ms
[32m2021-03-04T12:35:38 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T12:35:49 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T12:35:49 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, val/hateful_memes/cross_entropy: 2.3302, val/total_loss: 2.3302, val/hateful_memes/accuracy: 0.6926, val/hateful_memes/binary_f1: 0.4741, val/hateful_memes/roc_auc: 0.6818, num_updates: 15000, epoch: 224, iterations: 15000, max_updates: 22000, val_time: 10s 387ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T12:37:32 | mmf.trainers.callbacks.logistics: [0mprogress: 15100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0292, train/total_loss: 0.0001, train/total_loss/avg: 0.0292, max mem: 9622.0, experiment: run, epoch: 226, num_updates: 15100, iterations: 15100, max_updates: 22000, lr: 0.00002, ups: 0.97, time: 01m 43s 208ms, time_since_start: 04h 19m 04s 182ms, eta: 01h 58m 41s 397ms
[32m2021-03-04T12:39:05 | mmf.trainers.callbacks.logistics: [0mprogress: 15200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0290, train/total_loss: 0.0001, train/total_loss/avg: 0.0290, max mem: 9622.0, experiment: run, epoch: 227, num_updates: 15200, iterations: 15200, max_updates: 22000, lr: 0.00002, ups: 1.08, time: 01m 33s 325ms, time_since_start: 04h 20m 37s 508ms, eta: 01h 45m 46s 165ms
[32m2021-03-04T12:40:50 | mmf.trainers.callbacks.logistics: [0mprogress: 15300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0288, train/total_loss: 0.0001, train/total_loss/avg: 0.0288, max mem: 9622.0, experiment: run, epoch: 229, num_updates: 15300, iterations: 15300, max_updates: 22000, lr: 0.00002, ups: 0.96, time: 01m 44s 137ms, time_since_start: 04h 22m 21s 645ms, eta: 01h 56m 17s 235ms
[32m2021-03-04T12:42:25 | mmf.trainers.callbacks.logistics: [0mprogress: 15400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0286, train/total_loss: 0.0001, train/total_loss/avg: 0.0286, max mem: 9622.0, experiment: run, epoch: 230, num_updates: 15400, iterations: 15400, max_updates: 22000, lr: 0.00002, ups: 1.05, time: 01m 35s 010ms, time_since_start: 04h 23m 56s 656ms, eta: 01h 44m 30s 678ms
[32m2021-03-04T12:44:09 | mmf.trainers.callbacks.logistics: [0mprogress: 15500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0285, train/total_loss: 0.0001, train/total_loss/avg: 0.0285, max mem: 9622.0, experiment: run, epoch: 232, num_updates: 15500, iterations: 15500, max_updates: 22000, lr: 0.00002, ups: 0.96, time: 01m 44s 308ms, time_since_start: 04h 25m 40s 964ms, eta: 01h 53m 052ms
[32m2021-03-04T12:45:43 | mmf.trainers.callbacks.logistics: [0mprogress: 15600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0283, train/total_loss: 0.0000, train/total_loss/avg: 0.0283, max mem: 9622.0, experiment: run, epoch: 233, num_updates: 15600, iterations: 15600, max_updates: 22000, lr: 0.00002, ups: 1.06, time: 01m 34s 146ms, time_since_start: 04h 27m 15s 111ms, eta: 01h 40m 25s 389ms
[32m2021-03-04T12:47:27 | mmf.trainers.callbacks.logistics: [0mprogress: 15700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0281, train/total_loss: 0.0000, train/total_loss/avg: 0.0281, max mem: 9622.0, experiment: run, epoch: 235, num_updates: 15700, iterations: 15700, max_updates: 22000, lr: 0.00002, ups: 0.96, time: 01m 44s 490ms, time_since_start: 04h 28m 59s 602ms, eta: 01h 49m 42s 903ms
[32m2021-03-04T12:49:02 | mmf.trainers.callbacks.logistics: [0mprogress: 15800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0279, train/total_loss: 0.0000, train/total_loss/avg: 0.0279, max mem: 9622.0, experiment: run, epoch: 236, num_updates: 15800, iterations: 15800, max_updates: 22000, lr: 0.00002, ups: 1.06, time: 01m 34s 871ms, time_since_start: 04h 30m 34s 473ms, eta: 01h 38m 02s 055ms
[32m2021-03-04T12:50:48 | mmf.trainers.callbacks.logistics: [0mprogress: 15900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0277, train/total_loss: 0.0000, train/total_loss/avg: 0.0277, max mem: 9622.0, experiment: run, epoch: 238, num_updates: 15900, iterations: 15900, max_updates: 22000, lr: 0.00002, ups: 0.95, time: 01m 45s 395ms, time_since_start: 04h 32m 19s 869ms, eta: 01h 47m 09s 145ms
[32m2021-03-04T12:52:22 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T12:52:22 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T12:52:22 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T12:52:22 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T12:52:25 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T12:52:37 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T12:52:37 | mmf.trainers.callbacks.logistics: [0mprogress: 16000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0276, train/total_loss: 0.0000, train/total_loss/avg: 0.0276, max mem: 9622.0, experiment: run, epoch: 239, num_updates: 16000, iterations: 16000, max_updates: 22000, lr: 0.00002, ups: 0.92, time: 01m 49s 742ms, time_since_start: 04h 34m 09s 612ms, eta: 01h 49m 44s 544ms
[32m2021-03-04T12:52:37 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T12:52:51 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T12:52:51 | mmf.trainers.callbacks.logistics: [0mprogress: 16000/22000, val/hateful_memes/cross_entropy: 3.1042, val/total_loss: 3.1042, val/hateful_memes/accuracy: 0.6852, val/hateful_memes/binary_f1: 0.4582, val/hateful_memes/roc_auc: 0.6794, num_updates: 16000, epoch: 239, iterations: 16000, max_updates: 22000, val_time: 13s 147ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T12:54:34 | mmf.trainers.callbacks.logistics: [0mprogress: 16100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0274, train/total_loss: 0.0000, train/total_loss/avg: 0.0274, max mem: 9622.0, experiment: run, epoch: 241, num_updates: 16100, iterations: 16100, max_updates: 22000, lr: 0.00001, ups: 0.97, time: 01m 43s 384ms, time_since_start: 04h 36m 06s 146ms, eta: 01h 41m 39s 684ms
[32m2021-03-04T12:56:10 | mmf.trainers.callbacks.logistics: [0mprogress: 16200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0272, train/total_loss: 0.0000, train/total_loss/avg: 0.0272, max mem: 9622.0, experiment: run, epoch: 242, num_updates: 16200, iterations: 16200, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 636ms, time_since_start: 04h 37m 41s 783ms, eta: 01h 32m 26s 945ms
[32m2021-03-04T12:57:54 | mmf.trainers.callbacks.logistics: [0mprogress: 16300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0270, train/total_loss: 0.0000, train/total_loss/avg: 0.0270, max mem: 9622.0, experiment: run, epoch: 244, num_updates: 16300, iterations: 16300, max_updates: 22000, lr: 0.00001, ups: 0.96, time: 01m 44s 097ms, time_since_start: 04h 39m 25s 881ms, eta: 01h 38m 53s 586ms
[32m2021-03-04T12:59:30 | mmf.trainers.callbacks.logistics: [0mprogress: 16400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0269, train/total_loss: 0.0000, train/total_loss/avg: 0.0269, max mem: 9622.0, experiment: run, epoch: 245, num_updates: 16400, iterations: 16400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 916ms, time_since_start: 04h 41m 01s 797ms, eta: 01h 29m 31s 311ms
[32m2021-03-04T13:01:14 | mmf.trainers.callbacks.logistics: [0mprogress: 16500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0267, train/total_loss: 0.0000, train/total_loss/avg: 0.0267, max mem: 9622.0, experiment: run, epoch: 247, num_updates: 16500, iterations: 16500, max_updates: 22000, lr: 0.00001, ups: 0.96, time: 01m 44s 135ms, time_since_start: 04h 42m 45s 932ms, eta: 01h 35m 27s 429ms
[32m2021-03-04T13:02:48 | mmf.trainers.callbacks.logistics: [0mprogress: 16600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0266, train/total_loss: 0.0000, train/total_loss/avg: 0.0266, max mem: 9622.0, experiment: run, epoch: 248, num_updates: 16600, iterations: 16600, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 627ms, time_since_start: 04h 44m 20s 559ms, eta: 01h 25m 09s 862ms
[32m2021-03-04T13:04:31 | mmf.trainers.callbacks.logistics: [0mprogress: 16700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0264, train/total_loss: 0.0000, train/total_loss/avg: 0.0264, max mem: 9622.0, experiment: run, epoch: 250, num_updates: 16700, iterations: 16700, max_updates: 22000, lr: 0.00001, ups: 0.98, time: 01m 42s 937ms, time_since_start: 04h 46m 03s 498ms, eta: 01h 30m 55s 715ms
[32m2021-03-04T13:06:05 | mmf.trainers.callbacks.logistics: [0mprogress: 16800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0263, train/total_loss: 0.0000, train/total_loss/avg: 0.0263, max mem: 9622.0, experiment: run, epoch: 251, num_updates: 16800, iterations: 16800, max_updates: 22000, lr: 0.00001, ups: 1.08, time: 01m 33s 218ms, time_since_start: 04h 47m 36s 716ms, eta: 01h 20m 47s 379ms
[32m2021-03-04T13:07:49 | mmf.trainers.callbacks.logistics: [0mprogress: 16900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0262, train/total_loss: 0.0000, train/total_loss/avg: 0.0262, max mem: 9622.0, experiment: run, epoch: 253, num_updates: 16900, iterations: 16900, max_updates: 22000, lr: 0.00001, ups: 0.96, time: 01m 44s 913ms, time_since_start: 04h 49m 21s 630ms, eta: 01h 29m 10s 584ms
[32m2021-03-04T13:09:24 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T13:09:24 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T13:09:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T13:09:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T13:09:27 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T13:09:39 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T13:09:39 | mmf.trainers.callbacks.logistics: [0mprogress: 17000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0260, train/total_loss: 0.0000, train/total_loss/avg: 0.0260, max mem: 9622.0, experiment: run, epoch: 254, num_updates: 17000, iterations: 17000, max_updates: 22000, lr: 0.00001, ups: 0.92, time: 01m 49s 209ms, time_since_start: 04h 51m 10s 839ms, eta: 01h 31m 475ms
[32m2021-03-04T13:09:39 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T13:09:49 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T13:09:49 | mmf.trainers.callbacks.logistics: [0mprogress: 17000/22000, val/hateful_memes/cross_entropy: 2.3381, val/total_loss: 2.3381, val/hateful_memes/accuracy: 0.6741, val/hateful_memes/binary_f1: 0.4520, val/hateful_memes/roc_auc: 0.6778, num_updates: 17000, epoch: 254, iterations: 17000, max_updates: 22000, val_time: 10s 710ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T13:11:34 | mmf.trainers.callbacks.logistics: [0mprogress: 17100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0259, train/total_loss: 0.0000, train/total_loss/avg: 0.0259, max mem: 9622.0, experiment: run, epoch: 256, num_updates: 17100, iterations: 17100, max_updates: 22000, lr: 0.00001, ups: 0.96, time: 01m 44s 291ms, time_since_start: 04h 53m 05s 844ms, eta: 01h 25m 10s 274ms
[32m2021-03-04T13:13:08 | mmf.trainers.callbacks.logistics: [0mprogress: 17200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0257, train/total_loss: 0.0000, train/total_loss/avg: 0.0257, max mem: 9622.0, experiment: run, epoch: 257, num_updates: 17200, iterations: 17200, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 385ms, time_since_start: 04h 54m 40s 229ms, eta: 01h 15m 30s 499ms
[32m2021-03-04T13:14:54 | mmf.trainers.callbacks.logistics: [0mprogress: 17300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0256, train/total_loss: 0.0000, train/total_loss/avg: 0.0256, max mem: 9622.0, experiment: run, epoch: 259, num_updates: 17300, iterations: 17300, max_updates: 22000, lr: 0.00001, ups: 0.94, time: 01m 46s 092ms, time_since_start: 04h 56m 26s 322ms, eta: 01h 23m 06s 369ms
[32m2021-03-04T13:16:30 | mmf.trainers.callbacks.logistics: [0mprogress: 17400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0254, train/total_loss: 0.0000, train/total_loss/avg: 0.0254, max mem: 9622.0, experiment: run, epoch: 260, num_updates: 17400, iterations: 17400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 660ms, time_since_start: 04h 58m 01s 982ms, eta: 01h 13m 20s 376ms
[32m2021-03-04T13:18:14 | mmf.trainers.callbacks.logistics: [0mprogress: 17500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0253, train/total_loss: 0.0000, train/total_loss/avg: 0.0253, max mem: 9622.0, experiment: run, epoch: 262, num_updates: 17500, iterations: 17500, max_updates: 22000, lr: 0.00001, ups: 0.97, time: 01m 43s 992ms, time_since_start: 04h 59m 45s 975ms, eta: 01h 17m 59s 653ms
[32m2021-03-04T13:19:49 | mmf.trainers.callbacks.logistics: [0mprogress: 17600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0251, train/total_loss: 0.0000, train/total_loss/avg: 0.0251, max mem: 9622.0, experiment: run, epoch: 263, num_updates: 17600, iterations: 17600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 264ms, time_since_start: 05h 01m 21s 239ms, eta: 01h 09m 51s 631ms
[32m2021-03-04T13:21:33 | mmf.trainers.callbacks.logistics: [0mprogress: 17700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0250, train/total_loss: 0.0000, train/total_loss/avg: 0.0250, max mem: 9622.0, experiment: run, epoch: 265, num_updates: 17700, iterations: 17700, max_updates: 22000, lr: 0.00001, ups: 0.97, time: 01m 43s 581ms, time_since_start: 05h 03m 04s 820ms, eta: 01h 14m 13s 996ms
[32m2021-03-04T13:23:07 | mmf.trainers.callbacks.logistics: [0mprogress: 17800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0248, train/total_loss: 0.0000, train/total_loss/avg: 0.0248, max mem: 9622.0, experiment: run, epoch: 266, num_updates: 17800, iterations: 17800, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 213ms, time_since_start: 05h 04m 39s 034ms, eta: 01h 05m 56s 955ms
[32m2021-03-04T13:24:53 | mmf.trainers.callbacks.logistics: [0mprogress: 17900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0247, train/total_loss: 0.0000, train/total_loss/avg: 0.0247, max mem: 9622.0, experiment: run, epoch: 268, num_updates: 17900, iterations: 17900, max_updates: 22000, lr: 0.00001, ups: 0.94, time: 01m 46s 087ms, time_since_start: 05h 06m 25s 121ms, eta: 01h 12m 29s 594ms
[32m2021-03-04T13:26:27 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T13:26:27 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T13:26:27 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T13:26:27 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T13:26:30 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T13:26:42 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T13:26:42 | mmf.trainers.callbacks.logistics: [0mprogress: 18000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0246, train/total_loss: 0.0000, train/total_loss/avg: 0.0246, max mem: 9622.0, experiment: run, epoch: 269, num_updates: 18000, iterations: 18000, max_updates: 22000, lr: 0.00001, ups: 0.93, time: 01m 48s 909ms, time_since_start: 05h 08m 14s 031ms, eta: 01h 12m 36s 379ms
[32m2021-03-04T13:26:42 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T13:26:54 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T13:26:54 | mmf.trainers.callbacks.logistics: [0mprogress: 18000/22000, val/hateful_memes/cross_entropy: 2.9350, val/total_loss: 2.9350, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.4681, val/hateful_memes/roc_auc: 0.6784, num_updates: 18000, epoch: 269, iterations: 18000, max_updates: 22000, val_time: 12s 147ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T13:28:38 | mmf.trainers.callbacks.logistics: [0mprogress: 18100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0244, train/total_loss: 0.0000, train/total_loss/avg: 0.0244, max mem: 9622.0, experiment: run, epoch: 271, num_updates: 18100, iterations: 18100, max_updates: 22000, lr: 0.00001, ups: 0.97, time: 01m 43s 849ms, time_since_start: 05h 10m 10s 030ms, eta: 01h 07m 30s 127ms
[32m2021-03-04T13:30:12 | mmf.trainers.callbacks.logistics: [0mprogress: 18200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0243, train/total_loss: 0.0000, train/total_loss/avg: 0.0243, max mem: 9622.0, experiment: run, epoch: 272, num_updates: 18200, iterations: 18200, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 394ms, time_since_start: 05h 11m 44s 425ms, eta: 59m 47s 007ms
[32m2021-03-04T13:31:57 | mmf.trainers.callbacks.logistics: [0mprogress: 18300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0242, train/total_loss: 0.0000, train/total_loss/avg: 0.0242, max mem: 9622.0, experiment: run, epoch: 274, num_updates: 18300, iterations: 18300, max_updates: 22000, lr: 0.00001, ups: 0.96, time: 01m 44s 495ms, time_since_start: 05h 13m 28s 920ms, eta: 01h 04m 26s 318ms
[32m2021-03-04T13:33:31 | mmf.trainers.callbacks.logistics: [0mprogress: 18400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0240, train/total_loss: 0.0000, train/total_loss/avg: 0.0240, max mem: 9622.0, experiment: run, epoch: 275, num_updates: 18400, iterations: 18400, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 425ms, time_since_start: 05h 15m 03s 345ms, eta: 56m 39s 326ms
[32m2021-03-04T13:35:17 | mmf.trainers.callbacks.logistics: [0mprogress: 18500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0239, train/total_loss: 0.0000, train/total_loss/avg: 0.0239, max mem: 9622.0, experiment: run, epoch: 277, num_updates: 18500, iterations: 18500, max_updates: 22000, lr: 0.00001, ups: 0.95, time: 01m 45s 987ms, time_since_start: 05h 16m 49s 333ms, eta: 01h 01m 49s 563ms
[32m2021-03-04T13:36:51 | mmf.trainers.callbacks.logistics: [0mprogress: 18600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0238, train/total_loss: 0.0000, train/total_loss/avg: 0.0238, max mem: 9622.0, experiment: run, epoch: 278, num_updates: 18600, iterations: 18600, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 085ms, time_since_start: 05h 18m 23s 418ms, eta: 53m 18s 893ms
[32m2021-03-04T13:38:36 | mmf.trainers.callbacks.logistics: [0mprogress: 18700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0236, train/total_loss: 0.0000, train/total_loss/avg: 0.0236, max mem: 9622.0, experiment: run, epoch: 280, num_updates: 18700, iterations: 18700, max_updates: 22000, lr: 0.00001, ups: 0.96, time: 01m 44s 816ms, time_since_start: 05h 20m 08s 235ms, eta: 57m 38s 961ms
[32m2021-03-04T13:40:11 | mmf.trainers.callbacks.logistics: [0mprogress: 18800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0235, train/total_loss: 0.0000, train/total_loss/avg: 0.0235, max mem: 9622.0, experiment: run, epoch: 281, num_updates: 18800, iterations: 18800, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 776ms, time_since_start: 05h 21m 43s 012ms, eta: 50m 32s 846ms
[32m2021-03-04T13:41:56 | mmf.trainers.callbacks.logistics: [0mprogress: 18900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0234, train/total_loss: 0.0000, train/total_loss/avg: 0.0234, max mem: 9622.0, experiment: run, epoch: 283, num_updates: 18900, iterations: 18900, max_updates: 22000, lr: 0.00001, ups: 0.96, time: 01m 44s 687ms, time_since_start: 05h 23m 27s 699ms, eta: 54m 05s 307ms
[32m2021-03-04T13:43:30 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T13:43:30 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T13:43:30 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T13:43:30 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T13:43:33 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T13:43:43 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T13:43:43 | mmf.trainers.callbacks.logistics: [0mprogress: 19000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0233, train/total_loss: 0.0000, train/total_loss/avg: 0.0233, max mem: 9622.0, experiment: run, epoch: 284, num_updates: 19000, iterations: 19000, max_updates: 22000, lr: 0.00001, ups: 0.93, time: 01m 47s 823ms, time_since_start: 05h 25m 15s 523ms, eta: 53m 54s 704ms
[32m2021-03-04T13:43:43 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T13:43:54 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T13:43:54 | mmf.trainers.callbacks.logistics: [0mprogress: 19000/22000, val/hateful_memes/cross_entropy: 2.9416, val/total_loss: 2.9416, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.4828, val/hateful_memes/roc_auc: 0.6685, num_updates: 19000, epoch: 284, iterations: 19000, max_updates: 22000, val_time: 10s 816ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T13:45:37 | mmf.trainers.callbacks.logistics: [0mprogress: 19100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0231, train/total_loss: 0.0000, train/total_loss/avg: 0.0231, max mem: 9622.0, experiment: run, epoch: 286, num_updates: 19100, iterations: 19100, max_updates: 22000, lr: 0.00001, ups: 0.98, time: 01m 42s 434ms, time_since_start: 05h 27m 08s 775ms, eta: 49m 30s 587ms
[32m2021-03-04T13:47:10 | mmf.trainers.callbacks.logistics: [0mprogress: 19200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0230, train/total_loss: 0.0000, train/total_loss/avg: 0.0230, max mem: 9622.0, experiment: run, epoch: 287, num_updates: 19200, iterations: 19200, max_updates: 22000, lr: 0.00001, ups: 1.08, time: 01m 33s 372ms, time_since_start: 05h 28m 42s 148ms, eta: 43m 34s 431ms
[32m2021-03-04T13:48:54 | mmf.trainers.callbacks.logistics: [0mprogress: 19300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0229, train/total_loss: 0.0000, train/total_loss/avg: 0.0229, max mem: 9622.0, experiment: run, epoch: 289, num_updates: 19300, iterations: 19300, max_updates: 22000, lr: 0.00001, ups: 0.97, time: 01m 43s 919ms, time_since_start: 05h 30m 26s 067ms, eta: 46m 45s 818ms
[32m2021-03-04T13:50:27 | mmf.trainers.callbacks.logistics: [0mprogress: 19400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0228, train/total_loss: 0.0000, train/total_loss/avg: 0.0228, max mem: 9622.0, experiment: run, epoch: 290, num_updates: 19400, iterations: 19400, max_updates: 22000, lr: 0.00001, ups: 1.08, time: 01m 33s 217ms, time_since_start: 05h 31m 59s 284ms, eta: 40m 23s 652ms
[32m2021-03-04T13:52:12 | mmf.trainers.callbacks.logistics: [0mprogress: 19500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0227, train/total_loss: 0.0000, train/total_loss/avg: 0.0227, max mem: 9622.0, experiment: run, epoch: 292, num_updates: 19500, iterations: 19500, max_updates: 22000, lr: 0.00001, ups: 0.95, time: 01m 45s 113ms, time_since_start: 05h 33m 44s 398ms, eta: 43m 47s 837ms
[32m2021-03-04T13:53:46 | mmf.trainers.callbacks.logistics: [0mprogress: 19600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0225, train/total_loss: 0.0000, train/total_loss/avg: 0.0225, max mem: 9622.0, experiment: run, epoch: 293, num_updates: 19600, iterations: 19600, max_updates: 22000, lr: 0.00001, ups: 1.08, time: 01m 33s 819ms, time_since_start: 05h 35m 18s 217ms, eta: 37m 31s 669ms
[32m2021-03-04T13:55:31 | mmf.trainers.callbacks.logistics: [0mprogress: 19700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0224, train/total_loss: 0.0000, train/total_loss/avg: 0.0224, max mem: 9622.0, experiment: run, epoch: 295, num_updates: 19700, iterations: 19700, max_updates: 22000, lr: 0.00001, ups: 0.95, time: 01m 45s 120ms, time_since_start: 05h 37m 03s 338ms, eta: 40m 17s 772ms
[32m2021-03-04T13:57:04 | mmf.trainers.callbacks.logistics: [0mprogress: 19800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0223, train/total_loss: 0.0000, train/total_loss/avg: 0.0223, max mem: 9622.0, experiment: run, epoch: 296, num_updates: 19800, iterations: 19800, max_updates: 22000, lr: 0.00001, ups: 1.09, time: 01m 32s 324ms, time_since_start: 05h 38m 35s 663ms, eta: 33m 51s 144ms
[32m2021-03-04T13:58:47 | mmf.trainers.callbacks.logistics: [0mprogress: 19900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0222, train/total_loss: 0.0000, train/total_loss/avg: 0.0222, max mem: 9622.0, experiment: run, epoch: 298, num_updates: 19900, iterations: 19900, max_updates: 22000, lr: 0.00001, ups: 0.97, time: 01m 43s 184ms, time_since_start: 05h 40m 18s 848ms, eta: 36m 06s 885ms
[32m2021-03-04T14:00:20 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T14:00:20 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T14:00:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T14:00:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T14:00:31 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T14:00:41 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T14:00:41 | mmf.trainers.callbacks.logistics: [0mprogress: 20000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0221, train/total_loss: 0.0000, train/total_loss/avg: 0.0221, max mem: 9622.0, experiment: run, epoch: 299, num_updates: 20000, iterations: 20000, max_updates: 22000, lr: 0.00001, ups: 0.88, time: 01m 54s 303ms, time_since_start: 05h 42m 13s 151ms, eta: 38m 06s 061ms
[32m2021-03-04T14:00:41 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T14:00:52 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T14:00:52 | mmf.trainers.callbacks.logistics: [0mprogress: 20000/22000, val/hateful_memes/cross_entropy: 3.2631, val/total_loss: 3.2631, val/hateful_memes/accuracy: 0.6852, val/hateful_memes/binary_f1: 0.4825, val/hateful_memes/roc_auc: 0.6714, num_updates: 20000, epoch: 299, iterations: 20000, max_updates: 22000, val_time: 10s 747ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T14:02:23 | mmf.trainers.callbacks.logistics: [0mprogress: 20100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0220, train/total_loss: 0.0000, train/total_loss/avg: 0.0220, max mem: 9622.0, experiment: run, epoch: 300, num_updates: 20100, iterations: 20100, max_updates: 22000, lr: 0., ups: 1.10, time: 01m 31s 370ms, time_since_start: 05h 43m 55s 271ms, eta: 28m 56s 035ms
[32m2021-03-04T14:04:08 | mmf.trainers.callbacks.logistics: [0mprogress: 20200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0219, train/total_loss: 0.0000, train/total_loss/avg: 0.0219, max mem: 9622.0, experiment: run, epoch: 302, num_updates: 20200, iterations: 20200, max_updates: 22000, lr: 0., ups: 0.96, time: 01m 44s 719ms, time_since_start: 05h 45m 39s 991ms, eta: 31m 24s 959ms
[32m2021-03-04T14:05:39 | mmf.trainers.callbacks.logistics: [0mprogress: 20300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0218, train/total_loss: 0.0000, train/total_loss/avg: 0.0218, max mem: 9622.0, experiment: run, epoch: 303, num_updates: 20300, iterations: 20300, max_updates: 22000, lr: 0., ups: 1.10, time: 01m 31s 512ms, time_since_start: 05h 47m 11s 503ms, eta: 25m 55s 717ms
[32m2021-03-04T14:07:24 | mmf.trainers.callbacks.logistics: [0mprogress: 20400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0217, train/total_loss: 0.0000, train/total_loss/avg: 0.0217, max mem: 9622.0, experiment: run, epoch: 305, num_updates: 20400, iterations: 20400, max_updates: 22000, lr: 0., ups: 0.96, time: 01m 44s 436ms, time_since_start: 05h 48m 55s 940ms, eta: 27m 50s 991ms
[32m2021-03-04T14:08:58 | mmf.trainers.callbacks.logistics: [0mprogress: 20500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0216, train/total_loss: 0.0000, train/total_loss/avg: 0.0216, max mem: 9622.0, experiment: run, epoch: 306, num_updates: 20500, iterations: 20500, max_updates: 22000, lr: 0., ups: 1.08, time: 01m 33s 756ms, time_since_start: 05h 50m 29s 697ms, eta: 23m 26s 346ms
[32m2021-03-04T14:10:41 | mmf.trainers.callbacks.logistics: [0mprogress: 20600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0215, train/total_loss: 0.0000, train/total_loss/avg: 0.0215, max mem: 9622.0, experiment: run, epoch: 308, num_updates: 20600, iterations: 20600, max_updates: 22000, lr: 0., ups: 0.97, time: 01m 43s 604ms, time_since_start: 05h 52m 13s 301ms, eta: 24m 10s 458ms
[32m2021-03-04T14:12:15 | mmf.trainers.callbacks.logistics: [0mprogress: 20700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0214, train/total_loss: 0.0000, train/total_loss/avg: 0.0214, max mem: 9622.0, experiment: run, epoch: 309, num_updates: 20700, iterations: 20700, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 258ms, time_since_start: 05h 53m 47s 560ms, eta: 20m 25s 366ms
[32m2021-03-04T14:13:59 | mmf.trainers.callbacks.logistics: [0mprogress: 20800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0213, train/total_loss: 0.0000, train/total_loss/avg: 0.0213, max mem: 9622.0, experiment: run, epoch: 311, num_updates: 20800, iterations: 20800, max_updates: 22000, lr: 0., ups: 0.97, time: 01m 43s 990ms, time_since_start: 05h 55m 31s 550ms, eta: 20m 47s 883ms
[32m2021-03-04T14:15:34 | mmf.trainers.callbacks.logistics: [0mprogress: 20900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0212, train/total_loss: 0.0000, train/total_loss/avg: 0.0212, max mem: 9622.0, experiment: run, epoch: 312, num_updates: 20900, iterations: 20900, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 737ms, time_since_start: 05h 57m 06s 288ms, eta: 17m 22s 109ms
[32m2021-03-04T14:17:20 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T14:17:20 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T14:17:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T14:17:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T14:17:30 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T14:17:40 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T14:17:40 | mmf.trainers.callbacks.logistics: [0mprogress: 21000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0211, train/total_loss: 0.0000, train/total_loss/avg: 0.0211, max mem: 9622.0, experiment: run, epoch: 314, num_updates: 21000, iterations: 21000, max_updates: 22000, lr: 0., ups: 0.79, time: 02m 06s 036ms, time_since_start: 05h 59m 12s 324ms, eta: 21m 366ms
[32m2021-03-04T14:17:40 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T14:17:51 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T14:17:51 | mmf.trainers.callbacks.logistics: [0mprogress: 21000/22000, val/hateful_memes/cross_entropy: 3.4614, val/total_loss: 3.4614, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.5085, val/hateful_memes/roc_auc: 0.6734, num_updates: 21000, epoch: 314, iterations: 21000, max_updates: 22000, val_time: 10s 719ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T14:19:25 | mmf.trainers.callbacks.logistics: [0mprogress: 21100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0210, train/total_loss: 0.0000, train/total_loss/avg: 0.0210, max mem: 9622.0, experiment: run, epoch: 315, num_updates: 21100, iterations: 21100, max_updates: 22000, lr: 0., ups: 1.08, time: 01m 33s 790ms, time_since_start: 06h 56s 836ms, eta: 14m 04s 114ms
[32m2021-03-04T14:21:10 | mmf.trainers.callbacks.logistics: [0mprogress: 21200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0209, train/total_loss: 0.0000, train/total_loss/avg: 0.0209, max mem: 9622.0, experiment: run, epoch: 317, num_updates: 21200, iterations: 21200, max_updates: 22000, lr: 0., ups: 0.96, time: 01m 44s 958ms, time_since_start: 06h 02m 41s 795ms, eta: 13m 59s 671ms
[32m2021-03-04T14:22:45 | mmf.trainers.callbacks.logistics: [0mprogress: 21300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0208, train/total_loss: 0.0000, train/total_loss/avg: 0.0208, max mem: 9622.0, experiment: run, epoch: 318, num_updates: 21300, iterations: 21300, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 389ms, time_since_start: 06h 04m 17s 185ms, eta: 11m 07s 729ms
[32m2021-03-04T14:24:30 | mmf.trainers.callbacks.logistics: [0mprogress: 21400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0207, train/total_loss: 0.0000, train/total_loss/avg: 0.0207, max mem: 9622.0, experiment: run, epoch: 320, num_updates: 21400, iterations: 21400, max_updates: 22000, lr: 0., ups: 0.96, time: 01m 44s 450ms, time_since_start: 06h 06m 01s 636ms, eta: 10m 26s 705ms
[32m2021-03-04T14:26:04 | mmf.trainers.callbacks.logistics: [0mprogress: 21500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0206, train/total_loss: 0.0000, train/total_loss/avg: 0.0206, max mem: 9622.0, experiment: run, epoch: 321, num_updates: 21500, iterations: 21500, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 910ms, time_since_start: 06h 07m 36s 546ms, eta: 07m 54s 550ms
[32m2021-03-04T14:27:46 | mmf.trainers.callbacks.logistics: [0mprogress: 21600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0205, train/total_loss: 0.0000, train/total_loss/avg: 0.0205, max mem: 9622.0, experiment: run, epoch: 323, num_updates: 21600, iterations: 21600, max_updates: 22000, lr: 0., ups: 0.99, time: 01m 41s 859ms, time_since_start: 06h 09m 18s 406ms, eta: 06m 47s 439ms
[32m2021-03-04T14:29:21 | mmf.trainers.callbacks.logistics: [0mprogress: 21700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0204, train/total_loss: 0.0000, train/total_loss/avg: 0.0204, max mem: 9622.0, experiment: run, epoch: 324, num_updates: 21700, iterations: 21700, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 546ms, time_since_start: 06h 10m 52s 952ms, eta: 04m 43s 639ms
[32m2021-03-04T14:31:05 | mmf.trainers.callbacks.logistics: [0mprogress: 21800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0203, train/total_loss: 0.0000, train/total_loss/avg: 0.0203, max mem: 9622.0, experiment: run, epoch: 326, num_updates: 21800, iterations: 21800, max_updates: 22000, lr: 0., ups: 0.96, time: 01m 44s 221ms, time_since_start: 06h 12m 37s 174ms, eta: 03m 28s 442ms
[32m2021-03-04T14:32:40 | mmf.trainers.callbacks.logistics: [0mprogress: 21900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0202, train/total_loss: 0.0000, train/total_loss/avg: 0.0202, max mem: 9622.0, experiment: run, epoch: 327, num_updates: 21900, iterations: 21900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 403ms, time_since_start: 06h 14m 12s 577ms, eta: 01m 35s 403ms
[32m2021-03-04T14:34:23 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T14:34:23 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T14:34:23 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T14:34:23 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T14:34:33 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T14:34:44 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T14:34:44 | mmf.trainers.callbacks.logistics: [0mprogress: 22000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0201, train/total_loss: 0.0000, train/total_loss/avg: 0.0201, max mem: 9622.0, experiment: run, epoch: 329, num_updates: 22000, iterations: 22000, max_updates: 22000, lr: 0., ups: 0.81, time: 02m 03s 127ms, time_since_start: 06h 16m 15s 704ms, eta: 0ms
[32m2021-03-04T14:34:44 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T14:34:54 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T14:34:54 | mmf.trainers.callbacks.logistics: [0mprogress: 22000/22000, val/hateful_memes/cross_entropy: 3.4220, val/total_loss: 3.4220, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.4997, val/hateful_memes/roc_auc: 0.6749, num_updates: 22000, epoch: 329, iterations: 22000, max_updates: 22000, val_time: 10s 307ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.709550
[32m2021-03-04T14:34:55 | mmf.trainers.core.training_loop: [0mStepping into final validation check
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mRestoring checkpoint
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mLoading checkpoint
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.position_ids from model.bert.embeddings.position_ids
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.token_type_embeddings_visual.weight from model.bert.embeddings.token_type_embeddings_visual.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.position_embeddings_visual.weight from model.bert.embeddings.position_embeddings_visual.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.projection.weight from model.bert.embeddings.projection.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.projection.bias from model.bert.embeddings.projection.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.pooler.dense.weight from model.bert.pooler.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.bert.pooler.dense.bias from model.bert.pooler.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.dense.weight from model.classifier.0.dense.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.dense.bias from model.classifier.0.dense.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.LayerNorm.weight from model.classifier.0.LayerNorm.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.LayerNorm.bias from model.classifier.0.LayerNorm.bias
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.1.weight from model.classifier.1.weight
[32m2021-03-04T14:34:55 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.1.bias from model.classifier.1.bias
[5m[31mWARNING[0m [32m2021-03-04T14:34:56 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T14:34:56 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T14:34:56 | mmf.utils.checkpoint: [0mCheckpoint loaded.
[32m2021-03-04T14:34:56 | mmf.utils.checkpoint: [0mCurrent num updates: 1000
[32m2021-03-04T14:34:56 | mmf.utils.checkpoint: [0mCurrent iteration: 1000
[32m2021-03-04T14:34:56 | mmf.utils.checkpoint: [0mCurrent epoch: 15
[32m2021-03-04T14:34:59 | mmf.trainers.mmf_trainer: [0mStarting inference on val set
  0%|          | 0/17 [00:00<?, ?it/s]  6%|â–Œ         | 1/17 [00:09<02:37,  9.85s/it] 12%|â–ˆâ–        | 2/17 [00:10<01:02,  4.18s/it] 18%|â–ˆâ–Š        | 3/17 [00:10<00:33,  2.37s/it] 24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:10<00:19,  1.52s/it] 29%|â–ˆâ–ˆâ–‰       | 5/17 [00:10<00:12,  1.05s/it] 29%|â–ˆâ–ˆâ–‰       | 5/17 [00:11<00:26,  2.21s/it][32m2021-03-04T14:35:10 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T14:35:10 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, val/hateful_memes/cross_entropy: 1.1819, val/total_loss: 1.1819, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.3990, val/hateful_memes/roc_auc: 0.7096
[32m2021-03-04T14:35:10 | mmf.trainers.callbacks.logistics: [0mFinished run in 06h 16m 42s 154ms

Training VISUAL_BERT_DIRECT complete
********************************************************************
Training VILBERT_DIRECT
[32m2021-03-04T14:35:15 | mmf.utils.configuration: [0mOverriding option config to projects/hateful_memes/configs/vilbert/defaults.yaml
[32m2021-03-04T14:35:15 | mmf.utils.configuration: [0mOverriding option model to vilbert
[32m2021-03-04T14:35:15 | mmf.utils.configuration: [0mOverriding option datasets to hateful_memes
[32m2021-03-04T14:35:15 | mmf.utils.configuration: [0mOverriding option run_type to train_val
[32m2021-03-04T14:35:15 | mmf.utils.configuration: [0mOverriding option checkpoint.max_to_keep to 3
[32m2021-03-04T14:35:18 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T14:35:18 | mmf.utils.distributed: [0mDistributed Init (Rank 2): tcp://localhost:17114
[32m2021-03-04T14:35:18 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T14:35:18 | mmf.utils.distributed: [0mDistributed Init (Rank 0): tcp://localhost:17114
[32m2021-03-04T14:35:18 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T14:35:18 | mmf.utils.distributed: [0mDistributed Init (Rank 3): tcp://localhost:17114
[32m2021-03-04T14:35:18 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 3
[32m2021-03-04T14:35:18 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T14:35:18 | mmf.utils.distributed: [0mDistributed Init (Rank 1): tcp://localhost:17114
[32m2021-03-04T14:35:18 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 1
[32m2021-03-04T14:35:19 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 2
[32m2021-03-04T14:35:19 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 0
[32m2021-03-04T14:35:25 | mmf: [0mLogging to: /scratch/sagarsj42/save/train.log
[32m2021-03-04T14:35:25 | mmf_cli.run: [0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/vilbert/defaults.yaml', 'model=vilbert', 'dataset=hateful_memes', 'run_type=train_val', 'checkpoint.max_to_keep=3'])
[32m2021-03-04T14:35:25 | mmf_cli.run: [0mTorch version: 1.6.0
[32m2021-03-04T14:35:25 | mmf.utils.general: [0mCUDA Device 0 is: GeForce GTX 1080 Ti
[32m2021-03-04T14:35:25 | mmf_cli.run: [0mUsing seed 25341947
[32m2021-03-04T14:35:25 | mmf.trainers.mmf_trainer: [0mLoading datasets
[32m2021-03-04T14:35:31 | mmf.trainers.mmf_trainer: [0mLoading model
Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.v_embeddings.image_embeddings.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[32m2021-03-04T14:35:35 | mmf.trainers.mmf_trainer: [0mLoading optimizer
[32m2021-03-04T14:35:35 | mmf.trainers.mmf_trainer: [0mLoading metrics
[5m[31mWARNING[0m [32m2021-03-04T14:35:35 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.
Use OmegaConf.to_yaml(cfg)

  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T14:35:35 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.
Use OmegaConf.to_yaml(cfg)

  builtin_warn(*args, **kwargs)

Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.v_embeddings.image_embeddings.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.v_embeddings.image_embeddings.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.v_embeddings.image_embeddings.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[32m2021-03-04T14:35:40 | mmf.trainers.mmf_trainer: [0m===== Model =====
[32m2021-03-04T14:35:40 | mmf.trainers.mmf_trainer: [0mDistributedDataParallel(
  (module): ViLBERT(
    (model): ViLBERTForClassification(
      (bert): ViLBERTBase(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (v_embeddings): BertImageFeatureEmbeddings(
          (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)
          (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)
          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (v_layer): ModuleList(
            (0): BertImageLayer(
              (attention): BertImageAttention(
                (self): BertImageSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertImageSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertImageLayer(
              (attention): BertImageAttention(
                (self): BertImageSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertImageSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertImageLayer(
              (attention): BertImageAttention(
                (self): BertImageSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertImageSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertImageLayer(
              (attention): BertImageAttention(
                (self): BertImageSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertImageSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertImageLayer(
              (attention): BertImageAttention(
                (self): BertImageSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertImageSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertImageLayer(
              (attention): BertImageAttention(
                (self): BertImageSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertImageSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (c_layer): ModuleList(
            (0): BertConnectionLayer(
              (biattention): BertBiAttention(
                (query1): Linear(in_features=1024, out_features=1024, bias=True)
                (key1): Linear(in_features=1024, out_features=1024, bias=True)
                (value1): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (query2): Linear(in_features=768, out_features=1024, bias=True)
                (key2): Linear(in_features=768, out_features=1024, bias=True)
                (value2): Linear(in_features=768, out_features=1024, bias=True)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
              (biOutput): BertBiOutput(
                (dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (q_dropout1): Dropout(p=0.1, inplace=False)
                (dense2): Linear(in_features=1024, out_features=768, bias=True)
                (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout2): Dropout(p=0.1, inplace=False)
                (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
                (q_dropout2): Dropout(p=0.1, inplace=False)
              )
              (v_intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (v_output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (t_intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (t_output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertConnectionLayer(
              (biattention): BertBiAttention(
                (query1): Linear(in_features=1024, out_features=1024, bias=True)
                (key1): Linear(in_features=1024, out_features=1024, bias=True)
                (value1): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (query2): Linear(in_features=768, out_features=1024, bias=True)
                (key2): Linear(in_features=768, out_features=1024, bias=True)
                (value2): Linear(in_features=768, out_features=1024, bias=True)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
              (biOutput): BertBiOutput(
                (dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (q_dropout1): Dropout(p=0.1, inplace=False)
                (dense2): Linear(in_features=1024, out_features=768, bias=True)
                (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout2): Dropout(p=0.1, inplace=False)
                (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
                (q_dropout2): Dropout(p=0.1, inplace=False)
              )
              (v_intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (v_output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (t_intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (t_output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertConnectionLayer(
              (biattention): BertBiAttention(
                (query1): Linear(in_features=1024, out_features=1024, bias=True)
                (key1): Linear(in_features=1024, out_features=1024, bias=True)
                (value1): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (query2): Linear(in_features=768, out_features=1024, bias=True)
                (key2): Linear(in_features=768, out_features=1024, bias=True)
                (value2): Linear(in_features=768, out_features=1024, bias=True)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
              (biOutput): BertBiOutput(
                (dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (q_dropout1): Dropout(p=0.1, inplace=False)
                (dense2): Linear(in_features=1024, out_features=768, bias=True)
                (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout2): Dropout(p=0.1, inplace=False)
                (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
                (q_dropout2): Dropout(p=0.1, inplace=False)
              )
              (v_intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (v_output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (t_intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (t_output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertConnectionLayer(
              (biattention): BertBiAttention(
                (query1): Linear(in_features=1024, out_features=1024, bias=True)
                (key1): Linear(in_features=1024, out_features=1024, bias=True)
                (value1): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (query2): Linear(in_features=768, out_features=1024, bias=True)
                (key2): Linear(in_features=768, out_features=1024, bias=True)
                (value2): Linear(in_features=768, out_features=1024, bias=True)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
              (biOutput): BertBiOutput(
                (dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (q_dropout1): Dropout(p=0.1, inplace=False)
                (dense2): Linear(in_features=1024, out_features=768, bias=True)
                (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout2): Dropout(p=0.1, inplace=False)
                (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
                (q_dropout2): Dropout(p=0.1, inplace=False)
              )
              (v_intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (v_output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (t_intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (t_output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertConnectionLayer(
              (biattention): BertBiAttention(
                (query1): Linear(in_features=1024, out_features=1024, bias=True)
                (key1): Linear(in_features=1024, out_features=1024, bias=True)
                (value1): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (query2): Linear(in_features=768, out_features=1024, bias=True)
                (key2): Linear(in_features=768, out_features=1024, bias=True)
                (value2): Linear(in_features=768, out_features=1024, bias=True)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
              (biOutput): BertBiOutput(
                (dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (q_dropout1): Dropout(p=0.1, inplace=False)
                (dense2): Linear(in_features=1024, out_features=768, bias=True)
                (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout2): Dropout(p=0.1, inplace=False)
                (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
                (q_dropout2): Dropout(p=0.1, inplace=False)
              )
              (v_intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (v_output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (t_intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (t_output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertConnectionLayer(
              (biattention): BertBiAttention(
                (query1): Linear(in_features=1024, out_features=1024, bias=True)
                (key1): Linear(in_features=1024, out_features=1024, bias=True)
                (value1): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (query2): Linear(in_features=768, out_features=1024, bias=True)
                (key2): Linear(in_features=768, out_features=1024, bias=True)
                (value2): Linear(in_features=768, out_features=1024, bias=True)
                (dropout2): Dropout(p=0.1, inplace=False)
              )
              (biOutput): BertBiOutput(
                (dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
                (q_dropout1): Dropout(p=0.1, inplace=False)
                (dense2): Linear(in_features=1024, out_features=768, bias=True)
                (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout2): Dropout(p=0.1, inplace=False)
                (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
                (q_dropout2): Dropout(p=0.1, inplace=False)
              )
              (v_intermediate): BertImageIntermediate(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
              )
              (v_output): BertImageOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (t_intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (t_output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (t_pooler): BertTextPooler(
          (dense): Linear(in_features=768, out_features=1024, bias=True)
          (activation): ReLU()
        )
        (v_pooler): BertImagePooler(
          (dense): Linear(in_features=1024, out_features=1024, bias=True)
          (activation): ReLU()
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
      (classifier): Sequential(
        (0): BertPredictionHeadTransform(
          (dense): Linear(in_features=1024, out_features=1024, bias=True)
          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        )
        (1): Linear(in_features=1024, out_features=2, bias=True)
      )
    )
    (losses): Losses(
      (losses): ModuleList(
        (0): MMFLoss(
          (loss_criterion): CrossEntropyLoss(
            (loss_fn): CrossEntropyLoss()
          )
        )
      )
    )
  )
)
[32m2021-03-04T14:35:40 | mmf.utils.general: [0mTotal Parameters: 247780354. Trained Parameters: 247780354
[32m2021-03-04T14:35:40 | mmf.trainers.core.training_loop: [0mStarting training...
[32m2021-03-04T14:36:37 | mmf.trainers.callbacks.logistics: [0mprogress: 100/22000, train/hateful_memes/cross_entropy: 0.7471, train/hateful_memes/cross_entropy/avg: 0.7471, train/total_loss: 0.7471, train/total_loss/avg: 0.7471, max mem: 6431.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 1.75, time: 57s 409ms, time_since_start: 01m 02s 016ms, eta: 03h 29m 57s 782ms
[32m2021-03-04T14:37:25 | mmf.trainers.callbacks.logistics: [0mprogress: 200/22000, train/hateful_memes/cross_entropy: 0.7471, train/hateful_memes/cross_entropy/avg: 0.7884, train/total_loss: 0.7471, train/total_loss/avg: 0.7884, max mem: 6431.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0., ups: 2.13, time: 47s 656ms, time_since_start: 01m 49s 673ms, eta: 02h 53m 29s 950ms
[32m2021-03-04T14:38:24 | mmf.trainers.callbacks.logistics: [0mprogress: 300/22000, train/hateful_memes/cross_entropy: 0.7471, train/hateful_memes/cross_entropy/avg: 0.7447, train/total_loss: 0.7471, train/total_loss/avg: 0.7447, max mem: 6431.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0., ups: 1.72, time: 58s 590ms, time_since_start: 02m 48s 263ms, eta: 03h 32m 19s 576ms
[32m2021-03-04T14:39:12 | mmf.trainers.callbacks.logistics: [0mprogress: 400/22000, train/hateful_memes/cross_entropy: 0.6745, train/hateful_memes/cross_entropy/avg: 0.7271, train/total_loss: 0.6745, train/total_loss/avg: 0.7271, max mem: 6431.0, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 695ms, time_since_start: 03m 36s 959ms, eta: 02h 55m 39s 237ms
[32m2021-03-04T14:40:01 | mmf.trainers.callbacks.logistics: [0mprogress: 500/22000, train/hateful_memes/cross_entropy: 0.6745, train/hateful_memes/cross_entropy/avg: 0.7017, train/total_loss: 0.6745, train/total_loss/avg: 0.7017, max mem: 6431.0, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 817ms, time_since_start: 04m 25s 776ms, eta: 02h 55m 16s 778ms
[32m2021-03-04T14:41:00 | mmf.trainers.callbacks.logistics: [0mprogress: 600/22000, train/hateful_memes/cross_entropy: 0.6572, train/hateful_memes/cross_entropy/avg: 0.6840, train/total_loss: 0.6572, train/total_loss/avg: 0.6840, max mem: 6431.0, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 243ms, time_since_start: 05m 25s 020ms, eta: 03h 31m 43s 506ms
[32m2021-03-04T14:41:49 | mmf.trainers.callbacks.logistics: [0mprogress: 700/22000, train/hateful_memes/cross_entropy: 0.6745, train/hateful_memes/cross_entropy/avg: 0.7006, train/total_loss: 0.6745, train/total_loss/avg: 0.7006, max mem: 6431.0, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 725ms, time_since_start: 06m 13s 746ms, eta: 02h 53m 19s 278ms
[32m2021-03-04T14:42:48 | mmf.trainers.callbacks.logistics: [0mprogress: 800/22000, train/hateful_memes/cross_entropy: 0.6572, train/hateful_memes/cross_entropy/avg: 0.6900, train/total_loss: 0.6572, train/total_loss/avg: 0.6900, max mem: 6431.0, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 368ms, time_since_start: 07m 13s 115ms, eta: 03h 30m 11s 383ms
[32m2021-03-04T14:43:37 | mmf.trainers.callbacks.logistics: [0mprogress: 900/22000, train/hateful_memes/cross_entropy: 0.6572, train/hateful_memes/cross_entropy/avg: 0.6778, train/total_loss: 0.6572, train/total_loss/avg: 0.6778, max mem: 6431.0, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 055ms, time_since_start: 08m 02s 170ms, eta: 02h 52m 51s 490ms
[32m2021-03-04T14:44:27 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T14:44:27 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T14:44:27 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T14:44:27 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T14:44:33 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T14:45:02 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T14:45:03 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, train/hateful_memes/cross_entropy: 0.6159, train/hateful_memes/cross_entropy/avg: 0.6570, train/total_loss: 0.6159, train/total_loss/avg: 0.6570, max mem: 6431.0, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00001, ups: 1.18, time: 01m 25s 228ms, time_since_start: 09m 27s 399ms, eta: 04h 58m 53s 866ms
[32m2021-03-04T14:45:03 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T14:45:20 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T14:45:20 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T14:45:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T14:45:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T14:45:43 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T14:46:05 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T14:46:28 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T14:46:28 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, val/hateful_memes/cross_entropy: 0.7592, val/total_loss: 0.7592, val/hateful_memes/accuracy: 0.6074, val/hateful_memes/binary_f1: 0.4184, val/hateful_memes/roc_auc: 0.5988, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 22000, val_time: 01m 24s 868ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.598778
[32m2021-03-04T14:47:28 | mmf.trainers.callbacks.logistics: [0mprogress: 1100/22000, train/hateful_memes/cross_entropy: 0.6159, train/hateful_memes/cross_entropy/avg: 0.6437, train/total_loss: 0.6159, train/total_loss/avg: 0.6437, max mem: 6431.0, experiment: run, epoch: 5, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 293ms, time_since_start: 11m 52s 578ms, eta: 03h 30m 26s 483ms
[32m2021-03-04T14:48:17 | mmf.trainers.callbacks.logistics: [0mprogress: 1200/22000, train/hateful_memes/cross_entropy: 0.5999, train/hateful_memes/cross_entropy/avg: 0.6153, train/total_loss: 0.5999, train/total_loss/avg: 0.6153, max mem: 6431.0, experiment: run, epoch: 5, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 689ms, time_since_start: 12m 41s 267ms, eta: 02h 49m 07s 606ms
[32m2021-03-04T14:49:05 | mmf.trainers.callbacks.logistics: [0mprogress: 1300/22000, train/hateful_memes/cross_entropy: 0.5999, train/hateful_memes/cross_entropy/avg: 0.5967, train/total_loss: 0.5999, train/total_loss/avg: 0.5967, max mem: 6431.0, experiment: run, epoch: 5, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 880ms, time_since_start: 13m 30s 147ms, eta: 02h 48m 58s 504ms
[32m2021-03-04T14:50:05 | mmf.trainers.callbacks.logistics: [0mprogress: 1400/22000, train/hateful_memes/cross_entropy: 0.5958, train/hateful_memes/cross_entropy/avg: 0.5749, train/total_loss: 0.5958, train/total_loss/avg: 0.5749, max mem: 6431.0, experiment: run, epoch: 6, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 321ms, time_since_start: 14m 29s 468ms, eta: 03h 24m 04s 603ms
[32m2021-03-04T14:50:53 | mmf.trainers.callbacks.logistics: [0mprogress: 1500/22000, train/hateful_memes/cross_entropy: 0.5958, train/hateful_memes/cross_entropy/avg: 0.5574, train/total_loss: 0.5958, train/total_loss/avg: 0.5574, max mem: 6431.0, experiment: run, epoch: 6, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 384ms, time_since_start: 15m 17s 853ms, eta: 02h 45m 38s 634ms
[32m2021-03-04T14:51:52 | mmf.trainers.callbacks.logistics: [0mprogress: 1600/22000, train/hateful_memes/cross_entropy: 0.5798, train/hateful_memes/cross_entropy/avg: 0.5392, train/total_loss: 0.5798, train/total_loss/avg: 0.5392, max mem: 6431.0, experiment: run, epoch: 7, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 039ms, time_since_start: 16m 16s 893ms, eta: 03h 21m 08s 224ms
[32m2021-03-04T14:52:41 | mmf.trainers.callbacks.logistics: [0mprogress: 1700/22000, train/hateful_memes/cross_entropy: 0.5798, train/hateful_memes/cross_entropy/avg: 0.5217, train/total_loss: 0.5798, train/total_loss/avg: 0.5217, max mem: 6431.0, experiment: run, epoch: 7, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 928ms, time_since_start: 17m 05s 822ms, eta: 02h 45m 52s 400ms
[32m2021-03-04T14:53:30 | mmf.trainers.callbacks.logistics: [0mprogress: 1800/22000, train/hateful_memes/cross_entropy: 0.5798, train/hateful_memes/cross_entropy/avg: 0.5270, train/total_loss: 0.5798, train/total_loss/avg: 0.5270, max mem: 6431.0, experiment: run, epoch: 7, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 041ms, time_since_start: 17m 54s 863ms, eta: 02h 45m 26s 260ms
[32m2021-03-04T14:54:31 | mmf.trainers.callbacks.logistics: [0mprogress: 1900/22000, train/hateful_memes/cross_entropy: 0.5798, train/hateful_memes/cross_entropy/avg: 0.5143, train/total_loss: 0.5798, train/total_loss/avg: 0.5143, max mem: 6431.0, experiment: run, epoch: 8, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 522ms, time_since_start: 18m 55s 386ms, eta: 03h 23m 09s 287ms
[32m2021-03-04T14:55:20 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T14:55:20 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T14:55:21 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T14:55:21 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T14:55:27 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T14:55:55 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T14:55:55 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, train/hateful_memes/cross_entropy: 0.5104, train/hateful_memes/cross_entropy/avg: 0.5062, train/total_loss: 0.5104, train/total_loss/avg: 0.5062, max mem: 6431.0, experiment: run, epoch: 8, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00001, ups: 1.19, time: 01m 24s 797ms, time_since_start: 20m 20s 183ms, eta: 04h 43m 13s 433ms
[32m2021-03-04T14:55:55 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T14:56:13 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T14:56:13 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T14:56:13 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T14:56:13 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T14:56:36 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T14:56:58 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T14:57:21 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T14:57:21 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, val/hateful_memes/cross_entropy: 0.8811, val/total_loss: 0.8811, val/hateful_memes/accuracy: 0.6648, val/hateful_memes/binary_f1: 0.5443, val/hateful_memes/roc_auc: 0.6865, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 22000, val_time: 01m 25s 397ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.686541
[32m2021-03-04T14:58:11 | mmf.trainers.callbacks.logistics: [0mprogress: 2100/22000, train/hateful_memes/cross_entropy: 0.4701, train/hateful_memes/cross_entropy/avg: 0.4957, train/total_loss: 0.4701, train/total_loss/avg: 0.4957, max mem: 6431.0, experiment: run, epoch: 8, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 882ms, time_since_start: 22m 35s 480ms, eta: 02h 45m 46s 429ms
[32m2021-03-04T14:59:12 | mmf.trainers.callbacks.logistics: [0mprogress: 2200/22000, train/hateful_memes/cross_entropy: 0.3740, train/hateful_memes/cross_entropy/avg: 0.4800, train/total_loss: 0.3740, train/total_loss/avg: 0.4800, max mem: 6431.0, experiment: run, epoch: 9, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 888ms, time_since_start: 23m 36s 368ms, eta: 03h 21m 20s 025ms
[32m2021-03-04T15:00:00 | mmf.trainers.callbacks.logistics: [0mprogress: 2300/22000, train/hateful_memes/cross_entropy: 0.3535, train/hateful_memes/cross_entropy/avg: 0.4705, train/total_loss: 0.3535, train/total_loss/avg: 0.4705, max mem: 6431.0, experiment: run, epoch: 9, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 843ms, time_since_start: 24m 25s 212ms, eta: 02h 40m 41s 451ms
[32m2021-03-04T15:01:00 | mmf.trainers.callbacks.logistics: [0mprogress: 2400/22000, train/hateful_memes/cross_entropy: 0.3132, train/hateful_memes/cross_entropy/avg: 0.4537, train/total_loss: 0.3132, train/total_loss/avg: 0.4537, max mem: 6431.0, experiment: run, epoch: 10, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 857ms, time_since_start: 25m 25s 069ms, eta: 03h 15m 55s 456ms
[32m2021-03-04T15:01:49 | mmf.trainers.callbacks.logistics: [0mprogress: 2500/22000, train/hateful_memes/cross_entropy: 0.3027, train/hateful_memes/cross_entropy/avg: 0.4409, train/total_loss: 0.3027, train/total_loss/avg: 0.4409, max mem: 6431.0, experiment: run, epoch: 10, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 831ms, time_since_start: 26m 13s 901ms, eta: 02h 39m 01s 254ms
[32m2021-03-04T15:02:38 | mmf.trainers.callbacks.logistics: [0mprogress: 2600/22000, train/hateful_memes/cross_entropy: 0.2910, train/hateful_memes/cross_entropy/avg: 0.4292, train/total_loss: 0.2910, train/total_loss/avg: 0.4292, max mem: 6431.0, experiment: run, epoch: 10, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 001ms, time_since_start: 27m 02s 903ms, eta: 02h 38m 45s 322ms
[32m2021-03-04T15:03:38 | mmf.trainers.callbacks.logistics: [0mprogress: 2700/22000, train/hateful_memes/cross_entropy: 0.2863, train/hateful_memes/cross_entropy/avg: 0.4196, train/total_loss: 0.2863, train/total_loss/avg: 0.4196, max mem: 6431.0, experiment: run, epoch: 11, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 735ms, time_since_start: 28m 02s 638ms, eta: 03h 12m 31s 919ms
[32m2021-03-04T15:04:27 | mmf.trainers.callbacks.logistics: [0mprogress: 2800/22000, train/hateful_memes/cross_entropy: 0.2841, train/hateful_memes/cross_entropy/avg: 0.4053, train/total_loss: 0.2841, train/total_loss/avg: 0.4053, max mem: 6431.0, experiment: run, epoch: 11, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 293ms, time_since_start: 28m 51s 931ms, eta: 02h 38m 03s 300ms
[32m2021-03-04T15:05:17 | mmf.trainers.callbacks.logistics: [0mprogress: 2900/22000, train/hateful_memes/cross_entropy: 0.2841, train/hateful_memes/cross_entropy/avg: 0.4012, train/total_loss: 0.2841, train/total_loss/avg: 0.4012, max mem: 6431.0, experiment: run, epoch: 11, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 432ms, time_since_start: 29m 41s 364ms, eta: 02h 37m 40s 476ms
[32m2021-03-04T15:06:16 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T15:06:16 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T15:06:16 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T15:06:16 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T15:06:22 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T15:06:52 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T15:06:52 | mmf.trainers.callbacks.logistics: [0mprogress: 3000/22000, train/hateful_memes/cross_entropy: 0.2657, train/hateful_memes/cross_entropy/avg: 0.3892, train/total_loss: 0.2657, train/total_loss/avg: 0.3892, max mem: 6431.0, experiment: run, epoch: 12, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 960ms, time_since_start: 31m 16s 324ms, eta: 05h 01m 18s 591ms
[32m2021-03-04T15:06:52 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T15:07:09 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T15:07:10 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T15:07:10 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T15:07:10 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T15:07:32 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T15:07:55 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T15:08:17 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T15:08:17 | mmf.trainers.callbacks.logistics: [0mprogress: 3000/22000, val/hateful_memes/cross_entropy: 1.4646, val/total_loss: 1.4646, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4828, val/hateful_memes/roc_auc: 0.6921, num_updates: 3000, epoch: 12, iterations: 3000, max_updates: 22000, val_time: 01m 25s 640ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.692109
[32m2021-03-04T15:09:06 | mmf.trainers.callbacks.logistics: [0mprogress: 3100/22000, train/hateful_memes/cross_entropy: 0.2597, train/hateful_memes/cross_entropy/avg: 0.3795, train/total_loss: 0.2597, train/total_loss/avg: 0.3795, max mem: 6431.0, experiment: run, epoch: 12, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 846ms, time_since_start: 33m 30s 829ms, eta: 02h 34m 10s 474ms
[32m2021-03-04T15:10:06 | mmf.trainers.callbacks.logistics: [0mprogress: 3200/22000, train/hateful_memes/cross_entropy: 0.2421, train/hateful_memes/cross_entropy/avg: 0.3715, train/total_loss: 0.2421, train/total_loss/avg: 0.3715, max mem: 6431.0, experiment: run, epoch: 13, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 097ms, time_since_start: 34m 30s 926ms, eta: 03h 08m 40s 839ms
[32m2021-03-04T15:10:56 | mmf.trainers.callbacks.logistics: [0mprogress: 3300/22000, train/hateful_memes/cross_entropy: 0.1688, train/hateful_memes/cross_entropy/avg: 0.3614, train/total_loss: 0.1688, train/total_loss/avg: 0.3614, max mem: 6431.0, experiment: run, epoch: 13, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 814ms, time_since_start: 35m 20s 741ms, eta: 02h 35m 33s 986ms
[32m2021-03-04T15:11:46 | mmf.trainers.callbacks.logistics: [0mprogress: 3400/22000, train/hateful_memes/cross_entropy: 0.1501, train/hateful_memes/cross_entropy/avg: 0.3521, train/total_loss: 0.1501, train/total_loss/avg: 0.3521, max mem: 6431.0, experiment: run, epoch: 13, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 925ms, time_since_start: 36m 10s 667ms, eta: 02h 35m 04s 797ms
[32m2021-03-04T15:12:46 | mmf.trainers.callbacks.logistics: [0mprogress: 3500/22000, train/hateful_memes/cross_entropy: 0.1376, train/hateful_memes/cross_entropy/avg: 0.3439, train/total_loss: 0.1376, train/total_loss/avg: 0.3439, max mem: 6431.0, experiment: run, epoch: 14, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 920ms, time_since_start: 37m 10s 587ms, eta: 03h 05m 07s 409ms
[32m2021-03-04T15:13:34 | mmf.trainers.callbacks.logistics: [0mprogress: 3600/22000, train/hateful_memes/cross_entropy: 0.1332, train/hateful_memes/cross_entropy/avg: 0.3344, train/total_loss: 0.1332, train/total_loss/avg: 0.3344, max mem: 6431.0, experiment: run, epoch: 14, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 470ms, time_since_start: 37m 59s 058ms, eta: 02h 28m 56s 454ms
[32m2021-03-04T15:14:23 | mmf.trainers.callbacks.logistics: [0mprogress: 3700/22000, train/hateful_memes/cross_entropy: 0.1228, train/hateful_memes/cross_entropy/avg: 0.3255, train/total_loss: 0.1228, train/total_loss/avg: 0.3255, max mem: 6431.0, experiment: run, epoch: 14, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 650ms, time_since_start: 38m 47s 708ms, eta: 02h 28m 40s 786ms
[32m2021-03-04T15:15:22 | mmf.trainers.callbacks.logistics: [0mprogress: 3800/22000, train/hateful_memes/cross_entropy: 0.0868, train/hateful_memes/cross_entropy/avg: 0.3171, train/total_loss: 0.0868, train/total_loss/avg: 0.3171, max mem: 6431.0, experiment: run, epoch: 15, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 115ms, time_since_start: 39m 46s 824ms, eta: 02h 59m 40s 532ms
[32m2021-03-04T15:16:11 | mmf.trainers.callbacks.logistics: [0mprogress: 3900/22000, train/hateful_memes/cross_entropy: 0.0679, train/hateful_memes/cross_entropy/avg: 0.3090, train/total_loss: 0.0679, train/total_loss/avg: 0.3090, max mem: 6431.0, experiment: run, epoch: 15, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 608ms, time_since_start: 40m 35s 432ms, eta: 02h 26m 55s 678ms
[32m2021-03-04T15:17:10 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T15:17:10 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T15:17:10 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T15:17:10 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T15:17:15 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T15:17:48 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T15:17:48 | mmf.trainers.callbacks.logistics: [0mprogress: 4000/22000, train/hateful_memes/cross_entropy: 0.0636, train/hateful_memes/cross_entropy/avg: 0.3023, train/total_loss: 0.0636, train/total_loss/avg: 0.3023, max mem: 6431.0, experiment: run, epoch: 16, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 902ms, time_since_start: 42m 12s 335ms, eta: 04h 51m 17s 408ms
[32m2021-03-04T15:17:48 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T15:18:05 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T15:18:05 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T15:18:05 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T15:18:05 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T15:18:27 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T15:18:50 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T15:18:50 | mmf.trainers.callbacks.logistics: [0mprogress: 4000/22000, val/hateful_memes/cross_entropy: 1.5847, val/total_loss: 1.5847, val/hateful_memes/accuracy: 0.6926, val/hateful_memes/binary_f1: 0.5271, val/hateful_memes/roc_auc: 0.6902, num_updates: 4000, epoch: 16, iterations: 4000, max_updates: 22000, val_time: 01m 02s 677ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.692109
[32m2021-03-04T15:19:40 | mmf.trainers.callbacks.logistics: [0mprogress: 4100/22000, train/hateful_memes/cross_entropy: 0.0590, train/hateful_memes/cross_entropy/avg: 0.2964, train/total_loss: 0.0590, train/total_loss/avg: 0.2964, max mem: 6431.0, experiment: run, epoch: 16, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 657ms, time_since_start: 44m 04s 687ms, eta: 02h 28m 26s 453ms
[32m2021-03-04T15:20:29 | mmf.trainers.callbacks.logistics: [0mprogress: 4200/22000, train/hateful_memes/cross_entropy: 0.0460, train/hateful_memes/cross_entropy/avg: 0.2901, train/total_loss: 0.0460, train/total_loss/avg: 0.2901, max mem: 6431.0, experiment: run, epoch: 16, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 467ms, time_since_start: 44m 54s 154ms, eta: 02h 27m 02s 852ms
[32m2021-03-04T15:21:30 | mmf.trainers.callbacks.logistics: [0mprogress: 4300/22000, train/hateful_memes/cross_entropy: 0.0418, train/hateful_memes/cross_entropy/avg: 0.2843, train/total_loss: 0.0418, train/total_loss/avg: 0.2843, max mem: 6431.0, experiment: run, epoch: 17, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 598ms, time_since_start: 45m 54s 753ms, eta: 02h 59m 07s 447ms
[32m2021-03-04T15:22:20 | mmf.trainers.callbacks.logistics: [0mprogress: 4400/22000, train/hateful_memes/cross_entropy: 0.0414, train/hateful_memes/cross_entropy/avg: 0.2780, train/total_loss: 0.0414, train/total_loss/avg: 0.2780, max mem: 6431.0, experiment: run, epoch: 17, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 915ms, time_since_start: 46m 44s 669ms, eta: 02h 26m 42s 708ms
[32m2021-03-04T15:23:10 | mmf.trainers.callbacks.logistics: [0mprogress: 4500/22000, train/hateful_memes/cross_entropy: 0.0414, train/hateful_memes/cross_entropy/avg: 0.2734, train/total_loss: 0.0414, train/total_loss/avg: 0.2734, max mem: 6431.0, experiment: run, epoch: 17, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 852ms, time_since_start: 47m 34s 521ms, eta: 02h 25m 41s 595ms
[32m2021-03-04T15:24:09 | mmf.trainers.callbacks.logistics: [0mprogress: 4600/22000, train/hateful_memes/cross_entropy: 0.0401, train/hateful_memes/cross_entropy/avg: 0.2676, train/total_loss: 0.0401, train/total_loss/avg: 0.2676, max mem: 6431.0, experiment: run, epoch: 18, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 308ms, time_since_start: 48m 33s 829ms, eta: 02h 52m 20s 305ms
[32m2021-03-04T15:24:58 | mmf.trainers.callbacks.logistics: [0mprogress: 4700/22000, train/hateful_memes/cross_entropy: 0.0394, train/hateful_memes/cross_entropy/avg: 0.2622, train/total_loss: 0.0394, train/total_loss/avg: 0.2622, max mem: 6431.0, experiment: run, epoch: 18, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 419ms, time_since_start: 49m 22s 249ms, eta: 02h 19m 53s 269ms
[32m2021-03-04T15:25:57 | mmf.trainers.callbacks.logistics: [0mprogress: 4800/22000, train/hateful_memes/cross_entropy: 0.0401, train/hateful_memes/cross_entropy/avg: 0.2577, train/total_loss: 0.0401, train/total_loss/avg: 0.2577, max mem: 6431.0, experiment: run, epoch: 19, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 275ms, time_since_start: 50m 21s 524ms, eta: 02h 50m 15s 763ms
[32m2021-03-04T15:26:46 | mmf.trainers.callbacks.logistics: [0mprogress: 4900/22000, train/hateful_memes/cross_entropy: 0.0394, train/hateful_memes/cross_entropy/avg: 0.2525, train/total_loss: 0.0394, train/total_loss/avg: 0.2525, max mem: 6431.0, experiment: run, epoch: 19, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 265ms, time_since_start: 51m 10s 790ms, eta: 02h 20m 41s 266ms
[32m2021-03-04T15:27:35 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T15:27:35 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T15:27:35 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T15:27:35 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T15:27:41 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T15:28:12 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T15:28:13 | mmf.trainers.callbacks.logistics: [0mprogress: 5000/22000, train/hateful_memes/cross_entropy: 0.0303, train/hateful_memes/cross_entropy/avg: 0.2478, train/total_loss: 0.0303, train/total_loss/avg: 0.2478, max mem: 6431.0, experiment: run, epoch: 19, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00001, ups: 1.16, time: 01m 26s 432ms, time_since_start: 52m 37s 222ms, eta: 04h 05m 22s 943ms
[32m2021-03-04T15:28:13 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T15:28:30 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T15:28:30 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T15:28:30 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T15:28:30 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T15:28:53 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T15:29:16 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T15:29:39 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T15:29:39 | mmf.trainers.callbacks.logistics: [0mprogress: 5000/22000, val/hateful_memes/cross_entropy: 1.8230, val/total_loss: 1.8230, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4798, val/hateful_memes/roc_auc: 0.6925, num_updates: 5000, epoch: 19, iterations: 5000, max_updates: 22000, val_time: 01m 26s 391ms, best_update: 5000, best_iteration: 5000, best_val/hateful_memes/roc_auc: 0.692465
[32m2021-03-04T15:30:40 | mmf.trainers.callbacks.logistics: [0mprogress: 5100/22000, train/hateful_memes/cross_entropy: 0.0183, train/hateful_memes/cross_entropy/avg: 0.2432, train/total_loss: 0.0183, train/total_loss/avg: 0.2432, max mem: 6431.0, experiment: run, epoch: 20, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 349ms, time_since_start: 55m 04s 985ms, eta: 02h 53m 08s 888ms
[32m2021-03-04T15:31:31 | mmf.trainers.callbacks.logistics: [0mprogress: 5200/22000, train/hateful_memes/cross_entropy: 0.0183, train/hateful_memes/cross_entropy/avg: 0.2424, train/total_loss: 0.0183, train/total_loss/avg: 0.2424, max mem: 6431.0, experiment: run, epoch: 20, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 735ms, time_since_start: 55m 55s 720ms, eta: 02h 22m 20s 610ms
[32m2021-03-04T15:32:22 | mmf.trainers.callbacks.logistics: [0mprogress: 5300/22000, train/hateful_memes/cross_entropy: 0.0114, train/hateful_memes/cross_entropy/avg: 0.2378, train/total_loss: 0.0114, train/total_loss/avg: 0.2378, max mem: 6431.0, experiment: run, epoch: 20, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 033ms, time_since_start: 56m 46s 754ms, eta: 02h 22m 19s 641ms
[32m2021-03-04T15:33:22 | mmf.trainers.callbacks.logistics: [0mprogress: 5400/22000, train/hateful_memes/cross_entropy: 0.0111, train/hateful_memes/cross_entropy/avg: 0.2336, train/total_loss: 0.0111, train/total_loss/avg: 0.2336, max mem: 6431.0, experiment: run, epoch: 21, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 347ms, time_since_start: 57m 47s 101ms, eta: 02h 47m 17s 768ms
[32m2021-03-04T15:34:12 | mmf.trainers.callbacks.logistics: [0mprogress: 5500/22000, train/hateful_memes/cross_entropy: 0.0094, train/hateful_memes/cross_entropy/avg: 0.2294, train/total_loss: 0.0094, train/total_loss/avg: 0.2294, max mem: 6431.0, experiment: run, epoch: 21, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 050ms, time_since_start: 58m 37s 152ms, eta: 02h 17m 54s 869ms
[32m2021-03-04T15:35:13 | mmf.trainers.callbacks.logistics: [0mprogress: 5600/22000, train/hateful_memes/cross_entropy: 0.0111, train/hateful_memes/cross_entropy/avg: 0.2257, train/total_loss: 0.0111, train/total_loss/avg: 0.2257, max mem: 6431.0, experiment: run, epoch: 22, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 698ms, time_since_start: 59m 37s 851ms, eta: 02h 46m 14s 484ms
[32m2021-03-04T15:36:02 | mmf.trainers.callbacks.logistics: [0mprogress: 5700/22000, train/hateful_memes/cross_entropy: 0.0111, train/hateful_memes/cross_entropy/avg: 0.2218, train/total_loss: 0.0111, train/total_loss/avg: 0.2218, max mem: 6431.0, experiment: run, epoch: 22, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 770ms, time_since_start: 01h 26s 621ms, eta: 02h 12m 45s 544ms
[32m2021-03-04T15:36:51 | mmf.trainers.callbacks.logistics: [0mprogress: 5800/22000, train/hateful_memes/cross_entropy: 0.0111, train/hateful_memes/cross_entropy/avg: 0.2180, train/total_loss: 0.0111, train/total_loss/avg: 0.2180, max mem: 6431.0, experiment: run, epoch: 22, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 055ms, time_since_start: 01h 01m 15s 677ms, eta: 02h 12m 42s 923ms
[32m2021-03-04T15:37:50 | mmf.trainers.callbacks.logistics: [0mprogress: 5900/22000, train/hateful_memes/cross_entropy: 0.0111, train/hateful_memes/cross_entropy/avg: 0.2143, train/total_loss: 0.0111, train/total_loss/avg: 0.2143, max mem: 6431.0, experiment: run, epoch: 23, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 492ms, time_since_start: 01h 02m 15s 170ms, eta: 02h 39m 57s 469ms
[32m2021-03-04T15:38:40 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T15:38:40 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T15:38:40 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T15:38:40 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T15:38:45 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T15:39:08 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T15:39:08 | mmf.trainers.callbacks.logistics: [0mprogress: 6000/22000, train/hateful_memes/cross_entropy: 0.0094, train/hateful_memes/cross_entropy/avg: 0.2109, train/total_loss: 0.0094, train/total_loss/avg: 0.2109, max mem: 6431.0, experiment: run, epoch: 23, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00001, ups: 1.30, time: 01m 17s 587ms, time_since_start: 01h 03m 32s 757ms, eta: 03h 27m 18s 767ms
[32m2021-03-04T15:39:08 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T15:39:25 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T15:39:25 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T15:39:25 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T15:39:25 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T15:39:49 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T15:40:12 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T15:40:12 | mmf.trainers.callbacks.logistics: [0mprogress: 6000/22000, val/hateful_memes/cross_entropy: 2.0498, val/total_loss: 2.0498, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4535, val/hateful_memes/roc_auc: 0.6720, num_updates: 6000, epoch: 23, iterations: 6000, max_updates: 22000, val_time: 01m 04s 167ms, best_update: 5000, best_iteration: 5000, best_val/hateful_memes/roc_auc: 0.692465
[32m2021-03-04T15:41:01 | mmf.trainers.callbacks.logistics: [0mprogress: 6100/22000, train/hateful_memes/cross_entropy: 0.0091, train/hateful_memes/cross_entropy/avg: 0.2075, train/total_loss: 0.0091, train/total_loss/avg: 0.2075, max mem: 6431.0, experiment: run, epoch: 23, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 236ms, time_since_start: 01h 05m 26s 170ms, eta: 02h 10m 44s 195ms
[32m2021-03-04T15:42:02 | mmf.trainers.callbacks.logistics: [0mprogress: 6200/22000, train/hateful_memes/cross_entropy: 0.0086, train/hateful_memes/cross_entropy/avg: 0.2042, train/total_loss: 0.0086, train/total_loss/avg: 0.2042, max mem: 6431.0, experiment: run, epoch: 24, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 496ms, time_since_start: 01h 06m 26s 667ms, eta: 02h 39m 37s 607ms
[32m2021-03-04T15:42:52 | mmf.trainers.callbacks.logistics: [0mprogress: 6300/22000, train/hateful_memes/cross_entropy: 0.0086, train/hateful_memes/cross_entropy/avg: 0.2012, train/total_loss: 0.0086, train/total_loss/avg: 0.2012, max mem: 6431.0, experiment: run, epoch: 24, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 822ms, time_since_start: 01h 07m 16s 489ms, eta: 02h 10m 37s 762ms
[32m2021-03-04T15:43:52 | mmf.trainers.callbacks.logistics: [0mprogress: 6400/22000, train/hateful_memes/cross_entropy: 0.0085, train/hateful_memes/cross_entropy/avg: 0.1981, train/total_loss: 0.0085, train/total_loss/avg: 0.1981, max mem: 6431.0, experiment: run, epoch: 25, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 451ms, time_since_start: 01h 08m 16s 941ms, eta: 02h 37m 29s 311ms
[32m2021-03-04T15:44:41 | mmf.trainers.callbacks.logistics: [0mprogress: 6500/22000, train/hateful_memes/cross_entropy: 0.0085, train/hateful_memes/cross_entropy/avg: 0.1953, train/total_loss: 0.0085, train/total_loss/avg: 0.1953, max mem: 6431.0, experiment: run, epoch: 25, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 847ms, time_since_start: 01h 09m 05s 789ms, eta: 02h 06m 26s 490ms
[32m2021-03-04T15:45:30 | mmf.trainers.callbacks.logistics: [0mprogress: 6600/22000, train/hateful_memes/cross_entropy: 0.0072, train/hateful_memes/cross_entropy/avg: 0.1924, train/total_loss: 0.0072, train/total_loss/avg: 0.1924, max mem: 6431.0, experiment: run, epoch: 25, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 007ms, time_since_start: 01h 09m 54s 796ms, eta: 02h 06m 02s 282ms
[32m2021-03-04T15:46:29 | mmf.trainers.callbacks.logistics: [0mprogress: 6700/22000, train/hateful_memes/cross_entropy: 0.0051, train/hateful_memes/cross_entropy/avg: 0.1895, train/total_loss: 0.0051, train/total_loss/avg: 0.1895, max mem: 6431.0, experiment: run, epoch: 26, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 184ms, time_since_start: 01h 10m 53s 981ms, eta: 02h 31m 13s 394ms
[32m2021-03-04T15:47:18 | mmf.trainers.callbacks.logistics: [0mprogress: 6800/22000, train/hateful_memes/cross_entropy: 0.0051, train/hateful_memes/cross_entropy/avg: 0.1869, train/total_loss: 0.0051, train/total_loss/avg: 0.1869, max mem: 6431.0, experiment: run, epoch: 26, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 457ms, time_since_start: 01h 11m 42s 438ms, eta: 02h 03m 212ms
[32m2021-03-04T15:48:06 | mmf.trainers.callbacks.logistics: [0mprogress: 6900/22000, train/hateful_memes/cross_entropy: 0.0051, train/hateful_memes/cross_entropy/avg: 0.1842, train/total_loss: 0.0051, train/total_loss/avg: 0.1842, max mem: 6431.0, experiment: run, epoch: 26, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 575ms, time_since_start: 01h 12m 31s 014ms, eta: 02h 02m 29s 547ms
[32m2021-03-04T15:49:06 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T15:49:06 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T15:49:06 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T15:49:06 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T15:49:11 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T15:49:34 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T15:49:34 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.1817, train/total_loss: 0.0049, train/total_loss/avg: 0.1817, max mem: 6431.0, experiment: run, epoch: 27, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00001, ups: 1.15, time: 01m 27s 817ms, time_since_start: 01h 13m 58s 831ms, eta: 03h 39m 59s 007ms
[32m2021-03-04T15:49:34 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T15:49:53 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T15:49:53 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T15:49:53 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T15:49:53 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T15:50:17 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T15:50:40 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T15:50:40 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, val/hateful_memes/cross_entropy: 2.1644, val/total_loss: 2.1644, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.4818, val/hateful_memes/roc_auc: 0.6909, num_updates: 7000, epoch: 27, iterations: 7000, max_updates: 22000, val_time: 01m 05s 412ms, best_update: 5000, best_iteration: 5000, best_val/hateful_memes/roc_auc: 0.692465
[32m2021-03-04T15:51:29 | mmf.trainers.callbacks.logistics: [0mprogress: 7100/22000, train/hateful_memes/cross_entropy: 0.0028, train/hateful_memes/cross_entropy/avg: 0.1791, train/total_loss: 0.0028, train/total_loss/avg: 0.1791, max mem: 6431.0, experiment: run, epoch: 27, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 083ms, time_since_start: 01h 15m 53s 332ms, eta: 02h 02m 08s 013ms
[32m2021-03-04T15:52:30 | mmf.trainers.callbacks.logistics: [0mprogress: 7200/22000, train/hateful_memes/cross_entropy: 0.0028, train/hateful_memes/cross_entropy/avg: 0.1767, train/total_loss: 0.0028, train/total_loss/avg: 0.1767, max mem: 6431.0, experiment: run, epoch: 28, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 019ms, time_since_start: 01h 16m 54s 352ms, eta: 02h 30m 48s 958ms
[32m2021-03-04T15:53:20 | mmf.trainers.callbacks.logistics: [0mprogress: 7300/22000, train/hateful_memes/cross_entropy: 0.0028, train/hateful_memes/cross_entropy/avg: 0.1763, train/total_loss: 0.0028, train/total_loss/avg: 0.1763, max mem: 6431.0, experiment: run, epoch: 28, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 441ms, time_since_start: 01h 17m 44s 793ms, eta: 02h 03m 49s 780ms
[32m2021-03-04T15:54:11 | mmf.trainers.callbacks.logistics: [0mprogress: 7400/22000, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.1739, train/total_loss: 0.0026, train/total_loss/avg: 0.1739, max mem: 6431.0, experiment: run, epoch: 28, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 518ms, time_since_start: 01h 18m 35s 312ms, eta: 02h 03m 10s 457ms
[32m2021-03-04T15:55:11 | mmf.trainers.callbacks.logistics: [0mprogress: 7500/22000, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.1716, train/total_loss: 0.0026, train/total_loss/avg: 0.1716, max mem: 6431.0, experiment: run, epoch: 29, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 357ms, time_since_start: 01h 19m 35s 670ms, eta: 02h 26m 09s 347ms
[32m2021-03-04T15:56:00 | mmf.trainers.callbacks.logistics: [0mprogress: 7600/22000, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.1694, train/total_loss: 0.0026, train/total_loss/avg: 0.1694, max mem: 6431.0, experiment: run, epoch: 29, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 108ms, time_since_start: 01h 20m 24s 778ms, eta: 01h 58m 05s 713ms
[32m2021-03-04T15:56:50 | mmf.trainers.callbacks.logistics: [0mprogress: 7700/22000, train/hateful_memes/cross_entropy: 0.0028, train/hateful_memes/cross_entropy/avg: 0.1673, train/total_loss: 0.0028, train/total_loss/avg: 0.1673, max mem: 6431.0, experiment: run, epoch: 29, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 677ms, time_since_start: 01h 21m 14s 455ms, eta: 01h 58m 38s 043ms
[32m2021-03-04T15:57:49 | mmf.trainers.callbacks.logistics: [0mprogress: 7800/22000, train/hateful_memes/cross_entropy: 0.0028, train/hateful_memes/cross_entropy/avg: 0.1662, train/total_loss: 0.0028, train/total_loss/avg: 0.1662, max mem: 6431.0, experiment: run, epoch: 30, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00001, ups: 1.72, time: 58s 982ms, time_since_start: 01h 22m 13s 437ms, eta: 02h 19m 52s 242ms
[32m2021-03-04T15:58:37 | mmf.trainers.callbacks.logistics: [0mprogress: 7900/22000, train/hateful_memes/cross_entropy: 0.0045, train/hateful_memes/cross_entropy/avg: 0.1642, train/total_loss: 0.0045, train/total_loss/avg: 0.1642, max mem: 6431.0, experiment: run, epoch: 30, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 543ms, time_since_start: 01h 23m 01s 981ms, eta: 01h 54m 18s 306ms
[32m2021-03-04T15:59:37 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T15:59:37 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T15:59:37 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T15:59:37 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T15:59:42 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T16:00:06 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T16:00:06 | mmf.trainers.callbacks.logistics: [0mprogress: 8000/22000, train/hateful_memes/cross_entropy: 0.0028, train/hateful_memes/cross_entropy/avg: 0.1621, train/total_loss: 0.0028, train/total_loss/avg: 0.1621, max mem: 6431.0, experiment: run, epoch: 31, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00001, ups: 1.14, time: 01m 28s 314ms, time_since_start: 01h 24m 30s 295ms, eta: 03h 26m 28s 713ms
[32m2021-03-04T16:00:06 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T16:00:16 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T16:00:16 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T16:00:17 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T16:00:17 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T16:00:41 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T16:01:03 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T16:01:26 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T16:01:26 | mmf.trainers.callbacks.logistics: [0mprogress: 8000/22000, val/hateful_memes/cross_entropy: 2.0958, val/total_loss: 2.0958, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.5165, val/hateful_memes/roc_auc: 0.6933, num_updates: 8000, epoch: 31, iterations: 8000, max_updates: 22000, val_time: 01m 20s 618ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.693311
[32m2021-03-04T16:02:15 | mmf.trainers.callbacks.logistics: [0mprogress: 8100/22000, train/hateful_memes/cross_entropy: 0.0028, train/hateful_memes/cross_entropy/avg: 0.1604, train/total_loss: 0.0028, train/total_loss/avg: 0.1604, max mem: 6431.0, experiment: run, epoch: 31, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 759ms, time_since_start: 01h 26m 39s 678ms, eta: 01h 53m 11s 097ms
[32m2021-03-04T16:03:04 | mmf.trainers.callbacks.logistics: [0mprogress: 8200/22000, train/hateful_memes/cross_entropy: 0.0028, train/hateful_memes/cross_entropy/avg: 0.1585, train/total_loss: 0.0028, train/total_loss/avg: 0.1585, max mem: 6431.0, experiment: run, epoch: 31, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 844ms, time_since_start: 01h 27m 28s 522ms, eta: 01h 52m 33s 959ms
[32m2021-03-04T16:04:04 | mmf.trainers.callbacks.logistics: [0mprogress: 8300/22000, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.1566, train/total_loss: 0.0026, train/total_loss/avg: 0.1566, max mem: 6431.0, experiment: run, epoch: 32, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 981ms, time_since_start: 01h 28m 28s 504ms, eta: 02h 17m 13s 955ms
[32m2021-03-04T16:04:52 | mmf.trainers.callbacks.logistics: [0mprogress: 8400/22000, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.1547, train/total_loss: 0.0026, train/total_loss/avg: 0.1547, max mem: 6431.0, experiment: run, epoch: 32, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 661ms, time_since_start: 01h 29m 17s 166ms, eta: 01h 50m 31s 250ms
[32m2021-03-04T16:05:41 | mmf.trainers.callbacks.logistics: [0mprogress: 8500/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1529, train/total_loss: 0.0023, train/total_loss/avg: 0.1529, max mem: 6431.0, experiment: run, epoch: 32, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 869ms, time_since_start: 01h 30m 06s 035ms, eta: 01h 50m 10s 557ms
[32m2021-03-04T16:06:40 | mmf.trainers.callbacks.logistics: [0mprogress: 8600/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1512, train/total_loss: 0.0023, train/total_loss/avg: 0.1512, max mem: 6431.0, experiment: run, epoch: 33, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00001, ups: 1.72, time: 58s 665ms, time_since_start: 01h 31m 04s 700ms, eta: 02h 11m 16s 847ms
[32m2021-03-04T16:07:28 | mmf.trainers.callbacks.logistics: [0mprogress: 8700/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1494, train/total_loss: 0.0023, train/total_loss/avg: 0.1494, max mem: 6431.0, experiment: run, epoch: 33, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 082ms, time_since_start: 01h 31m 52s 783ms, eta: 01h 46m 47s 820ms
[32m2021-03-04T16:08:27 | mmf.trainers.callbacks.logistics: [0mprogress: 8800/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1477, train/total_loss: 0.0023, train/total_loss/avg: 0.1477, max mem: 6431.0, experiment: run, epoch: 34, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00001, ups: 1.72, time: 58s 781ms, time_since_start: 01h 32m 51s 565ms, eta: 02h 09m 34s 714ms
[32m2021-03-04T16:09:15 | mmf.trainers.callbacks.logistics: [0mprogress: 8900/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1461, train/total_loss: 0.0023, train/total_loss/avg: 0.1461, max mem: 6431.0, experiment: run, epoch: 34, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 267ms, time_since_start: 01h 33m 39s 832ms, eta: 01h 45m 35s 657ms
[32m2021-03-04T16:10:04 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T16:10:04 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T16:10:04 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T16:10:04 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T16:10:09 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T16:10:48 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T16:10:48 | mmf.trainers.callbacks.logistics: [0mprogress: 9000/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1445, train/total_loss: 0.0020, train/total_loss/avg: 0.1445, max mem: 6431.0, experiment: run, epoch: 34, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00001, ups: 1.09, time: 01m 32s 993ms, time_since_start: 01h 35m 12s 825ms, eta: 03h 21m 53s 299ms
[32m2021-03-04T16:10:48 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T16:11:06 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T16:11:06 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T16:11:06 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T16:11:06 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T16:11:29 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T16:11:52 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T16:11:52 | mmf.trainers.callbacks.logistics: [0mprogress: 9000/22000, val/hateful_memes/cross_entropy: 2.4609, val/total_loss: 2.4609, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4367, val/hateful_memes/roc_auc: 0.6848, num_updates: 9000, epoch: 34, iterations: 9000, max_updates: 22000, val_time: 01m 03s 943ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.693311
[32m2021-03-04T16:12:53 | mmf.trainers.callbacks.logistics: [0mprogress: 9100/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1429, train/total_loss: 0.0013, train/total_loss/avg: 0.1429, max mem: 6431.0, experiment: run, epoch: 35, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 594ms, time_since_start: 01h 37m 17s 380ms, eta: 02h 10m 32s 337ms
[32m2021-03-04T16:13:43 | mmf.trainers.callbacks.logistics: [0mprogress: 9200/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1414, train/total_loss: 0.0014, train/total_loss/avg: 0.1414, max mem: 6431.0, experiment: run, epoch: 35, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 403ms, time_since_start: 01h 38m 07s 783ms, eta: 01h 47m 44s 518ms
[32m2021-03-04T16:14:34 | mmf.trainers.callbacks.logistics: [0mprogress: 9300/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.1398, train/total_loss: 0.0011, train/total_loss/avg: 0.1398, max mem: 6431.0, experiment: run, epoch: 35, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 508ms, time_since_start: 01h 38m 58s 292ms, eta: 01h 47m 07s 365ms
[32m2021-03-04T16:15:33 | mmf.trainers.callbacks.logistics: [0mprogress: 9400/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1384, train/total_loss: 0.0010, train/total_loss/avg: 0.1384, max mem: 6431.0, experiment: run, epoch: 36, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 208ms, time_since_start: 01h 39m 57s 500ms, eta: 02h 04m 35s 210ms
[32m2021-03-04T16:16:22 | mmf.trainers.callbacks.logistics: [0mprogress: 9500/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1369, train/total_loss: 0.0010, train/total_loss/avg: 0.1369, max mem: 6431.0, experiment: run, epoch: 36, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 867ms, time_since_start: 01h 40m 46s 367ms, eta: 01h 42m 608ms
[32m2021-03-04T16:17:21 | mmf.trainers.callbacks.logistics: [0mprogress: 9600/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1355, train/total_loss: 0.0010, train/total_loss/avg: 0.1355, max mem: 6431.0, experiment: run, epoch: 37, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 177ms, time_since_start: 01h 41m 45s 545ms, eta: 02h 02m 32s 738ms
[32m2021-03-04T16:18:09 | mmf.trainers.callbacks.logistics: [0mprogress: 9700/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1342, train/total_loss: 0.0010, train/total_loss/avg: 0.1342, max mem: 6431.0, experiment: run, epoch: 37, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00001, ups: 2.13, time: 47s 910ms, time_since_start: 01h 42m 33s 456ms, eta: 01h 38m 24s 789ms
[32m2021-03-04T16:18:57 | mmf.trainers.callbacks.logistics: [0mprogress: 9800/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1328, train/total_loss: 0.0009, train/total_loss/avg: 0.1328, max mem: 6431.0, experiment: run, epoch: 37, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00001, ups: 2.08, time: 48s 088ms, time_since_start: 01h 43m 21s 544ms, eta: 01h 37m 58s 484ms
[32m2021-03-04T16:19:56 | mmf.trainers.callbacks.logistics: [0mprogress: 9900/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1315, train/total_loss: 0.0009, train/total_loss/avg: 0.1315, max mem: 6431.0, experiment: run, epoch: 38, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 229ms, time_since_start: 01h 44m 20s 773ms, eta: 01h 59m 41s 082ms
[32m2021-03-04T16:20:46 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T16:20:46 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T16:20:46 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T16:20:46 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T16:20:51 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T16:21:25 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T16:21:25 | mmf.trainers.callbacks.logistics: [0mprogress: 10000/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1302, train/total_loss: 0.0010, train/total_loss/avg: 0.1302, max mem: 6431.0, experiment: run, epoch: 38, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00001, ups: 1.14, time: 01m 28s 635ms, time_since_start: 01h 45m 49s 409ms, eta: 02h 57m 37s 504ms
[32m2021-03-04T16:21:25 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T16:21:43 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T16:21:43 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T16:21:43 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T16:21:43 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T16:22:06 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T16:22:29 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T16:22:29 | mmf.trainers.callbacks.logistics: [0mprogress: 10000/22000, val/hateful_memes/cross_entropy: 2.2666, val/total_loss: 2.2666, val/hateful_memes/accuracy: 0.6704, val/hateful_memes/binary_f1: 0.4242, val/hateful_memes/roc_auc: 0.6738, num_updates: 10000, epoch: 38, iterations: 10000, max_updates: 22000, val_time: 01m 04s 702ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.693311
[32m2021-03-04T16:23:19 | mmf.trainers.callbacks.logistics: [0mprogress: 10100/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1290, train/total_loss: 0.0010, train/total_loss/avg: 0.1290, max mem: 6431.0, experiment: run, epoch: 38, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 401ms, time_since_start: 01h 47m 43s 530ms, eta: 01h 38m 10s 551ms
[32m2021-03-04T16:24:20 | mmf.trainers.callbacks.logistics: [0mprogress: 10200/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1285, train/total_loss: 0.0010, train/total_loss/avg: 0.1285, max mem: 6431.0, experiment: run, epoch: 39, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 346ms, time_since_start: 01h 48m 44s 876ms, eta: 02h 53s 309ms
[32m2021-03-04T16:25:11 | mmf.trainers.callbacks.logistics: [0mprogress: 10300/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1272, train/total_loss: 0.0010, train/total_loss/avg: 0.1272, max mem: 6431.0, experiment: run, epoch: 39, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 426ms, time_since_start: 01h 49m 35s 302ms, eta: 01h 38m 31s 676ms
[32m2021-03-04T16:26:11 | mmf.trainers.callbacks.logistics: [0mprogress: 10400/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1260, train/total_loss: 0.0010, train/total_loss/avg: 0.1260, max mem: 6431.0, experiment: run, epoch: 40, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 598ms, time_since_start: 01h 50m 35s 900ms, eta: 01h 57m 23s 433ms
[32m2021-03-04T16:27:01 | mmf.trainers.callbacks.logistics: [0mprogress: 10500/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1248, train/total_loss: 0.0010, train/total_loss/avg: 0.1248, max mem: 6431.0, experiment: run, epoch: 40, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 388ms, time_since_start: 01h 51m 25s 289ms, eta: 01h 34m 51s 091ms
[32m2021-03-04T16:27:50 | mmf.trainers.callbacks.logistics: [0mprogress: 10600/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1237, train/total_loss: 0.0010, train/total_loss/avg: 0.1237, max mem: 6431.0, experiment: run, epoch: 40, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 498ms, time_since_start: 01h 52m 14s 788ms, eta: 01h 34m 14s 126ms
[32m2021-03-04T16:28:50 | mmf.trainers.callbacks.logistics: [0mprogress: 10700/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1225, train/total_loss: 0.0010, train/total_loss/avg: 0.1225, max mem: 6431.0, experiment: run, epoch: 41, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 837ms, time_since_start: 01h 53m 14s 626ms, eta: 01h 52m 55s 212ms
[32m2021-03-04T16:29:40 | mmf.trainers.callbacks.logistics: [0mprogress: 10800/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1214, train/total_loss: 0.0010, train/total_loss/avg: 0.1214, max mem: 6431.0, experiment: run, epoch: 41, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 639ms, time_since_start: 01h 54m 04s 266ms, eta: 01h 32m 50s 799ms
[32m2021-03-04T16:30:29 | mmf.trainers.callbacks.logistics: [0mprogress: 10900/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.1203, train/total_loss: 0.0011, train/total_loss/avg: 0.1203, max mem: 6431.0, experiment: run, epoch: 41, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 750ms, time_since_start: 01h 54m 54s 016ms, eta: 01h 32m 13s 321ms
[32m2021-03-04T16:31:29 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T16:31:29 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T16:31:29 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T16:31:29 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T16:31:35 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T16:31:58 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T16:31:58 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.1192, train/total_loss: 0.0011, train/total_loss/avg: 0.1192, max mem: 6431.0, experiment: run, epoch: 42, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00001, ups: 1.14, time: 01m 28s 750ms, time_since_start: 01h 56m 22s 767ms, eta: 02h 43m 02s 076ms
[32m2021-03-04T16:31:58 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T16:32:10 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T16:32:10 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T16:32:10 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T16:32:10 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T16:32:34 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T16:32:57 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T16:32:57 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, val/hateful_memes/cross_entropy: 2.2730, val/total_loss: 2.2730, val/hateful_memes/accuracy: 0.6889, val/hateful_memes/binary_f1: 0.5127, val/hateful_memes/roc_auc: 0.6871, num_updates: 11000, epoch: 42, iterations: 11000, max_updates: 22000, val_time: 58s 787ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.693311
[32m2021-03-04T16:33:47 | mmf.trainers.callbacks.logistics: [0mprogress: 11100/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.1182, train/total_loss: 0.0011, train/total_loss/avg: 0.1182, max mem: 6431.0, experiment: run, epoch: 42, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 025ms, time_since_start: 01h 58m 11s 585ms, eta: 01h 31m 03s 646ms
[32m2021-03-04T16:34:47 | mmf.trainers.callbacks.logistics: [0mprogress: 11200/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1171, train/total_loss: 0.0010, train/total_loss/avg: 0.1171, max mem: 6431.0, experiment: run, epoch: 43, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 630ms, time_since_start: 01h 59m 12s 216ms, eta: 01h 49m 21s 216ms
[32m2021-03-04T16:35:37 | mmf.trainers.callbacks.logistics: [0mprogress: 11300/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1161, train/total_loss: 0.0010, train/total_loss/avg: 0.1161, max mem: 6431.0, experiment: run, epoch: 43, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 701ms, time_since_start: 02h 01s 918ms, eta: 01h 28m 48s 724ms
[32m2021-03-04T16:36:27 | mmf.trainers.callbacks.logistics: [0mprogress: 11400/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.1151, train/total_loss: 0.0011, train/total_loss/avg: 0.1151, max mem: 6431.0, experiment: run, epoch: 43, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 848ms, time_since_start: 02h 51s 766ms, eta: 01h 28m 14s 510ms
[32m2021-03-04T16:37:27 | mmf.trainers.callbacks.logistics: [0mprogress: 11500/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1141, train/total_loss: 0.0010, train/total_loss/avg: 0.1141, max mem: 6431.0, experiment: run, epoch: 44, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 989ms, time_since_start: 02h 01m 51s 756ms, eta: 01h 45m 11s 502ms
[32m2021-03-04T16:38:16 | mmf.trainers.callbacks.logistics: [0mprogress: 11600/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1131, train/total_loss: 0.0010, train/total_loss/avg: 0.1131, max mem: 6431.0, experiment: run, epoch: 44, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 242ms, time_since_start: 02h 02m 40s 999ms, eta: 01h 25m 31s 493ms
[32m2021-03-04T16:39:06 | mmf.trainers.callbacks.logistics: [0mprogress: 11700/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.1122, train/total_loss: 0.0008, train/total_loss/avg: 0.1122, max mem: 6431.0, experiment: run, epoch: 44, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 220ms, time_since_start: 02h 03m 30s 220ms, eta: 01h 24m 39s 899ms
[32m2021-03-04T16:40:05 | mmf.trainers.callbacks.logistics: [0mprogress: 11800/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.1112, train/total_loss: 0.0008, train/total_loss/avg: 0.1112, max mem: 6431.0, experiment: run, epoch: 45, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 619ms, time_since_start: 02h 04m 29s 839ms, eta: 01h 41m 33s 307ms
[32m2021-03-04T16:40:54 | mmf.trainers.callbacks.logistics: [0mprogress: 11900/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1103, train/total_loss: 0.0006, train/total_loss/avg: 0.1103, max mem: 6431.0, experiment: run, epoch: 45, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 243ms, time_since_start: 02h 05m 19s 082ms, eta: 01h 23m 03s 566ms
[32m2021-03-04T16:41:54 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T16:41:54 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T16:41:54 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T16:41:54 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T16:41:59 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T16:42:22 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T16:42:22 | mmf.trainers.callbacks.logistics: [0mprogress: 12000/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1094, train/total_loss: 0.0006, train/total_loss/avg: 0.1094, max mem: 6431.0, experiment: run, epoch: 46, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00001, ups: 1.15, time: 01m 27s 797ms, time_since_start: 02h 06m 46s 880ms, eta: 02h 26m 37s 344ms
[32m2021-03-04T16:42:22 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T16:42:33 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T16:42:33 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T16:42:33 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T16:42:33 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T16:42:57 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T16:43:20 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T16:43:20 | mmf.trainers.callbacks.logistics: [0mprogress: 12000/22000, val/hateful_memes/cross_entropy: 2.4744, val/total_loss: 2.4744, val/hateful_memes/accuracy: 0.6796, val/hateful_memes/binary_f1: 0.4749, val/hateful_memes/roc_auc: 0.6854, num_updates: 12000, epoch: 46, iterations: 12000, max_updates: 22000, val_time: 57s 973ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.693311
[32m2021-03-04T16:44:10 | mmf.trainers.callbacks.logistics: [0mprogress: 12100/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1085, train/total_loss: 0.0006, train/total_loss/avg: 0.1085, max mem: 6431.0, experiment: run, epoch: 46, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 706ms, time_since_start: 02h 08m 34s 568ms, eta: 01h 22m 10s 765ms
[32m2021-03-04T16:45:00 | mmf.trainers.callbacks.logistics: [0mprogress: 12200/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1079, train/total_loss: 0.0006, train/total_loss/avg: 0.1079, max mem: 6431.0, experiment: run, epoch: 46, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 654ms, time_since_start: 02h 09m 24s 223ms, eta: 01h 21m 15s 912ms
[32m2021-03-04T16:46:00 | mmf.trainers.callbacks.logistics: [0mprogress: 12300/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1070, train/total_loss: 0.0006, train/total_loss/avg: 0.1070, max mem: 6431.0, experiment: run, epoch: 47, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 617ms, time_since_start: 02h 10m 24s 840ms, eta: 01h 38m 11s 613ms
[32m2021-03-04T16:46:50 | mmf.trainers.callbacks.logistics: [0mprogress: 12400/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1061, train/total_loss: 0.0006, train/total_loss/avg: 0.1061, max mem: 6431.0, experiment: run, epoch: 47, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 641ms, time_since_start: 02h 11m 14s 482ms, eta: 01h 19m 35s 085ms
[32m2021-03-04T16:47:39 | mmf.trainers.callbacks.logistics: [0mprogress: 12500/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1053, train/total_loss: 0.0006, train/total_loss/avg: 0.1053, max mem: 6431.0, experiment: run, epoch: 47, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 652ms, time_since_start: 02h 12m 04s 134ms, eta: 01h 18m 46s 407ms
[32m2021-03-04T16:48:38 | mmf.trainers.callbacks.logistics: [0mprogress: 12600/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1049, train/total_loss: 0.0006, train/total_loss/avg: 0.1049, max mem: 6431.0, experiment: run, epoch: 48, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0., ups: 1.72, time: 58s 789ms, time_since_start: 02h 13m 02s 923ms, eta: 01h 32m 17s 251ms
[32m2021-03-04T16:49:27 | mmf.trainers.callbacks.logistics: [0mprogress: 12700/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.1041, train/total_loss: 0.0005, train/total_loss/avg: 0.1041, max mem: 6431.0, experiment: run, epoch: 48, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 328ms, time_since_start: 02h 13m 51s 252ms, eta: 01h 15m 03s 531ms
[32m2021-03-04T16:50:26 | mmf.trainers.callbacks.logistics: [0mprogress: 12800/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.1033, train/total_loss: 0.0005, train/total_loss/avg: 0.1033, max mem: 6431.0, experiment: run, epoch: 49, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 416ms, time_since_start: 02h 14m 50s 668ms, eta: 01h 31m 17s 244ms
[32m2021-03-04T16:51:15 | mmf.trainers.callbacks.logistics: [0mprogress: 12900/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.1025, train/total_loss: 0.0003, train/total_loss/avg: 0.1025, max mem: 6431.0, experiment: run, epoch: 49, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 283ms, time_since_start: 02h 15m 39s 952ms, eta: 01h 14m 53s 810ms
[32m2021-03-04T16:52:05 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T16:52:05 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T16:52:05 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T16:52:05 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T16:52:10 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T16:52:33 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T16:52:33 | mmf.trainers.callbacks.logistics: [0mprogress: 13000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.1017, train/total_loss: 0.0002, train/total_loss/avg: 0.1017, max mem: 6431.0, experiment: run, epoch: 49, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0., ups: 1.30, time: 01m 17s 532ms, time_since_start: 02h 16m 57s 484ms, eta: 01h 56m 31s 861ms
[32m2021-03-04T16:52:33 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T16:52:44 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T16:52:44 | mmf.trainers.callbacks.logistics: [0mprogress: 13000/22000, val/hateful_memes/cross_entropy: 2.4522, val/total_loss: 2.4522, val/hateful_memes/accuracy: 0.6926, val/hateful_memes/binary_f1: 0.4728, val/hateful_memes/roc_auc: 0.6892, num_updates: 13000, epoch: 49, iterations: 13000, max_updates: 22000, val_time: 10s 840ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.693311
[32m2021-03-04T16:53:44 | mmf.trainers.callbacks.logistics: [0mprogress: 13100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.1009, train/total_loss: 0.0002, train/total_loss/avg: 0.1009, max mem: 6431.0, experiment: run, epoch: 50, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 001ms, time_since_start: 02h 18m 08s 338ms, eta: 01h 29m 10s 846ms
[32m2021-03-04T16:54:32 | mmf.trainers.callbacks.logistics: [0mprogress: 13200/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.1001, train/total_loss: 0.0002, train/total_loss/avg: 0.1001, max mem: 6431.0, experiment: run, epoch: 50, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 263ms, time_since_start: 02h 18m 56s 601ms, eta: 01h 10m 55s 689ms
[32m2021-03-04T16:55:20 | mmf.trainers.callbacks.logistics: [0mprogress: 13300/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0997, train/total_loss: 0.0002, train/total_loss/avg: 0.0997, max mem: 6431.0, experiment: run, epoch: 50, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 079ms, time_since_start: 02h 19m 44s 681ms, eta: 01h 09m 51s 283ms
[32m2021-03-04T16:56:20 | mmf.trainers.callbacks.logistics: [0mprogress: 13400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0989, train/total_loss: 0.0001, train/total_loss/avg: 0.0989, max mem: 6431.0, experiment: run, epoch: 51, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 039ms, time_since_start: 02h 20m 44s 720ms, eta: 01h 26m 13s 724ms
[32m2021-03-04T16:57:09 | mmf.trainers.callbacks.logistics: [0mprogress: 13500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0982, train/total_loss: 0.0001, train/total_loss/avg: 0.0982, max mem: 6431.0, experiment: run, epoch: 51, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 038ms, time_since_start: 02h 21m 33s 759ms, eta: 01h 09m 36s 620ms
[32m2021-03-04T16:58:09 | mmf.trainers.callbacks.logistics: [0mprogress: 13600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0975, train/total_loss: 0.0001, train/total_loss/avg: 0.0975, max mem: 6431.0, experiment: run, epoch: 52, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 909ms, time_since_start: 02h 22m 33s 668ms, eta: 01h 24m 02s 449ms
[32m2021-03-04T16:58:58 | mmf.trainers.callbacks.logistics: [0mprogress: 13700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0967, train/total_loss: 0.0001, train/total_loss/avg: 0.0967, max mem: 6431.0, experiment: run, epoch: 52, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 231ms, time_since_start: 02h 23m 22s 899ms, eta: 01h 08m 14s 347ms
[32m2021-03-04T16:59:48 | mmf.trainers.callbacks.logistics: [0mprogress: 13800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0960, train/total_loss: 0.0001, train/total_loss/avg: 0.0960, max mem: 6431.0, experiment: run, epoch: 52, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 467ms, time_since_start: 02h 24m 12s 366ms, eta: 01h 07m 44s 414ms
[32m2021-03-04T17:00:48 | mmf.trainers.callbacks.logistics: [0mprogress: 13900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0954, train/total_loss: 0.0001, train/total_loss/avg: 0.0954, max mem: 6431.0, experiment: run, epoch: 53, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 884ms, time_since_start: 02h 25m 12s 251ms, eta: 01h 21m 325ms
[32m2021-03-04T17:01:37 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T17:01:37 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T17:01:37 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T17:01:37 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T17:01:42 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T17:02:06 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T17:02:06 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0947, train/total_loss: 0.0001, train/total_loss/avg: 0.0947, max mem: 6431.0, experiment: run, epoch: 53, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0., ups: 1.28, time: 01m 18s 511ms, time_since_start: 02h 26m 30s 762ms, eta: 01h 44m 53s 508ms
[32m2021-03-04T17:02:06 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T17:02:19 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T17:02:19 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T17:02:19 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T17:02:19 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T17:02:43 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T17:03:06 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T17:03:29 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T17:03:29 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, val/hateful_memes/cross_entropy: 2.5404, val/total_loss: 2.5404, val/hateful_memes/accuracy: 0.6963, val/hateful_memes/binary_f1: 0.5161, val/hateful_memes/roc_auc: 0.6934, num_updates: 14000, epoch: 53, iterations: 14000, max_updates: 22000, val_time: 01m 22s 749ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.693353
[32m2021-03-04T17:04:29 | mmf.trainers.callbacks.logistics: [0mprogress: 14100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0940, train/total_loss: 0.0001, train/total_loss/avg: 0.0940, max mem: 6431.0, experiment: run, epoch: 54, num_updates: 14100, iterations: 14100, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 499ms, time_since_start: 02h 28m 54s 017ms, eta: 01h 19m 49s 041ms
[32m2021-03-04T17:05:19 | mmf.trainers.callbacks.logistics: [0mprogress: 14200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0934, train/total_loss: 0.0001, train/total_loss/avg: 0.0934, max mem: 6431.0, experiment: run, epoch: 54, num_updates: 14200, iterations: 14200, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 942ms, time_since_start: 02h 29m 43s 959ms, eta: 01h 05m 03s 289ms
[32m2021-03-04T17:06:09 | mmf.trainers.callbacks.logistics: [0mprogress: 14300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0927, train/total_loss: 0.0001, train/total_loss/avg: 0.0927, max mem: 6431.0, experiment: run, epoch: 54, num_updates: 14300, iterations: 14300, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 147ms, time_since_start: 02h 30m 34s 106ms, eta: 01h 04m 29s 051ms
[32m2021-03-04T17:07:10 | mmf.trainers.callbacks.logistics: [0mprogress: 14400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0921, train/total_loss: 0.0001, train/total_loss/avg: 0.0921, max mem: 6431.0, experiment: run, epoch: 55, num_updates: 14400, iterations: 14400, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 468ms, time_since_start: 02h 31m 34s 575ms, eta: 01h 16m 44s 776ms
[32m2021-03-04T17:07:59 | mmf.trainers.callbacks.logistics: [0mprogress: 14500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0915, train/total_loss: 0.0001, train/total_loss/avg: 0.0915, max mem: 6431.0, experiment: run, epoch: 55, num_updates: 14500, iterations: 14500, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 637ms, time_since_start: 02h 32m 24s 213ms, eta: 01h 02m 10s 285ms
[32m2021-03-04T17:08:49 | mmf.trainers.callbacks.logistics: [0mprogress: 14600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0909, train/total_loss: 0.0001, train/total_loss/avg: 0.0909, max mem: 6431.0, experiment: run, epoch: 55, num_updates: 14600, iterations: 14600, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 657ms, time_since_start: 02h 33m 13s 871ms, eta: 01h 01m 22s 038ms
[32m2021-03-04T17:09:48 | mmf.trainers.callbacks.logistics: [0mprogress: 14700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0903, train/total_loss: 0.0001, train/total_loss/avg: 0.0903, max mem: 6431.0, experiment: run, epoch: 56, num_updates: 14700, iterations: 14700, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 194ms, time_since_start: 02h 34m 13s 065ms, eta: 01h 12m 09s 824ms
[32m2021-03-04T17:10:37 | mmf.trainers.callbacks.logistics: [0mprogress: 14800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0897, train/total_loss: 0.0001, train/total_loss/avg: 0.0897, max mem: 6431.0, experiment: run, epoch: 56, num_updates: 14800, iterations: 14800, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 251ms, time_since_start: 02h 35m 01s 316ms, eta: 58m 01s 042ms
[32m2021-03-04T17:11:35 | mmf.trainers.callbacks.logistics: [0mprogress: 14900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0891, train/total_loss: 0.0001, train/total_loss/avg: 0.0891, max mem: 6431.0, experiment: run, epoch: 57, num_updates: 14900, iterations: 14900, max_updates: 22000, lr: 0., ups: 1.72, time: 58s 734ms, time_since_start: 02h 36m 050ms, eta: 01h 09m 38s 469ms
[32m2021-03-04T17:12:24 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T17:12:24 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T17:12:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T17:12:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T17:12:30 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T17:13:10 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T17:13:10 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0885, train/total_loss: 0.0001, train/total_loss/avg: 0.0885, max mem: 6431.0, experiment: run, epoch: 57, num_updates: 15000, iterations: 15000, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 332ms, time_since_start: 02h 37m 34s 383ms, eta: 01h 50m 16s 457ms
[32m2021-03-04T17:13:10 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T17:13:23 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T17:13:23 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T17:13:23 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T17:13:23 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T17:13:46 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T17:14:09 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T17:14:09 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, val/hateful_memes/cross_entropy: 2.7830, val/total_loss: 2.7830, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4678, val/hateful_memes/roc_auc: 0.6817, num_updates: 15000, epoch: 57, iterations: 15000, max_updates: 22000, val_time: 59s 193ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.693353
[32m2021-03-04T17:14:58 | mmf.trainers.callbacks.logistics: [0mprogress: 15100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0879, train/total_loss: 0.0001, train/total_loss/avg: 0.0879, max mem: 6431.0, experiment: run, epoch: 57, num_updates: 15100, iterations: 15100, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 286ms, time_since_start: 02h 39m 22s 879ms, eta: 56m 47s 598ms
[32m2021-03-04T17:15:58 | mmf.trainers.callbacks.logistics: [0mprogress: 15200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0873, train/total_loss: 0.0001, train/total_loss/avg: 0.0873, max mem: 6431.0, experiment: run, epoch: 58, num_updates: 15200, iterations: 15200, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 743ms, time_since_start: 02h 40m 22s 622ms, eta: 01h 07m 50s 662ms
[32m2021-03-04T17:16:47 | mmf.trainers.callbacks.logistics: [0mprogress: 15300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0867, train/total_loss: 0.0001, train/total_loss/avg: 0.0867, max mem: 6431.0, experiment: run, epoch: 58, num_updates: 15300, iterations: 15300, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 004ms, time_since_start: 02h 41m 11s 627ms, eta: 54m 49s 850ms
[32m2021-03-04T17:17:36 | mmf.trainers.callbacks.logistics: [0mprogress: 15400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0862, train/total_loss: 0.0001, train/total_loss/avg: 0.0862, max mem: 6431.0, experiment: run, epoch: 58, num_updates: 15400, iterations: 15400, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 024ms, time_since_start: 02h 42m 651ms, eta: 54m 02s 061ms
[32m2021-03-04T17:18:35 | mmf.trainers.callbacks.logistics: [0mprogress: 15500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0856, train/total_loss: 0.0001, train/total_loss/avg: 0.0856, max mem: 6431.0, experiment: run, epoch: 59, num_updates: 15500, iterations: 15500, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 520ms, time_since_start: 02h 43m 171ms, eta: 01h 04m 36s 555ms
[32m2021-03-04T17:19:25 | mmf.trainers.callbacks.logistics: [0mprogress: 15600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0851, train/total_loss: 0.0001, train/total_loss/avg: 0.0851, max mem: 6431.0, experiment: run, epoch: 59, num_updates: 15600, iterations: 15600, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 066ms, time_since_start: 02h 43m 49s 238ms, eta: 52m 26s 555ms
[32m2021-03-04T17:20:24 | mmf.trainers.callbacks.logistics: [0mprogress: 15700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0845, train/total_loss: 0.0001, train/total_loss/avg: 0.0845, max mem: 6431.0, experiment: run, epoch: 60, num_updates: 15700, iterations: 15700, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 684ms, time_since_start: 02h 44m 48s 922ms, eta: 01h 02m 47s 628ms
[32m2021-03-04T17:21:13 | mmf.trainers.callbacks.logistics: [0mprogress: 15800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0840, train/total_loss: 0.0001, train/total_loss/avg: 0.0840, max mem: 6431.0, experiment: run, epoch: 60, num_updates: 15800, iterations: 15800, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 587ms, time_since_start: 02h 45m 37s 509ms, eta: 50m 18s 423ms
[32m2021-03-04T17:22:01 | mmf.trainers.callbacks.logistics: [0mprogress: 15900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0835, train/total_loss: 0.0001, train/total_loss/avg: 0.0835, max mem: 6431.0, experiment: run, epoch: 60, num_updates: 15900, iterations: 15900, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 622ms, time_since_start: 02h 46m 26s 132ms, eta: 49m 31s 911ms
[32m2021-03-04T17:23:00 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T17:23:00 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T17:23:00 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T17:23:00 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T17:23:05 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T17:23:29 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T17:23:29 | mmf.trainers.callbacks.logistics: [0mprogress: 16000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0830, train/total_loss: 0.0001, train/total_loss/avg: 0.0830, max mem: 6431.0, experiment: run, epoch: 61, num_updates: 16000, iterations: 16000, max_updates: 22000, lr: 0., ups: 1.15, time: 01m 27s 151ms, time_since_start: 02h 47m 53s 283ms, eta: 01h 27m 19s 539ms
[32m2021-03-04T17:23:29 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T17:23:45 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T17:23:45 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T17:23:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T17:23:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T17:24:09 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T17:24:32 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T17:24:32 | mmf.trainers.callbacks.logistics: [0mprogress: 16000/22000, val/hateful_memes/cross_entropy: 2.6682, val/total_loss: 2.6682, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.4553, val/hateful_memes/roc_auc: 0.6891, num_updates: 16000, epoch: 61, iterations: 16000, max_updates: 22000, val_time: 01m 03s 314ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.693353
[32m2021-03-04T17:25:20 | mmf.trainers.callbacks.logistics: [0mprogress: 16100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0824, train/total_loss: 0.0001, train/total_loss/avg: 0.0824, max mem: 6431.0, experiment: run, epoch: 61, num_updates: 16100, iterations: 16100, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 272ms, time_since_start: 02h 49m 44s 879ms, eta: 47m 33s 759ms
[32m2021-03-04T17:26:08 | mmf.trainers.callbacks.logistics: [0mprogress: 16200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0819, train/total_loss: 0.0001, train/total_loss/avg: 0.0819, max mem: 6431.0, experiment: run, epoch: 61, num_updates: 16200, iterations: 16200, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 130ms, time_since_start: 02h 50m 33s 010ms, eta: 46m 37s 166ms
[32m2021-03-04T17:27:09 | mmf.trainers.callbacks.logistics: [0mprogress: 16300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0814, train/total_loss: 0.0001, train/total_loss/avg: 0.0814, max mem: 6431.0, experiment: run, epoch: 62, num_updates: 16300, iterations: 16300, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 113ms, time_since_start: 02h 51m 34s 124ms, eta: 58m 10s 441ms
[32m2021-03-04T17:27:59 | mmf.trainers.callbacks.logistics: [0mprogress: 16400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0811, train/total_loss: 0.0001, train/total_loss/avg: 0.0811, max mem: 6431.0, experiment: run, epoch: 62, num_updates: 16400, iterations: 16400, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 714ms, time_since_start: 02h 52m 23s 838ms, eta: 46m 29s 598ms
[32m2021-03-04T17:28:59 | mmf.trainers.callbacks.logistics: [0mprogress: 16500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0806, train/total_loss: 0.0001, train/total_loss/avg: 0.0806, max mem: 6431.0, experiment: run, epoch: 63, num_updates: 16500, iterations: 16500, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 213ms, time_since_start: 02h 53m 24s 052ms, eta: 55m 18s 358ms
[32m2021-03-04T17:29:48 | mmf.trainers.callbacks.logistics: [0mprogress: 16600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0801, train/total_loss: 0.0001, train/total_loss/avg: 0.0801, max mem: 6431.0, experiment: run, epoch: 63, num_updates: 16600, iterations: 16600, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 805ms, time_since_start: 02h 54m 12s 857ms, eta: 44m 761ms
[32m2021-03-04T17:30:37 | mmf.trainers.callbacks.logistics: [0mprogress: 16700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0797, train/total_loss: 0.0001, train/total_loss/avg: 0.0797, max mem: 6431.0, experiment: run, epoch: 63, num_updates: 16700, iterations: 16700, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 773ms, time_since_start: 02h 55m 01s 631ms, eta: 43m 10s 190ms
[32m2021-03-04T17:31:36 | mmf.trainers.callbacks.logistics: [0mprogress: 16800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0792, train/total_loss: 0.0001, train/total_loss/avg: 0.0792, max mem: 6431.0, experiment: run, epoch: 64, num_updates: 16800, iterations: 16800, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 319ms, time_since_start: 02h 56m 951ms, eta: 51m 30s 809ms
[32m2021-03-04T17:32:25 | mmf.trainers.callbacks.logistics: [0mprogress: 16900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0787, train/total_loss: 0.0001, train/total_loss/avg: 0.0787, max mem: 6431.0, experiment: run, epoch: 64, num_updates: 16900, iterations: 16900, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 546ms, time_since_start: 02h 56m 49s 497ms, eta: 41m 20s 803ms
[32m2021-03-04T17:33:14 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T17:33:14 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T17:33:14 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T17:33:14 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T17:33:19 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T17:33:42 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T17:33:42 | mmf.trainers.callbacks.logistics: [0mprogress: 17000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0783, train/total_loss: 0.0000, train/total_loss/avg: 0.0783, max mem: 6431.0, experiment: run, epoch: 64, num_updates: 17000, iterations: 17000, max_updates: 22000, lr: 0., ups: 1.30, time: 01m 17s 132ms, time_since_start: 02h 58m 06s 630ms, eta: 01h 04m 24s 324ms
[32m2021-03-04T17:33:42 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T17:33:54 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T17:33:54 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T17:33:54 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T17:33:54 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T17:34:18 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T17:34:41 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T17:34:41 | mmf.trainers.callbacks.logistics: [0mprogress: 17000/22000, val/hateful_memes/cross_entropy: 2.8627, val/total_loss: 2.8627, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4921, val/hateful_memes/roc_auc: 0.6807, num_updates: 17000, epoch: 64, iterations: 17000, max_updates: 22000, val_time: 59s 227ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.693353
[32m2021-03-04T17:35:43 | mmf.trainers.callbacks.logistics: [0mprogress: 17100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0778, train/total_loss: 0.0000, train/total_loss/avg: 0.0778, max mem: 6431.0, experiment: run, epoch: 65, num_updates: 17100, iterations: 17100, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 696ms, time_since_start: 03h 07s 558ms, eta: 50m 29s 164ms
[32m2021-03-04T17:36:34 | mmf.trainers.callbacks.logistics: [0mprogress: 17200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0773, train/total_loss: 0.0001, train/total_loss/avg: 0.0773, max mem: 6431.0, experiment: run, epoch: 65, num_updates: 17200, iterations: 17200, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 811ms, time_since_start: 03h 58s 370ms, eta: 40m 43s 825ms
[32m2021-03-04T17:37:35 | mmf.trainers.callbacks.logistics: [0mprogress: 17300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0769, train/total_loss: 0.0001, train/total_loss/avg: 0.0769, max mem: 6431.0, experiment: run, epoch: 66, num_updates: 17300, iterations: 17300, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 256ms, time_since_start: 03h 01m 59s 627ms, eta: 48m 04s 834ms
[32m2021-03-04T17:38:24 | mmf.trainers.callbacks.logistics: [0mprogress: 17400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0765, train/total_loss: 0.0001, train/total_loss/avg: 0.0765, max mem: 6431.0, experiment: run, epoch: 66, num_updates: 17400, iterations: 17400, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 521ms, time_since_start: 03h 02m 49s 148ms, eta: 38m 02s 543ms
[32m2021-03-04T17:39:14 | mmf.trainers.callbacks.logistics: [0mprogress: 17500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0760, train/total_loss: 0.0001, train/total_loss/avg: 0.0760, max mem: 6431.0, experiment: run, epoch: 66, num_updates: 17500, iterations: 17500, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 502ms, time_since_start: 03h 03m 38s 651ms, eta: 37m 12s 073ms
[32m2021-03-04T17:40:14 | mmf.trainers.callbacks.logistics: [0mprogress: 17600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0756, train/total_loss: 0.0001, train/total_loss/avg: 0.0756, max mem: 6431.0, experiment: run, epoch: 67, num_updates: 17600, iterations: 17600, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 143ms, time_since_start: 03h 04m 38s 795ms, eta: 44m 11s 628ms
[32m2021-03-04T17:41:04 | mmf.trainers.callbacks.logistics: [0mprogress: 17700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0752, train/total_loss: 0.0001, train/total_loss/avg: 0.0752, max mem: 6431.0, experiment: run, epoch: 67, num_updates: 17700, iterations: 17700, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 297ms, time_since_start: 03h 05m 29s 092ms, eta: 36m 07s 117ms
[32m2021-03-04T17:41:55 | mmf.trainers.callbacks.logistics: [0mprogress: 17800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0747, train/total_loss: 0.0001, train/total_loss/avg: 0.0747, max mem: 6431.0, experiment: run, epoch: 67, num_updates: 17800, iterations: 17800, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 484ms, time_since_start: 03h 06m 19s 576ms, eta: 35m 24s 573ms
[32m2021-03-04T17:42:55 | mmf.trainers.callbacks.logistics: [0mprogress: 17900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0743, train/total_loss: 0.0001, train/total_loss/avg: 0.0743, max mem: 6431.0, experiment: run, epoch: 68, num_updates: 17900, iterations: 17900, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 227ms, time_since_start: 03h 07m 19s 804ms, eta: 41m 14s 278ms
[32m2021-03-04T17:43:44 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T17:43:44 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T17:43:44 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T17:43:44 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T17:43:49 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T17:44:12 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T17:44:12 | mmf.trainers.callbacks.logistics: [0mprogress: 18000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0753, train/total_loss: 0.0001, train/total_loss/avg: 0.0753, max mem: 6431.0, experiment: run, epoch: 68, num_updates: 18000, iterations: 18000, max_updates: 22000, lr: 0., ups: 1.30, time: 01m 17s 345ms, time_since_start: 03h 08m 37s 150ms, eta: 51m 40s 025ms
[32m2021-03-04T17:44:12 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T17:44:23 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T17:44:23 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T17:44:23 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T17:44:23 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T17:44:47 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T17:45:10 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T17:45:10 | mmf.trainers.callbacks.logistics: [0mprogress: 18000/22000, val/hateful_memes/cross_entropy: 2.8428, val/total_loss: 2.8428, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.4592, val/hateful_memes/roc_auc: 0.6849, num_updates: 18000, epoch: 68, iterations: 18000, max_updates: 22000, val_time: 57s 594ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.693353
[32m2021-03-04T17:46:11 | mmf.trainers.callbacks.logistics: [0mprogress: 18100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0749, train/total_loss: 0.0001, train/total_loss/avg: 0.0749, max mem: 6431.0, experiment: run, epoch: 69, num_updates: 18100, iterations: 18100, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 558ms, time_since_start: 03h 10m 35s 309ms, eta: 39m 26s 505ms
[32m2021-03-04T17:46:59 | mmf.trainers.callbacks.logistics: [0mprogress: 18200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0745, train/total_loss: 0.0001, train/total_loss/avg: 0.0745, max mem: 6431.0, experiment: run, epoch: 69, num_updates: 18200, iterations: 18200, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 216ms, time_since_start: 03h 11m 23s 526ms, eta: 30m 35s 909ms
[32m2021-03-04T17:47:47 | mmf.trainers.callbacks.logistics: [0mprogress: 18300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0741, train/total_loss: 0.0001, train/total_loss/avg: 0.0741, max mem: 6431.0, experiment: run, epoch: 69, num_updates: 18300, iterations: 18300, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 363ms, time_since_start: 03h 12m 11s 889ms, eta: 29m 53s 010ms
[32m2021-03-04T17:48:47 | mmf.trainers.callbacks.logistics: [0mprogress: 18400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0737, train/total_loss: 0.0001, train/total_loss/avg: 0.0737, max mem: 6431.0, experiment: run, epoch: 70, num_updates: 18400, iterations: 18400, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 904ms, time_since_start: 03h 13m 11s 794ms, eta: 36m 891ms
[32m2021-03-04T17:49:37 | mmf.trainers.callbacks.logistics: [0mprogress: 18500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0733, train/total_loss: 0.0001, train/total_loss/avg: 0.0733, max mem: 6431.0, experiment: run, epoch: 70, num_updates: 18500, iterations: 18500, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 782ms, time_since_start: 03h 14m 01s 576ms, eta: 29m 05s 860ms
[32m2021-03-04T17:50:27 | mmf.trainers.callbacks.logistics: [0mprogress: 18600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0729, train/total_loss: 0.0001, train/total_loss/avg: 0.0729, max mem: 6431.0, experiment: run, epoch: 70, num_updates: 18600, iterations: 18600, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 825ms, time_since_start: 03h 14m 51s 402ms, eta: 28m 17s 463ms
[32m2021-03-04T17:51:27 | mmf.trainers.callbacks.logistics: [0mprogress: 18700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0725, train/total_loss: 0.0001, train/total_loss/avg: 0.0725, max mem: 6431.0, experiment: run, epoch: 71, num_updates: 18700, iterations: 18700, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 351ms, time_since_start: 03h 15m 51s 753ms, eta: 33m 15s 590ms
[32m2021-03-04T17:52:17 | mmf.trainers.callbacks.logistics: [0mprogress: 18800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0721, train/total_loss: 0.0001, train/total_loss/avg: 0.0721, max mem: 6431.0, experiment: run, epoch: 71, num_updates: 18800, iterations: 18800, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 900ms, time_since_start: 03h 16m 41s 654ms, eta: 26m 40s 017ms
[32m2021-03-04T17:53:17 | mmf.trainers.callbacks.logistics: [0mprogress: 18900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0717, train/total_loss: 0.0001, train/total_loss/avg: 0.0717, max mem: 6431.0, experiment: run, epoch: 72, num_updates: 18900, iterations: 18900, max_updates: 22000, lr: 0., ups: 1.67, time: 01m 085ms, time_since_start: 03h 17m 41s 740ms, eta: 31m 06s 371ms
[32m2021-03-04T17:54:05 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T17:54:05 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T17:54:05 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T17:54:05 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T17:54:11 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T17:54:42 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T17:54:42 | mmf.trainers.callbacks.logistics: [0mprogress: 19000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0714, train/total_loss: 0.0001, train/total_loss/avg: 0.0714, max mem: 6431.0, experiment: run, epoch: 72, num_updates: 19000, iterations: 19000, max_updates: 22000, lr: 0., ups: 1.19, time: 01m 24s 952ms, time_since_start: 03h 19m 06s 692ms, eta: 42m 33s 661ms
[32m2021-03-04T17:54:42 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T17:54:53 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T17:54:53 | mmf.trainers.callbacks.logistics: [0mprogress: 19000/22000, val/hateful_memes/cross_entropy: 2.7854, val/total_loss: 2.7854, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4882, val/hateful_memes/roc_auc: 0.6861, num_updates: 19000, epoch: 72, iterations: 19000, max_updates: 22000, val_time: 10s 732ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.693353
[32m2021-03-04T17:55:41 | mmf.trainers.callbacks.logistics: [0mprogress: 19100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0710, train/total_loss: 0.0001, train/total_loss/avg: 0.0710, max mem: 6431.0, experiment: run, epoch: 72, num_updates: 19100, iterations: 19100, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 631ms, time_since_start: 03h 20m 06s 072ms, eta: 23m 33s 120ms
[32m2021-03-04T17:56:41 | mmf.trainers.callbacks.logistics: [0mprogress: 19200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0706, train/total_loss: 0.0001, train/total_loss/avg: 0.0706, max mem: 6431.0, experiment: run, epoch: 73, num_updates: 19200, iterations: 19200, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 809ms, time_since_start: 03h 21m 05s 881ms, eta: 27m 58s 002ms
[32m2021-03-04T17:57:31 | mmf.trainers.callbacks.logistics: [0mprogress: 19300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0702, train/total_loss: 0.0001, train/total_loss/avg: 0.0702, max mem: 6431.0, experiment: run, epoch: 73, num_updates: 19300, iterations: 19300, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 953ms, time_since_start: 03h 21m 55s 835ms, eta: 22m 31s 432ms
[32m2021-03-04T17:58:21 | mmf.trainers.callbacks.logistics: [0mprogress: 19400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0699, train/total_loss: 0.0000, train/total_loss/avg: 0.0699, max mem: 6431.0, experiment: run, epoch: 73, num_updates: 19400, iterations: 19400, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 192ms, time_since_start: 03h 22m 46s 027ms, eta: 21m 47s 615ms
[32m2021-03-04T17:59:21 | mmf.trainers.callbacks.logistics: [0mprogress: 19500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0695, train/total_loss: 0.0000, train/total_loss/avg: 0.0695, max mem: 6431.0, experiment: run, epoch: 74, num_updates: 19500, iterations: 19500, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 447ms, time_since_start: 03h 23m 45s 475ms, eta: 24m 49s 158ms
[32m2021-03-04T18:00:09 | mmf.trainers.callbacks.logistics: [0mprogress: 19600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0692, train/total_loss: 0.0000, train/total_loss/avg: 0.0692, max mem: 6431.0, experiment: run, epoch: 74, num_updates: 19600, iterations: 19600, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 591ms, time_since_start: 03h 24m 34s 066ms, eta: 19m 28s 527ms
[32m2021-03-04T18:01:09 | mmf.trainers.callbacks.logistics: [0mprogress: 19700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0688, train/total_loss: 0.0000, train/total_loss/avg: 0.0688, max mem: 6431.0, experiment: run, epoch: 75, num_updates: 19700, iterations: 19700, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 396ms, time_since_start: 03h 25m 33s 463ms, eta: 22m 48s 863ms
[32m2021-03-04T18:01:58 | mmf.trainers.callbacks.logistics: [0mprogress: 19800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0685, train/total_loss: 0.0000, train/total_loss/avg: 0.0685, max mem: 6431.0, experiment: run, epoch: 75, num_updates: 19800, iterations: 19800, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 839ms, time_since_start: 03h 26m 22s 303ms, eta: 17m 56s 622ms
[32m2021-03-04T18:02:47 | mmf.trainers.callbacks.logistics: [0mprogress: 19900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0681, train/total_loss: 0.0000, train/total_loss/avg: 0.0681, max mem: 6431.0, experiment: run, epoch: 75, num_updates: 19900, iterations: 19900, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 989ms, time_since_start: 03h 27m 11s 292ms, eta: 17m 10s 834ms
[32m2021-03-04T18:03:46 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T18:03:46 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:03:46 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:03:46 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:04:10 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:04:33 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:04:33 | mmf.trainers.callbacks.logistics: [0mprogress: 20000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0678, train/total_loss: 0.0000, train/total_loss/avg: 0.0678, max mem: 6431.0, experiment: run, epoch: 76, num_updates: 20000, iterations: 20000, max_updates: 22000, lr: 0., ups: 0.94, time: 01m 46s 644ms, time_since_start: 03h 28m 57s 936ms, eta: 35m 37s 146ms
[32m2021-03-04T18:04:33 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T18:04:45 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T18:04:45 | mmf.trainers.callbacks.logistics: [0mprogress: 20000/22000, val/hateful_memes/cross_entropy: 2.8831, val/total_loss: 2.8831, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4797, val/hateful_memes/roc_auc: 0.6860, num_updates: 20000, epoch: 76, iterations: 20000, max_updates: 22000, val_time: 12s 234ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.693353
[32m2021-03-04T18:05:34 | mmf.trainers.callbacks.logistics: [0mprogress: 20100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0674, train/total_loss: 0.0000, train/total_loss/avg: 0.0674, max mem: 6431.0, experiment: run, epoch: 76, num_updates: 20100, iterations: 20100, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 927ms, time_since_start: 03h 29m 59s 103ms, eta: 15m 31s 483ms
[32m2021-03-04T18:06:23 | mmf.trainers.callbacks.logistics: [0mprogress: 20200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0671, train/total_loss: 0.0000, train/total_loss/avg: 0.0671, max mem: 6431.0, experiment: run, epoch: 76, num_updates: 20200, iterations: 20200, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 893ms, time_since_start: 03h 30m 47s 997ms, eta: 14m 41s 848ms
[32m2021-03-04T18:07:23 | mmf.trainers.callbacks.logistics: [0mprogress: 20300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0668, train/total_loss: 0.0000, train/total_loss/avg: 0.0668, max mem: 6431.0, experiment: run, epoch: 77, num_updates: 20300, iterations: 20300, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 590ms, time_since_start: 03h 31m 47s 588ms, eta: 16m 55s 072ms
[32m2021-03-04T18:08:12 | mmf.trainers.callbacks.logistics: [0mprogress: 20400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0665, train/total_loss: 0.0000, train/total_loss/avg: 0.0665, max mem: 6431.0, experiment: run, epoch: 77, num_updates: 20400, iterations: 20400, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 908ms, time_since_start: 03h 32m 36s 496ms, eta: 13m 04s 094ms
[32m2021-03-04T18:09:11 | mmf.trainers.callbacks.logistics: [0mprogress: 20500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0661, train/total_loss: 0.0000, train/total_loss/avg: 0.0661, max mem: 6431.0, experiment: run, epoch: 78, num_updates: 20500, iterations: 20500, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 636ms, time_since_start: 03h 33m 36s 132ms, eta: 14m 56s 330ms
[32m2021-03-04T18:10:01 | mmf.trainers.callbacks.logistics: [0mprogress: 20600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0658, train/total_loss: 0.0000, train/total_loss/avg: 0.0658, max mem: 6431.0, experiment: run, epoch: 78, num_updates: 20600, iterations: 20600, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 316ms, time_since_start: 03h 34m 25s 449ms, eta: 11m 31s 815ms
[32m2021-03-04T18:10:50 | mmf.trainers.callbacks.logistics: [0mprogress: 20700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0655, train/total_loss: 0.0000, train/total_loss/avg: 0.0655, max mem: 6431.0, experiment: run, epoch: 78, num_updates: 20700, iterations: 20700, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 351ms, time_since_start: 03h 35m 14s 801ms, eta: 10m 42s 854ms
[32m2021-03-04T18:11:50 | mmf.trainers.callbacks.logistics: [0mprogress: 20800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0652, train/total_loss: 0.0000, train/total_loss/avg: 0.0652, max mem: 6431.0, experiment: run, epoch: 79, num_updates: 20800, iterations: 20800, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 708ms, time_since_start: 03h 36m 14s 509ms, eta: 11m 57s 933ms
[32m2021-03-04T18:12:39 | mmf.trainers.callbacks.logistics: [0mprogress: 20900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0649, train/total_loss: 0.0000, train/total_loss/avg: 0.0649, max mem: 6431.0, experiment: run, epoch: 79, num_updates: 20900, iterations: 20900, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 274ms, time_since_start: 03h 37m 03s 784ms, eta: 09m 03s 107ms
[32m2021-03-04T18:13:28 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T18:13:28 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:13:28 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:13:28 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:13:52 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:14:15 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:14:15 | mmf.trainers.callbacks.logistics: [0mprogress: 21000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0646, train/total_loss: 0.0000, train/total_loss/avg: 0.0646, max mem: 6431.0, experiment: run, epoch: 79, num_updates: 21000, iterations: 21000, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 895ms, time_since_start: 03h 38m 39s 680ms, eta: 16m 875ms
[32m2021-03-04T18:14:15 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T18:14:35 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T18:14:35 | mmf.trainers.callbacks.logistics: [0mprogress: 21000/22000, val/hateful_memes/cross_entropy: 2.8800, val/total_loss: 2.8800, val/hateful_memes/accuracy: 0.6963, val/hateful_memes/binary_f1: 0.4956, val/hateful_memes/roc_auc: 0.6901, num_updates: 21000, epoch: 79, iterations: 21000, max_updates: 22000, val_time: 20s 120ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.693353
[32m2021-03-04T18:15:38 | mmf.trainers.callbacks.logistics: [0mprogress: 21100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0642, train/total_loss: 0.0000, train/total_loss/avg: 0.0642, max mem: 6431.0, experiment: run, epoch: 80, num_updates: 21100, iterations: 21100, max_updates: 22000, lr: 0., ups: 1.61, time: 01m 02s 707ms, time_since_start: 03h 40m 02s 522ms, eta: 09m 25s 499ms
[32m2021-03-04T18:16:29 | mmf.trainers.callbacks.logistics: [0mprogress: 21200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0639, train/total_loss: 0.0000, train/total_loss/avg: 0.0639, max mem: 6431.0, experiment: run, epoch: 80, num_updates: 21200, iterations: 21200, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 289ms, time_since_start: 03h 40m 53s 811ms, eta: 06m 51s 134ms
[32m2021-03-04T18:17:30 | mmf.trainers.callbacks.logistics: [0mprogress: 21300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0636, train/total_loss: 0.0000, train/total_loss/avg: 0.0636, max mem: 6431.0, experiment: run, epoch: 81, num_updates: 21300, iterations: 21300, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 285ms, time_since_start: 03h 41m 55s 097ms, eta: 07m 09s 857ms
[32m2021-03-04T18:18:19 | mmf.trainers.callbacks.logistics: [0mprogress: 21400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0633, train/total_loss: 0.0000, train/total_loss/avg: 0.0633, max mem: 6431.0, experiment: run, epoch: 81, num_updates: 21400, iterations: 21400, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 862ms, time_since_start: 03h 42m 43s 959ms, eta: 04m 53s 759ms
[32m2021-03-04T18:19:08 | mmf.trainers.callbacks.logistics: [0mprogress: 21500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0630, train/total_loss: 0.0000, train/total_loss/avg: 0.0630, max mem: 6431.0, experiment: run, epoch: 81, num_updates: 21500, iterations: 21500, max_updates: 22000, lr: 0., ups: 2.08, time: 48s 830ms, time_since_start: 03h 43m 32s 789ms, eta: 04m 04s 638ms
[32m2021-03-04T18:20:08 | mmf.trainers.callbacks.logistics: [0mprogress: 21600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0628, train/total_loss: 0.0000, train/total_loss/avg: 0.0628, max mem: 6431.0, experiment: run, epoch: 82, num_updates: 21600, iterations: 21600, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 591ms, time_since_start: 03h 44m 32s 380ms, eta: 03m 58s 841ms
[32m2021-03-04T18:20:57 | mmf.trainers.callbacks.logistics: [0mprogress: 21700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0625, train/total_loss: 0.0000, train/total_loss/avg: 0.0625, max mem: 6431.0, experiment: run, epoch: 82, num_updates: 21700, iterations: 21700, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 211ms, time_since_start: 03h 45m 21s 592ms, eta: 02m 27s 928ms
[32m2021-03-04T18:21:46 | mmf.trainers.callbacks.logistics: [0mprogress: 21800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0622, train/total_loss: 0.0000, train/total_loss/avg: 0.0622, max mem: 6431.0, experiment: run, epoch: 82, num_updates: 21800, iterations: 21800, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 239ms, time_since_start: 03h 46m 10s 831ms, eta: 01m 38s 675ms
[32m2021-03-04T18:22:45 | mmf.trainers.callbacks.logistics: [0mprogress: 21900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0619, train/total_loss: 0.0000, train/total_loss/avg: 0.0619, max mem: 6431.0, experiment: run, epoch: 83, num_updates: 21900, iterations: 21900, max_updates: 22000, lr: 0., ups: 1.72, time: 58s 668ms, time_since_start: 03h 47m 09s 499ms, eta: 58s 785ms
[32m2021-03-04T18:23:33 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T18:23:33 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:23:33 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:23:33 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:23:57 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:24:20 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:24:20 | mmf.trainers.callbacks.logistics: [0mprogress: 22000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0616, train/total_loss: 0.0000, train/total_loss/avg: 0.0616, max mem: 6431.0, experiment: run, epoch: 83, num_updates: 22000, iterations: 22000, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 457ms, time_since_start: 03h 48m 44s 956ms, eta: 0ms
[32m2021-03-04T18:24:20 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T18:24:33 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T18:24:33 | mmf.trainers.callbacks.logistics: [0mprogress: 22000/22000, val/hateful_memes/cross_entropy: 2.9701, val/total_loss: 2.9701, val/hateful_memes/accuracy: 0.6944, val/hateful_memes/binary_f1: 0.4755, val/hateful_memes/roc_auc: 0.6896, num_updates: 22000, epoch: 83, iterations: 22000, max_updates: 22000, val_time: 12s 824ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.693353
[32m2021-03-04T18:24:34 | mmf.trainers.core.training_loop: [0mStepping into final validation check
[32m2021-03-04T18:24:34 | mmf.utils.checkpoint: [0mRestoring checkpoint
[32m2021-03-04T18:24:34 | mmf.utils.checkpoint: [0mLoading checkpoint
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.position_ids from model.bert.embeddings.position_ids
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_embeddings.image_embeddings.weight from model.bert.v_embeddings.image_embeddings.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_embeddings.image_embeddings.bias from model.bert.v_embeddings.image_embeddings.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_embeddings.image_location_embeddings.weight from model.bert.v_embeddings.image_location_embeddings.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_embeddings.image_location_embeddings.bias from model.bert.v_embeddings.image_location_embeddings.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_embeddings.LayerNorm.weight from model.bert.v_embeddings.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_embeddings.LayerNorm.bias from model.bert.v_embeddings.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.self.query.weight from model.bert.encoder.v_layer.0.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.self.query.bias from model.bert.encoder.v_layer.0.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.self.key.weight from model.bert.encoder.v_layer.0.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.self.key.bias from model.bert.encoder.v_layer.0.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.self.value.weight from model.bert.encoder.v_layer.0.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.self.value.bias from model.bert.encoder.v_layer.0.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.output.dense.weight from model.bert.encoder.v_layer.0.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.output.dense.bias from model.bert.encoder.v_layer.0.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.0.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.0.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.intermediate.dense.weight from model.bert.encoder.v_layer.0.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.intermediate.dense.bias from model.bert.encoder.v_layer.0.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.output.dense.weight from model.bert.encoder.v_layer.0.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.output.dense.bias from model.bert.encoder.v_layer.0.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.output.LayerNorm.weight from model.bert.encoder.v_layer.0.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.0.output.LayerNorm.bias from model.bert.encoder.v_layer.0.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.self.query.weight from model.bert.encoder.v_layer.1.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.self.query.bias from model.bert.encoder.v_layer.1.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.self.key.weight from model.bert.encoder.v_layer.1.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.self.key.bias from model.bert.encoder.v_layer.1.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.self.value.weight from model.bert.encoder.v_layer.1.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.self.value.bias from model.bert.encoder.v_layer.1.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.output.dense.weight from model.bert.encoder.v_layer.1.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.output.dense.bias from model.bert.encoder.v_layer.1.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.1.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.1.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.intermediate.dense.weight from model.bert.encoder.v_layer.1.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.intermediate.dense.bias from model.bert.encoder.v_layer.1.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.output.dense.weight from model.bert.encoder.v_layer.1.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.output.dense.bias from model.bert.encoder.v_layer.1.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.output.LayerNorm.weight from model.bert.encoder.v_layer.1.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.1.output.LayerNorm.bias from model.bert.encoder.v_layer.1.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.self.query.weight from model.bert.encoder.v_layer.2.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.self.query.bias from model.bert.encoder.v_layer.2.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.self.key.weight from model.bert.encoder.v_layer.2.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.self.key.bias from model.bert.encoder.v_layer.2.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.self.value.weight from model.bert.encoder.v_layer.2.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.self.value.bias from model.bert.encoder.v_layer.2.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.output.dense.weight from model.bert.encoder.v_layer.2.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.output.dense.bias from model.bert.encoder.v_layer.2.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.2.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.2.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.intermediate.dense.weight from model.bert.encoder.v_layer.2.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.intermediate.dense.bias from model.bert.encoder.v_layer.2.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.output.dense.weight from model.bert.encoder.v_layer.2.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.output.dense.bias from model.bert.encoder.v_layer.2.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.output.LayerNorm.weight from model.bert.encoder.v_layer.2.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.2.output.LayerNorm.bias from model.bert.encoder.v_layer.2.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.self.query.weight from model.bert.encoder.v_layer.3.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.self.query.bias from model.bert.encoder.v_layer.3.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.self.key.weight from model.bert.encoder.v_layer.3.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.self.key.bias from model.bert.encoder.v_layer.3.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.self.value.weight from model.bert.encoder.v_layer.3.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.self.value.bias from model.bert.encoder.v_layer.3.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.output.dense.weight from model.bert.encoder.v_layer.3.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.output.dense.bias from model.bert.encoder.v_layer.3.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.3.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.3.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.intermediate.dense.weight from model.bert.encoder.v_layer.3.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.intermediate.dense.bias from model.bert.encoder.v_layer.3.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.output.dense.weight from model.bert.encoder.v_layer.3.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.output.dense.bias from model.bert.encoder.v_layer.3.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.output.LayerNorm.weight from model.bert.encoder.v_layer.3.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.3.output.LayerNorm.bias from model.bert.encoder.v_layer.3.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.self.query.weight from model.bert.encoder.v_layer.4.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.self.query.bias from model.bert.encoder.v_layer.4.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.self.key.weight from model.bert.encoder.v_layer.4.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.self.key.bias from model.bert.encoder.v_layer.4.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.self.value.weight from model.bert.encoder.v_layer.4.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.self.value.bias from model.bert.encoder.v_layer.4.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.output.dense.weight from model.bert.encoder.v_layer.4.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.output.dense.bias from model.bert.encoder.v_layer.4.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.4.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.4.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.intermediate.dense.weight from model.bert.encoder.v_layer.4.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.intermediate.dense.bias from model.bert.encoder.v_layer.4.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.output.dense.weight from model.bert.encoder.v_layer.4.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.output.dense.bias from model.bert.encoder.v_layer.4.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.output.LayerNorm.weight from model.bert.encoder.v_layer.4.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.4.output.LayerNorm.bias from model.bert.encoder.v_layer.4.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.self.query.weight from model.bert.encoder.v_layer.5.attention.self.query.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.self.query.bias from model.bert.encoder.v_layer.5.attention.self.query.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.self.key.weight from model.bert.encoder.v_layer.5.attention.self.key.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.self.key.bias from model.bert.encoder.v_layer.5.attention.self.key.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.self.value.weight from model.bert.encoder.v_layer.5.attention.self.value.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.self.value.bias from model.bert.encoder.v_layer.5.attention.self.value.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.output.dense.weight from model.bert.encoder.v_layer.5.attention.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.output.dense.bias from model.bert.encoder.v_layer.5.attention.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.5.attention.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.5.attention.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.intermediate.dense.weight from model.bert.encoder.v_layer.5.intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.intermediate.dense.bias from model.bert.encoder.v_layer.5.intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.output.dense.weight from model.bert.encoder.v_layer.5.output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.output.dense.bias from model.bert.encoder.v_layer.5.output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.output.LayerNorm.weight from model.bert.encoder.v_layer.5.output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.v_layer.5.output.LayerNorm.bias from model.bert.encoder.v_layer.5.output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.query1.weight from model.bert.encoder.c_layer.0.biattention.query1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.query1.bias from model.bert.encoder.c_layer.0.biattention.query1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.key1.weight from model.bert.encoder.c_layer.0.biattention.key1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.key1.bias from model.bert.encoder.c_layer.0.biattention.key1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.value1.weight from model.bert.encoder.c_layer.0.biattention.value1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.value1.bias from model.bert.encoder.c_layer.0.biattention.value1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.query2.weight from model.bert.encoder.c_layer.0.biattention.query2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.query2.bias from model.bert.encoder.c_layer.0.biattention.query2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.key2.weight from model.bert.encoder.c_layer.0.biattention.key2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.key2.bias from model.bert.encoder.c_layer.0.biattention.key2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.value2.weight from model.bert.encoder.c_layer.0.biattention.value2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biattention.value2.bias from model.bert.encoder.c_layer.0.biattention.value2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.dense1.weight from model.bert.encoder.c_layer.0.biOutput.dense1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.dense1.bias from model.bert.encoder.c_layer.0.biOutput.dense1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.0.biOutput.LayerNorm1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.0.biOutput.LayerNorm1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.q_dense1.weight from model.bert.encoder.c_layer.0.biOutput.q_dense1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.q_dense1.bias from model.bert.encoder.c_layer.0.biOutput.q_dense1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.dense2.weight from model.bert.encoder.c_layer.0.biOutput.dense2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.dense2.bias from model.bert.encoder.c_layer.0.biOutput.dense2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.0.biOutput.LayerNorm2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.0.biOutput.LayerNorm2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.q_dense2.weight from model.bert.encoder.c_layer.0.biOutput.q_dense2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.biOutput.q_dense2.bias from model.bert.encoder.c_layer.0.biOutput.q_dense2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.v_intermediate.dense.weight from model.bert.encoder.c_layer.0.v_intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.v_intermediate.dense.bias from model.bert.encoder.c_layer.0.v_intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.v_output.dense.weight from model.bert.encoder.c_layer.0.v_output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.v_output.dense.bias from model.bert.encoder.c_layer.0.v_output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.v_output.LayerNorm.weight from model.bert.encoder.c_layer.0.v_output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.v_output.LayerNorm.bias from model.bert.encoder.c_layer.0.v_output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.t_intermediate.dense.weight from model.bert.encoder.c_layer.0.t_intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.t_intermediate.dense.bias from model.bert.encoder.c_layer.0.t_intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.t_output.dense.weight from model.bert.encoder.c_layer.0.t_output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.t_output.dense.bias from model.bert.encoder.c_layer.0.t_output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.t_output.LayerNorm.weight from model.bert.encoder.c_layer.0.t_output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.0.t_output.LayerNorm.bias from model.bert.encoder.c_layer.0.t_output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.query1.weight from model.bert.encoder.c_layer.1.biattention.query1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.query1.bias from model.bert.encoder.c_layer.1.biattention.query1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.key1.weight from model.bert.encoder.c_layer.1.biattention.key1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.key1.bias from model.bert.encoder.c_layer.1.biattention.key1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.value1.weight from model.bert.encoder.c_layer.1.biattention.value1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.value1.bias from model.bert.encoder.c_layer.1.biattention.value1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.query2.weight from model.bert.encoder.c_layer.1.biattention.query2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.query2.bias from model.bert.encoder.c_layer.1.biattention.query2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.key2.weight from model.bert.encoder.c_layer.1.biattention.key2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.key2.bias from model.bert.encoder.c_layer.1.biattention.key2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.value2.weight from model.bert.encoder.c_layer.1.biattention.value2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biattention.value2.bias from model.bert.encoder.c_layer.1.biattention.value2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.dense1.weight from model.bert.encoder.c_layer.1.biOutput.dense1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.dense1.bias from model.bert.encoder.c_layer.1.biOutput.dense1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.1.biOutput.LayerNorm1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.1.biOutput.LayerNorm1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.q_dense1.weight from model.bert.encoder.c_layer.1.biOutput.q_dense1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.q_dense1.bias from model.bert.encoder.c_layer.1.biOutput.q_dense1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.dense2.weight from model.bert.encoder.c_layer.1.biOutput.dense2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.dense2.bias from model.bert.encoder.c_layer.1.biOutput.dense2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.1.biOutput.LayerNorm2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.1.biOutput.LayerNorm2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.q_dense2.weight from model.bert.encoder.c_layer.1.biOutput.q_dense2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.biOutput.q_dense2.bias from model.bert.encoder.c_layer.1.biOutput.q_dense2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.v_intermediate.dense.weight from model.bert.encoder.c_layer.1.v_intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.v_intermediate.dense.bias from model.bert.encoder.c_layer.1.v_intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.v_output.dense.weight from model.bert.encoder.c_layer.1.v_output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.v_output.dense.bias from model.bert.encoder.c_layer.1.v_output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.v_output.LayerNorm.weight from model.bert.encoder.c_layer.1.v_output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.v_output.LayerNorm.bias from model.bert.encoder.c_layer.1.v_output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.t_intermediate.dense.weight from model.bert.encoder.c_layer.1.t_intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.t_intermediate.dense.bias from model.bert.encoder.c_layer.1.t_intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.t_output.dense.weight from model.bert.encoder.c_layer.1.t_output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.t_output.dense.bias from model.bert.encoder.c_layer.1.t_output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.t_output.LayerNorm.weight from model.bert.encoder.c_layer.1.t_output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.1.t_output.LayerNorm.bias from model.bert.encoder.c_layer.1.t_output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.query1.weight from model.bert.encoder.c_layer.2.biattention.query1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.query1.bias from model.bert.encoder.c_layer.2.biattention.query1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.key1.weight from model.bert.encoder.c_layer.2.biattention.key1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.key1.bias from model.bert.encoder.c_layer.2.biattention.key1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.value1.weight from model.bert.encoder.c_layer.2.biattention.value1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.value1.bias from model.bert.encoder.c_layer.2.biattention.value1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.query2.weight from model.bert.encoder.c_layer.2.biattention.query2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.query2.bias from model.bert.encoder.c_layer.2.biattention.query2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.key2.weight from model.bert.encoder.c_layer.2.biattention.key2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.key2.bias from model.bert.encoder.c_layer.2.biattention.key2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.value2.weight from model.bert.encoder.c_layer.2.biattention.value2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biattention.value2.bias from model.bert.encoder.c_layer.2.biattention.value2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.dense1.weight from model.bert.encoder.c_layer.2.biOutput.dense1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.dense1.bias from model.bert.encoder.c_layer.2.biOutput.dense1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.2.biOutput.LayerNorm1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.2.biOutput.LayerNorm1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.q_dense1.weight from model.bert.encoder.c_layer.2.biOutput.q_dense1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.q_dense1.bias from model.bert.encoder.c_layer.2.biOutput.q_dense1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.dense2.weight from model.bert.encoder.c_layer.2.biOutput.dense2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.dense2.bias from model.bert.encoder.c_layer.2.biOutput.dense2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.2.biOutput.LayerNorm2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.2.biOutput.LayerNorm2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.q_dense2.weight from model.bert.encoder.c_layer.2.biOutput.q_dense2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.biOutput.q_dense2.bias from model.bert.encoder.c_layer.2.biOutput.q_dense2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.v_intermediate.dense.weight from model.bert.encoder.c_layer.2.v_intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.v_intermediate.dense.bias from model.bert.encoder.c_layer.2.v_intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.v_output.dense.weight from model.bert.encoder.c_layer.2.v_output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.v_output.dense.bias from model.bert.encoder.c_layer.2.v_output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.v_output.LayerNorm.weight from model.bert.encoder.c_layer.2.v_output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.v_output.LayerNorm.bias from model.bert.encoder.c_layer.2.v_output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.t_intermediate.dense.weight from model.bert.encoder.c_layer.2.t_intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.t_intermediate.dense.bias from model.bert.encoder.c_layer.2.t_intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.t_output.dense.weight from model.bert.encoder.c_layer.2.t_output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.t_output.dense.bias from model.bert.encoder.c_layer.2.t_output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.t_output.LayerNorm.weight from model.bert.encoder.c_layer.2.t_output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.2.t_output.LayerNorm.bias from model.bert.encoder.c_layer.2.t_output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.query1.weight from model.bert.encoder.c_layer.3.biattention.query1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.query1.bias from model.bert.encoder.c_layer.3.biattention.query1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.key1.weight from model.bert.encoder.c_layer.3.biattention.key1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.key1.bias from model.bert.encoder.c_layer.3.biattention.key1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.value1.weight from model.bert.encoder.c_layer.3.biattention.value1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.value1.bias from model.bert.encoder.c_layer.3.biattention.value1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.query2.weight from model.bert.encoder.c_layer.3.biattention.query2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.query2.bias from model.bert.encoder.c_layer.3.biattention.query2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.key2.weight from model.bert.encoder.c_layer.3.biattention.key2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.key2.bias from model.bert.encoder.c_layer.3.biattention.key2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.value2.weight from model.bert.encoder.c_layer.3.biattention.value2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biattention.value2.bias from model.bert.encoder.c_layer.3.biattention.value2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.dense1.weight from model.bert.encoder.c_layer.3.biOutput.dense1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.dense1.bias from model.bert.encoder.c_layer.3.biOutput.dense1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.3.biOutput.LayerNorm1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.3.biOutput.LayerNorm1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.q_dense1.weight from model.bert.encoder.c_layer.3.biOutput.q_dense1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.q_dense1.bias from model.bert.encoder.c_layer.3.biOutput.q_dense1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.dense2.weight from model.bert.encoder.c_layer.3.biOutput.dense2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.dense2.bias from model.bert.encoder.c_layer.3.biOutput.dense2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.3.biOutput.LayerNorm2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.3.biOutput.LayerNorm2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.q_dense2.weight from model.bert.encoder.c_layer.3.biOutput.q_dense2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.biOutput.q_dense2.bias from model.bert.encoder.c_layer.3.biOutput.q_dense2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.v_intermediate.dense.weight from model.bert.encoder.c_layer.3.v_intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.v_intermediate.dense.bias from model.bert.encoder.c_layer.3.v_intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.v_output.dense.weight from model.bert.encoder.c_layer.3.v_output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.v_output.dense.bias from model.bert.encoder.c_layer.3.v_output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.v_output.LayerNorm.weight from model.bert.encoder.c_layer.3.v_output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.v_output.LayerNorm.bias from model.bert.encoder.c_layer.3.v_output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.t_intermediate.dense.weight from model.bert.encoder.c_layer.3.t_intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.t_intermediate.dense.bias from model.bert.encoder.c_layer.3.t_intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.t_output.dense.weight from model.bert.encoder.c_layer.3.t_output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.t_output.dense.bias from model.bert.encoder.c_layer.3.t_output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.t_output.LayerNorm.weight from model.bert.encoder.c_layer.3.t_output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.3.t_output.LayerNorm.bias from model.bert.encoder.c_layer.3.t_output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.query1.weight from model.bert.encoder.c_layer.4.biattention.query1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.query1.bias from model.bert.encoder.c_layer.4.biattention.query1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.key1.weight from model.bert.encoder.c_layer.4.biattention.key1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.key1.bias from model.bert.encoder.c_layer.4.biattention.key1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.value1.weight from model.bert.encoder.c_layer.4.biattention.value1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.value1.bias from model.bert.encoder.c_layer.4.biattention.value1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.query2.weight from model.bert.encoder.c_layer.4.biattention.query2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.query2.bias from model.bert.encoder.c_layer.4.biattention.query2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.key2.weight from model.bert.encoder.c_layer.4.biattention.key2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.key2.bias from model.bert.encoder.c_layer.4.biattention.key2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.value2.weight from model.bert.encoder.c_layer.4.biattention.value2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biattention.value2.bias from model.bert.encoder.c_layer.4.biattention.value2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.dense1.weight from model.bert.encoder.c_layer.4.biOutput.dense1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.dense1.bias from model.bert.encoder.c_layer.4.biOutput.dense1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.4.biOutput.LayerNorm1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.4.biOutput.LayerNorm1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.q_dense1.weight from model.bert.encoder.c_layer.4.biOutput.q_dense1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.q_dense1.bias from model.bert.encoder.c_layer.4.biOutput.q_dense1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.dense2.weight from model.bert.encoder.c_layer.4.biOutput.dense2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.dense2.bias from model.bert.encoder.c_layer.4.biOutput.dense2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.4.biOutput.LayerNorm2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.4.biOutput.LayerNorm2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.q_dense2.weight from model.bert.encoder.c_layer.4.biOutput.q_dense2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.biOutput.q_dense2.bias from model.bert.encoder.c_layer.4.biOutput.q_dense2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.v_intermediate.dense.weight from model.bert.encoder.c_layer.4.v_intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.v_intermediate.dense.bias from model.bert.encoder.c_layer.4.v_intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.v_output.dense.weight from model.bert.encoder.c_layer.4.v_output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.v_output.dense.bias from model.bert.encoder.c_layer.4.v_output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.v_output.LayerNorm.weight from model.bert.encoder.c_layer.4.v_output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.v_output.LayerNorm.bias from model.bert.encoder.c_layer.4.v_output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.t_intermediate.dense.weight from model.bert.encoder.c_layer.4.t_intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.t_intermediate.dense.bias from model.bert.encoder.c_layer.4.t_intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.t_output.dense.weight from model.bert.encoder.c_layer.4.t_output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.t_output.dense.bias from model.bert.encoder.c_layer.4.t_output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.t_output.LayerNorm.weight from model.bert.encoder.c_layer.4.t_output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.4.t_output.LayerNorm.bias from model.bert.encoder.c_layer.4.t_output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.query1.weight from model.bert.encoder.c_layer.5.biattention.query1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.query1.bias from model.bert.encoder.c_layer.5.biattention.query1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.key1.weight from model.bert.encoder.c_layer.5.biattention.key1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.key1.bias from model.bert.encoder.c_layer.5.biattention.key1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.value1.weight from model.bert.encoder.c_layer.5.biattention.value1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.value1.bias from model.bert.encoder.c_layer.5.biattention.value1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.query2.weight from model.bert.encoder.c_layer.5.biattention.query2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.query2.bias from model.bert.encoder.c_layer.5.biattention.query2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.key2.weight from model.bert.encoder.c_layer.5.biattention.key2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.key2.bias from model.bert.encoder.c_layer.5.biattention.key2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.value2.weight from model.bert.encoder.c_layer.5.biattention.value2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biattention.value2.bias from model.bert.encoder.c_layer.5.biattention.value2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.dense1.weight from model.bert.encoder.c_layer.5.biOutput.dense1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.dense1.bias from model.bert.encoder.c_layer.5.biOutput.dense1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.5.biOutput.LayerNorm1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.5.biOutput.LayerNorm1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.q_dense1.weight from model.bert.encoder.c_layer.5.biOutput.q_dense1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.q_dense1.bias from model.bert.encoder.c_layer.5.biOutput.q_dense1.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.dense2.weight from model.bert.encoder.c_layer.5.biOutput.dense2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.dense2.bias from model.bert.encoder.c_layer.5.biOutput.dense2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.5.biOutput.LayerNorm2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.5.biOutput.LayerNorm2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.q_dense2.weight from model.bert.encoder.c_layer.5.biOutput.q_dense2.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.biOutput.q_dense2.bias from model.bert.encoder.c_layer.5.biOutput.q_dense2.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.v_intermediate.dense.weight from model.bert.encoder.c_layer.5.v_intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.v_intermediate.dense.bias from model.bert.encoder.c_layer.5.v_intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.v_output.dense.weight from model.bert.encoder.c_layer.5.v_output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.v_output.dense.bias from model.bert.encoder.c_layer.5.v_output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.v_output.LayerNorm.weight from model.bert.encoder.c_layer.5.v_output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.v_output.LayerNorm.bias from model.bert.encoder.c_layer.5.v_output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.t_intermediate.dense.weight from model.bert.encoder.c_layer.5.t_intermediate.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.t_intermediate.dense.bias from model.bert.encoder.c_layer.5.t_intermediate.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.t_output.dense.weight from model.bert.encoder.c_layer.5.t_output.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.t_output.dense.bias from model.bert.encoder.c_layer.5.t_output.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.t_output.LayerNorm.weight from model.bert.encoder.c_layer.5.t_output.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.encoder.c_layer.5.t_output.LayerNorm.bias from model.bert.encoder.c_layer.5.t_output.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.t_pooler.dense.weight from model.bert.t_pooler.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.t_pooler.dense.bias from model.bert.t_pooler.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_pooler.dense.weight from model.bert.v_pooler.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.bert.v_pooler.dense.bias from model.bert.v_pooler.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.dense.weight from model.classifier.0.dense.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.dense.bias from model.classifier.0.dense.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.LayerNorm.weight from model.classifier.0.LayerNorm.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.LayerNorm.bias from model.classifier.0.LayerNorm.bias
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.1.weight from model.classifier.1.weight
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.1.bias from model.classifier.1.bias
[5m[31mWARNING[0m [32m2021-03-04T18:25:00 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:25:00 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mCheckpoint loaded.
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mCurrent num updates: 14000
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mCurrent iteration: 14000
[32m2021-03-04T18:25:00 | mmf.utils.checkpoint: [0mCurrent epoch: 53
[32m2021-03-04T18:25:07 | mmf.trainers.mmf_trainer: [0mStarting inference on val set
  0%|          | 0/68 [00:00<?, ?it/s]  1%|â–         | 1/68 [00:09<10:34,  9.46s/it]  4%|â–         | 3/68 [00:09<02:43,  2.52s/it]  7%|â–‹         | 5/68 [00:09<01:20,  1.27s/it] 10%|â–ˆ         | 7/68 [00:09<00:46,  1.30it/s] 13%|â–ˆâ–Ž        | 9/68 [00:10<00:30,  1.95it/s] 16%|â–ˆâ–Œ        | 11/68 [00:10<00:20,  2.78it/s] 19%|â–ˆâ–‰        | 13/68 [00:10<00:14,  3.76it/s] 22%|â–ˆâ–ˆâ–       | 15/68 [00:10<00:10,  4.89it/s] 25%|â–ˆâ–ˆâ–Œ       | 17/68 [00:10<00:08,  6.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 17/68 [00:11<00:33,  1.52it/s][32m2021-03-04T18:25:18 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T18:25:18 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, val/hateful_memes/cross_entropy: 2.5404, val/total_loss: 2.5404, val/hateful_memes/accuracy: 0.6963, val/hateful_memes/binary_f1: 0.5161, val/hateful_memes/roc_auc: 0.6934
[32m2021-03-04T18:25:18 | mmf.trainers.callbacks.logistics: [0mFinished run in 03h 49m 42s 968ms

Training VILBERT_DIRECT complete
********************************************************************
Training MMBT_FEATURES
[32m2021-03-04T18:25:24 | mmf.utils.configuration: [0mOverriding option config to projects/hateful_memes/configs/mmbt/with_features.yaml
[32m2021-03-04T18:25:24 | mmf.utils.configuration: [0mOverriding option model to mmbt
[32m2021-03-04T18:25:24 | mmf.utils.configuration: [0mOverriding option datasets to hateful_memes
[32m2021-03-04T18:25:24 | mmf.utils.configuration: [0mOverriding option run_type to train_val
[32m2021-03-04T18:25:24 | mmf.utils.configuration: [0mOverriding option checkpoint.max_to_keep to 3
[32m2021-03-04T18:25:26 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T18:25:26 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T18:25:26 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T18:25:26 | mmf.utils.distributed: [0mDistributed Init (Rank 1): tcp://localhost:12711
[32m2021-03-04T18:25:26 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T18:25:26 | mmf.utils.distributed: [0mDistributed Init (Rank 0): tcp://localhost:12711
[32m2021-03-04T18:25:26 | mmf.utils.distributed: [0mDistributed Init (Rank 2): tcp://localhost:12711
[32m2021-03-04T18:25:26 | mmf.utils.distributed: [0mDistributed Init (Rank 3): tcp://localhost:12711
[32m2021-03-04T18:25:26 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 1
[32m2021-03-04T18:25:26 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 2
[32m2021-03-04T18:25:26 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 3
[32m2021-03-04T18:25:26 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 0
[32m2021-03-04T18:25:32 | mmf: [0mLogging to: /scratch/sagarsj42/save/train.log
[32m2021-03-04T18:25:32 | mmf_cli.run: [0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/mmbt/with_features.yaml', 'model=mmbt', 'dataset=hateful_memes', 'run_type=train_val', 'checkpoint.max_to_keep=3'])
[32m2021-03-04T18:25:32 | mmf_cli.run: [0mTorch version: 1.6.0
[32m2021-03-04T18:25:32 | mmf.utils.general: [0mCUDA Device 0 is: GeForce GTX 1080 Ti
[32m2021-03-04T18:25:32 | mmf_cli.run: [0mUsing seed 32200510
[32m2021-03-04T18:25:32 | mmf.trainers.mmf_trainer: [0mLoading datasets
[32m2021-03-04T18:25:38 | mmf.trainers.mmf_trainer: [0mLoading model
[32m2021-03-04T18:25:57 | mmf.trainers.mmf_trainer: [0mLoading optimizer
[32m2021-03-04T18:25:57 | mmf.trainers.mmf_trainer: [0mLoading metrics
[5m[31mWARNING[0m [32m2021-03-04T18:25:57 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.
Use OmegaConf.to_yaml(cfg)

  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:25:57 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.
Use OmegaConf.to_yaml(cfg)

  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:25:57 | mmf.trainers.mmf_trainer: [0m===== Model =====
[32m2021-03-04T18:25:57 | mmf.trainers.mmf_trainer: [0mDistributedDataParallel(
  (module): MMBT(
    (model): MMBTForClassification(
      (bert): MMBTBase(
        (mmbt): MMBTModel(
          (transformer): BertModelJit(
            (embeddings): BertEmbeddingsJit(
              (word_embeddings): Embedding(30522, 768, padding_idx=0)
              (position_embeddings): Embedding(512, 768)
              (token_type_embeddings): Embedding(2, 768)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (encoder): BertEncoderJit(
              (layer): ModuleList(
                (0): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (1): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (2): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (3): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (4): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (5): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (6): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (7): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (8): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (9): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (10): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (11): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (pooler): BertPooler(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (activation): Tanh()
            )
          )
          (modal_encoder): ModalEmbeddings(
            (encoder): FinetuneFasterRcnnFpnFc7(
              (lc): Linear(in_features=2048, out_features=2048, bias=True)
            )
            (proj_embeddings): Linear(in_features=2048, out_features=768, bias=True)
            (position_embeddings): Embedding(512, 768)
            (token_type_embeddings): Embedding(2, 768)
            (word_embeddings): Embedding(30522, 768, padding_idx=0)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
      (classifier): Sequential(
        (0): BertPredictionHeadTransform(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (1): Linear(in_features=768, out_features=2, bias=True)
      )
    )
    (losses): Losses(
      (losses): ModuleList(
        (0): MMFLoss(
          (loss_criterion): CrossEntropyLoss(
            (loss_fn): CrossEntropyLoss()
          )
        )
      )
    )
  )
)
[32m2021-03-04T18:25:57 | mmf.utils.general: [0mTotal Parameters: 115845890. Trained Parameters: 115845890
[32m2021-03-04T18:25:57 | mmf.trainers.core.training_loop: [0mStarting training...
[32m2021-03-04T18:26:39 | mmf.trainers.callbacks.logistics: [0mprogress: 100/22000, train/hateful_memes/cross_entropy: 0.7733, train/hateful_memes/cross_entropy/avg: 0.7733, train/total_loss: 0.7733, train/total_loss/avg: 0.7733, max mem: 4155.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 2.38, time: 42s 052ms, time_since_start: 42s 276ms, eta: 02h 33m 47s 890ms
[32m2021-03-04T18:27:10 | mmf.trainers.callbacks.logistics: [0mprogress: 200/22000, train/hateful_memes/cross_entropy: 0.7733, train/hateful_memes/cross_entropy/avg: 0.7967, train/total_loss: 0.7733, train/total_loss/avg: 0.7967, max mem: 4155.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 709ms, time_since_start: 01m 12s 986ms, eta: 01h 51m 48s 027ms
[32m2021-03-04T18:27:52 | mmf.trainers.callbacks.logistics: [0mprogress: 300/22000, train/hateful_memes/cross_entropy: 0.7733, train/hateful_memes/cross_entropy/avg: 0.7319, train/total_loss: 0.7733, train/total_loss/avg: 0.7319, max mem: 4155.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0.00001, ups: 2.38, time: 42s 068ms, time_since_start: 01m 55s 054ms, eta: 02h 32m 27s 110ms
[32m2021-03-04T18:28:23 | mmf.trainers.callbacks.logistics: [0mprogress: 400/22000, train/hateful_memes/cross_entropy: 0.6884, train/hateful_memes/cross_entropy/avg: 0.7210, train/total_loss: 0.6884, train/total_loss/avg: 0.7210, max mem: 4155.0, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 715ms, time_since_start: 02m 25s 770ms, eta: 01h 50m 47s 923ms
[32m2021-03-04T18:28:53 | mmf.trainers.callbacks.logistics: [0mprogress: 500/22000, train/hateful_memes/cross_entropy: 0.6884, train/hateful_memes/cross_entropy/avg: 0.6789, train/total_loss: 0.6884, train/total_loss/avg: 0.6789, max mem: 4155.0, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 596ms, time_since_start: 02m 56s 366ms, eta: 01h 49m 51s 313ms
[32m2021-03-04T18:29:33 | mmf.trainers.callbacks.logistics: [0mprogress: 600/22000, train/hateful_memes/cross_entropy: 0.6023, train/hateful_memes/cross_entropy/avg: 0.6477, train/total_loss: 0.6023, train/total_loss/avg: 0.6477, max mem: 4155.0, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0.00002, ups: 2.56, time: 39s 956ms, time_since_start: 03m 36s 322ms, eta: 02h 22m 47s 731ms
[32m2021-03-04T18:30:03 | mmf.trainers.callbacks.logistics: [0mprogress: 700/22000, train/hateful_memes/cross_entropy: 0.6522, train/hateful_memes/cross_entropy/avg: 0.6484, train/total_loss: 0.6522, train/total_loss/avg: 0.6484, max mem: 4155.0, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0.00002, ups: 3.45, time: 29s 261ms, time_since_start: 04m 05s 584ms, eta: 01h 44m 05s 211ms
[32m2021-03-04T18:30:43 | mmf.trainers.callbacks.logistics: [0mprogress: 800/22000, train/hateful_memes/cross_entropy: 0.6023, train/hateful_memes/cross_entropy/avg: 0.6256, train/total_loss: 0.6023, train/total_loss/avg: 0.6256, max mem: 4155.0, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0.00002, ups: 2.50, time: 40s 178ms, time_since_start: 04m 45s 763ms, eta: 02h 22m 14s 914ms
[32m2021-03-04T18:31:14 | mmf.trainers.callbacks.logistics: [0mprogress: 900/22000, train/hateful_memes/cross_entropy: 0.6023, train/hateful_memes/cross_entropy/avg: 0.6155, train/total_loss: 0.6023, train/total_loss/avg: 0.6155, max mem: 4155.0, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 937ms, time_since_start: 05m 16s 701ms, eta: 01h 49m 951ms
[32m2021-03-04T18:31:45 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T18:31:45 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:31:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:31:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:31:49 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:32:07 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:32:07 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, train/hateful_memes/cross_entropy: 0.5340, train/hateful_memes/cross_entropy/avg: 0.5904, train/total_loss: 0.5340, train/total_loss/avg: 0.5904, max mem: 4155.0, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00003, ups: 1.89, time: 53s 394ms, time_since_start: 06m 10s 095ms, eta: 03h 07m 15s 277ms
[32m2021-03-04T18:32:07 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T18:32:24 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T18:32:24 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:32:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:32:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:32:35 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T18:32:45 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:32:56 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:32:56 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, val/hateful_memes/cross_entropy: 0.7199, val/total_loss: 0.7199, val/hateful_memes/accuracy: 0.5926, val/hateful_memes/binary_f1: 0.3566, val/hateful_memes/roc_auc: 0.6163, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 22000, val_time: 48s 555ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.616263
[32m2021-03-04T18:33:39 | mmf.trainers.callbacks.logistics: [0mprogress: 1100/22000, train/hateful_memes/cross_entropy: 0.5340, train/hateful_memes/cross_entropy/avg: 0.5682, train/total_loss: 0.5340, train/total_loss/avg: 0.5682, max mem: 4158.0, experiment: run, epoch: 5, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00003, ups: 2.33, time: 43s 043ms, time_since_start: 07m 41s 696ms, eta: 02h 30m 14s 126ms
[32m2021-03-04T18:34:09 | mmf.trainers.callbacks.logistics: [0mprogress: 1200/22000, train/hateful_memes/cross_entropy: 0.5106, train/hateful_memes/cross_entropy/avg: 0.5402, train/total_loss: 0.5106, train/total_loss/avg: 0.5402, max mem: 4158.0, experiment: run, epoch: 5, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 687ms, time_since_start: 08m 12s 384ms, eta: 01h 46m 35s 789ms
[32m2021-03-04T18:34:40 | mmf.trainers.callbacks.logistics: [0mprogress: 1300/22000, train/hateful_memes/cross_entropy: 0.5340, train/hateful_memes/cross_entropy/avg: 0.5454, train/total_loss: 0.5340, train/total_loss/avg: 0.5454, max mem: 4158.0, experiment: run, epoch: 5, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 726ms, time_since_start: 08m 43s 110ms, eta: 01h 46m 13s 065ms
[32m2021-03-04T18:35:21 | mmf.trainers.callbacks.logistics: [0mprogress: 1400/22000, train/hateful_memes/cross_entropy: 0.5106, train/hateful_memes/cross_entropy/avg: 0.5255, train/total_loss: 0.5106, train/total_loss/avg: 0.5255, max mem: 4158.0, experiment: run, epoch: 6, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00003, ups: 2.50, time: 40s 800ms, time_since_start: 09m 23s 911ms, eta: 02h 20m 21s 643ms
[32m2021-03-04T18:35:51 | mmf.trainers.callbacks.logistics: [0mprogress: 1500/22000, train/hateful_memes/cross_entropy: 0.5106, train/hateful_memes/cross_entropy/avg: 0.5151, train/total_loss: 0.5106, train/total_loss/avg: 0.5151, max mem: 4158.0, experiment: run, epoch: 6, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 517ms, time_since_start: 09m 54s 428ms, eta: 01h 44m 28s 558ms
[32m2021-03-04T18:36:32 | mmf.trainers.callbacks.logistics: [0mprogress: 1600/22000, train/hateful_memes/cross_entropy: 0.4919, train/hateful_memes/cross_entropy/avg: 0.4946, train/total_loss: 0.4919, train/total_loss/avg: 0.4946, max mem: 4158.0, experiment: run, epoch: 7, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00004, ups: 2.44, time: 41s 054ms, time_since_start: 10m 35s 483ms, eta: 02h 19m 51s 893ms
[32m2021-03-04T18:37:03 | mmf.trainers.callbacks.logistics: [0mprogress: 1700/22000, train/hateful_memes/cross_entropy: 0.4919, train/hateful_memes/cross_entropy/avg: 0.4790, train/total_loss: 0.4919, train/total_loss/avg: 0.4790, max mem: 4158.0, experiment: run, epoch: 7, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 431ms, time_since_start: 11m 05s 914ms, eta: 01h 43m 09s 915ms
[32m2021-03-04T18:37:33 | mmf.trainers.callbacks.logistics: [0mprogress: 1800/22000, train/hateful_memes/cross_entropy: 0.4666, train/hateful_memes/cross_entropy/avg: 0.4655, train/total_loss: 0.4666, train/total_loss/avg: 0.4655, max mem: 4158.0, experiment: run, epoch: 7, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00005, ups: 3.33, time: 30s 503ms, time_since_start: 11m 36s 417ms, eta: 01h 42m 53s 981ms
[32m2021-03-04T18:38:14 | mmf.trainers.callbacks.logistics: [0mprogress: 1900/22000, train/hateful_memes/cross_entropy: 0.4666, train/hateful_memes/cross_entropy/avg: 0.4471, train/total_loss: 0.4666, train/total_loss/avg: 0.4471, max mem: 4158.0, experiment: run, epoch: 8, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00005, ups: 2.44, time: 41s 116ms, time_since_start: 12m 17s 534ms, eta: 02h 18m 958ms
[32m2021-03-04T18:38:45 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T18:38:45 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:38:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:38:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:38:48 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:38:58 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:38:58 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, train/hateful_memes/cross_entropy: 0.3692, train/hateful_memes/cross_entropy/avg: 0.4413, train/total_loss: 0.3692, train/total_loss/avg: 0.4413, max mem: 4158.0, experiment: run, epoch: 8, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00005, ups: 2.33, time: 43s 680ms, time_since_start: 13m 01s 215ms, eta: 02h 25m 53s 651ms
[32m2021-03-04T18:38:58 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T18:39:16 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T18:39:16 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:39:16 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:39:16 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:39:27 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T18:39:38 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:39:48 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:39:48 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, val/hateful_memes/cross_entropy: 0.9478, val/total_loss: 0.9478, val/hateful_memes/accuracy: 0.6593, val/hateful_memes/binary_f1: 0.5159, val/hateful_memes/roc_auc: 0.6748, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 22000, val_time: 50s 244ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.674840
[32m2021-03-04T18:40:19 | mmf.trainers.callbacks.logistics: [0mprogress: 2100/22000, train/hateful_memes/cross_entropy: 0.3652, train/hateful_memes/cross_entropy/avg: 0.4321, train/total_loss: 0.3652, train/total_loss/avg: 0.4321, max mem: 4158.0, experiment: run, epoch: 8, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00005, ups: 3.33, time: 30s 230ms, time_since_start: 14m 21s 692ms, eta: 01h 40m 27s 913ms
[32m2021-03-04T18:41:01 | mmf.trainers.callbacks.logistics: [0mprogress: 2200/22000, train/hateful_memes/cross_entropy: 0.3456, train/hateful_memes/cross_entropy/avg: 0.4258, train/total_loss: 0.3456, train/total_loss/avg: 0.4258, max mem: 4158.0, experiment: run, epoch: 9, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00005, ups: 2.38, time: 42s 121ms, time_since_start: 15m 03s 813ms, eta: 02h 19m 16s 811ms
[32m2021-03-04T18:41:32 | mmf.trainers.callbacks.logistics: [0mprogress: 2300/22000, train/hateful_memes/cross_entropy: 0.3310, train/hateful_memes/cross_entropy/avg: 0.4165, train/total_loss: 0.3310, train/total_loss/avg: 0.4165, max mem: 4158.0, experiment: run, epoch: 9, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00005, ups: 3.23, time: 31s 409ms, time_since_start: 15m 35s 223ms, eta: 01h 43m 19s 969ms
[32m2021-03-04T18:42:14 | mmf.trainers.callbacks.logistics: [0mprogress: 2400/22000, train/hateful_memes/cross_entropy: 0.2926, train/hateful_memes/cross_entropy/avg: 0.4019, train/total_loss: 0.2926, train/total_loss/avg: 0.4019, max mem: 4158.0, experiment: run, epoch: 10, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00005, ups: 2.44, time: 41s 746ms, time_since_start: 16m 16s 969ms, eta: 02h 16m 38s 674ms
[32m2021-03-04T18:42:44 | mmf.trainers.callbacks.logistics: [0mprogress: 2500/22000, train/hateful_memes/cross_entropy: 0.2926, train/hateful_memes/cross_entropy/avg: 0.4013, train/total_loss: 0.2926, train/total_loss/avg: 0.4013, max mem: 4158.0, experiment: run, epoch: 10, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00005, ups: 3.33, time: 30s 430ms, time_since_start: 16m 47s 399ms, eta: 01h 39m 05s 745ms
[32m2021-03-04T18:43:15 | mmf.trainers.callbacks.logistics: [0mprogress: 2600/22000, train/hateful_memes/cross_entropy: 0.2679, train/hateful_memes/cross_entropy/avg: 0.3912, train/total_loss: 0.2679, train/total_loss/avg: 0.3912, max mem: 4158.0, experiment: run, epoch: 10, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00005, ups: 3.33, time: 30s 720ms, time_since_start: 17m 18s 120ms, eta: 01h 39m 31s 788ms
[32m2021-03-04T18:43:56 | mmf.trainers.callbacks.logistics: [0mprogress: 2700/22000, train/hateful_memes/cross_entropy: 0.2486, train/hateful_memes/cross_entropy/avg: 0.3795, train/total_loss: 0.2486, train/total_loss/avg: 0.3795, max mem: 4158.0, experiment: run, epoch: 11, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00005, ups: 2.50, time: 40s 961ms, time_since_start: 17m 59s 082ms, eta: 02h 12m 01s 399ms
[32m2021-03-04T18:44:27 | mmf.trainers.callbacks.logistics: [0mprogress: 2800/22000, train/hateful_memes/cross_entropy: 0.2371, train/hateful_memes/cross_entropy/avg: 0.3687, train/total_loss: 0.2371, train/total_loss/avg: 0.3687, max mem: 4158.0, experiment: run, epoch: 11, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00005, ups: 3.33, time: 30s 632ms, time_since_start: 18m 29s 715ms, eta: 01h 38m 13s 278ms
[32m2021-03-04T18:44:58 | mmf.trainers.callbacks.logistics: [0mprogress: 2900/22000, train/hateful_memes/cross_entropy: 0.2322, train/hateful_memes/cross_entropy/avg: 0.3569, train/total_loss: 0.2322, train/total_loss/avg: 0.3569, max mem: 4158.0, experiment: run, epoch: 11, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00005, ups: 3.33, time: 30s 885ms, time_since_start: 19m 600ms, eta: 01h 38m 30s 965ms
[32m2021-03-04T18:45:38 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T18:45:38 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:45:38 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:45:38 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:45:41 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:45:52 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:45:52 | mmf.trainers.callbacks.logistics: [0mprogress: 3000/22000, train/hateful_memes/cross_entropy: 0.2293, train/hateful_memes/cross_entropy/avg: 0.3453, train/total_loss: 0.2293, train/total_loss/avg: 0.3453, max mem: 4158.0, experiment: run, epoch: 12, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00005, ups: 1.85, time: 54s 061ms, time_since_start: 19m 54s 662ms, eta: 02h 51m 32s 168ms
[32m2021-03-04T18:45:52 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T18:46:08 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T18:46:08 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:46:08 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:46:08 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:46:17 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:46:27 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:46:27 | mmf.trainers.callbacks.logistics: [0mprogress: 3000/22000, val/hateful_memes/cross_entropy: 1.4156, val/total_loss: 1.4156, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4939, val/hateful_memes/roc_auc: 0.6714, num_updates: 3000, epoch: 12, iterations: 3000, max_updates: 22000, val_time: 35s 771ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.674840
[32m2021-03-04T18:46:57 | mmf.trainers.callbacks.logistics: [0mprogress: 3100/22000, train/hateful_memes/cross_entropy: 0.2121, train/hateful_memes/cross_entropy/avg: 0.3356, train/total_loss: 0.2121, train/total_loss/avg: 0.3356, max mem: 4158.0, experiment: run, epoch: 12, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00005, ups: 3.33, time: 30s 069ms, time_since_start: 21m 504ms, eta: 01h 34m 54s 448ms
[32m2021-03-04T18:47:39 | mmf.trainers.callbacks.logistics: [0mprogress: 3200/22000, train/hateful_memes/cross_entropy: 0.1867, train/hateful_memes/cross_entropy/avg: 0.3262, train/total_loss: 0.1867, train/total_loss/avg: 0.3262, max mem: 4158.0, experiment: run, epoch: 13, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00005, ups: 2.44, time: 41s 612ms, time_since_start: 21m 42s 116ms, eta: 02h 10m 38s 709ms
[32m2021-03-04T18:48:11 | mmf.trainers.callbacks.logistics: [0mprogress: 3300/22000, train/hateful_memes/cross_entropy: 0.1385, train/hateful_memes/cross_entropy/avg: 0.3166, train/total_loss: 0.1385, train/total_loss/avg: 0.3166, max mem: 4158.0, experiment: run, epoch: 13, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00005, ups: 3.23, time: 31s 582ms, time_since_start: 22m 13s 699ms, eta: 01h 38m 37s 777ms
[32m2021-03-04T18:48:42 | mmf.trainers.callbacks.logistics: [0mprogress: 3400/22000, train/hateful_memes/cross_entropy: 0.1146, train/hateful_memes/cross_entropy/avg: 0.3075, train/total_loss: 0.1146, train/total_loss/avg: 0.3075, max mem: 4158.0, experiment: run, epoch: 13, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00005, ups: 3.23, time: 31s 615ms, time_since_start: 22m 45s 314ms, eta: 01h 38m 12s 214ms
[32m2021-03-04T18:49:24 | mmf.trainers.callbacks.logistics: [0mprogress: 3500/22000, train/hateful_memes/cross_entropy: 0.0765, train/hateful_memes/cross_entropy/avg: 0.2988, train/total_loss: 0.0765, train/total_loss/avg: 0.2988, max mem: 4158.0, experiment: run, epoch: 14, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00005, ups: 2.44, time: 41s 641ms, time_since_start: 23m 26s 956ms, eta: 02h 08m 39s 041ms
[32m2021-03-04T18:49:55 | mmf.trainers.callbacks.logistics: [0mprogress: 3600/22000, train/hateful_memes/cross_entropy: 0.0765, train/hateful_memes/cross_entropy/avg: 0.2969, train/total_loss: 0.0765, train/total_loss/avg: 0.2969, max mem: 4158.0, experiment: run, epoch: 14, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00005, ups: 3.33, time: 30s 618ms, time_since_start: 23m 57s 575ms, eta: 01h 34m 05s 154ms
[32m2021-03-04T18:50:25 | mmf.trainers.callbacks.logistics: [0mprogress: 3700/22000, train/hateful_memes/cross_entropy: 0.0756, train/hateful_memes/cross_entropy/avg: 0.2890, train/total_loss: 0.0756, train/total_loss/avg: 0.2890, max mem: 4158.0, experiment: run, epoch: 14, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00005, ups: 3.33, time: 30s 810ms, time_since_start: 24m 28s 385ms, eta: 01h 34m 09s 564ms
[32m2021-03-04T18:51:06 | mmf.trainers.callbacks.logistics: [0mprogress: 3800/22000, train/hateful_memes/cross_entropy: 0.0664, train/hateful_memes/cross_entropy/avg: 0.2821, train/total_loss: 0.0664, train/total_loss/avg: 0.2821, max mem: 4158.0, experiment: run, epoch: 15, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00005, ups: 2.50, time: 40s 785ms, time_since_start: 25m 09s 171ms, eta: 02h 03m 57s 877ms
[32m2021-03-04T18:51:37 | mmf.trainers.callbacks.logistics: [0mprogress: 3900/22000, train/hateful_memes/cross_entropy: 0.0438, train/hateful_memes/cross_entropy/avg: 0.2749, train/total_loss: 0.0438, train/total_loss/avg: 0.2749, max mem: 4158.0, experiment: run, epoch: 15, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00005, ups: 3.33, time: 30s 620ms, time_since_start: 25m 39s 791ms, eta: 01h 32m 33s 417ms
[32m2021-03-04T18:52:18 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T18:52:18 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:52:18 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:52:18 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:52:21 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:52:32 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:52:32 | mmf.trainers.callbacks.logistics: [0mprogress: 4000/22000, train/hateful_memes/cross_entropy: 0.0353, train/hateful_memes/cross_entropy/avg: 0.2684, train/total_loss: 0.0353, train/total_loss/avg: 0.2684, max mem: 4158.0, experiment: run, epoch: 16, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00005, ups: 1.85, time: 54s 882ms, time_since_start: 26m 34s 674ms, eta: 02h 44m 58s 655ms
[32m2021-03-04T18:52:32 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T18:52:44 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T18:52:44 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:52:44 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:52:44 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:52:55 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T18:53:05 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:53:15 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:53:15 | mmf.trainers.callbacks.logistics: [0mprogress: 4000/22000, val/hateful_memes/cross_entropy: 1.7885, val/total_loss: 1.7885, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4821, val/hateful_memes/roc_auc: 0.6891, num_updates: 4000, epoch: 16, iterations: 4000, max_updates: 22000, val_time: 43s 541ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.689133
[32m2021-03-04T18:53:46 | mmf.trainers.callbacks.logistics: [0mprogress: 4100/22000, train/hateful_memes/cross_entropy: 0.0353, train/hateful_memes/cross_entropy/avg: 0.2637, train/total_loss: 0.0353, train/total_loss/avg: 0.2637, max mem: 4158.0, experiment: run, epoch: 16, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 380ms, time_since_start: 27m 48s 598ms, eta: 01h 30m 48s 936ms
[32m2021-03-04T18:54:16 | mmf.trainers.callbacks.logistics: [0mprogress: 4200/22000, train/hateful_memes/cross_entropy: 0.0278, train/hateful_memes/cross_entropy/avg: 0.2576, train/total_loss: 0.0278, train/total_loss/avg: 0.2576, max mem: 4158.0, experiment: run, epoch: 16, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 606ms, time_since_start: 28m 19s 204ms, eta: 01h 30m 58s 803ms
[32m2021-03-04T18:54:58 | mmf.trainers.callbacks.logistics: [0mprogress: 4300/22000, train/hateful_memes/cross_entropy: 0.0272, train/hateful_memes/cross_entropy/avg: 0.2516, train/total_loss: 0.0272, train/total_loss/avg: 0.2516, max mem: 4158.0, experiment: run, epoch: 17, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00004, ups: 2.38, time: 42s 299ms, time_since_start: 29m 01s 504ms, eta: 02h 05m 02s 049ms
[32m2021-03-04T18:55:30 | mmf.trainers.callbacks.logistics: [0mprogress: 4400/22000, train/hateful_memes/cross_entropy: 0.0133, train/hateful_memes/cross_entropy/avg: 0.2459, train/total_loss: 0.0133, train/total_loss/avg: 0.2459, max mem: 4158.0, experiment: run, epoch: 17, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00004, ups: 3.23, time: 31s 609ms, time_since_start: 29m 33s 113ms, eta: 01h 32m 54s 447ms
[32m2021-03-04T18:56:02 | mmf.trainers.callbacks.logistics: [0mprogress: 4500/22000, train/hateful_memes/cross_entropy: 0.0130, train/hateful_memes/cross_entropy/avg: 0.2408, train/total_loss: 0.0130, train/total_loss/avg: 0.2408, max mem: 4158.0, experiment: run, epoch: 17, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00004, ups: 3.12, time: 32s 012ms, time_since_start: 30m 05s 126ms, eta: 01h 33m 33s 368ms
[32m2021-03-04T18:56:43 | mmf.trainers.callbacks.logistics: [0mprogress: 4600/22000, train/hateful_memes/cross_entropy: 0.0120, train/hateful_memes/cross_entropy/avg: 0.2358, train/total_loss: 0.0120, train/total_loss/avg: 0.2358, max mem: 4158.0, experiment: run, epoch: 18, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00004, ups: 2.50, time: 40s 740ms, time_since_start: 30m 45s 866ms, eta: 01h 58m 22s 947ms
[32m2021-03-04T18:57:13 | mmf.trainers.callbacks.logistics: [0mprogress: 4700/22000, train/hateful_memes/cross_entropy: 0.0120, train/hateful_memes/cross_entropy/avg: 0.2327, train/total_loss: 0.0120, train/total_loss/avg: 0.2327, max mem: 4158.0, experiment: run, epoch: 18, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 260ms, time_since_start: 31m 16s 127ms, eta: 01h 27m 25s 546ms
[32m2021-03-04T18:57:54 | mmf.trainers.callbacks.logistics: [0mprogress: 4800/22000, train/hateful_memes/cross_entropy: 0.0104, train/hateful_memes/cross_entropy/avg: 0.2279, train/total_loss: 0.0104, train/total_loss/avg: 0.2279, max mem: 4158.0, experiment: run, epoch: 19, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00004, ups: 2.50, time: 40s 652ms, time_since_start: 31m 56s 779ms, eta: 01h 56m 46s 166ms
[32m2021-03-04T18:58:23 | mmf.trainers.callbacks.logistics: [0mprogress: 4900/22000, train/hateful_memes/cross_entropy: 0.0104, train/hateful_memes/cross_entropy/avg: 0.2235, train/total_loss: 0.0104, train/total_loss/avg: 0.2235, max mem: 4158.0, experiment: run, epoch: 19, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00004, ups: 3.45, time: 29s 482ms, time_since_start: 32m 26s 261ms, eta: 01h 24m 11s 593ms
[32m2021-03-04T18:58:53 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T18:58:53 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:58:53 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:58:53 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:58:56 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:59:06 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:59:06 | mmf.trainers.callbacks.logistics: [0mprogress: 5000/22000, train/hateful_memes/cross_entropy: 0.0120, train/hateful_memes/cross_entropy/avg: 0.2196, train/total_loss: 0.0120, train/total_loss/avg: 0.2196, max mem: 4158.0, experiment: run, epoch: 19, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00004, ups: 2.38, time: 42s 908ms, time_since_start: 33m 09s 170ms, eta: 02h 01m 49s 122ms
[32m2021-03-04T18:59:06 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T18:59:18 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T18:59:18 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T18:59:18 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T18:59:18 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T18:59:29 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T18:59:39 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T18:59:39 | mmf.trainers.callbacks.logistics: [0mprogress: 5000/22000, val/hateful_memes/cross_entropy: 1.7053, val/total_loss: 1.7053, val/hateful_memes/accuracy: 0.6574, val/hateful_memes/binary_f1: 0.4477, val/hateful_memes/roc_auc: 0.6714, num_updates: 5000, epoch: 19, iterations: 5000, max_updates: 22000, val_time: 32s 479ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.689133
[32m2021-03-04T19:00:19 | mmf.trainers.callbacks.logistics: [0mprogress: 5100/22000, train/hateful_memes/cross_entropy: 0.0101, train/hateful_memes/cross_entropy/avg: 0.2153, train/total_loss: 0.0101, train/total_loss/avg: 0.2153, max mem: 4158.0, experiment: run, epoch: 20, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00004, ups: 2.50, time: 40s 512ms, time_since_start: 34m 22s 164ms, eta: 01h 54m 20s 245ms
[32m2021-03-04T19:00:49 | mmf.trainers.callbacks.logistics: [0mprogress: 5200/22000, train/hateful_memes/cross_entropy: 0.0101, train/hateful_memes/cross_entropy/avg: 0.2169, train/total_loss: 0.0101, train/total_loss/avg: 0.2169, max mem: 4158.0, experiment: run, epoch: 20, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 171ms, time_since_start: 34m 52s 335ms, eta: 01h 24m 38s 872ms
[32m2021-03-04T19:01:20 | mmf.trainers.callbacks.logistics: [0mprogress: 5300/22000, train/hateful_memes/cross_entropy: 0.0101, train/hateful_memes/cross_entropy/avg: 0.2129, train/total_loss: 0.0101, train/total_loss/avg: 0.2129, max mem: 4158.0, experiment: run, epoch: 20, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 677ms, time_since_start: 35m 23s 013ms, eta: 01h 25m 33s 437ms
[32m2021-03-04T19:02:00 | mmf.trainers.callbacks.logistics: [0mprogress: 5400/22000, train/hateful_memes/cross_entropy: 0.0074, train/hateful_memes/cross_entropy/avg: 0.2091, train/total_loss: 0.0074, train/total_loss/avg: 0.2091, max mem: 4158.0, experiment: run, epoch: 21, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00004, ups: 2.50, time: 40s 229ms, time_since_start: 36m 03s 243ms, eta: 01h 51m 31s 458ms
[32m2021-03-04T19:02:30 | mmf.trainers.callbacks.logistics: [0mprogress: 5500/22000, train/hateful_memes/cross_entropy: 0.0074, train/hateful_memes/cross_entropy/avg: 0.2053, train/total_loss: 0.0074, train/total_loss/avg: 0.2053, max mem: 4158.0, experiment: run, epoch: 21, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00004, ups: 3.45, time: 29s 908ms, time_since_start: 36m 33s 151ms, eta: 01h 22m 24s 803ms
[32m2021-03-04T19:03:11 | mmf.trainers.callbacks.logistics: [0mprogress: 5600/22000, train/hateful_memes/cross_entropy: 0.0073, train/hateful_memes/cross_entropy/avg: 0.2017, train/total_loss: 0.0073, train/total_loss/avg: 0.2017, max mem: 4158.0, experiment: run, epoch: 22, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00004, ups: 2.50, time: 40s 564ms, time_since_start: 37m 13s 716ms, eta: 01h 51m 05s 903ms
[32m2021-03-04T19:03:40 | mmf.trainers.callbacks.logistics: [0mprogress: 5700/22000, train/hateful_memes/cross_entropy: 0.0073, train/hateful_memes/cross_entropy/avg: 0.1982, train/total_loss: 0.0073, train/total_loss/avg: 0.1982, max mem: 4158.0, experiment: run, epoch: 22, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00004, ups: 3.45, time: 29s 799ms, time_since_start: 37m 43s 516ms, eta: 01h 21m 07s 109ms
[32m2021-03-04T19:04:11 | mmf.trainers.callbacks.logistics: [0mprogress: 5800/22000, train/hateful_memes/cross_entropy: 0.0055, train/hateful_memes/cross_entropy/avg: 0.1949, train/total_loss: 0.0055, train/total_loss/avg: 0.1949, max mem: 4158.0, experiment: run, epoch: 22, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 269ms, time_since_start: 38m 13s 786ms, eta: 01h 21m 53s 455ms
[32m2021-03-04T19:04:51 | mmf.trainers.callbacks.logistics: [0mprogress: 5900/22000, train/hateful_memes/cross_entropy: 0.0061, train/hateful_memes/cross_entropy/avg: 0.1917, train/total_loss: 0.0061, train/total_loss/avg: 0.1917, max mem: 4158.0, experiment: run, epoch: 23, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00004, ups: 2.50, time: 40s 604ms, time_since_start: 38m 54s 390ms, eta: 01h 49m 10s 397ms
[32m2021-03-04T19:05:21 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T19:05:21 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:05:21 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:05:21 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:05:24 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:05:35 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:05:35 | mmf.trainers.callbacks.logistics: [0mprogress: 6000/22000, train/hateful_memes/cross_entropy: 0.0055, train/hateful_memes/cross_entropy/avg: 0.1885, train/total_loss: 0.0055, train/total_loss/avg: 0.1885, max mem: 4158.0, experiment: run, epoch: 23, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00004, ups: 2.33, time: 43s 352ms, time_since_start: 39m 37s 743ms, eta: 01h 55m 50s 340ms
[32m2021-03-04T19:05:35 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T19:05:45 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T19:05:45 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:05:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:05:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:05:56 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:06:07 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:06:07 | mmf.trainers.callbacks.logistics: [0mprogress: 6000/22000, val/hateful_memes/cross_entropy: 1.8136, val/total_loss: 1.8136, val/hateful_memes/accuracy: 0.6759, val/hateful_memes/binary_f1: 0.4419, val/hateful_memes/roc_auc: 0.6743, num_updates: 6000, epoch: 23, iterations: 6000, max_updates: 22000, val_time: 32s 050ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.689133
[32m2021-03-04T19:06:37 | mmf.trainers.callbacks.logistics: [0mprogress: 6100/22000, train/hateful_memes/cross_entropy: 0.0055, train/hateful_memes/cross_entropy/avg: 0.1856, train/total_loss: 0.0055, train/total_loss/avg: 0.1856, max mem: 4158.0, experiment: run, epoch: 23, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 212ms, time_since_start: 40m 40s 007ms, eta: 01h 20m 13s 378ms
[32m2021-03-04T19:07:18 | mmf.trainers.callbacks.logistics: [0mprogress: 6200/22000, train/hateful_memes/cross_entropy: 0.0055, train/hateful_memes/cross_entropy/avg: 0.1827, train/total_loss: 0.0055, train/total_loss/avg: 0.1827, max mem: 4158.0, experiment: run, epoch: 24, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00004, ups: 2.50, time: 40s 896ms, time_since_start: 41m 20s 903ms, eta: 01h 47m 54s 516ms
[32m2021-03-04T19:07:48 | mmf.trainers.callbacks.logistics: [0mprogress: 6300/22000, train/hateful_memes/cross_entropy: 0.0061, train/hateful_memes/cross_entropy/avg: 0.1800, train/total_loss: 0.0061, train/total_loss/avg: 0.1800, max mem: 4158.0, experiment: run, epoch: 24, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 181ms, time_since_start: 41m 51s 085ms, eta: 01h 19m 07s 920ms
[32m2021-03-04T19:08:29 | mmf.trainers.callbacks.logistics: [0mprogress: 6400/22000, train/hateful_memes/cross_entropy: 0.0073, train/hateful_memes/cross_entropy/avg: 0.1774, train/total_loss: 0.0073, train/total_loss/avg: 0.1774, max mem: 4158.0, experiment: run, epoch: 25, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00004, ups: 2.50, time: 40s 917ms, time_since_start: 42m 32s 002ms, eta: 01h 46m 35s 902ms
[32m2021-03-04T19:08:59 | mmf.trainers.callbacks.logistics: [0mprogress: 6500/22000, train/hateful_memes/cross_entropy: 0.0061, train/hateful_memes/cross_entropy/avg: 0.1747, train/total_loss: 0.0061, train/total_loss/avg: 0.1747, max mem: 4158.0, experiment: run, epoch: 25, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00004, ups: 3.45, time: 29s 899ms, time_since_start: 43m 01s 902ms, eta: 01h 17m 23s 733ms
[32m2021-03-04T19:09:29 | mmf.trainers.callbacks.logistics: [0mprogress: 6600/22000, train/hateful_memes/cross_entropy: 0.0061, train/hateful_memes/cross_entropy/avg: 0.1722, train/total_loss: 0.0061, train/total_loss/avg: 0.1722, max mem: 4158.0, experiment: run, epoch: 25, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 270ms, time_since_start: 43m 32s 173ms, eta: 01h 17m 51s 005ms
[32m2021-03-04T19:10:10 | mmf.trainers.callbacks.logistics: [0mprogress: 6700/22000, train/hateful_memes/cross_entropy: 0.0061, train/hateful_memes/cross_entropy/avg: 0.1698, train/total_loss: 0.0061, train/total_loss/avg: 0.1698, max mem: 4158.0, experiment: run, epoch: 26, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00004, ups: 2.50, time: 40s 475ms, time_since_start: 44m 12s 649ms, eta: 01h 43m 25s 197ms
[32m2021-03-04T19:10:40 | mmf.trainers.callbacks.logistics: [0mprogress: 6800/22000, train/hateful_memes/cross_entropy: 0.0063, train/hateful_memes/cross_entropy/avg: 0.1674, train/total_loss: 0.0063, train/total_loss/avg: 0.1674, max mem: 4158.0, experiment: run, epoch: 26, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 327ms, time_since_start: 44m 42s 976ms, eta: 01h 16m 58s 940ms
[32m2021-03-04T19:11:11 | mmf.trainers.callbacks.logistics: [0mprogress: 6900/22000, train/hateful_memes/cross_entropy: 0.0061, train/hateful_memes/cross_entropy/avg: 0.1650, train/total_loss: 0.0061, train/total_loss/avg: 0.1650, max mem: 4158.0, experiment: run, epoch: 26, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 637ms, time_since_start: 45m 13s 613ms, eta: 01h 17m 15s 508ms
[32m2021-03-04T19:11:51 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T19:11:51 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:11:51 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:11:51 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:11:54 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:12:05 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:12:05 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, train/hateful_memes/cross_entropy: 0.0055, train/hateful_memes/cross_entropy/avg: 0.1626, train/total_loss: 0.0055, train/total_loss/avg: 0.1626, max mem: 4158.0, experiment: run, epoch: 27, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00004, ups: 1.85, time: 54s 109ms, time_since_start: 46m 07s 723ms, eta: 02h 15m 32s 673ms
[32m2021-03-04T19:12:05 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T19:12:15 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T19:12:15 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:12:15 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:12:15 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:12:26 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T19:12:36 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:12:46 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:12:46 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, val/hateful_memes/cross_entropy: 1.9013, val/total_loss: 1.9013, val/hateful_memes/accuracy: 0.6648, val/hateful_memes/binary_f1: 0.4488, val/hateful_memes/roc_auc: 0.6958, num_updates: 7000, epoch: 27, iterations: 7000, max_updates: 22000, val_time: 41s 789ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T19:13:17 | mmf.trainers.callbacks.logistics: [0mprogress: 7100/22000, train/hateful_memes/cross_entropy: 0.0061, train/hateful_memes/cross_entropy/avg: 0.1604, train/total_loss: 0.0061, train/total_loss/avg: 0.1604, max mem: 4158.0, experiment: run, epoch: 27, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 432ms, time_since_start: 47m 19s 946ms, eta: 01h 15m 43s 450ms
[32m2021-03-04T19:13:58 | mmf.trainers.callbacks.logistics: [0mprogress: 7200/22000, train/hateful_memes/cross_entropy: 0.0055, train/hateful_memes/cross_entropy/avg: 0.1582, train/total_loss: 0.0055, train/total_loss/avg: 0.1582, max mem: 4158.0, experiment: run, epoch: 28, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00004, ups: 2.50, time: 40s 903ms, time_since_start: 48m 849ms, eta: 01h 41m 05s 810ms
[32m2021-03-04T19:14:29 | mmf.trainers.callbacks.logistics: [0mprogress: 7300/22000, train/hateful_memes/cross_entropy: 0.0055, train/hateful_memes/cross_entropy/avg: 0.1561, train/total_loss: 0.0055, train/total_loss/avg: 0.1561, max mem: 4158.0, experiment: run, epoch: 28, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 843ms, time_since_start: 48m 31s 693ms, eta: 01h 15m 43s 049ms
[32m2021-03-04T19:15:00 | mmf.trainers.callbacks.logistics: [0mprogress: 7400/22000, train/hateful_memes/cross_entropy: 0.0051, train/hateful_memes/cross_entropy/avg: 0.1540, train/total_loss: 0.0051, train/total_loss/avg: 0.1540, max mem: 4158.0, experiment: run, epoch: 28, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00004, ups: 3.23, time: 31s 014ms, time_since_start: 49m 02s 707ms, eta: 01h 15m 37s 114ms
[32m2021-03-04T19:15:41 | mmf.trainers.callbacks.logistics: [0mprogress: 7500/22000, train/hateful_memes/cross_entropy: 0.0055, train/hateful_memes/cross_entropy/avg: 0.1526, train/total_loss: 0.0055, train/total_loss/avg: 0.1526, max mem: 4158.0, experiment: run, epoch: 29, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00004, ups: 2.44, time: 41s 296ms, time_since_start: 49m 44s 003ms, eta: 01h 39m 59s 991ms
[32m2021-03-04T19:16:12 | mmf.trainers.callbacks.logistics: [0mprogress: 7600/22000, train/hateful_memes/cross_entropy: 0.0055, train/hateful_memes/cross_entropy/avg: 0.1506, train/total_loss: 0.0055, train/total_loss/avg: 0.1506, max mem: 4158.0, experiment: run, epoch: 29, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00004, ups: 3.23, time: 31s 014ms, time_since_start: 50m 15s 018ms, eta: 01h 14m 34s 984ms
[32m2021-03-04T19:16:43 | mmf.trainers.callbacks.logistics: [0mprogress: 7700/22000, train/hateful_memes/cross_entropy: 0.0055, train/hateful_memes/cross_entropy/avg: 0.1487, train/total_loss: 0.0055, train/total_loss/avg: 0.1487, max mem: 4158.0, experiment: run, epoch: 29, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00004, ups: 3.23, time: 31s 367ms, time_since_start: 50m 46s 385ms, eta: 01h 14m 54s 548ms
[32m2021-03-04T19:17:24 | mmf.trainers.callbacks.logistics: [0mprogress: 7800/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1468, train/total_loss: 0.0037, train/total_loss/avg: 0.1468, max mem: 4158.0, experiment: run, epoch: 30, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00004, ups: 2.50, time: 40s 999ms, time_since_start: 51m 27s 385ms, eta: 01h 37m 13s 536ms
[32m2021-03-04T19:17:55 | mmf.trainers.callbacks.logistics: [0mprogress: 7900/22000, train/hateful_memes/cross_entropy: 0.0027, train/hateful_memes/cross_entropy/avg: 0.1450, train/total_loss: 0.0027, train/total_loss/avg: 0.1450, max mem: 4158.0, experiment: run, epoch: 30, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00004, ups: 3.33, time: 30s 554ms, time_since_start: 51m 57s 939ms, eta: 01h 11m 56s 775ms
[32m2021-03-04T19:18:36 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T19:18:36 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:18:36 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:18:36 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:18:39 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:18:49 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:18:49 | mmf.trainers.callbacks.logistics: [0mprogress: 8000/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1431, train/total_loss: 0.0016, train/total_loss/avg: 0.1431, max mem: 4158.0, experiment: run, epoch: 31, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00003, ups: 1.85, time: 54s 330ms, time_since_start: 52m 52s 270ms, eta: 02h 07m 01s 506ms
[32m2021-03-04T19:18:49 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T19:19:00 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T19:19:00 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:19:00 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:19:00 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:19:10 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:19:21 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:19:21 | mmf.trainers.callbacks.logistics: [0mprogress: 8000/22000, val/hateful_memes/cross_entropy: 2.1340, val/total_loss: 2.1340, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4665, val/hateful_memes/roc_auc: 0.6880, num_updates: 8000, epoch: 31, iterations: 8000, max_updates: 22000, val_time: 31s 479ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T19:19:51 | mmf.trainers.callbacks.logistics: [0mprogress: 8100/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1415, train/total_loss: 0.0016, train/total_loss/avg: 0.1415, max mem: 4158.0, experiment: run, epoch: 31, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 516ms, time_since_start: 53m 54s 268ms, eta: 01h 10m 50s 342ms
[32m2021-03-04T19:20:21 | mmf.trainers.callbacks.logistics: [0mprogress: 8200/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1398, train/total_loss: 0.0015, train/total_loss/avg: 0.1398, max mem: 4158.0, experiment: run, epoch: 31, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 179ms, time_since_start: 54m 24s 447ms, eta: 01h 09m 33s 035ms
[32m2021-03-04T19:21:03 | mmf.trainers.callbacks.logistics: [0mprogress: 8300/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1386, train/total_loss: 0.0015, train/total_loss/avg: 0.1386, max mem: 4158.0, experiment: run, epoch: 32, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00003, ups: 2.44, time: 41s 636ms, time_since_start: 55m 06s 083ms, eta: 01h 35m 15s 579ms
[32m2021-03-04T19:21:33 | mmf.trainers.callbacks.logistics: [0mprogress: 8400/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1372, train/total_loss: 0.0015, train/total_loss/avg: 0.1372, max mem: 4158.0, experiment: run, epoch: 32, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00003, ups: 3.45, time: 29s 757ms, time_since_start: 55m 35s 841ms, eta: 01h 07m 35s 172ms
[32m2021-03-04T19:22:03 | mmf.trainers.callbacks.logistics: [0mprogress: 8500/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1378, train/total_loss: 0.0016, train/total_loss/avg: 0.1378, max mem: 4158.0, experiment: run, epoch: 32, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 032ms, time_since_start: 56m 05s 874ms, eta: 01h 07m 42s 504ms
[32m2021-03-04T19:22:43 | mmf.trainers.callbacks.logistics: [0mprogress: 8600/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1363, train/total_loss: 0.0016, train/total_loss/avg: 0.1363, max mem: 4158.0, experiment: run, epoch: 33, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00003, ups: 2.50, time: 40s 067ms, time_since_start: 56m 45s 942ms, eta: 01h 29m 39s 798ms
[32m2021-03-04T19:23:13 | mmf.trainers.callbacks.logistics: [0mprogress: 8700/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1347, train/total_loss: 0.0016, train/total_loss/avg: 0.1347, max mem: 4158.0, experiment: run, epoch: 33, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00003, ups: 3.45, time: 29s 632ms, time_since_start: 57m 15s 574ms, eta: 01h 05m 49s 043ms
[32m2021-03-04T19:23:53 | mmf.trainers.callbacks.logistics: [0mprogress: 8800/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1332, train/total_loss: 0.0015, train/total_loss/avg: 0.1332, max mem: 4158.0, experiment: run, epoch: 34, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00003, ups: 2.50, time: 40s 654ms, time_since_start: 57m 56s 229ms, eta: 01h 29m 37s 114ms
[32m2021-03-04T19:24:23 | mmf.trainers.callbacks.logistics: [0mprogress: 8900/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1317, train/total_loss: 0.0015, train/total_loss/avg: 0.1317, max mem: 4158.0, experiment: run, epoch: 34, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 235ms, time_since_start: 58m 26s 465ms, eta: 01h 06m 08s 831ms
[32m2021-03-04T19:24:54 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T19:24:54 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:24:54 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:24:54 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:24:57 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:25:08 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:25:08 | mmf.trainers.callbacks.logistics: [0mprogress: 9000/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1303, train/total_loss: 0.0016, train/total_loss/avg: 0.1303, max mem: 4158.0, experiment: run, epoch: 34, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00003, ups: 2.27, time: 44s 105ms, time_since_start: 59m 10s 571ms, eta: 01h 35m 45s 232ms
[32m2021-03-04T19:25:08 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T19:25:18 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T19:25:18 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:25:18 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:25:18 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:25:29 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:25:39 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:25:39 | mmf.trainers.callbacks.logistics: [0mprogress: 9000/22000, val/hateful_memes/cross_entropy: 1.6820, val/total_loss: 1.6820, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4479, val/hateful_memes/roc_auc: 0.6686, num_updates: 9000, epoch: 34, iterations: 9000, max_updates: 22000, val_time: 31s 392ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T19:26:21 | mmf.trainers.callbacks.logistics: [0mprogress: 9100/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1289, train/total_loss: 0.0015, train/total_loss/avg: 0.1289, max mem: 4158.0, experiment: run, epoch: 35, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00003, ups: 2.44, time: 41s 727ms, time_since_start: 01h 23s 692ms, eta: 01h 29m 53s 593ms
[32m2021-03-04T19:26:52 | mmf.trainers.callbacks.logistics: [0mprogress: 9200/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1275, train/total_loss: 0.0016, train/total_loss/avg: 0.1275, max mem: 4158.0, experiment: run, epoch: 35, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 889ms, time_since_start: 01h 54s 581ms, eta: 01h 06m 01s 764ms
[32m2021-03-04T19:27:23 | mmf.trainers.callbacks.logistics: [0mprogress: 9300/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1261, train/total_loss: 0.0016, train/total_loss/avg: 0.1261, max mem: 4158.0, experiment: run, epoch: 35, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00003, ups: 3.23, time: 31s 228ms, time_since_start: 01h 01m 25s 810ms, eta: 01h 06m 13s 972ms
[32m2021-03-04T19:28:04 | mmf.trainers.callbacks.logistics: [0mprogress: 9400/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1248, train/total_loss: 0.0016, train/total_loss/avg: 0.1248, max mem: 4158.0, experiment: run, epoch: 36, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00003, ups: 2.50, time: 40s 973ms, time_since_start: 01h 02m 06s 784ms, eta: 01h 26m 12s 992ms
[32m2021-03-04T19:28:34 | mmf.trainers.callbacks.logistics: [0mprogress: 9500/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1235, train/total_loss: 0.0016, train/total_loss/avg: 0.1235, max mem: 4158.0, experiment: run, epoch: 36, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 714ms, time_since_start: 01h 02m 37s 498ms, eta: 01h 04m 06s 937ms
[32m2021-03-04T19:29:15 | mmf.trainers.callbacks.logistics: [0mprogress: 9600/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1222, train/total_loss: 0.0015, train/total_loss/avg: 0.1222, max mem: 4158.0, experiment: run, epoch: 37, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00003, ups: 2.44, time: 41s 012ms, time_since_start: 01h 03m 18s 510ms, eta: 01h 24m 55s 670ms
[32m2021-03-04T19:29:46 | mmf.trainers.callbacks.logistics: [0mprogress: 9700/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1210, train/total_loss: 0.0015, train/total_loss/avg: 0.1210, max mem: 4158.0, experiment: run, epoch: 37, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 029ms, time_since_start: 01h 03m 48s 539ms, eta: 01h 01m 41s 003ms
[32m2021-03-04T19:30:16 | mmf.trainers.callbacks.logistics: [0mprogress: 9800/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1224, train/total_loss: 0.0015, train/total_loss/avg: 0.1224, max mem: 4158.0, experiment: run, epoch: 37, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 168ms, time_since_start: 01h 04m 18s 708ms, eta: 01h 01m 27s 978ms
[32m2021-03-04T19:30:57 | mmf.trainers.callbacks.logistics: [0mprogress: 9900/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.1212, train/total_loss: 0.0017, train/total_loss/avg: 0.1212, max mem: 4158.0, experiment: run, epoch: 38, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00003, ups: 2.50, time: 40s 973ms, time_since_start: 01h 04m 59s 682ms, eta: 01h 22m 47s 721ms
[32m2021-03-04T19:31:28 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T19:31:28 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:31:28 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:31:28 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:31:30 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:31:41 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:31:41 | mmf.trainers.callbacks.logistics: [0mprogress: 10000/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.1200, train/total_loss: 0.0017, train/total_loss/avg: 0.1200, max mem: 4158.0, experiment: run, epoch: 38, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00003, ups: 2.27, time: 44s 263ms, time_since_start: 01h 05m 43s 946ms, eta: 01h 28m 42s 281ms
[32m2021-03-04T19:31:41 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T19:31:51 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T19:31:51 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:31:51 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:31:51 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:32:02 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:32:12 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:32:12 | mmf.trainers.callbacks.logistics: [0mprogress: 10000/22000, val/hateful_memes/cross_entropy: 1.9982, val/total_loss: 1.9982, val/hateful_memes/accuracy: 0.6759, val/hateful_memes/binary_f1: 0.5513, val/hateful_memes/roc_auc: 0.6830, num_updates: 10000, epoch: 38, iterations: 10000, max_updates: 22000, val_time: 30s 779ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T19:32:43 | mmf.trainers.callbacks.logistics: [0mprogress: 10100/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.1188, train/total_loss: 0.0017, train/total_loss/avg: 0.1188, max mem: 4158.0, experiment: run, epoch: 38, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 998ms, time_since_start: 01h 06m 45s 726ms, eta: 01h 01m 36s 243ms
[32m2021-03-04T19:33:23 | mmf.trainers.callbacks.logistics: [0mprogress: 10200/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1178, train/total_loss: 0.0020, train/total_loss/avg: 0.1178, max mem: 4158.0, experiment: run, epoch: 39, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00003, ups: 2.50, time: 40s 323ms, time_since_start: 01h 07m 26s 050ms, eta: 01h 19m 27s 744ms
[32m2021-03-04T19:33:53 | mmf.trainers.callbacks.logistics: [0mprogress: 10300/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1167, train/total_loss: 0.0020, train/total_loss/avg: 0.1167, max mem: 4158.0, experiment: run, epoch: 39, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 020ms, time_since_start: 01h 07m 56s 071ms, eta: 58m 39s 404ms
[32m2021-03-04T19:34:34 | mmf.trainers.callbacks.logistics: [0mprogress: 10400/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1156, train/total_loss: 0.0020, train/total_loss/avg: 0.1156, max mem: 4158.0, experiment: run, epoch: 40, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00003, ups: 2.50, time: 40s 812ms, time_since_start: 01h 08m 36s 883ms, eta: 01h 19m 03s 742ms
[32m2021-03-04T19:35:04 | mmf.trainers.callbacks.logistics: [0mprogress: 10500/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.1145, train/total_loss: 0.0017, train/total_loss/avg: 0.1145, max mem: 4158.0, experiment: run, epoch: 40, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 353ms, time_since_start: 01h 09m 07s 237ms, eta: 58m 17s 629ms
[32m2021-03-04T19:35:35 | mmf.trainers.callbacks.logistics: [0mprogress: 10600/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1135, train/total_loss: 0.0014, train/total_loss/avg: 0.1135, max mem: 4158.0, experiment: run, epoch: 40, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 334ms, time_since_start: 01h 09m 37s 571ms, eta: 57m 45s 008ms
[32m2021-03-04T19:36:15 | mmf.trainers.callbacks.logistics: [0mprogress: 10700/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.1124, train/total_loss: 0.0012, train/total_loss/avg: 0.1124, max mem: 4158.0, experiment: run, epoch: 41, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00003, ups: 2.50, time: 40s 602ms, time_since_start: 01h 10m 18s 173ms, eta: 01h 16m 37s 210ms
[32m2021-03-04T19:36:45 | mmf.trainers.callbacks.logistics: [0mprogress: 10800/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.1114, train/total_loss: 0.0012, train/total_loss/avg: 0.1114, max mem: 4158.0, experiment: run, epoch: 41, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 049ms, time_since_start: 01h 10m 48s 222ms, eta: 56m 12s 255ms
[32m2021-03-04T19:37:15 | mmf.trainers.callbacks.logistics: [0mprogress: 10900/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.1104, train/total_loss: 0.0012, train/total_loss/avg: 0.1104, max mem: 4158.0, experiment: run, epoch: 41, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 304ms, time_since_start: 01h 11m 18s 527ms, eta: 56m 10s 540ms
[32m2021-03-04T19:37:56 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T19:37:56 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:37:56 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:37:56 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:37:59 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:38:09 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:38:09 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.1094, train/total_loss: 0.0012, train/total_loss/avg: 0.1094, max mem: 4158.0, experiment: run, epoch: 42, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00003, ups: 1.89, time: 53s 831ms, time_since_start: 01h 12m 12s 359ms, eta: 01h 38m 53s 352ms
[32m2021-03-04T19:38:09 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T19:38:20 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T19:38:20 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:38:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:38:20 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:38:31 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:38:41 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:38:41 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, val/hateful_memes/cross_entropy: 2.4691, val/total_loss: 2.4691, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.4591, val/hateful_memes/roc_auc: 0.6627, num_updates: 11000, epoch: 42, iterations: 11000, max_updates: 22000, val_time: 31s 673ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T19:39:11 | mmf.trainers.callbacks.logistics: [0mprogress: 11100/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.1084, train/total_loss: 0.0012, train/total_loss/avg: 0.1084, max mem: 4158.0, experiment: run, epoch: 42, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 031ms, time_since_start: 01h 13m 14s 066ms, eta: 54m 39s 980ms
[32m2021-03-04T19:39:52 | mmf.trainers.callbacks.logistics: [0mprogress: 11200/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1074, train/total_loss: 0.0010, train/total_loss/avg: 0.1074, max mem: 4158.0, experiment: run, epoch: 43, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00003, ups: 2.44, time: 41s 113ms, time_since_start: 01h 13m 55s 179ms, eta: 01h 14m 09s 101ms
[32m2021-03-04T19:40:22 | mmf.trainers.callbacks.logistics: [0mprogress: 11300/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.1067, train/total_loss: 0.0012, train/total_loss/avg: 0.1067, max mem: 4158.0, experiment: run, epoch: 43, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 112ms, time_since_start: 01h 14m 25s 292ms, eta: 53m 48s 514ms
[32m2021-03-04T19:40:53 | mmf.trainers.callbacks.logistics: [0mprogress: 11400/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.1058, train/total_loss: 0.0012, train/total_loss/avg: 0.1058, max mem: 4158.0, experiment: run, epoch: 43, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 368ms, time_since_start: 01h 14m 55s 660ms, eta: 53m 45s 467ms
[32m2021-03-04T19:41:33 | mmf.trainers.callbacks.logistics: [0mprogress: 11500/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1048, train/total_loss: 0.0010, train/total_loss/avg: 0.1048, max mem: 4158.0, experiment: run, epoch: 44, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00003, ups: 2.50, time: 40s 638ms, time_since_start: 01h 15m 36s 298ms, eta: 01h 11m 15s 572ms
[32m2021-03-04T19:42:03 | mmf.trainers.callbacks.logistics: [0mprogress: 11600/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1040, train/total_loss: 0.0010, train/total_loss/avg: 0.1040, max mem: 4158.0, experiment: run, epoch: 44, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00003, ups: 3.45, time: 29s 726ms, time_since_start: 01h 16m 06s 025ms, eta: 51m 37s 716ms
[32m2021-03-04T19:42:33 | mmf.trainers.callbacks.logistics: [0mprogress: 11700/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1031, train/total_loss: 0.0010, train/total_loss/avg: 0.1031, max mem: 4158.0, experiment: run, epoch: 44, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00003, ups: 3.45, time: 29s 970ms, time_since_start: 01h 16m 35s 995ms, eta: 51m 33s 113ms
[32m2021-03-04T19:43:14 | mmf.trainers.callbacks.logistics: [0mprogress: 11800/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.1022, train/total_loss: 0.0007, train/total_loss/avg: 0.1022, max mem: 4158.0, experiment: run, epoch: 45, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00003, ups: 2.44, time: 41s 347ms, time_since_start: 01h 17m 17s 342ms, eta: 01h 10m 25s 884ms
[32m2021-03-04T19:43:45 | mmf.trainers.callbacks.logistics: [0mprogress: 11900/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.1021, train/total_loss: 0.0007, train/total_loss/avg: 0.1021, max mem: 4158.0, experiment: run, epoch: 45, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00003, ups: 3.33, time: 30s 794ms, time_since_start: 01h 17m 48s 137ms, eta: 51m 56s 510ms
[32m2021-03-04T19:44:26 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T19:44:26 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:44:26 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:44:26 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:44:29 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:44:40 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:44:40 | mmf.trainers.callbacks.logistics: [0mprogress: 12000/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1013, train/total_loss: 0.0010, train/total_loss/avg: 0.1013, max mem: 4158.0, experiment: run, epoch: 46, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00003, ups: 1.85, time: 54s 528ms, time_since_start: 01h 18m 42s 666ms, eta: 01h 31m 03s 791ms
[32m2021-03-04T19:44:40 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T19:44:50 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T19:44:50 | mmf.trainers.callbacks.logistics: [0mprogress: 12000/22000, val/hateful_memes/cross_entropy: 2.0964, val/total_loss: 2.0964, val/hateful_memes/accuracy: 0.6611, val/hateful_memes/binary_f1: 0.5170, val/hateful_memes/roc_auc: 0.6683, num_updates: 12000, epoch: 46, iterations: 12000, max_updates: 22000, val_time: 10s 438ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T19:45:20 | mmf.trainers.callbacks.logistics: [0mprogress: 12100/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.1005, train/total_loss: 0.0008, train/total_loss/avg: 0.1005, max mem: 4158.0, experiment: run, epoch: 46, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0.00002, ups: 3.45, time: 29s 922ms, time_since_start: 01h 19m 23s 030ms, eta: 49m 28s 301ms
[32m2021-03-04T19:45:50 | mmf.trainers.callbacks.logistics: [0mprogress: 12200/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0997, train/total_loss: 0.0008, train/total_loss/avg: 0.0997, max mem: 4158.0, experiment: run, epoch: 46, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 071ms, time_since_start: 01h 19m 53s 101ms, eta: 49m 12s 862ms
[32m2021-03-04T19:46:31 | mmf.trainers.callbacks.logistics: [0mprogress: 12300/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0989, train/total_loss: 0.0007, train/total_loss/avg: 0.0989, max mem: 4158.0, experiment: run, epoch: 47, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0.00002, ups: 2.44, time: 41s 419ms, time_since_start: 01h 20m 34s 521ms, eta: 01h 07m 05s 775ms
[32m2021-03-04T19:47:03 | mmf.trainers.callbacks.logistics: [0mprogress: 12400/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0981, train/total_loss: 0.0005, train/total_loss/avg: 0.0981, max mem: 4158.0, experiment: run, epoch: 47, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0.00002, ups: 3.23, time: 31s 350ms, time_since_start: 01h 21m 05s 871ms, eta: 50m 15s 670ms
[32m2021-03-04T19:47:35 | mmf.trainers.callbacks.logistics: [0mprogress: 12500/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0973, train/total_loss: 0.0005, train/total_loss/avg: 0.0973, max mem: 4158.0, experiment: run, epoch: 47, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0.00002, ups: 3.23, time: 31s 853ms, time_since_start: 01h 21m 37s 725ms, eta: 50m 32s 116ms
[32m2021-03-04T19:48:15 | mmf.trainers.callbacks.logistics: [0mprogress: 12600/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0965, train/total_loss: 0.0004, train/total_loss/avg: 0.0965, max mem: 4158.0, experiment: run, epoch: 48, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0.00002, ups: 2.50, time: 40s 556ms, time_since_start: 01h 22m 18s 282ms, eta: 01h 03m 39s 977ms
[32m2021-03-04T19:48:46 | mmf.trainers.callbacks.logistics: [0mprogress: 12700/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0958, train/total_loss: 0.0003, train/total_loss/avg: 0.0958, max mem: 4158.0, experiment: run, epoch: 48, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 274ms, time_since_start: 01h 22m 48s 557ms, eta: 47m 01s 201ms
[32m2021-03-04T19:49:26 | mmf.trainers.callbacks.logistics: [0mprogress: 12800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0950, train/total_loss: 0.0002, train/total_loss/avg: 0.0950, max mem: 4158.0, experiment: run, epoch: 49, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0.00002, ups: 2.50, time: 40s 780ms, time_since_start: 01h 23m 29s 338ms, eta: 01h 02m 39s 344ms
[32m2021-03-04T19:49:57 | mmf.trainers.callbacks.logistics: [0mprogress: 12900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0943, train/total_loss: 0.0002, train/total_loss/avg: 0.0943, max mem: 4158.0, experiment: run, epoch: 49, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 615ms, time_since_start: 01h 23m 59s 953ms, eta: 46m 31s 547ms
[32m2021-03-04T19:50:28 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T19:50:28 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:50:28 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:50:28 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:50:30 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:50:41 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:50:41 | mmf.trainers.callbacks.logistics: [0mprogress: 13000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0936, train/total_loss: 0.0002, train/total_loss/avg: 0.0936, max mem: 4158.0, experiment: run, epoch: 49, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0.00002, ups: 2.27, time: 44s 098ms, time_since_start: 01h 24m 44s 052ms, eta: 01h 06m 16s 840ms
[32m2021-03-04T19:50:41 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T19:50:53 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T19:50:53 | mmf.trainers.callbacks.logistics: [0mprogress: 13000/22000, val/hateful_memes/cross_entropy: 2.6901, val/total_loss: 2.6901, val/hateful_memes/accuracy: 0.6685, val/hateful_memes/binary_f1: 0.4440, val/hateful_memes/roc_auc: 0.6550, num_updates: 13000, epoch: 49, iterations: 13000, max_updates: 22000, val_time: 12s 310ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T19:51:34 | mmf.trainers.callbacks.logistics: [0mprogress: 13100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0929, train/total_loss: 0.0002, train/total_loss/avg: 0.0929, max mem: 4158.0, experiment: run, epoch: 50, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0.00002, ups: 2.44, time: 41s 156ms, time_since_start: 01h 25m 37s 520ms, eta: 01h 01m 10s 247ms
[32m2021-03-04T19:52:05 | mmf.trainers.callbacks.logistics: [0mprogress: 13200/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0922, train/total_loss: 0.0002, train/total_loss/avg: 0.0922, max mem: 4158.0, experiment: run, epoch: 50, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 443ms, time_since_start: 01h 26m 07s 964ms, eta: 44m 44s 406ms
[32m2021-03-04T19:52:35 | mmf.trainers.callbacks.logistics: [0mprogress: 13300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0917, train/total_loss: 0.0001, train/total_loss/avg: 0.0917, max mem: 4158.0, experiment: run, epoch: 50, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 538ms, time_since_start: 01h 26m 38s 502ms, eta: 44m 22s 175ms
[32m2021-03-04T19:53:17 | mmf.trainers.callbacks.logistics: [0mprogress: 13400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0910, train/total_loss: 0.0002, train/total_loss/avg: 0.0910, max mem: 4158.0, experiment: run, epoch: 51, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0.00002, ups: 2.44, time: 41s 139ms, time_since_start: 01h 27m 19s 642ms, eta: 59m 05s 047ms
[32m2021-03-04T19:53:47 | mmf.trainers.callbacks.logistics: [0mprogress: 13500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0904, train/total_loss: 0.0002, train/total_loss/avg: 0.0904, max mem: 4158.0, experiment: run, epoch: 51, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 674ms, time_since_start: 01h 27m 50s 316ms, eta: 43m 32s 507ms
[32m2021-03-04T19:54:28 | mmf.trainers.callbacks.logistics: [0mprogress: 13600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0897, train/total_loss: 0.0001, train/total_loss/avg: 0.0897, max mem: 4158.0, experiment: run, epoch: 52, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0.00002, ups: 2.44, time: 41s 033ms, time_since_start: 01h 28m 31s 349ms, eta: 57m 33s 710ms
[32m2021-03-04T19:54:58 | mmf.trainers.callbacks.logistics: [0mprogress: 13700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0890, train/total_loss: 0.0001, train/total_loss/avg: 0.0890, max mem: 4158.0, experiment: run, epoch: 52, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 167ms, time_since_start: 01h 29m 01s 516ms, eta: 41m 48s 881ms
[32m2021-03-04T19:55:29 | mmf.trainers.callbacks.logistics: [0mprogress: 13800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0884, train/total_loss: 0.0001, train/total_loss/avg: 0.0884, max mem: 4158.0, experiment: run, epoch: 52, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 451ms, time_since_start: 01h 29m 31s 968ms, eta: 41m 42s 058ms
[32m2021-03-04T19:56:09 | mmf.trainers.callbacks.logistics: [0mprogress: 13900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0878, train/total_loss: 0.0001, train/total_loss/avg: 0.0878, max mem: 4158.0, experiment: run, epoch: 53, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0.00002, ups: 2.50, time: 40s 541ms, time_since_start: 01h 30m 12s 510ms, eta: 54m 50s 436ms
[32m2021-03-04T19:56:40 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T19:56:40 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T19:56:40 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T19:56:40 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T19:56:42 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T19:56:53 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T19:56:53 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0872, train/total_loss: 0.0001, train/total_loss/avg: 0.0872, max mem: 4158.0, experiment: run, epoch: 53, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0.00002, ups: 2.33, time: 43s 589ms, time_since_start: 01h 30m 56s 100ms, eta: 58m 14s 130ms
[32m2021-03-04T19:56:53 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T19:57:10 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T19:57:10 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, val/hateful_memes/cross_entropy: 2.4377, val/total_loss: 2.4377, val/hateful_memes/accuracy: 0.6704, val/hateful_memes/binary_f1: 0.4516, val/hateful_memes/roc_auc: 0.6894, num_updates: 14000, epoch: 53, iterations: 14000, max_updates: 22000, val_time: 16s 823ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T19:57:51 | mmf.trainers.callbacks.logistics: [0mprogress: 14100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0866, train/total_loss: 0.0001, train/total_loss/avg: 0.0866, max mem: 4158.0, experiment: run, epoch: 54, num_updates: 14100, iterations: 14100, max_updates: 22000, lr: 0.00002, ups: 2.44, time: 41s 065ms, time_since_start: 01h 31m 53s 990ms, eta: 54m 10s 690ms
[32m2021-03-04T19:58:21 | mmf.trainers.callbacks.logistics: [0mprogress: 14200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0860, train/total_loss: 0.0001, train/total_loss/avg: 0.0860, max mem: 4158.0, experiment: run, epoch: 54, num_updates: 14200, iterations: 14200, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 416ms, time_since_start: 01h 32m 24s 407ms, eta: 39m 37s 204ms
[32m2021-03-04T19:58:52 | mmf.trainers.callbacks.logistics: [0mprogress: 14300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0854, train/total_loss: 0.0001, train/total_loss/avg: 0.0854, max mem: 4158.0, experiment: run, epoch: 54, num_updates: 14300, iterations: 14300, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 352ms, time_since_start: 01h 32m 54s 759ms, eta: 39m 01s 828ms
[32m2021-03-04T19:59:33 | mmf.trainers.callbacks.logistics: [0mprogress: 14400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0848, train/total_loss: 0.0002, train/total_loss/avg: 0.0848, max mem: 4158.0, experiment: run, epoch: 55, num_updates: 14400, iterations: 14400, max_updates: 22000, lr: 0.00002, ups: 2.44, time: 41s 064ms, time_since_start: 01h 33m 35s 824ms, eta: 52m 07s 157ms
[32m2021-03-04T20:00:03 | mmf.trainers.callbacks.logistics: [0mprogress: 14500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0842, train/total_loss: 0.0002, train/total_loss/avg: 0.0842, max mem: 4158.0, experiment: run, epoch: 55, num_updates: 14500, iterations: 14500, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 588ms, time_since_start: 01h 34m 06s 413ms, eta: 38m 18s 735ms
[32m2021-03-04T20:00:34 | mmf.trainers.callbacks.logistics: [0mprogress: 14600/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0837, train/total_loss: 0.0002, train/total_loss/avg: 0.0837, max mem: 4158.0, experiment: run, epoch: 55, num_updates: 14600, iterations: 14600, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 859ms, time_since_start: 01h 34m 37s 272ms, eta: 38m 08s 154ms
[32m2021-03-04T20:01:14 | mmf.trainers.callbacks.logistics: [0mprogress: 14700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0831, train/total_loss: 0.0002, train/total_loss/avg: 0.0831, max mem: 4158.0, experiment: run, epoch: 56, num_updates: 14700, iterations: 14700, max_updates: 22000, lr: 0.00002, ups: 2.50, time: 40s 205ms, time_since_start: 01h 35m 17s 477ms, eta: 49m 842ms
[32m2021-03-04T20:01:44 | mmf.trainers.callbacks.logistics: [0mprogress: 14800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0825, train/total_loss: 0.0001, train/total_loss/avg: 0.0825, max mem: 4158.0, experiment: run, epoch: 56, num_updates: 14800, iterations: 14800, max_updates: 22000, lr: 0.00002, ups: 3.45, time: 29s 267ms, time_since_start: 01h 35m 46s 744ms, eta: 35m 11s 461ms
[32m2021-03-04T20:02:24 | mmf.trainers.callbacks.logistics: [0mprogress: 14900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0820, train/total_loss: 0.0001, train/total_loss/avg: 0.0820, max mem: 4158.0, experiment: run, epoch: 57, num_updates: 14900, iterations: 14900, max_updates: 22000, lr: 0.00002, ups: 2.50, time: 40s 050ms, time_since_start: 01h 36m 26s 795ms, eta: 47m 29s 306ms
[32m2021-03-04T20:02:55 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T20:02:55 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T20:02:55 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T20:02:55 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T20:02:58 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T20:03:09 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T20:03:09 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0814, train/total_loss: 0.0001, train/total_loss/avg: 0.0814, max mem: 4158.0, experiment: run, epoch: 57, num_updates: 15000, iterations: 15000, max_updates: 22000, lr: 0.00002, ups: 2.27, time: 44s 960ms, time_since_start: 01h 37m 11s 756ms, eta: 52m 33s 533ms
[32m2021-03-04T20:03:09 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T20:03:21 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T20:03:21 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, val/hateful_memes/cross_entropy: 2.7707, val/total_loss: 2.7707, val/hateful_memes/accuracy: 0.6759, val/hateful_memes/binary_f1: 0.4808, val/hateful_memes/roc_auc: 0.6885, num_updates: 15000, epoch: 57, iterations: 15000, max_updates: 22000, val_time: 12s 390ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T20:03:53 | mmf.trainers.callbacks.logistics: [0mprogress: 15100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0809, train/total_loss: 0.0001, train/total_loss/avg: 0.0809, max mem: 4158.0, experiment: run, epoch: 57, num_updates: 15100, iterations: 15100, max_updates: 22000, lr: 0.00002, ups: 3.23, time: 31s 445ms, time_since_start: 01h 37m 55s 594ms, eta: 36m 14s 077ms
[32m2021-03-04T20:04:34 | mmf.trainers.callbacks.logistics: [0mprogress: 15200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0804, train/total_loss: 0.0001, train/total_loss/avg: 0.0804, max mem: 4158.0, experiment: run, epoch: 58, num_updates: 15200, iterations: 15200, max_updates: 22000, lr: 0.00002, ups: 2.44, time: 41s 496ms, time_since_start: 01h 38m 37s 091ms, eta: 47m 07s 433ms
[32m2021-03-04T20:05:05 | mmf.trainers.callbacks.logistics: [0mprogress: 15300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0798, train/total_loss: 0.0001, train/total_loss/avg: 0.0798, max mem: 4158.0, experiment: run, epoch: 58, num_updates: 15300, iterations: 15300, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 751ms, time_since_start: 01h 39m 07s 842ms, eta: 34m 24s 444ms
[32m2021-03-04T20:05:36 | mmf.trainers.callbacks.logistics: [0mprogress: 15400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0793, train/total_loss: 0.0000, train/total_loss/avg: 0.0793, max mem: 4158.0, experiment: run, epoch: 58, num_updates: 15400, iterations: 15400, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 949ms, time_since_start: 01h 39m 38s 792ms, eta: 34m 06s 741ms
[32m2021-03-04T20:06:17 | mmf.trainers.callbacks.logistics: [0mprogress: 15500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0788, train/total_loss: 0.0000, train/total_loss/avg: 0.0788, max mem: 4158.0, experiment: run, epoch: 59, num_updates: 15500, iterations: 15500, max_updates: 22000, lr: 0.00002, ups: 2.44, time: 41s 239ms, time_since_start: 01h 40m 20s 031ms, eta: 44m 45s 910ms
[32m2021-03-04T20:06:47 | mmf.trainers.callbacks.logistics: [0mprogress: 15600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0783, train/total_loss: 0.0000, train/total_loss/avg: 0.0783, max mem: 4158.0, experiment: run, epoch: 59, num_updates: 15600, iterations: 15600, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 494ms, time_since_start: 01h 40m 50s 525ms, eta: 32m 35s 530ms
[32m2021-03-04T20:07:29 | mmf.trainers.callbacks.logistics: [0mprogress: 15700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0778, train/total_loss: 0.0000, train/total_loss/avg: 0.0778, max mem: 4158.0, experiment: run, epoch: 60, num_updates: 15700, iterations: 15700, max_updates: 22000, lr: 0.00002, ups: 2.44, time: 41s 477ms, time_since_start: 01h 41m 32s 002ms, eta: 43m 38s 295ms
[32m2021-03-04T20:07:59 | mmf.trainers.callbacks.logistics: [0mprogress: 15800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0773, train/total_loss: 0.0000, train/total_loss/avg: 0.0773, max mem: 4158.0, experiment: run, epoch: 60, num_updates: 15800, iterations: 15800, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 342ms, time_since_start: 01h 42m 02s 345ms, eta: 31m 25s 018ms
[32m2021-03-04T20:08:30 | mmf.trainers.callbacks.logistics: [0mprogress: 15900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0769, train/total_loss: 0.0000, train/total_loss/avg: 0.0769, max mem: 4158.0, experiment: run, epoch: 60, num_updates: 15900, iterations: 15900, max_updates: 22000, lr: 0.00002, ups: 3.33, time: 30s 799ms, time_since_start: 01h 42m 33s 144ms, eta: 31m 22s 512ms
[32m2021-03-04T20:09:12 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T20:09:12 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T20:09:12 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T20:09:12 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T20:09:15 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T20:09:25 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T20:09:25 | mmf.trainers.callbacks.logistics: [0mprogress: 16000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0764, train/total_loss: 0.0000, train/total_loss/avg: 0.0764, max mem: 4158.0, experiment: run, epoch: 61, num_updates: 16000, iterations: 16000, max_updates: 22000, lr: 0.00002, ups: 1.82, time: 55s 054ms, time_since_start: 01h 43m 28s 199ms, eta: 55m 09s 882ms
[32m2021-03-04T20:09:25 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T20:09:36 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T20:09:36 | mmf.trainers.callbacks.logistics: [0mprogress: 16000/22000, val/hateful_memes/cross_entropy: 2.9667, val/total_loss: 2.9667, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4432, val/hateful_memes/roc_auc: 0.6826, num_updates: 16000, epoch: 61, iterations: 16000, max_updates: 22000, val_time: 10s 474ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T20:10:07 | mmf.trainers.callbacks.logistics: [0mprogress: 16100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0759, train/total_loss: 0.0000, train/total_loss/avg: 0.0759, max mem: 4158.0, experiment: run, epoch: 61, num_updates: 16100, iterations: 16100, max_updates: 22000, lr: 0.00001, ups: 3.23, time: 31s 276ms, time_since_start: 01h 44m 09s 952ms, eta: 30m 49s 022ms
[32m2021-03-04T20:10:38 | mmf.trainers.callbacks.logistics: [0mprogress: 16200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0754, train/total_loss: 0.0000, train/total_loss/avg: 0.0754, max mem: 4158.0, experiment: run, epoch: 61, num_updates: 16200, iterations: 16200, max_updates: 22000, lr: 0.00001, ups: 3.23, time: 31s 220ms, time_since_start: 01h 44m 41s 173ms, eta: 30m 14s 423ms
[32m2021-03-04T20:11:19 | mmf.trainers.callbacks.logistics: [0mprogress: 16300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0750, train/total_loss: 0.0000, train/total_loss/avg: 0.0750, max mem: 4158.0, experiment: run, epoch: 62, num_updates: 16300, iterations: 16300, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 253ms, time_since_start: 01h 45m 22s 427ms, eta: 39m 16s 174ms
[32m2021-03-04T20:11:50 | mmf.trainers.callbacks.logistics: [0mprogress: 16400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0745, train/total_loss: 0.0000, train/total_loss/avg: 0.0745, max mem: 4158.0, experiment: run, epoch: 62, num_updates: 16400, iterations: 16400, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 572ms, time_since_start: 01h 45m 53s 000ms, eta: 28m 35s 495ms
[32m2021-03-04T20:12:31 | mmf.trainers.callbacks.logistics: [0mprogress: 16500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0741, train/total_loss: 0.0000, train/total_loss/avg: 0.0741, max mem: 4158.0, experiment: run, epoch: 63, num_updates: 16500, iterations: 16500, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 226ms, time_since_start: 01h 46m 34s 227ms, eta: 37m 52s 016ms
[32m2021-03-04T20:13:03 | mmf.trainers.callbacks.logistics: [0mprogress: 16600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0736, train/total_loss: 0.0000, train/total_loss/avg: 0.0736, max mem: 4158.0, experiment: run, epoch: 63, num_updates: 16600, iterations: 16600, max_updates: 22000, lr: 0.00001, ups: 3.23, time: 31s 313ms, time_since_start: 01h 47m 05s 540ms, eta: 28m 14s 315ms
[32m2021-03-04T20:13:34 | mmf.trainers.callbacks.logistics: [0mprogress: 16700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0732, train/total_loss: 0.0000, train/total_loss/avg: 0.0732, max mem: 4158.0, experiment: run, epoch: 63, num_updates: 16700, iterations: 16700, max_updates: 22000, lr: 0.00001, ups: 3.23, time: 31s 534ms, time_since_start: 01h 47m 37s 075ms, eta: 27m 54s 689ms
[32m2021-03-04T20:14:16 | mmf.trainers.callbacks.logistics: [0mprogress: 16800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0727, train/total_loss: 0.0000, train/total_loss/avg: 0.0727, max mem: 4158.0, experiment: run, epoch: 64, num_updates: 16800, iterations: 16800, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 537ms, time_since_start: 01h 48m 18s 612ms, eta: 36m 04s 264ms
[32m2021-03-04T20:14:46 | mmf.trainers.callbacks.logistics: [0mprogress: 16900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0723, train/total_loss: 0.0000, train/total_loss/avg: 0.0723, max mem: 4158.0, experiment: run, epoch: 64, num_updates: 16900, iterations: 16900, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 122ms, time_since_start: 01h 48m 48s 735ms, eta: 25m 39s 342ms
[32m2021-03-04T20:15:16 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T20:15:16 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T20:15:16 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T20:15:16 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T20:15:19 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T20:15:29 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T20:15:29 | mmf.trainers.callbacks.logistics: [0mprogress: 17000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0719, train/total_loss: 0.0000, train/total_loss/avg: 0.0719, max mem: 4158.0, experiment: run, epoch: 64, num_updates: 17000, iterations: 17000, max_updates: 22000, lr: 0.00001, ups: 2.33, time: 43s 477ms, time_since_start: 01h 49m 32s 213ms, eta: 36m 18s 231ms
[32m2021-03-04T20:15:29 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T20:15:42 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T20:15:42 | mmf.trainers.callbacks.logistics: [0mprogress: 17000/22000, val/hateful_memes/cross_entropy: 2.5627, val/total_loss: 2.5627, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4961, val/hateful_memes/roc_auc: 0.6879, num_updates: 17000, epoch: 64, iterations: 17000, max_updates: 22000, val_time: 12s 758ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T20:16:23 | mmf.trainers.callbacks.logistics: [0mprogress: 17100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0715, train/total_loss: 0.0000, train/total_loss/avg: 0.0715, max mem: 4158.0, experiment: run, epoch: 65, num_updates: 17100, iterations: 17100, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 896ms, time_since_start: 01h 50m 25s 869ms, eta: 33m 27s 929ms
[32m2021-03-04T20:16:54 | mmf.trainers.callbacks.logistics: [0mprogress: 17200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0710, train/total_loss: 0.0000, train/total_loss/avg: 0.0710, max mem: 4158.0, experiment: run, epoch: 65, num_updates: 17200, iterations: 17200, max_updates: 22000, lr: 0.00001, ups: 3.23, time: 31s 137ms, time_since_start: 01h 50m 57s 007ms, eta: 24m 57s 585ms
[32m2021-03-04T20:17:36 | mmf.trainers.callbacks.logistics: [0mprogress: 17300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0706, train/total_loss: 0.0000, train/total_loss/avg: 0.0706, max mem: 4158.0, experiment: run, epoch: 66, num_updates: 17300, iterations: 17300, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 630ms, time_since_start: 01h 51m 38s 638ms, eta: 32m 40s 565ms
[32m2021-03-04T20:18:06 | mmf.trainers.callbacks.logistics: [0mprogress: 17400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0702, train/total_loss: 0.0000, train/total_loss/avg: 0.0702, max mem: 4158.0, experiment: run, epoch: 66, num_updates: 17400, iterations: 17400, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 128ms, time_since_start: 01h 52m 08s 766ms, eta: 23m 08s 685ms
[32m2021-03-04T20:18:36 | mmf.trainers.callbacks.logistics: [0mprogress: 17500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0699, train/total_loss: 0.0000, train/total_loss/avg: 0.0699, max mem: 4158.0, experiment: run, epoch: 66, num_updates: 17500, iterations: 17500, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 309ms, time_since_start: 01h 52m 39s 075ms, eta: 22m 46s 643ms
[32m2021-03-04T20:19:17 | mmf.trainers.callbacks.logistics: [0mprogress: 17600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0695, train/total_loss: 0.0000, train/total_loss/avg: 0.0695, max mem: 4158.0, experiment: run, epoch: 67, num_updates: 17600, iterations: 17600, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 184ms, time_since_start: 01h 53m 20s 260ms, eta: 30m 15s 724ms
[32m2021-03-04T20:19:48 | mmf.trainers.callbacks.logistics: [0mprogress: 17700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0691, train/total_loss: 0.0000, train/total_loss/avg: 0.0691, max mem: 4158.0, experiment: run, epoch: 67, num_updates: 17700, iterations: 17700, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 651ms, time_since_start: 01h 53m 50s 911ms, eta: 22m 650ms
[32m2021-03-04T20:20:18 | mmf.trainers.callbacks.logistics: [0mprogress: 17800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0687, train/total_loss: 0.0000, train/total_loss/avg: 0.0687, max mem: 4158.0, experiment: run, epoch: 67, num_updates: 17800, iterations: 17800, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 544ms, time_since_start: 01h 54m 21s 456ms, eta: 21m 25s 436ms
[32m2021-03-04T20:20:59 | mmf.trainers.callbacks.logistics: [0mprogress: 17900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0683, train/total_loss: 0.0000, train/total_loss/avg: 0.0683, max mem: 4158.0, experiment: run, epoch: 68, num_updates: 17900, iterations: 17900, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 574ms, time_since_start: 01h 55m 02s 030ms, eta: 27m 46s 874ms
[32m2021-03-04T20:21:29 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T20:21:29 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T20:21:29 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T20:21:29 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T20:21:32 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T20:21:43 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T20:21:43 | mmf.trainers.callbacks.logistics: [0mprogress: 18000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0679, train/total_loss: 0.0000, train/total_loss/avg: 0.0679, max mem: 4158.0, experiment: run, epoch: 68, num_updates: 18000, iterations: 18000, max_updates: 22000, lr: 0.00001, ups: 2.33, time: 43s 628ms, time_since_start: 01h 55m 45s 659ms, eta: 29m 08s 649ms
[32m2021-03-04T20:21:43 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T20:21:53 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T20:21:53 | mmf.trainers.callbacks.logistics: [0mprogress: 18000/22000, val/hateful_memes/cross_entropy: 3.3089, val/total_loss: 3.3089, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.4630, val/hateful_memes/roc_auc: 0.6926, num_updates: 18000, epoch: 68, iterations: 18000, max_updates: 22000, val_time: 10s 475ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T20:22:34 | mmf.trainers.callbacks.logistics: [0mprogress: 18100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0675, train/total_loss: 0.0000, train/total_loss/avg: 0.0675, max mem: 4158.0, experiment: run, epoch: 69, num_updates: 18100, iterations: 18100, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 416ms, time_since_start: 01h 56m 36s 553ms, eta: 26m 19s 382ms
[32m2021-03-04T20:23:04 | mmf.trainers.callbacks.logistics: [0mprogress: 18200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0672, train/total_loss: 0.0000, train/total_loss/avg: 0.0672, max mem: 4158.0, experiment: run, epoch: 69, num_updates: 18200, iterations: 18200, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 547ms, time_since_start: 01h 57m 07s 101ms, eta: 19m 23s 143ms
[32m2021-03-04T20:23:35 | mmf.trainers.callbacks.logistics: [0mprogress: 18300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0668, train/total_loss: 0.0000, train/total_loss/avg: 0.0668, max mem: 4158.0, experiment: run, epoch: 69, num_updates: 18300, iterations: 18300, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 619ms, time_since_start: 01h 57m 37s 720ms, eta: 18m 55s 175ms
[32m2021-03-04T20:24:16 | mmf.trainers.callbacks.logistics: [0mprogress: 18400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0664, train/total_loss: 0.0000, train/total_loss/avg: 0.0664, max mem: 4158.0, experiment: run, epoch: 70, num_updates: 18400, iterations: 18400, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 023ms, time_since_start: 01h 58m 18s 744ms, eta: 24m 39s 800ms
[32m2021-03-04T20:24:46 | mmf.trainers.callbacks.logistics: [0mprogress: 18500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0661, train/total_loss: 0.0000, train/total_loss/avg: 0.0661, max mem: 4158.0, experiment: run, epoch: 70, num_updates: 18500, iterations: 18500, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 695ms, time_since_start: 01h 58m 49s 439ms, eta: 17m 56s 486ms
[32m2021-03-04T20:25:17 | mmf.trainers.callbacks.logistics: [0mprogress: 18600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0657, train/total_loss: 0.0000, train/total_loss/avg: 0.0657, max mem: 4158.0, experiment: run, epoch: 70, num_updates: 18600, iterations: 18600, max_updates: 22000, lr: 0.00001, ups: 3.23, time: 31s 006ms, time_since_start: 01h 59m 20s 445ms, eta: 17m 36s 324ms
[32m2021-03-04T20:25:58 | mmf.trainers.callbacks.logistics: [0mprogress: 18700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0654, train/total_loss: 0.0000, train/total_loss/avg: 0.0654, max mem: 4158.0, experiment: run, epoch: 71, num_updates: 18700, iterations: 18700, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 665ms, time_since_start: 02h 01s 111ms, eta: 22m 24s 643ms
[32m2021-03-04T20:26:29 | mmf.trainers.callbacks.logistics: [0mprogress: 18800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0650, train/total_loss: 0.0000, train/total_loss/avg: 0.0650, max mem: 4158.0, experiment: run, epoch: 71, num_updates: 18800, iterations: 18800, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 608ms, time_since_start: 02h 31s 719ms, eta: 16m 21s 433ms
[32m2021-03-04T20:27:10 | mmf.trainers.callbacks.logistics: [0mprogress: 18900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0647, train/total_loss: 0.0000, train/total_loss/avg: 0.0647, max mem: 4158.0, experiment: run, epoch: 72, num_updates: 18900, iterations: 18900, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 948ms, time_since_start: 02h 01m 12s 668ms, eta: 21m 11s 949ms
[32m2021-03-04T20:27:40 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T20:27:40 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T20:27:40 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T20:27:40 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T20:27:43 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T20:27:53 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T20:27:53 | mmf.trainers.callbacks.logistics: [0mprogress: 19000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0643, train/total_loss: 0.0000, train/total_loss/avg: 0.0643, max mem: 4158.0, experiment: run, epoch: 72, num_updates: 19000, iterations: 19000, max_updates: 22000, lr: 0.00001, ups: 2.33, time: 43s 749ms, time_since_start: 02h 01m 56s 418ms, eta: 21m 55s 117ms
[32m2021-03-04T20:27:53 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T20:28:04 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T20:28:04 | mmf.trainers.callbacks.logistics: [0mprogress: 19000/22000, val/hateful_memes/cross_entropy: 3.3711, val/total_loss: 3.3711, val/hateful_memes/accuracy: 0.6963, val/hateful_memes/binary_f1: 0.4744, val/hateful_memes/roc_auc: 0.6948, num_updates: 19000, epoch: 72, iterations: 19000, max_updates: 22000, val_time: 10s 804ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T20:28:35 | mmf.trainers.callbacks.logistics: [0mprogress: 19100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0640, train/total_loss: 0.0000, train/total_loss/avg: 0.0640, max mem: 4158.0, experiment: run, epoch: 72, num_updates: 19100, iterations: 19100, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 355ms, time_since_start: 02h 02m 37s 580ms, eta: 14m 42s 084ms
[32m2021-03-04T20:29:15 | mmf.trainers.callbacks.logistics: [0mprogress: 19200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0637, train/total_loss: 0.0000, train/total_loss/avg: 0.0637, max mem: 4158.0, experiment: run, epoch: 73, num_updates: 19200, iterations: 19200, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 588ms, time_since_start: 02h 03m 18s 169ms, eta: 18m 58s 746ms
[32m2021-03-04T20:29:46 | mmf.trainers.callbacks.logistics: [0mprogress: 19300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0633, train/total_loss: 0.0000, train/total_loss/avg: 0.0633, max mem: 4158.0, experiment: run, epoch: 73, num_updates: 19300, iterations: 19300, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 616ms, time_since_start: 02h 03m 48s 785ms, eta: 13m 48s 293ms
[32m2021-03-04T20:30:17 | mmf.trainers.callbacks.logistics: [0mprogress: 19400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0630, train/total_loss: 0.0000, train/total_loss/avg: 0.0630, max mem: 4158.0, experiment: run, epoch: 73, num_updates: 19400, iterations: 19400, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 938ms, time_since_start: 02h 04m 19s 723ms, eta: 13m 26s 003ms
[32m2021-03-04T20:30:58 | mmf.trainers.callbacks.logistics: [0mprogress: 19500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0627, train/total_loss: 0.0000, train/total_loss/avg: 0.0627, max mem: 4158.0, experiment: run, epoch: 74, num_updates: 19500, iterations: 19500, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 475ms, time_since_start: 02h 05m 01s 198ms, eta: 17m 18s 957ms
[32m2021-03-04T20:31:29 | mmf.trainers.callbacks.logistics: [0mprogress: 19600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0624, train/total_loss: 0.0000, train/total_loss/avg: 0.0624, max mem: 4158.0, experiment: run, epoch: 74, num_updates: 19600, iterations: 19600, max_updates: 22000, lr: 0.00001, ups: 3.33, time: 30s 686ms, time_since_start: 02h 05m 31s 885ms, eta: 12m 17s 947ms
[32m2021-03-04T20:32:10 | mmf.trainers.callbacks.logistics: [0mprogress: 19700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0620, train/total_loss: 0.0000, train/total_loss/avg: 0.0620, max mem: 4158.0, experiment: run, epoch: 75, num_updates: 19700, iterations: 19700, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 406ms, time_since_start: 02h 06m 13s 292ms, eta: 15m 54s 255ms
[32m2021-03-04T20:32:41 | mmf.trainers.callbacks.logistics: [0mprogress: 19800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0617, train/total_loss: 0.0000, train/total_loss/avg: 0.0617, max mem: 4158.0, experiment: run, epoch: 75, num_updates: 19800, iterations: 19800, max_updates: 22000, lr: 0.00001, ups: 3.23, time: 31s 135ms, time_since_start: 02h 06m 44s 427ms, eta: 11m 26s 353ms
[32m2021-03-04T20:33:13 | mmf.trainers.callbacks.logistics: [0mprogress: 19900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0614, train/total_loss: 0.0000, train/total_loss/avg: 0.0614, max mem: 4158.0, experiment: run, epoch: 75, num_updates: 19900, iterations: 19900, max_updates: 22000, lr: 0.00001, ups: 3.23, time: 31s 513ms, time_since_start: 02h 07m 15s 940ms, eta: 11m 03s 102ms
[32m2021-03-04T20:33:55 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T20:33:55 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T20:33:55 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T20:33:55 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T20:34:06 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T20:34:16 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T20:34:16 | mmf.trainers.callbacks.logistics: [0mprogress: 20000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0611, train/total_loss: 0.0000, train/total_loss/avg: 0.0611, max mem: 4158.0, experiment: run, epoch: 76, num_updates: 20000, iterations: 20000, max_updates: 22000, lr: 0.00001, ups: 1.59, time: 01m 03s 150ms, time_since_start: 02h 08m 19s 091ms, eta: 21m 05s 527ms
[32m2021-03-04T20:34:16 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T20:34:26 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T20:34:26 | mmf.trainers.callbacks.logistics: [0mprogress: 20000/22000, val/hateful_memes/cross_entropy: 2.7983, val/total_loss: 2.7983, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.4734, val/hateful_memes/roc_auc: 0.6874, num_updates: 20000, epoch: 76, iterations: 20000, max_updates: 22000, val_time: 10s 279ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T20:34:57 | mmf.trainers.callbacks.logistics: [0mprogress: 20100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0608, train/total_loss: 0.0000, train/total_loss/avg: 0.0608, max mem: 4158.0, experiment: run, epoch: 76, num_updates: 20100, iterations: 20100, max_updates: 22000, lr: 0., ups: 3.33, time: 30s 591ms, time_since_start: 02h 08m 59s 964ms, eta: 09m 42s 410ms
[32m2021-03-04T20:35:28 | mmf.trainers.callbacks.logistics: [0mprogress: 20200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0605, train/total_loss: 0.0000, train/total_loss/avg: 0.0605, max mem: 4158.0, experiment: run, epoch: 76, num_updates: 20200, iterations: 20200, max_updates: 22000, lr: 0., ups: 3.33, time: 30s 702ms, time_since_start: 02h 09m 30s 666ms, eta: 09m 13s 753ms
[32m2021-03-04T20:36:09 | mmf.trainers.callbacks.logistics: [0mprogress: 20300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0602, train/total_loss: 0.0000, train/total_loss/avg: 0.0602, max mem: 4158.0, experiment: run, epoch: 77, num_updates: 20300, iterations: 20300, max_updates: 22000, lr: 0., ups: 2.44, time: 41s 144ms, time_since_start: 02h 10m 11s 810ms, eta: 11m 40s 847ms
[32m2021-03-04T20:36:39 | mmf.trainers.callbacks.logistics: [0mprogress: 20400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0599, train/total_loss: 0.0000, train/total_loss/avg: 0.0599, max mem: 4158.0, experiment: run, epoch: 77, num_updates: 20400, iterations: 20400, max_updates: 22000, lr: 0., ups: 3.33, time: 30s 673ms, time_since_start: 02h 10m 42s 484ms, eta: 08m 11s 765ms
[32m2021-03-04T20:37:21 | mmf.trainers.callbacks.logistics: [0mprogress: 20500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0596, train/total_loss: 0.0000, train/total_loss/avg: 0.0596, max mem: 4158.0, experiment: run, epoch: 78, num_updates: 20500, iterations: 20500, max_updates: 22000, lr: 0., ups: 2.44, time: 41s 315ms, time_since_start: 02h 11m 23s 799ms, eta: 10m 20s 964ms
[32m2021-03-04T20:37:51 | mmf.trainers.callbacks.logistics: [0mprogress: 20600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0593, train/total_loss: 0.0000, train/total_loss/avg: 0.0593, max mem: 4158.0, experiment: run, epoch: 78, num_updates: 20600, iterations: 20600, max_updates: 22000, lr: 0., ups: 3.33, time: 30s 306ms, time_since_start: 02h 11m 54s 106ms, eta: 07m 05s 140ms
[32m2021-03-04T20:38:22 | mmf.trainers.callbacks.logistics: [0mprogress: 20700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0590, train/total_loss: 0.0000, train/total_loss/avg: 0.0590, max mem: 4158.0, experiment: run, epoch: 78, num_updates: 20700, iterations: 20700, max_updates: 22000, lr: 0., ups: 3.33, time: 30s 734ms, time_since_start: 02h 12m 24s 841ms, eta: 06m 40s 352ms
[32m2021-03-04T20:39:02 | mmf.trainers.callbacks.logistics: [0mprogress: 20800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0588, train/total_loss: 0.0000, train/total_loss/avg: 0.0588, max mem: 4158.0, experiment: run, epoch: 79, num_updates: 20800, iterations: 20800, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 461ms, time_since_start: 02h 13m 05s 302ms, eta: 08m 06s 505ms
[32m2021-03-04T20:39:32 | mmf.trainers.callbacks.logistics: [0mprogress: 20900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0585, train/total_loss: 0.0000, train/total_loss/avg: 0.0585, max mem: 4158.0, experiment: run, epoch: 79, num_updates: 20900, iterations: 20900, max_updates: 22000, lr: 0., ups: 3.45, time: 29s 609ms, time_since_start: 02h 13m 34s 912ms, eta: 05m 26s 360ms
[32m2021-03-04T20:40:02 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T20:40:02 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T20:40:02 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T20:40:02 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T20:40:13 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T20:40:23 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T20:40:23 | mmf.trainers.callbacks.logistics: [0mprogress: 21000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0582, train/total_loss: 0.0000, train/total_loss/avg: 0.0582, max mem: 4158.0, experiment: run, epoch: 79, num_updates: 21000, iterations: 21000, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 461ms, time_since_start: 02h 14m 26s 374ms, eta: 08m 35s 647ms
[32m2021-03-04T20:40:23 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T20:40:34 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T20:40:34 | mmf.trainers.callbacks.logistics: [0mprogress: 21000/22000, val/hateful_memes/cross_entropy: 2.9467, val/total_loss: 2.9467, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.4622, val/hateful_memes/roc_auc: 0.6893, num_updates: 21000, epoch: 79, iterations: 21000, max_updates: 22000, val_time: 10s 462ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T20:41:15 | mmf.trainers.callbacks.logistics: [0mprogress: 21100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0579, train/total_loss: 0.0000, train/total_loss/avg: 0.0579, max mem: 4158.0, experiment: run, epoch: 80, num_updates: 21100, iterations: 21100, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 802ms, time_since_start: 02h 15m 17s 641ms, eta: 06m 07s 959ms
[32m2021-03-04T20:41:45 | mmf.trainers.callbacks.logistics: [0mprogress: 21200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0576, train/total_loss: 0.0000, train/total_loss/avg: 0.0576, max mem: 4158.0, experiment: run, epoch: 80, num_updates: 21200, iterations: 21200, max_updates: 22000, lr: 0., ups: 3.33, time: 30s 507ms, time_since_start: 02h 15m 48s 149ms, eta: 04m 04s 551ms
[32m2021-03-04T20:42:26 | mmf.trainers.callbacks.logistics: [0mprogress: 21300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0574, train/total_loss: 0.0000, train/total_loss/avg: 0.0574, max mem: 4158.0, experiment: run, epoch: 81, num_updates: 21300, iterations: 21300, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 960ms, time_since_start: 02h 16m 29s 110ms, eta: 04m 47s 298ms
[32m2021-03-04T20:42:57 | mmf.trainers.callbacks.logistics: [0mprogress: 21400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0571, train/total_loss: 0.0000, train/total_loss/avg: 0.0571, max mem: 4158.0, experiment: run, epoch: 81, num_updates: 21400, iterations: 21400, max_updates: 22000, lr: 0., ups: 3.33, time: 30s 559ms, time_since_start: 02h 16m 59s 670ms, eta: 03m 03s 724ms
[32m2021-03-04T20:43:28 | mmf.trainers.callbacks.logistics: [0mprogress: 21500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0568, train/total_loss: 0.0000, train/total_loss/avg: 0.0568, max mem: 4158.0, experiment: run, epoch: 81, num_updates: 21500, iterations: 21500, max_updates: 22000, lr: 0., ups: 3.23, time: 31s 063ms, time_since_start: 02h 17m 30s 734ms, eta: 02m 35s 630ms
[32m2021-03-04T20:44:09 | mmf.trainers.callbacks.logistics: [0mprogress: 21600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0566, train/total_loss: 0.0000, train/total_loss/avg: 0.0566, max mem: 4158.0, experiment: run, epoch: 82, num_updates: 21600, iterations: 21600, max_updates: 22000, lr: 0., ups: 2.44, time: 41s 256ms, time_since_start: 02h 18m 11s 990ms, eta: 02m 45s 357ms
[32m2021-03-04T20:44:39 | mmf.trainers.callbacks.logistics: [0mprogress: 21700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0563, train/total_loss: 0.0000, train/total_loss/avg: 0.0563, max mem: 4158.0, experiment: run, epoch: 82, num_updates: 21700, iterations: 21700, max_updates: 22000, lr: 0., ups: 3.33, time: 30s 337ms, time_since_start: 02h 18m 42s 328ms, eta: 01m 31s 193ms
[32m2021-03-04T20:45:10 | mmf.trainers.callbacks.logistics: [0mprogress: 21800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0561, train/total_loss: 0.0000, train/total_loss/avg: 0.0561, max mem: 4158.0, experiment: run, epoch: 82, num_updates: 21800, iterations: 21800, max_updates: 22000, lr: 0., ups: 3.33, time: 30s 560ms, time_since_start: 02h 19m 12s 888ms, eta: 01m 01s 243ms
[32m2021-03-04T20:45:51 | mmf.trainers.callbacks.logistics: [0mprogress: 21900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0558, train/total_loss: 0.0000, train/total_loss/avg: 0.0558, max mem: 4158.0, experiment: run, epoch: 83, num_updates: 21900, iterations: 21900, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 955ms, time_since_start: 02h 19m 53s 844ms, eta: 41s 037ms
[32m2021-03-04T20:46:22 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T20:46:22 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T20:46:22 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T20:46:22 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T20:46:33 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T20:46:44 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T20:46:44 | mmf.trainers.callbacks.logistics: [0mprogress: 22000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0555, train/total_loss: 0.0000, train/total_loss/avg: 0.0555, max mem: 4158.0, experiment: run, epoch: 83, num_updates: 22000, iterations: 22000, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 987ms, time_since_start: 02h 20m 46s 831ms, eta: 0ms
[32m2021-03-04T20:46:44 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T20:46:54 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T20:46:54 | mmf.trainers.callbacks.logistics: [0mprogress: 22000/22000, val/hateful_memes/cross_entropy: 3.0006, val/total_loss: 3.0006, val/hateful_memes/accuracy: 0.6759, val/hateful_memes/binary_f1: 0.4517, val/hateful_memes/roc_auc: 0.6885, num_updates: 22000, epoch: 83, iterations: 22000, max_updates: 22000, val_time: 10s 268ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.695758
[32m2021-03-04T20:46:55 | mmf.trainers.core.training_loop: [0mStepping into final validation check
[32m2021-03-04T20:46:55 | mmf.utils.checkpoint: [0mRestoring checkpoint
[32m2021-03-04T20:46:55 | mmf.utils.checkpoint: [0mLoading checkpoint
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.embeddings.position_ids from model.bert.mmbt.transformer.embeddings.position_ids
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.embeddings.word_embeddings.weight from model.bert.mmbt.transformer.embeddings.word_embeddings.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.embeddings.position_embeddings.weight from model.bert.mmbt.transformer.embeddings.position_embeddings.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.embeddings.token_type_embeddings.weight from model.bert.mmbt.transformer.embeddings.token_type_embeddings.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.embeddings.LayerNorm.weight from model.bert.mmbt.transformer.embeddings.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.embeddings.LayerNorm.bias from model.bert.mmbt.transformer.embeddings.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.0.attention.self.query.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.0.attention.self.query.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.0.attention.self.key.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.0.attention.self.key.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.0.attention.self.value.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.0.attention.self.value.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.0.attention.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.0.attention.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.0.attention.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.0.attention.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.0.intermediate.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.0.intermediate.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.0.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.0.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.0.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.0.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.1.attention.self.query.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.1.attention.self.query.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.1.attention.self.key.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.1.attention.self.key.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.1.attention.self.value.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.1.attention.self.value.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.1.attention.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.1.attention.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.1.attention.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.1.attention.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.1.intermediate.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.1.intermediate.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.1.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.1.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.1.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.1.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.2.attention.self.query.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.2.attention.self.query.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.2.attention.self.key.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.2.attention.self.key.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.2.attention.self.value.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.2.attention.self.value.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.2.attention.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.2.attention.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.2.attention.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.2.attention.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.2.intermediate.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.2.intermediate.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.2.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.2.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.2.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.2.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.3.attention.self.query.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.3.attention.self.query.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.3.attention.self.key.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.3.attention.self.key.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.3.attention.self.value.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.3.attention.self.value.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.3.attention.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.3.attention.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.3.attention.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.3.attention.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.3.intermediate.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.3.intermediate.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.3.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.3.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.3.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.3.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.4.attention.self.query.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.4.attention.self.query.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.4.attention.self.key.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.4.attention.self.key.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.4.attention.self.value.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.4.attention.self.value.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.4.attention.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.4.attention.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.4.attention.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.4.attention.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.4.intermediate.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.4.intermediate.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.4.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.4.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.4.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.4.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.5.attention.self.query.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.5.attention.self.query.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.5.attention.self.key.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.5.attention.self.key.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.5.attention.self.value.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.5.attention.self.value.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.5.attention.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.5.attention.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.5.attention.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.5.attention.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.5.intermediate.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.5.intermediate.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.5.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.5.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.5.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.5.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.6.attention.self.query.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.6.attention.self.query.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.6.attention.self.key.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.6.attention.self.key.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.6.attention.self.value.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.6.attention.self.value.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.6.attention.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.6.attention.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.6.attention.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.6.attention.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.6.intermediate.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.6.intermediate.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.6.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.6.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.6.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.6.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.7.attention.self.query.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.7.attention.self.query.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.7.attention.self.key.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.7.attention.self.key.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.7.attention.self.value.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.7.attention.self.value.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.7.attention.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.7.attention.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.7.attention.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.7.attention.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.7.intermediate.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.7.intermediate.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.7.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.7.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.7.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.7.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.8.attention.self.query.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.8.attention.self.query.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.8.attention.self.key.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.8.attention.self.key.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.8.attention.self.value.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.8.attention.self.value.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.8.attention.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.8.attention.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.8.attention.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.8.attention.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.8.intermediate.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.8.intermediate.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.8.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.8.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.8.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.8.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.9.attention.self.query.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.9.attention.self.query.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.9.attention.self.key.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.9.attention.self.key.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.9.attention.self.value.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.9.attention.self.value.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.9.attention.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.9.attention.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.9.attention.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.9.attention.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.9.intermediate.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.9.intermediate.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.9.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.9.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.9.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.9.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.10.attention.self.query.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.10.attention.self.query.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.10.attention.self.key.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.10.attention.self.key.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.10.attention.self.value.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.10.attention.self.value.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.10.attention.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.10.attention.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.10.attention.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.10.attention.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.10.intermediate.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.10.intermediate.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.10.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.10.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.10.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.10.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.11.attention.self.query.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.11.attention.self.query.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.11.attention.self.key.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.11.attention.self.key.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.11.attention.self.value.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.11.attention.self.value.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.11.attention.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.11.attention.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.11.attention.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.11.attention.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.11.intermediate.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.11.intermediate.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.11.output.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.11.output.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.11.output.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.11.output.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.pooler.dense.weight from model.bert.mmbt.transformer.pooler.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.pooler.dense.bias from model.bert.mmbt.transformer.pooler.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.lc.weight from model.bert.mmbt.modal_encoder.encoder.lc.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.lc.bias from model.bert.mmbt.modal_encoder.encoder.lc.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.proj_embeddings.weight from model.bert.mmbt.modal_encoder.proj_embeddings.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.proj_embeddings.bias from model.bert.mmbt.modal_encoder.proj_embeddings.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.position_embeddings.weight from model.bert.mmbt.modal_encoder.position_embeddings.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.token_type_embeddings.weight from model.bert.mmbt.modal_encoder.token_type_embeddings.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.word_embeddings.weight from model.bert.mmbt.modal_encoder.word_embeddings.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.LayerNorm.weight from model.bert.mmbt.modal_encoder.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.LayerNorm.bias from model.bert.mmbt.modal_encoder.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.dense.weight from model.classifier.0.dense.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.dense.bias from model.classifier.0.dense.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.LayerNorm.weight from model.classifier.0.LayerNorm.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.LayerNorm.bias from model.classifier.0.LayerNorm.bias
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.1.weight from model.classifier.1.weight
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.1.bias from model.classifier.1.bias
[5m[31mWARNING[0m [32m2021-03-04T20:47:05 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T20:47:05 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mCheckpoint loaded.
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mCurrent num updates: 7000
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mCurrent iteration: 7000
[32m2021-03-04T20:47:05 | mmf.utils.checkpoint: [0mCurrent epoch: 27
[32m2021-03-04T20:47:06 | mmf.trainers.mmf_trainer: [0mStarting inference on val set
  0%|          | 0/68 [00:00<?, ?it/s]  1%|â–         | 1/68 [00:09<11:09,  9.99s/it]  3%|â–Ž         | 2/68 [00:10<04:35,  4.18s/it]  6%|â–Œ         | 4/68 [00:10<01:42,  1.60s/it]  9%|â–‰         | 6/68 [00:10<00:54,  1.13it/s] 12%|â–ˆâ–        | 8/68 [00:10<00:33,  1.81it/s] 15%|â–ˆâ–        | 10/68 [00:10<00:22,  2.62it/s] 18%|â–ˆâ–Š        | 12/68 [00:10<00:15,  3.67it/s] 21%|â–ˆâ–ˆ        | 14/68 [00:10<00:11,  4.91it/s] 24%|â–ˆâ–ˆâ–Ž       | 16/68 [00:11<00:08,  6.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 17/68 [00:11<00:34,  1.48it/s][32m2021-03-04T20:47:18 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T20:47:18 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, val/hateful_memes/cross_entropy: 1.9013, val/total_loss: 1.9013, val/hateful_memes/accuracy: 0.6648, val/hateful_memes/binary_f1: 0.4488, val/hateful_memes/roc_auc: 0.6958
[32m2021-03-04T20:47:18 | mmf.trainers.callbacks.logistics: [0mFinished run in 02h 21m 20s 612ms

Training MMBT_FEATURES complete
********************************************************************
Training MMBT_DEFAULTS
[32m2021-03-04T20:47:23 | mmf.utils.configuration: [0mOverriding option config to projects/hateful_memes/configs/mmbt/defaults.yaml
[32m2021-03-04T20:47:23 | mmf.utils.configuration: [0mOverriding option model to mmbt
[32m2021-03-04T20:47:23 | mmf.utils.configuration: [0mOverriding option datasets to hateful_memes
[32m2021-03-04T20:47:23 | mmf.utils.configuration: [0mOverriding option run_type to train_val
[32m2021-03-04T20:47:23 | mmf.utils.configuration: [0mOverriding option checkpoint.max_to_keep to 3
[32m2021-03-04T20:47:25 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T20:47:25 | mmf.utils.distributed: [0mDistributed Init (Rank 3): tcp://localhost:15350
[32m2021-03-04T20:47:25 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T20:47:25 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T20:47:25 | mmf.utils.distributed: [0mXLA Mode:None
[32m2021-03-04T20:47:25 | mmf.utils.distributed: [0mDistributed Init (Rank 0): tcp://localhost:15350
[32m2021-03-04T20:47:25 | mmf.utils.distributed: [0mDistributed Init (Rank 1): tcp://localhost:15350
[32m2021-03-04T20:47:25 | mmf.utils.distributed: [0mDistributed Init (Rank 2): tcp://localhost:15350
[32m2021-03-04T20:47:26 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 3
[32m2021-03-04T20:47:26 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 2
[32m2021-03-04T20:47:26 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 1
[32m2021-03-04T20:47:26 | mmf.utils.distributed: [0mInitialized Host gnode42 as Rank 0
[32m2021-03-04T20:47:28 | mmf: [0mLogging to: /scratch/sagarsj42/save/train.log
[32m2021-03-04T20:47:28 | mmf_cli.run: [0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/mmbt/defaults.yaml', 'model=mmbt', 'dataset=hateful_memes', 'run_type=train_val', 'checkpoint.max_to_keep=3'])
[32m2021-03-04T20:47:28 | mmf_cli.run: [0mTorch version: 1.6.0
[32m2021-03-04T20:47:28 | mmf.utils.general: [0mCUDA Device 0 is: GeForce GTX 1080 Ti
[32m2021-03-04T20:47:28 | mmf_cli.run: [0mUsing seed 28673116
[32m2021-03-04T20:47:28 | mmf.trainers.mmf_trainer: [0mLoading datasets
[32m2021-03-04T20:47:34 | mmf.trainers.mmf_trainer: [0mLoading model
[32m2021-03-04T20:47:48 | mmf.trainers.mmf_trainer: [0mLoading optimizer
[32m2021-03-04T20:47:48 | mmf.trainers.mmf_trainer: [0mLoading metrics
[5m[31mWARNING[0m [32m2021-03-04T20:47:48 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.
Use OmegaConf.to_yaml(cfg)

  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T20:47:48 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.
Use OmegaConf.to_yaml(cfg)

  builtin_warn(*args, **kwargs)

[32m2021-03-04T20:47:56 | mmf.trainers.mmf_trainer: [0m===== Model =====
[32m2021-03-04T20:47:56 | mmf.trainers.mmf_trainer: [0mDistributedDataParallel(
  (module): MMBT(
    (model): MMBTForClassification(
      (bert): MMBTBase(
        (mmbt): MMBTModel(
          (transformer): BertModelJit(
            (embeddings): BertEmbeddingsJit(
              (word_embeddings): Embedding(30522, 768, padding_idx=0)
              (position_embeddings): Embedding(512, 768)
              (token_type_embeddings): Embedding(2, 768)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (encoder): BertEncoderJit(
              (layer): ModuleList(
                (0): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (1): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (2): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (3): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (4): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (5): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (6): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (7): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (8): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (9): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (10): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (11): BertLayerJit(
                  (attention): BertAttentionJit(
                    (self): BertSelfAttentionJit(
                      (query): Linear(in_features=768, out_features=768, bias=True)
                      (key): Linear(in_features=768, out_features=768, bias=True)
                      (value): Linear(in_features=768, out_features=768, bias=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): Linear(in_features=768, out_features=768, bias=True)
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): Linear(in_features=768, out_features=3072, bias=True)
                  )
                  (output): BertOutput(
                    (dense): Linear(in_features=3072, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (pooler): BertPooler(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (activation): Tanh()
            )
          )
          (modal_encoder): ModalEmbeddings(
            (encoder): ResNet152ImageEncoder(
              (model): Sequential(
                (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                (4): Sequential(
                  (0): Bottleneck(
                    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                    (downsample): Sequential(
                      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    )
                  )
                  (1): Bottleneck(
                    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (2): Bottleneck(
                    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                )
                (5): Sequential(
                  (0): Bottleneck(
                    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                    (downsample): Sequential(
                      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    )
                  )
                  (1): Bottleneck(
                    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (2): Bottleneck(
                    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (3): Bottleneck(
                    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (4): Bottleneck(
                    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (5): Bottleneck(
                    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (6): Bottleneck(
                    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (7): Bottleneck(
                    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                )
                (6): Sequential(
                  (0): Bottleneck(
                    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                    (downsample): Sequential(
                      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    )
                  )
                  (1): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (2): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (3): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (4): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (5): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (6): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (7): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (8): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (9): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (10): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (11): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (12): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (13): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (14): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (15): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (16): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (17): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (18): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (19): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (20): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (21): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (22): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (23): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (24): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (25): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (26): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (27): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (28): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (29): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (30): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (31): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (32): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (33): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (34): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (35): Bottleneck(
                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                )
                (7): Sequential(
                  (0): Bottleneck(
                    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                    (downsample): Sequential(
                      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    )
                  )
                  (1): Bottleneck(
                    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                  (2): Bottleneck(
                    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (relu): ReLU(inplace=True)
                  )
                )
              )
              (pool): AdaptiveAvgPool2d(output_size=(1, 1))
            )
            (proj_embeddings): Linear(in_features=2048, out_features=768, bias=True)
            (position_embeddings): Embedding(512, 768)
            (token_type_embeddings): Embedding(2, 768)
            (word_embeddings): Embedding(30522, 768, padding_idx=0)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
      (classifier): Sequential(
        (0): BertPredictionHeadTransform(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (1): Linear(in_features=768, out_features=2, bias=True)
      )
    )
    (losses): Losses(
      (losses): ModuleList(
        (0): MMFLoss(
          (loss_criterion): CrossEntropyLoss(
            (loss_fn): CrossEntropyLoss()
          )
        )
      )
    )
  )
)
[32m2021-03-04T20:47:57 | mmf.utils.general: [0mTotal Parameters: 169793346. Trained Parameters: 169793346
[32m2021-03-04T20:47:57 | mmf.trainers.core.training_loop: [0mStarting training...
[32m2021-03-04T20:48:53 | mmf.trainers.callbacks.logistics: [0mprogress: 100/22000, train/hateful_memes/cross_entropy: 0.7608, train/hateful_memes/cross_entropy/avg: 0.7608, train/total_loss: 0.7608, train/total_loss/avg: 0.7608, max mem: 5549.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 1.79, time: 56s 597ms, time_since_start: 01m 04s 929ms, eta: 03h 26m 59s 545ms
[32m2021-03-04T20:49:35 | mmf.trainers.callbacks.logistics: [0mprogress: 200/22000, train/hateful_memes/cross_entropy: 0.7077, train/hateful_memes/cross_entropy/avg: 0.7343, train/total_loss: 0.7077, train/total_loss/avg: 0.7343, max mem: 5549.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0., ups: 2.44, time: 41s 808ms, time_since_start: 01m 46s 738ms, eta: 02h 32m 12s 569ms
[32m2021-03-04T20:50:26 | mmf.trainers.callbacks.logistics: [0mprogress: 300/22000, train/hateful_memes/cross_entropy: 0.7077, train/hateful_memes/cross_entropy/avg: 0.6941, train/total_loss: 0.7077, train/total_loss/avg: 0.6941, max mem: 5549.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 329ms, time_since_start: 02m 38s 067ms, eta: 03h 06m 680ms
[32m2021-03-04T20:51:05 | mmf.trainers.callbacks.logistics: [0mprogress: 400/22000, train/hateful_memes/cross_entropy: 0.6370, train/hateful_memes/cross_entropy/avg: 0.6798, train/total_loss: 0.6370, train/total_loss/avg: 0.6798, max mem: 5549.0, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 241ms, time_since_start: 03m 17s 309ms, eta: 02h 21m 33s 193ms
[32m2021-03-04T20:51:45 | mmf.trainers.callbacks.logistics: [0mprogress: 500/22000, train/hateful_memes/cross_entropy: 0.6370, train/hateful_memes/cross_entropy/avg: 0.6593, train/total_loss: 0.6370, train/total_loss/avg: 0.6593, max mem: 5549.0, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 939ms, time_since_start: 03m 57s 249ms, eta: 02h 23m 24s 192ms
[32m2021-03-04T20:52:36 | mmf.trainers.callbacks.logistics: [0mprogress: 600/22000, train/hateful_memes/cross_entropy: 0.6138, train/hateful_memes/cross_entropy/avg: 0.6498, train/total_loss: 0.6138, train/total_loss/avg: 0.6498, max mem: 5549.0, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 101ms, time_since_start: 04m 47s 350ms, eta: 02h 59m 03s 083ms
[32m2021-03-04T20:53:15 | mmf.trainers.callbacks.logistics: [0mprogress: 700/22000, train/hateful_memes/cross_entropy: 0.6138, train/hateful_memes/cross_entropy/avg: 0.6408, train/total_loss: 0.6138, train/total_loss/avg: 0.6408, max mem: 5549.0, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 403ms, time_since_start: 05m 26s 754ms, eta: 02h 20m 09s 740ms
[32m2021-03-04T20:54:05 | mmf.trainers.callbacks.logistics: [0mprogress: 800/22000, train/hateful_memes/cross_entropy: 0.6138, train/hateful_memes/cross_entropy/avg: 0.6433, train/total_loss: 0.6138, train/total_loss/avg: 0.6433, max mem: 5549.0, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 382ms, time_since_start: 06m 17s 136ms, eta: 02h 58m 22s 509ms
[32m2021-03-04T20:54:44 | mmf.trainers.callbacks.logistics: [0mprogress: 900/22000, train/hateful_memes/cross_entropy: 0.6138, train/hateful_memes/cross_entropy/avg: 0.6307, train/total_loss: 0.6138, train/total_loss/avg: 0.6307, max mem: 5549.0, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 084ms, time_since_start: 06m 56s 221ms, eta: 02h 17m 43s 397ms
[32m2021-03-04T20:55:24 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T20:55:24 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T20:55:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T20:55:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T20:55:28 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T20:55:48 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T20:55:48 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, train/hateful_memes/cross_entropy: 0.6023, train/hateful_memes/cross_entropy/avg: 0.5992, train/total_loss: 0.6023, train/total_loss/avg: 0.5992, max mem: 5549.0, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00001, ups: 1.59, time: 01m 03s 534ms, time_since_start: 07m 59s 756ms, eta: 03h 42m 48s 924ms
[32m2021-03-04T20:55:48 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T20:56:08 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T20:56:08 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T20:56:08 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T20:56:08 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T20:56:25 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T20:56:41 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T20:56:56 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T20:56:56 | mmf.trainers.callbacks.logistics: [0mprogress: 1000/22000, val/hateful_memes/cross_entropy: 0.7618, val/total_loss: 0.7618, val/hateful_memes/accuracy: 0.6241, val/hateful_memes/binary_f1: 0.2759, val/hateful_memes/roc_auc: 0.6025, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 22000, val_time: 01m 07s 977ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.602519
[32m2021-03-04T20:57:47 | mmf.trainers.callbacks.logistics: [0mprogress: 1100/22000, train/hateful_memes/cross_entropy: 0.6023, train/hateful_memes/cross_entropy/avg: 0.5832, train/total_loss: 0.6023, train/total_loss/avg: 0.5832, max mem: 5552.0, experiment: run, epoch: 5, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 438ms, time_since_start: 09m 59s 174ms, eta: 02h 59m 32s 191ms
[32m2021-03-04T20:58:26 | mmf.trainers.callbacks.logistics: [0mprogress: 1200/22000, train/hateful_memes/cross_entropy: 0.5870, train/hateful_memes/cross_entropy/avg: 0.5590, train/total_loss: 0.5870, train/total_loss/avg: 0.5590, max mem: 5552.0, experiment: run, epoch: 5, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00001, ups: 2.63, time: 38s 783ms, time_since_start: 10m 37s 958ms, eta: 02h 14m 43s 105ms
[32m2021-03-04T20:59:05 | mmf.trainers.callbacks.logistics: [0mprogress: 1300/22000, train/hateful_memes/cross_entropy: 0.5870, train/hateful_memes/cross_entropy/avg: 0.5593, train/total_loss: 0.5870, train/total_loss/avg: 0.5593, max mem: 5552.0, experiment: run, epoch: 5, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 225ms, time_since_start: 11m 17s 184ms, eta: 02h 15m 35s 963ms
[32m2021-03-04T20:59:55 | mmf.trainers.callbacks.logistics: [0mprogress: 1400/22000, train/hateful_memes/cross_entropy: 0.5771, train/hateful_memes/cross_entropy/avg: 0.5400, train/total_loss: 0.5771, train/total_loss/avg: 0.5400, max mem: 5552.0, experiment: run, epoch: 6, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 987ms, time_since_start: 12m 07s 171ms, eta: 02h 51m 57s 924ms
[32m2021-03-04T21:00:35 | mmf.trainers.callbacks.logistics: [0mprogress: 1500/22000, train/hateful_memes/cross_entropy: 0.5771, train/hateful_memes/cross_entropy/avg: 0.5259, train/total_loss: 0.5771, train/total_loss/avg: 0.5259, max mem: 5552.0, experiment: run, epoch: 6, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 917ms, time_since_start: 12m 47s 088ms, eta: 02h 16m 39s 380ms
[32m2021-03-04T21:01:26 | mmf.trainers.callbacks.logistics: [0mprogress: 1600/22000, train/hateful_memes/cross_entropy: 0.5632, train/hateful_memes/cross_entropy/avg: 0.5171, train/total_loss: 0.5632, train/total_loss/avg: 0.5171, max mem: 5552.0, experiment: run, epoch: 7, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 339ms, time_since_start: 13m 37s 428ms, eta: 02h 51m 29s 821ms
[32m2021-03-04T21:02:05 | mmf.trainers.callbacks.logistics: [0mprogress: 1700/22000, train/hateful_memes/cross_entropy: 0.5632, train/hateful_memes/cross_entropy/avg: 0.5078, train/total_loss: 0.5632, train/total_loss/avg: 0.5078, max mem: 5552.0, experiment: run, epoch: 7, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 274ms, time_since_start: 14m 16s 702ms, eta: 02h 13m 08s 650ms
[32m2021-03-04T21:02:45 | mmf.trainers.callbacks.logistics: [0mprogress: 1800/22000, train/hateful_memes/cross_entropy: 0.5297, train/hateful_memes/cross_entropy/avg: 0.5032, train/total_loss: 0.5297, train/total_loss/avg: 0.5032, max mem: 5552.0, experiment: run, epoch: 7, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 640ms, time_since_start: 14m 56s 343ms, eta: 02h 13m 43s 407ms
[32m2021-03-04T21:03:35 | mmf.trainers.callbacks.logistics: [0mprogress: 1900/22000, train/hateful_memes/cross_entropy: 0.5297, train/hateful_memes/cross_entropy/avg: 0.4864, train/total_loss: 0.5297, train/total_loss/avg: 0.4864, max mem: 5552.0, experiment: run, epoch: 8, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 317ms, time_since_start: 15m 46s 660ms, eta: 02h 48m 53s 975ms
[32m2021-03-04T21:04:14 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T21:04:14 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:04:14 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:04:14 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:04:18 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:04:34 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:04:34 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, train/hateful_memes/cross_entropy: 0.5297, train/hateful_memes/cross_entropy/avg: 0.4940, train/total_loss: 0.5297, train/total_loss/avg: 0.4940, max mem: 5552.0, experiment: run, epoch: 8, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00001, ups: 1.69, time: 59s 407ms, time_since_start: 16m 46s 067ms, eta: 03h 18m 25s 318ms
[32m2021-03-04T21:04:34 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T21:04:45 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T21:04:45 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:04:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:04:45 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:05:01 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T21:05:16 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:05:32 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:05:32 | mmf.trainers.callbacks.logistics: [0mprogress: 2000/22000, val/hateful_memes/cross_entropy: 1.0302, val/total_loss: 1.0302, val/hateful_memes/accuracy: 0.6130, val/hateful_memes/binary_f1: 0.2906, val/hateful_memes/roc_auc: 0.6064, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 22000, val_time: 58s 171ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.606417
[32m2021-03-04T21:06:11 | mmf.trainers.callbacks.logistics: [0mprogress: 2100/22000, train/hateful_memes/cross_entropy: 0.4238, train/hateful_memes/cross_entropy/avg: 0.4837, train/total_loss: 0.4238, train/total_loss/avg: 0.4837, max mem: 5552.0, experiment: run, epoch: 8, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00001, ups: 2.63, time: 38s 859ms, time_since_start: 18m 23s 100ms, eta: 02h 09m 08s 528ms
[32m2021-03-04T21:07:02 | mmf.trainers.callbacks.logistics: [0mprogress: 2200/22000, train/hateful_memes/cross_entropy: 0.4235, train/hateful_memes/cross_entropy/avg: 0.4707, train/total_loss: 0.4235, train/total_loss/avg: 0.4707, max mem: 5552.0, experiment: run, epoch: 9, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 535ms, time_since_start: 19m 13s 636ms, eta: 02h 47m 05s 950ms
[32m2021-03-04T21:07:42 | mmf.trainers.callbacks.logistics: [0mprogress: 2300/22000, train/hateful_memes/cross_entropy: 0.3846, train/hateful_memes/cross_entropy/avg: 0.4607, train/total_loss: 0.3846, train/total_loss/avg: 0.4607, max mem: 5552.0, experiment: run, epoch: 9, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 721ms, time_since_start: 19m 53s 357ms, eta: 02h 10m 40s 737ms
[32m2021-03-04T21:08:32 | mmf.trainers.callbacks.logistics: [0mprogress: 2400/22000, train/hateful_memes/cross_entropy: 0.3602, train/hateful_memes/cross_entropy/avg: 0.4477, train/total_loss: 0.3602, train/total_loss/avg: 0.4477, max mem: 5552.0, experiment: run, epoch: 10, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 274ms, time_since_start: 20m 43s 631ms, eta: 02h 44m 33s 464ms
[32m2021-03-04T21:09:11 | mmf.trainers.callbacks.logistics: [0mprogress: 2500/22000, train/hateful_memes/cross_entropy: 0.3284, train/hateful_memes/cross_entropy/avg: 0.4346, train/total_loss: 0.3284, train/total_loss/avg: 0.4346, max mem: 5552.0, experiment: run, epoch: 10, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00001, ups: 2.63, time: 38s 820ms, time_since_start: 21m 22s 452ms, eta: 02h 06m 25s 176ms
[32m2021-03-04T21:09:50 | mmf.trainers.callbacks.logistics: [0mprogress: 2600/22000, train/hateful_memes/cross_entropy: 0.3160, train/hateful_memes/cross_entropy/avg: 0.4253, train/total_loss: 0.3160, train/total_loss/avg: 0.4253, max mem: 5552.0, experiment: run, epoch: 10, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 447ms, time_since_start: 22m 01s 899ms, eta: 02h 07m 48s 100ms
[32m2021-03-04T21:10:40 | mmf.trainers.callbacks.logistics: [0mprogress: 2700/22000, train/hateful_memes/cross_entropy: 0.2921, train/hateful_memes/cross_entropy/avg: 0.4103, train/total_loss: 0.2921, train/total_loss/avg: 0.4103, max mem: 5552.0, experiment: run, epoch: 11, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 196ms, time_since_start: 22m 52s 095ms, eta: 02h 41m 47s 231ms
[32m2021-03-04T21:11:20 | mmf.trainers.callbacks.logistics: [0mprogress: 2800/22000, train/hateful_memes/cross_entropy: 0.2891, train/hateful_memes/cross_entropy/avg: 0.3960, train/total_loss: 0.2891, train/total_loss/avg: 0.3960, max mem: 5552.0, experiment: run, epoch: 11, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 727ms, time_since_start: 23m 31s 822ms, eta: 02h 07m 22s 849ms
[32m2021-03-04T21:12:01 | mmf.trainers.callbacks.logistics: [0mprogress: 2900/22000, train/hateful_memes/cross_entropy: 0.2773, train/hateful_memes/cross_entropy/avg: 0.3848, train/total_loss: 0.2773, train/total_loss/avg: 0.3848, max mem: 5552.0, experiment: run, epoch: 11, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 826ms, time_since_start: 24m 12s 649ms, eta: 02h 10m 13s 524ms
[32m2021-03-04T21:12:51 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T21:12:51 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:12:51 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:12:51 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:12:55 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:13:11 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:13:11 | mmf.trainers.callbacks.logistics: [0mprogress: 3000/22000, train/hateful_memes/cross_entropy: 0.2401, train/hateful_memes/cross_entropy/avg: 0.3734, train/total_loss: 0.2401, train/total_loss/avg: 0.3734, max mem: 5552.0, experiment: run, epoch: 12, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00001, ups: 1.45, time: 01m 09s 875ms, time_since_start: 25m 22s 525ms, eta: 03h 41m 42s 946ms
[32m2021-03-04T21:13:11 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T21:13:22 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T21:13:22 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:13:22 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:13:22 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:13:35 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T21:13:51 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:14:06 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:14:06 | mmf.trainers.callbacks.logistics: [0mprogress: 3000/22000, val/hateful_memes/cross_entropy: 1.7295, val/total_loss: 1.7295, val/hateful_memes/accuracy: 0.6204, val/hateful_memes/binary_f1: 0.4555, val/hateful_memes/roc_auc: 0.6098, num_updates: 3000, epoch: 12, iterations: 3000, max_updates: 22000, val_time: 55s 702ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.609798
[32m2021-03-04T21:14:47 | mmf.trainers.callbacks.logistics: [0mprogress: 3100/22000, train/hateful_memes/cross_entropy: 0.1978, train/hateful_memes/cross_entropy/avg: 0.3674, train/total_loss: 0.1978, train/total_loss/avg: 0.3674, max mem: 5552.0, experiment: run, epoch: 12, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 649ms, time_since_start: 26m 58s 879ms, eta: 02h 08m 18s 110ms
[32m2021-03-04T21:15:37 | mmf.trainers.callbacks.logistics: [0mprogress: 3200/22000, train/hateful_memes/cross_entropy: 0.1946, train/hateful_memes/cross_entropy/avg: 0.3574, train/total_loss: 0.1946, train/total_loss/avg: 0.3574, max mem: 5552.0, experiment: run, epoch: 13, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 703ms, time_since_start: 27m 48s 583ms, eta: 02h 36m 03s 042ms
[32m2021-03-04T21:16:16 | mmf.trainers.callbacks.logistics: [0mprogress: 3300/22000, train/hateful_memes/cross_entropy: 0.1859, train/hateful_memes/cross_entropy/avg: 0.3469, train/total_loss: 0.1859, train/total_loss/avg: 0.3469, max mem: 5552.0, experiment: run, epoch: 13, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 408ms, time_since_start: 28m 27s 992ms, eta: 02h 03m 04s 121ms
[32m2021-03-04T21:16:56 | mmf.trainers.callbacks.logistics: [0mprogress: 3400/22000, train/hateful_memes/cross_entropy: 0.1844, train/hateful_memes/cross_entropy/avg: 0.3375, train/total_loss: 0.1844, train/total_loss/avg: 0.3375, max mem: 5552.0, experiment: run, epoch: 13, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 458ms, time_since_start: 29m 07s 450ms, eta: 02h 02m 33s 909ms
[32m2021-03-04T21:17:46 | mmf.trainers.callbacks.logistics: [0mprogress: 3500/22000, train/hateful_memes/cross_entropy: 0.1499, train/hateful_memes/cross_entropy/avg: 0.3283, train/total_loss: 0.1499, train/total_loss/avg: 0.3283, max mem: 5552.0, experiment: run, epoch: 14, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 014ms, time_since_start: 29m 57s 464ms, eta: 02h 34m 31s 131ms
[32m2021-03-04T21:18:25 | mmf.trainers.callbacks.logistics: [0mprogress: 3600/22000, train/hateful_memes/cross_entropy: 0.1187, train/hateful_memes/cross_entropy/avg: 0.3195, train/total_loss: 0.1187, train/total_loss/avg: 0.3195, max mem: 5552.0, experiment: run, epoch: 14, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 153ms, time_since_start: 30m 36s 617ms, eta: 02h 18s 622ms
[32m2021-03-04T21:19:04 | mmf.trainers.callbacks.logistics: [0mprogress: 3700/22000, train/hateful_memes/cross_entropy: 0.0707, train/hateful_memes/cross_entropy/avg: 0.3119, train/total_loss: 0.0707, train/total_loss/avg: 0.3119, max mem: 5552.0, experiment: run, epoch: 14, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 506ms, time_since_start: 31m 16s 124ms, eta: 02h 44s 115ms
[32m2021-03-04T21:19:55 | mmf.trainers.callbacks.logistics: [0mprogress: 3800/22000, train/hateful_memes/cross_entropy: 0.0478, train/hateful_memes/cross_entropy/avg: 0.3039, train/total_loss: 0.0478, train/total_loss/avg: 0.3039, max mem: 5552.0, experiment: run, epoch: 15, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 775ms, time_since_start: 32m 06s 899ms, eta: 02h 34m 19s 558ms
[32m2021-03-04T21:20:34 | mmf.trainers.callbacks.logistics: [0mprogress: 3900/22000, train/hateful_memes/cross_entropy: 0.0428, train/hateful_memes/cross_entropy/avg: 0.2964, train/total_loss: 0.0428, train/total_loss/avg: 0.2964, max mem: 5552.0, experiment: run, epoch: 15, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 283ms, time_since_start: 32m 46s 182ms, eta: 01h 58m 44s 524ms
[32m2021-03-04T21:21:25 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T21:21:25 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:21:25 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:21:25 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:21:29 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:21:45 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:21:45 | mmf.trainers.callbacks.logistics: [0mprogress: 4000/22000, train/hateful_memes/cross_entropy: 0.0376, train/hateful_memes/cross_entropy/avg: 0.2895, train/total_loss: 0.0376, train/total_loss/avg: 0.2895, max mem: 5552.0, experiment: run, epoch: 16, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00001, ups: 1.43, time: 01m 10s 761ms, time_since_start: 33m 56s 944ms, eta: 03h 32m 42s 604ms
[32m2021-03-04T21:21:45 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T21:21:56 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T21:21:56 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:21:56 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:21:56 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:22:10 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:22:26 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:22:26 | mmf.trainers.callbacks.logistics: [0mprogress: 4000/22000, val/hateful_memes/cross_entropy: 1.7834, val/total_loss: 1.7834, val/hateful_memes/accuracy: 0.6204, val/hateful_memes/binary_f1: 0.3670, val/hateful_memes/roc_auc: 0.6093, num_updates: 4000, epoch: 16, iterations: 4000, max_updates: 22000, val_time: 40s 814ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.609798
[32m2021-03-04T21:23:05 | mmf.trainers.callbacks.logistics: [0mprogress: 4100/22000, train/hateful_memes/cross_entropy: 0.0368, train/hateful_memes/cross_entropy/avg: 0.2833, train/total_loss: 0.0368, train/total_loss/avg: 0.2833, max mem: 5552.0, experiment: run, epoch: 16, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00001, ups: 2.63, time: 38s 846ms, time_since_start: 35m 16s 607ms, eta: 01h 56m 07s 473ms
[32m2021-03-04T21:23:44 | mmf.trainers.callbacks.logistics: [0mprogress: 4200/22000, train/hateful_memes/cross_entropy: 0.0270, train/hateful_memes/cross_entropy/avg: 0.2767, train/total_loss: 0.0270, train/total_loss/avg: 0.2767, max mem: 5552.0, experiment: run, epoch: 16, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 592ms, time_since_start: 35m 56s 199ms, eta: 01h 57m 41s 503ms
[32m2021-03-04T21:24:36 | mmf.trainers.callbacks.logistics: [0mprogress: 4300/22000, train/hateful_memes/cross_entropy: 0.0203, train/hateful_memes/cross_entropy/avg: 0.2705, train/total_loss: 0.0203, train/total_loss/avg: 0.2705, max mem: 5552.0, experiment: run, epoch: 17, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 631ms, time_since_start: 36m 47s 831ms, eta: 02h 32m 37s 036ms
[32m2021-03-04T21:25:15 | mmf.trainers.callbacks.logistics: [0mprogress: 4400/22000, train/hateful_memes/cross_entropy: 0.0171, train/hateful_memes/cross_entropy/avg: 0.2643, train/total_loss: 0.0171, train/total_loss/avg: 0.2643, max mem: 5552.0, experiment: run, epoch: 17, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 389ms, time_since_start: 37m 27s 220ms, eta: 01h 55m 46s 345ms
[32m2021-03-04T21:25:55 | mmf.trainers.callbacks.logistics: [0mprogress: 4500/22000, train/hateful_memes/cross_entropy: 0.0171, train/hateful_memes/cross_entropy/avg: 0.2585, train/total_loss: 0.0171, train/total_loss/avg: 0.2585, max mem: 5552.0, experiment: run, epoch: 17, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 419ms, time_since_start: 38m 06s 639ms, eta: 01h 55m 12s 172ms
[32m2021-03-04T21:26:46 | mmf.trainers.callbacks.logistics: [0mprogress: 4600/22000, train/hateful_memes/cross_entropy: 0.0142, train/hateful_memes/cross_entropy/avg: 0.2532, train/total_loss: 0.0142, train/total_loss/avg: 0.2532, max mem: 5552.0, experiment: run, epoch: 18, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 999ms, time_since_start: 38m 57s 639ms, eta: 02h 28m 11s 751ms
[32m2021-03-04T21:27:27 | mmf.trainers.callbacks.logistics: [0mprogress: 4700/22000, train/hateful_memes/cross_entropy: 0.0130, train/hateful_memes/cross_entropy/avg: 0.2478, train/total_loss: 0.0130, train/total_loss/avg: 0.2478, max mem: 5552.0, experiment: run, epoch: 18, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 140ms, time_since_start: 39m 38s 780ms, eta: 01h 58m 51s 514ms
[32m2021-03-04T21:28:18 | mmf.trainers.callbacks.logistics: [0mprogress: 4800/22000, train/hateful_memes/cross_entropy: 0.0130, train/hateful_memes/cross_entropy/avg: 0.2428, train/total_loss: 0.0130, train/total_loss/avg: 0.2428, max mem: 5552.0, experiment: run, epoch: 19, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 123ms, time_since_start: 40m 29s 903ms, eta: 02h 26m 50s 870ms
[32m2021-03-04T21:28:57 | mmf.trainers.callbacks.logistics: [0mprogress: 4900/22000, train/hateful_memes/cross_entropy: 0.0130, train/hateful_memes/cross_entropy/avg: 0.2382, train/total_loss: 0.0130, train/total_loss/avg: 0.2382, max mem: 5552.0, experiment: run, epoch: 19, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00001, ups: 2.63, time: 38s 981ms, time_since_start: 41m 08s 885ms, eta: 01h 51m 19s 236ms
[32m2021-03-04T21:29:38 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T21:29:38 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:29:38 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:29:38 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:29:42 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:29:58 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:29:58 | mmf.trainers.callbacks.logistics: [0mprogress: 5000/22000, train/hateful_memes/cross_entropy: 0.0110, train/hateful_memes/cross_entropy/avg: 0.2336, train/total_loss: 0.0110, train/total_loss/avg: 0.2336, max mem: 5552.0, experiment: run, epoch: 19, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 734ms, time_since_start: 42m 09s 620ms, eta: 02h 52m 25s 452ms
[32m2021-03-04T21:29:58 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T21:30:08 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T21:30:08 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:30:08 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:30:08 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:30:24 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T21:30:40 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:30:55 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:30:55 | mmf.trainers.callbacks.logistics: [0mprogress: 5000/22000, val/hateful_memes/cross_entropy: 2.0863, val/total_loss: 2.0863, val/hateful_memes/accuracy: 0.6278, val/hateful_memes/binary_f1: 0.4301, val/hateful_memes/roc_auc: 0.6131, num_updates: 5000, epoch: 19, iterations: 5000, max_updates: 22000, val_time: 57s 441ms, best_update: 5000, best_iteration: 5000, best_val/hateful_memes/roc_auc: 0.613096
[32m2021-03-04T21:31:46 | mmf.trainers.callbacks.logistics: [0mprogress: 5100/22000, train/hateful_memes/cross_entropy: 0.0105, train/hateful_memes/cross_entropy/avg: 0.2290, train/total_loss: 0.0105, train/total_loss/avg: 0.2290, max mem: 5552.0, experiment: run, epoch: 20, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 894ms, time_since_start: 43m 57s 957ms, eta: 02h 23m 38s 350ms
[32m2021-03-04T21:32:26 | mmf.trainers.callbacks.logistics: [0mprogress: 5200/22000, train/hateful_memes/cross_entropy: 0.0081, train/hateful_memes/cross_entropy/avg: 0.2247, train/total_loss: 0.0081, train/total_loss/avg: 0.2247, max mem: 5552.0, experiment: run, epoch: 20, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 134ms, time_since_start: 44m 38s 091ms, eta: 01h 52m 36s 010ms
[32m2021-03-04T21:33:07 | mmf.trainers.callbacks.logistics: [0mprogress: 5300/22000, train/hateful_memes/cross_entropy: 0.0075, train/hateful_memes/cross_entropy/avg: 0.2204, train/total_loss: 0.0075, train/total_loss/avg: 0.2204, max mem: 5552.0, experiment: run, epoch: 20, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 530ms, time_since_start: 45m 18s 622ms, eta: 01h 53m 02s 177ms
[32m2021-03-04T21:33:58 | mmf.trainers.callbacks.logistics: [0mprogress: 5400/22000, train/hateful_memes/cross_entropy: 0.0075, train/hateful_memes/cross_entropy/avg: 0.2176, train/total_loss: 0.0075, train/total_loss/avg: 0.2176, max mem: 5552.0, experiment: run, epoch: 21, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 335ms, time_since_start: 46m 09s 957ms, eta: 02h 22m 18s 687ms
[32m2021-03-04T21:34:39 | mmf.trainers.callbacks.logistics: [0mprogress: 5500/22000, train/hateful_memes/cross_entropy: 0.0068, train/hateful_memes/cross_entropy/avg: 0.2138, train/total_loss: 0.0068, train/total_loss/avg: 0.2138, max mem: 5552.0, experiment: run, epoch: 21, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 657ms, time_since_start: 46m 50s 615ms, eta: 01h 52m 01s 987ms
[32m2021-03-04T21:35:29 | mmf.trainers.callbacks.logistics: [0mprogress: 5600/22000, train/hateful_memes/cross_entropy: 0.0063, train/hateful_memes/cross_entropy/avg: 0.2100, train/total_loss: 0.0063, train/total_loss/avg: 0.2100, max mem: 5552.0, experiment: run, epoch: 22, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 566ms, time_since_start: 47m 41s 182ms, eta: 02h 18m 29s 419ms
[32m2021-03-04T21:36:09 | mmf.trainers.callbacks.logistics: [0mprogress: 5700/22000, train/hateful_memes/cross_entropy: 0.0059, train/hateful_memes/cross_entropy/avg: 0.2064, train/total_loss: 0.0059, train/total_loss/avg: 0.2064, max mem: 5552.0, experiment: run, epoch: 22, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 220ms, time_since_start: 48m 20s 402ms, eta: 01h 46m 45s 752ms
[32m2021-03-04T21:36:48 | mmf.trainers.callbacks.logistics: [0mprogress: 5800/22000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.2029, train/total_loss: 0.0049, train/total_loss/avg: 0.2029, max mem: 5552.0, experiment: run, epoch: 22, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 688ms, time_since_start: 49m 091ms, eta: 01h 47m 22s 402ms
[32m2021-03-04T21:37:38 | mmf.trainers.callbacks.logistics: [0mprogress: 5900/22000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.2003, train/total_loss: 0.0049, train/total_loss/avg: 0.2003, max mem: 5552.0, experiment: run, epoch: 23, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 179ms, time_since_start: 49m 50s 271ms, eta: 02h 14m 55s 132ms
[32m2021-03-04T21:38:19 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T21:38:19 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:38:19 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:38:19 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:38:23 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:38:39 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:38:39 | mmf.trainers.callbacks.logistics: [0mprogress: 6000/22000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.1975, train/total_loss: 0.0049, train/total_loss/avg: 0.1975, max mem: 5552.0, experiment: run, epoch: 23, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 164ms, time_since_start: 50m 50s 435ms, eta: 02h 40m 45s 597ms
[32m2021-03-04T21:38:39 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T21:38:49 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T21:38:49 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:38:49 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:38:49 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:39:06 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T21:39:22 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:39:39 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:39:39 | mmf.trainers.callbacks.logistics: [0mprogress: 6000/22000, val/hateful_memes/cross_entropy: 2.2485, val/total_loss: 2.2485, val/hateful_memes/accuracy: 0.6537, val/hateful_memes/binary_f1: 0.3439, val/hateful_memes/roc_auc: 0.6319, num_updates: 6000, epoch: 23, iterations: 6000, max_updates: 22000, val_time: 59s 898ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.631914
[32m2021-03-04T21:40:17 | mmf.trainers.callbacks.logistics: [0mprogress: 6100/22000, train/hateful_memes/cross_entropy: 0.0039, train/hateful_memes/cross_entropy/avg: 0.1944, train/total_loss: 0.0039, train/total_loss/avg: 0.1944, max mem: 5552.0, experiment: run, epoch: 23, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00001, ups: 2.63, time: 38s 688ms, time_since_start: 52m 29s 025ms, eta: 01h 42m 43s 816ms
[32m2021-03-04T21:41:07 | mmf.trainers.callbacks.logistics: [0mprogress: 6200/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1913, train/total_loss: 0.0037, train/total_loss/avg: 0.1913, max mem: 5552.0, experiment: run, epoch: 24, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 614ms, time_since_start: 53m 18s 639ms, eta: 02h 10m 54s 715ms
[32m2021-03-04T21:41:48 | mmf.trainers.callbacks.logistics: [0mprogress: 6300/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1888, train/total_loss: 0.0037, train/total_loss/avg: 0.1888, max mem: 5552.0, experiment: run, epoch: 24, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 442ms, time_since_start: 54m 082ms, eta: 01h 48m 39s 541ms
[32m2021-03-04T21:42:40 | mmf.trainers.callbacks.logistics: [0mprogress: 6400/22000, train/hateful_memes/cross_entropy: 0.0039, train/hateful_memes/cross_entropy/avg: 0.1860, train/total_loss: 0.0039, train/total_loss/avg: 0.1860, max mem: 5552.0, experiment: run, epoch: 25, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 821ms, time_since_start: 54m 51s 903ms, eta: 02h 15m 284ms
[32m2021-03-04T21:43:21 | mmf.trainers.callbacks.logistics: [0mprogress: 6500/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1832, train/total_loss: 0.0041, train/total_loss/avg: 0.1832, max mem: 5552.0, experiment: run, epoch: 25, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 177ms, time_since_start: 55m 33s 081ms, eta: 01h 46m 35s 348ms
[32m2021-03-04T21:44:03 | mmf.trainers.callbacks.logistics: [0mprogress: 6600/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1806, train/total_loss: 0.0041, train/total_loss/avg: 0.1806, max mem: 5552.0, experiment: run, epoch: 25, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 484ms, time_since_start: 56m 14s 566ms, eta: 01h 46m 41s 446ms
[32m2021-03-04T21:44:54 | mmf.trainers.callbacks.logistics: [0mprogress: 6700/22000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.1780, train/total_loss: 0.0049, train/total_loss/avg: 0.1780, max mem: 5552.0, experiment: run, epoch: 26, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 211ms, time_since_start: 57m 05s 777ms, eta: 02h 10m 50s 995ms
[32m2021-03-04T21:45:33 | mmf.trainers.callbacks.logistics: [0mprogress: 6800/22000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.1754, train/total_loss: 0.0049, train/total_loss/avg: 0.1754, max mem: 5552.0, experiment: run, epoch: 26, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 217ms, time_since_start: 57m 44s 994ms, eta: 01h 39m 32s 912ms
[32m2021-03-04T21:46:15 | mmf.trainers.callbacks.logistics: [0mprogress: 6900/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1729, train/total_loss: 0.0041, train/total_loss/avg: 0.1729, max mem: 5552.0, experiment: run, epoch: 26, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 812ms, time_since_start: 58m 26s 807ms, eta: 01h 45m 26s 378ms
[32m2021-03-04T21:47:05 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T21:47:05 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:47:05 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:47:05 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:47:09 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:47:25 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:47:25 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1706, train/total_loss: 0.0041, train/total_loss/avg: 0.1706, max mem: 5552.0, experiment: run, epoch: 27, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00001, ups: 1.43, time: 01m 10s 021ms, time_since_start: 59m 36s 828ms, eta: 02h 55m 24s 189ms
[32m2021-03-04T21:47:25 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T21:47:36 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T21:47:36 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:47:36 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:47:36 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:47:52 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:48:08 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:48:08 | mmf.trainers.callbacks.logistics: [0mprogress: 7000/22000, val/hateful_memes/cross_entropy: 2.2691, val/total_loss: 2.2691, val/hateful_memes/accuracy: 0.6333, val/hateful_memes/binary_f1: 0.3141, val/hateful_memes/roc_auc: 0.6217, num_updates: 7000, epoch: 27, iterations: 7000, max_updates: 22000, val_time: 42s 916ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.631914
[32m2021-03-04T21:48:47 | mmf.trainers.callbacks.logistics: [0mprogress: 7100/22000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.1684, train/total_loss: 0.0049, train/total_loss/avg: 0.1684, max mem: 5552.0, experiment: run, epoch: 27, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00001, ups: 2.63, time: 38s 742ms, time_since_start: 01h 58s 489ms, eta: 01h 36m 24s 122ms
[32m2021-03-04T21:49:37 | mmf.trainers.callbacks.logistics: [0mprogress: 7200/22000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.1661, train/total_loss: 0.0049, train/total_loss/avg: 0.1661, max mem: 5552.0, experiment: run, epoch: 28, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 181ms, time_since_start: 01h 01m 48s 670ms, eta: 02h 04m 01s 681ms
[32m2021-03-04T21:50:18 | mmf.trainers.callbacks.logistics: [0mprogress: 7300/22000, train/hateful_memes/cross_entropy: 0.0049, train/hateful_memes/cross_entropy/avg: 0.1639, train/total_loss: 0.0049, train/total_loss/avg: 0.1639, max mem: 5552.0, experiment: run, epoch: 28, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 777ms, time_since_start: 01h 02m 29s 447ms, eta: 01h 40m 06s 234ms
[32m2021-03-04T21:50:59 | mmf.trainers.callbacks.logistics: [0mprogress: 7400/22000, train/hateful_memes/cross_entropy: 0.0045, train/hateful_memes/cross_entropy/avg: 0.1617, train/total_loss: 0.0045, train/total_loss/avg: 0.1617, max mem: 5552.0, experiment: run, epoch: 28, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 236ms, time_since_start: 01h 03m 10s 683ms, eta: 01h 40m 32s 524ms
[32m2021-03-04T21:51:51 | mmf.trainers.callbacks.logistics: [0mprogress: 7500/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1596, train/total_loss: 0.0041, train/total_loss/avg: 0.1596, max mem: 5552.0, experiment: run, epoch: 29, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 938ms, time_since_start: 01h 04m 02s 622ms, eta: 02h 05m 46s 168ms
[32m2021-03-04T21:52:32 | mmf.trainers.callbacks.logistics: [0mprogress: 7600/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1575, train/total_loss: 0.0041, train/total_loss/avg: 0.1575, max mem: 5552.0, experiment: run, epoch: 29, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 931ms, time_since_start: 01h 04m 43s 553ms, eta: 01h 38m 25s 860ms
[32m2021-03-04T21:53:12 | mmf.trainers.callbacks.logistics: [0mprogress: 7700/22000, train/hateful_memes/cross_entropy: 0.0040, train/hateful_memes/cross_entropy/avg: 0.1555, train/total_loss: 0.0040, train/total_loss/avg: 0.1555, max mem: 5552.0, experiment: run, epoch: 29, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 991ms, time_since_start: 01h 05m 23s 545ms, eta: 01h 35m 30s 245ms
[32m2021-03-04T21:54:02 | mmf.trainers.callbacks.logistics: [0mprogress: 7800/22000, train/hateful_memes/cross_entropy: 0.0040, train/hateful_memes/cross_entropy/avg: 0.1535, train/total_loss: 0.0040, train/total_loss/avg: 0.1535, max mem: 5552.0, experiment: run, epoch: 30, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 046ms, time_since_start: 01h 06m 13s 591ms, eta: 01h 58m 40s 838ms
[32m2021-03-04T21:54:41 | mmf.trainers.callbacks.logistics: [0mprogress: 7900/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1516, train/total_loss: 0.0037, train/total_loss/avg: 0.1516, max mem: 5552.0, experiment: run, epoch: 30, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 274ms, time_since_start: 01h 06m 52s 866ms, eta: 01h 32m 28s 723ms
[32m2021-03-04T21:55:32 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T21:55:32 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:55:32 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:55:32 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:55:36 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:55:52 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:55:52 | mmf.trainers.callbacks.logistics: [0mprogress: 8000/22000, train/hateful_memes/cross_entropy: 0.0035, train/hateful_memes/cross_entropy/avg: 0.1497, train/total_loss: 0.0035, train/total_loss/avg: 0.1497, max mem: 5552.0, experiment: run, epoch: 31, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00001, ups: 1.41, time: 01m 11s 346ms, time_since_start: 01h 08m 04s 212ms, eta: 02h 46m 48s 442ms
[32m2021-03-04T21:55:52 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T21:56:03 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T21:56:03 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T21:56:03 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T21:56:03 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T21:56:18 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T21:56:34 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T21:56:50 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T21:56:50 | mmf.trainers.callbacks.logistics: [0mprogress: 8000/22000, val/hateful_memes/cross_entropy: 2.1631, val/total_loss: 2.1631, val/hateful_memes/accuracy: 0.6315, val/hateful_memes/binary_f1: 0.4325, val/hateful_memes/roc_auc: 0.6349, num_updates: 8000, epoch: 31, iterations: 8000, max_updates: 22000, val_time: 57s 593ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.634902
[32m2021-03-04T21:57:29 | mmf.trainers.callbacks.logistics: [0mprogress: 8100/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1480, train/total_loss: 0.0037, train/total_loss/avg: 0.1480, max mem: 5552.0, experiment: run, epoch: 31, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00001, ups: 2.63, time: 38s 704ms, time_since_start: 01h 09m 40s 512ms, eta: 01h 29m 50s 643ms
[32m2021-03-04T21:58:08 | mmf.trainers.callbacks.logistics: [0mprogress: 8200/22000, train/hateful_memes/cross_entropy: 0.0035, train/hateful_memes/cross_entropy/avg: 0.1462, train/total_loss: 0.0035, train/total_loss/avg: 0.1462, max mem: 5552.0, experiment: run, epoch: 31, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 131ms, time_since_start: 01h 10m 19s 644ms, eta: 01h 30m 10s 959ms
[32m2021-03-04T21:58:58 | mmf.trainers.callbacks.logistics: [0mprogress: 8300/22000, train/hateful_memes/cross_entropy: 0.0029, train/hateful_memes/cross_entropy/avg: 0.1444, train/total_loss: 0.0029, train/total_loss/avg: 0.1444, max mem: 5552.0, experiment: run, epoch: 32, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 427ms, time_since_start: 01h 11m 10s 071ms, eta: 01h 55m 22s 399ms
[32m2021-03-04T21:59:38 | mmf.trainers.callbacks.logistics: [0mprogress: 8400/22000, train/hateful_memes/cross_entropy: 0.0029, train/hateful_memes/cross_entropy/avg: 0.1429, train/total_loss: 0.0029, train/total_loss/avg: 0.1429, max mem: 5552.0, experiment: run, epoch: 32, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 296ms, time_since_start: 01h 11m 49s 368ms, eta: 01h 29m 15s 050ms
[32m2021-03-04T22:00:17 | mmf.trainers.callbacks.logistics: [0mprogress: 8500/22000, train/hateful_memes/cross_entropy: 0.0028, train/hateful_memes/cross_entropy/avg: 0.1412, train/total_loss: 0.0028, train/total_loss/avg: 0.1412, max mem: 5552.0, experiment: run, epoch: 32, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 669ms, time_since_start: 01h 12m 29s 038ms, eta: 01h 29m 26s 108ms
[32m2021-03-04T22:01:08 | mmf.trainers.callbacks.logistics: [0mprogress: 8600/22000, train/hateful_memes/cross_entropy: 0.0028, train/hateful_memes/cross_entropy/avg: 0.1414, train/total_loss: 0.0028, train/total_loss/avg: 0.1414, max mem: 5552.0, experiment: run, epoch: 33, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 004ms, time_since_start: 01h 13m 20s 042ms, eta: 01h 54m 08s 241ms
[32m2021-03-04T22:01:49 | mmf.trainers.callbacks.logistics: [0mprogress: 8700/22000, train/hateful_memes/cross_entropy: 0.0022, train/hateful_memes/cross_entropy/avg: 0.1397, train/total_loss: 0.0022, train/total_loss/avg: 0.1397, max mem: 5552.0, experiment: run, epoch: 33, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 065ms, time_since_start: 01h 14m 01s 108ms, eta: 01h 31m 12s 678ms
[32m2021-03-04T22:02:42 | mmf.trainers.callbacks.logistics: [0mprogress: 8800/22000, train/hateful_memes/cross_entropy: 0.0022, train/hateful_memes/cross_entropy/avg: 0.1382, train/total_loss: 0.0022, train/total_loss/avg: 0.1382, max mem: 5552.0, experiment: run, epoch: 34, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 677ms, time_since_start: 01h 14m 53s 785ms, eta: 01h 56m 07s 360ms
[32m2021-03-04T22:03:22 | mmf.trainers.callbacks.logistics: [0mprogress: 8900/22000, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1366, train/total_loss: 0.0021, train/total_loss/avg: 0.1366, max mem: 5552.0, experiment: run, epoch: 34, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 089ms, time_since_start: 01h 15m 33s 875ms, eta: 01h 27m 42s 196ms
[32m2021-03-04T22:04:02 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T22:04:02 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:04:02 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:04:02 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:04:06 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:04:22 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:04:22 | mmf.trainers.callbacks.logistics: [0mprogress: 9000/22000, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1353, train/total_loss: 0.0021, train/total_loss/avg: 0.1353, max mem: 5552.0, experiment: run, epoch: 34, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00001, ups: 1.67, time: 01m 184ms, time_since_start: 01h 16m 34s 060ms, eta: 02h 10m 39s 683ms
[32m2021-03-04T22:04:22 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T22:04:33 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T22:04:33 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:04:33 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:04:33 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:04:46 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:05:02 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:05:02 | mmf.trainers.callbacks.logistics: [0mprogress: 9000/22000, val/hateful_memes/cross_entropy: 2.6544, val/total_loss: 2.6544, val/hateful_memes/accuracy: 0.6407, val/hateful_memes/binary_f1: 0.4017, val/hateful_memes/roc_auc: 0.6139, num_updates: 9000, epoch: 34, iterations: 9000, max_updates: 22000, val_time: 40s 080ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.634902
[32m2021-03-04T22:05:53 | mmf.trainers.callbacks.logistics: [0mprogress: 9100/22000, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1338, train/total_loss: 0.0021, train/total_loss/avg: 0.1338, max mem: 5552.0, experiment: run, epoch: 35, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 740ms, time_since_start: 01h 18m 04s 883ms, eta: 01h 49m 18s 659ms
[32m2021-03-04T22:06:32 | mmf.trainers.callbacks.logistics: [0mprogress: 9200/22000, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1324, train/total_loss: 0.0021, train/total_loss/avg: 0.1324, max mem: 5552.0, experiment: run, epoch: 35, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00001, ups: 2.63, time: 38s 967ms, time_since_start: 01h 18m 43s 851ms, eta: 01h 23m 17s 871ms
[32m2021-03-04T22:07:11 | mmf.trainers.callbacks.logistics: [0mprogress: 9300/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1310, train/total_loss: 0.0016, train/total_loss/avg: 0.1310, max mem: 5552.0, experiment: run, epoch: 35, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 444ms, time_since_start: 01h 19m 23s 296ms, eta: 01h 23m 39s 469ms
[32m2021-03-04T22:08:02 | mmf.trainers.callbacks.logistics: [0mprogress: 9400/22000, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1313, train/total_loss: 0.0021, train/total_loss/avg: 0.1313, max mem: 5552.0, experiment: run, epoch: 36, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 714ms, time_since_start: 01h 20m 14s 010ms, eta: 01h 46m 42s 751ms
[32m2021-03-04T22:08:42 | mmf.trainers.callbacks.logistics: [0mprogress: 9500/22000, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1300, train/total_loss: 0.0021, train/total_loss/avg: 0.1300, max mem: 5552.0, experiment: run, epoch: 36, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 078ms, time_since_start: 01h 20m 54s 088ms, eta: 01h 23m 39s 776ms
[32m2021-03-04T22:09:32 | mmf.trainers.callbacks.logistics: [0mprogress: 9600/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1287, train/total_loss: 0.0016, train/total_loss/avg: 0.1287, max mem: 5552.0, experiment: run, epoch: 37, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 757ms, time_since_start: 01h 21m 43s 846ms, eta: 01h 43m 02s 294ms
[32m2021-03-04T22:10:11 | mmf.trainers.callbacks.logistics: [0mprogress: 9700/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.1273, train/total_loss: 0.0016, train/total_loss/avg: 0.1273, max mem: 5552.0, experiment: run, epoch: 37, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00001, ups: 2.63, time: 38s 852ms, time_since_start: 01h 22m 22s 698ms, eta: 01h 19m 48s 449ms
[32m2021-03-04T22:10:50 | mmf.trainers.callbacks.logistics: [0mprogress: 9800/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1260, train/total_loss: 0.0014, train/total_loss/avg: 0.1260, max mem: 5552.0, experiment: run, epoch: 37, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 515ms, time_since_start: 01h 23m 02s 213ms, eta: 01h 20m 30s 483ms
[32m2021-03-04T22:11:40 | mmf.trainers.callbacks.logistics: [0mprogress: 9900/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1250, train/total_loss: 0.0014, train/total_loss/avg: 0.1250, max mem: 5552.0, experiment: run, epoch: 38, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00001, ups: 2.04, time: 49s 869ms, time_since_start: 01h 23m 52s 083ms, eta: 01h 40m 46s 230ms
[32m2021-03-04T22:12:21 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T22:12:21 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:12:21 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:12:21 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:12:25 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:12:41 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:12:41 | mmf.trainers.callbacks.logistics: [0mprogress: 10000/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1237, train/total_loss: 0.0014, train/total_loss/avg: 0.1237, max mem: 5552.0, experiment: run, epoch: 38, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00001, ups: 1.64, time: 01m 01s 174ms, time_since_start: 01h 24m 53s 257ms, eta: 02h 02m 35s 615ms
[32m2021-03-04T22:12:41 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T22:12:52 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T22:12:52 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:12:52 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:12:52 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:13:09 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:13:25 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:13:25 | mmf.trainers.callbacks.logistics: [0mprogress: 10000/22000, val/hateful_memes/cross_entropy: 2.5132, val/total_loss: 2.5132, val/hateful_memes/accuracy: 0.6500, val/hateful_memes/binary_f1: 0.3813, val/hateful_memes/roc_auc: 0.6324, num_updates: 10000, epoch: 38, iterations: 10000, max_updates: 22000, val_time: 43s 314ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.634902
[32m2021-03-04T22:14:04 | mmf.trainers.callbacks.logistics: [0mprogress: 10100/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1225, train/total_loss: 0.0010, train/total_loss/avg: 0.1225, max mem: 5552.0, experiment: run, epoch: 38, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00001, ups: 2.63, time: 38s 967ms, time_since_start: 01h 26m 15s 541ms, eta: 01h 17m 26s 392ms
[32m2021-03-04T22:14:54 | mmf.trainers.callbacks.logistics: [0mprogress: 10200/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1213, train/total_loss: 0.0009, train/total_loss/avg: 0.1213, max mem: 5552.0, experiment: run, epoch: 39, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 407ms, time_since_start: 01h 27m 05s 948ms, eta: 01h 39m 19s 980ms
[32m2021-03-04T22:15:34 | mmf.trainers.callbacks.logistics: [0mprogress: 10300/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1202, train/total_loss: 0.0010, train/total_loss/avg: 0.1202, max mem: 5552.0, experiment: run, epoch: 39, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 910ms, time_since_start: 01h 27m 45s 859ms, eta: 01h 17m 58s 905ms
[32m2021-03-04T22:16:25 | mmf.trainers.callbacks.logistics: [0mprogress: 10400/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1191, train/total_loss: 0.0009, train/total_loss/avg: 0.1191, max mem: 5552.0, experiment: run, epoch: 40, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 591ms, time_since_start: 01h 28m 36s 451ms, eta: 01h 38m 369ms
[32m2021-03-04T22:17:04 | mmf.trainers.callbacks.logistics: [0mprogress: 10500/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1180, train/total_loss: 0.0010, train/total_loss/avg: 0.1180, max mem: 5552.0, experiment: run, epoch: 40, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 135ms, time_since_start: 01h 29m 15s 587ms, eta: 01h 15m 09s 639ms
[32m2021-03-04T22:17:45 | mmf.trainers.callbacks.logistics: [0mprogress: 10600/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1169, train/total_loss: 0.0010, train/total_loss/avg: 0.1169, max mem: 5552.0, experiment: run, epoch: 40, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00001, ups: 2.44, time: 41s 657ms, time_since_start: 01h 29m 57s 244ms, eta: 01h 19m 18s 427ms
[32m2021-03-04T22:18:37 | mmf.trainers.callbacks.logistics: [0mprogress: 10700/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1158, train/total_loss: 0.0010, train/total_loss/avg: 0.1158, max mem: 5552.0, experiment: run, epoch: 41, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 072ms, time_since_start: 01h 30m 48s 316ms, eta: 01h 36m 22s 715ms
[32m2021-03-04T22:19:16 | mmf.trainers.callbacks.logistics: [0mprogress: 10800/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1148, train/total_loss: 0.0010, train/total_loss/avg: 0.1148, max mem: 5552.0, experiment: run, epoch: 41, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 734ms, time_since_start: 01h 31m 28s 051ms, eta: 01h 14m 19s 154ms
[32m2021-03-04T22:19:56 | mmf.trainers.callbacks.logistics: [0mprogress: 10900/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1137, train/total_loss: 0.0014, train/total_loss/avg: 0.1137, max mem: 5552.0, experiment: run, epoch: 41, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 362ms, time_since_start: 01h 32m 07s 413ms, eta: 01h 12m 57s 942ms
[32m2021-03-04T22:20:46 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T22:20:46 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:20:46 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:20:46 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:20:50 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:21:06 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:21:06 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1129, train/total_loss: 0.0014, train/total_loss/avg: 0.1129, max mem: 5552.0, experiment: run, epoch: 42, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00001, ups: 1.43, time: 01m 10s 180ms, time_since_start: 01h 33m 17s 593ms, eta: 02h 08m 55s 260ms
[32m2021-03-04T22:21:06 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T22:21:17 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T22:21:17 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:21:17 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:21:17 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:21:34 | mmf.utils.checkpoint: [0mSaving best checkpoint
[32m2021-03-04T22:21:50 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:22:06 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:22:06 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, val/hateful_memes/cross_entropy: 2.3279, val/total_loss: 2.3279, val/hateful_memes/accuracy: 0.6426, val/hateful_memes/binary_f1: 0.3971, val/hateful_memes/roc_auc: 0.6360, num_updates: 11000, epoch: 42, iterations: 11000, max_updates: 22000, val_time: 59s 842ms, best_update: 11000, best_iteration: 11000, best_val/hateful_memes/roc_auc: 0.635959
[32m2021-03-04T22:22:45 | mmf.trainers.callbacks.logistics: [0mprogress: 11100/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1118, train/total_loss: 0.0010, train/total_loss/avg: 0.1118, max mem: 5552.0, experiment: run, epoch: 42, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 274ms, time_since_start: 01h 34m 56s 712ms, eta: 01h 11m 29s 500ms
[32m2021-03-04T22:23:35 | mmf.trainers.callbacks.logistics: [0mprogress: 11200/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1108, train/total_loss: 0.0009, train/total_loss/avg: 0.1108, max mem: 5552.0, experiment: run, epoch: 43, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00001, ups: 2.00, time: 50s 060ms, time_since_start: 01h 35m 46s 773ms, eta: 01h 30m 17s 324ms
[32m2021-03-04T22:24:14 | mmf.trainers.callbacks.logistics: [0mprogress: 11300/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1099, train/total_loss: 0.0009, train/total_loss/avg: 0.1099, max mem: 5552.0, experiment: run, epoch: 43, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00001, ups: 2.63, time: 38s 972ms, time_since_start: 01h 36m 25s 745ms, eta: 01h 09m 38s 403ms
[32m2021-03-04T22:24:55 | mmf.trainers.callbacks.logistics: [0mprogress: 11400/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1089, train/total_loss: 0.0009, train/total_loss/avg: 0.1089, max mem: 5552.0, experiment: run, epoch: 43, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 899ms, time_since_start: 01h 37m 06s 645ms, eta: 01h 12m 24s 045ms
[32m2021-03-04T22:25:46 | mmf.trainers.callbacks.logistics: [0mprogress: 11500/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1080, train/total_loss: 0.0009, train/total_loss/avg: 0.1080, max mem: 5552.0, experiment: run, epoch: 44, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 379ms, time_since_start: 01h 37m 58s 024ms, eta: 01h 30m 05s 610ms
[32m2021-03-04T22:26:26 | mmf.trainers.callbacks.logistics: [0mprogress: 11600/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1071, train/total_loss: 0.0009, train/total_loss/avg: 0.1071, max mem: 5552.0, experiment: run, epoch: 44, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00001, ups: 2.50, time: 40s 198ms, time_since_start: 01h 38m 38s 223ms, eta: 01h 09m 48s 990ms
[32m2021-03-04T22:27:06 | mmf.trainers.callbacks.logistics: [0mprogress: 11700/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1066, train/total_loss: 0.0010, train/total_loss/avg: 0.1066, max mem: 5552.0, experiment: run, epoch: 44, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 484ms, time_since_start: 01h 39m 17s 707ms, eta: 01h 07m 55s 065ms
[32m2021-03-04T22:27:57 | mmf.trainers.callbacks.logistics: [0mprogress: 11800/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1057, train/total_loss: 0.0010, train/total_loss/avg: 0.1057, max mem: 5552.0, experiment: run, epoch: 45, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 396ms, time_since_start: 01h 40m 09s 105ms, eta: 01h 27m 32s 980ms
[32m2021-03-04T22:28:37 | mmf.trainers.callbacks.logistics: [0mprogress: 11900/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1062, train/total_loss: 0.0010, train/total_loss/avg: 0.1062, max mem: 5552.0, experiment: run, epoch: 45, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00001, ups: 2.56, time: 39s 467ms, time_since_start: 01h 40m 48s 572ms, eta: 01h 06m 34s 160ms
[32m2021-03-04T22:29:28 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T22:29:28 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:29:28 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:29:28 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:29:32 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:29:49 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:29:49 | mmf.trainers.callbacks.logistics: [0mprogress: 12000/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1053, train/total_loss: 0.0010, train/total_loss/avg: 0.1053, max mem: 5552.0, experiment: run, epoch: 46, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00001, ups: 1.41, time: 01m 11s 832ms, time_since_start: 01h 42m 404ms, eta: 01h 59m 57s 634ms
[32m2021-03-04T22:29:49 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T22:29:59 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T22:29:59 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:29:59 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:29:59 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:30:14 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:30:30 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:30:30 | mmf.trainers.callbacks.logistics: [0mprogress: 12000/22000, val/hateful_memes/cross_entropy: 2.7384, val/total_loss: 2.7384, val/hateful_memes/accuracy: 0.6481, val/hateful_memes/binary_f1: 0.3873, val/hateful_memes/roc_auc: 0.6327, num_updates: 12000, epoch: 46, iterations: 12000, max_updates: 22000, val_time: 41s 413ms, best_update: 11000, best_iteration: 11000, best_val/hateful_memes/roc_auc: 0.635959
[32m2021-03-04T22:31:09 | mmf.trainers.callbacks.logistics: [0mprogress: 12100/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1044, train/total_loss: 0.0010, train/total_loss/avg: 0.1044, max mem: 5552.0, experiment: run, epoch: 46, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0., ups: 2.63, time: 38s 948ms, time_since_start: 01h 43m 20s 769ms, eta: 01h 04m 23s 649ms
[32m2021-03-04T22:31:48 | mmf.trainers.callbacks.logistics: [0mprogress: 12200/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1036, train/total_loss: 0.0010, train/total_loss/avg: 0.1036, max mem: 5552.0, experiment: run, epoch: 46, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 158ms, time_since_start: 01h 43m 59s 928ms, eta: 01h 04m 05s 253ms
[32m2021-03-04T22:32:38 | mmf.trainers.callbacks.logistics: [0mprogress: 12300/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1027, train/total_loss: 0.0009, train/total_loss/avg: 0.1027, max mem: 5552.0, experiment: run, epoch: 47, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 990ms, time_since_start: 01h 44m 49s 918ms, eta: 01h 20m 58s 780ms
[32m2021-03-04T22:33:18 | mmf.trainers.callbacks.logistics: [0mprogress: 12400/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.1019, train/total_loss: 0.0005, train/total_loss/avg: 0.1019, max mem: 5552.0, experiment: run, epoch: 47, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 903ms, time_since_start: 01h 45m 29s 822ms, eta: 01h 03m 58s 438ms
[32m2021-03-04T22:33:58 | mmf.trainers.callbacks.logistics: [0mprogress: 12500/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.1011, train/total_loss: 0.0005, train/total_loss/avg: 0.1011, max mem: 5552.0, experiment: run, epoch: 47, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 110ms, time_since_start: 01h 46m 09s 933ms, eta: 01h 03m 38s 123ms
[32m2021-03-04T22:34:49 | mmf.trainers.callbacks.logistics: [0mprogress: 12600/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.1003, train/total_loss: 0.0005, train/total_loss/avg: 0.1003, max mem: 5552.0, experiment: run, epoch: 48, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 220ms, time_since_start: 01h 47m 01s 153ms, eta: 01h 20m 24s 340ms
[32m2021-03-04T22:35:31 | mmf.trainers.callbacks.logistics: [0mprogress: 12700/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0995, train/total_loss: 0.0005, train/total_loss/avg: 0.0995, max mem: 5552.0, experiment: run, epoch: 48, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0., ups: 2.44, time: 41s 575ms, time_since_start: 01h 47m 42s 729ms, eta: 01h 04m 34s 286ms
[32m2021-03-04T22:36:21 | mmf.trainers.callbacks.logistics: [0mprogress: 12800/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0987, train/total_loss: 0.0005, train/total_loss/avg: 0.0987, max mem: 5552.0, experiment: run, epoch: 49, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 577ms, time_since_start: 01h 48m 33s 307ms, eta: 01h 17m 42s 437ms
[32m2021-03-04T22:37:01 | mmf.trainers.callbacks.logistics: [0mprogress: 12900/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0980, train/total_loss: 0.0003, train/total_loss/avg: 0.0980, max mem: 5552.0, experiment: run, epoch: 49, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 376ms, time_since_start: 01h 49m 12s 683ms, eta: 59m 50s 389ms
[32m2021-03-04T22:37:40 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T22:37:40 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:37:40 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:37:40 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:37:44 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:38:00 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:38:00 | mmf.trainers.callbacks.logistics: [0mprogress: 13000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0972, train/total_loss: 0.0002, train/total_loss/avg: 0.0972, max mem: 5552.0, experiment: run, epoch: 49, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 569ms, time_since_start: 01h 50m 12s 253ms, eta: 01h 29m 32s 022ms
[32m2021-03-04T22:38:00 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T22:38:11 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T22:38:11 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:38:11 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:38:11 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:38:25 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:38:41 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:38:41 | mmf.trainers.callbacks.logistics: [0mprogress: 13000/22000, val/hateful_memes/cross_entropy: 2.9100, val/total_loss: 2.9100, val/hateful_memes/accuracy: 0.6593, val/hateful_memes/binary_f1: 0.4084, val/hateful_memes/roc_auc: 0.6230, num_updates: 13000, epoch: 49, iterations: 13000, max_updates: 22000, val_time: 40s 370ms, best_update: 11000, best_iteration: 11000, best_val/hateful_memes/roc_auc: 0.635959
[32m2021-03-04T22:39:30 | mmf.trainers.callbacks.logistics: [0mprogress: 13100/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0966, train/total_loss: 0.0003, train/total_loss/avg: 0.0966, max mem: 5552.0, experiment: run, epoch: 50, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 345ms, time_since_start: 01h 51m 41s 970ms, eta: 01h 13m 20s 520ms
[32m2021-03-04T22:40:09 | mmf.trainers.callbacks.logistics: [0mprogress: 13200/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0958, train/total_loss: 0.0003, train/total_loss/avg: 0.0958, max mem: 5552.0, experiment: run, epoch: 50, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0., ups: 2.63, time: 38s 936ms, time_since_start: 01h 52m 20s 907ms, eta: 57m 13s 266ms
[32m2021-03-04T22:40:48 | mmf.trainers.callbacks.logistics: [0mprogress: 13300/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0954, train/total_loss: 0.0003, train/total_loss/avg: 0.0954, max mem: 5552.0, experiment: run, epoch: 50, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 382ms, time_since_start: 01h 53m 289ms, eta: 57m 13s 135ms
[32m2021-03-04T22:41:38 | mmf.trainers.callbacks.logistics: [0mprogress: 13400/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0947, train/total_loss: 0.0003, train/total_loss/avg: 0.0947, max mem: 5552.0, experiment: run, epoch: 51, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 879ms, time_since_start: 01h 53m 50s 169ms, eta: 01h 11m 38s 192ms
[32m2021-03-04T22:42:19 | mmf.trainers.callbacks.logistics: [0mprogress: 13500/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0940, train/total_loss: 0.0003, train/total_loss/avg: 0.0940, max mem: 5552.0, experiment: run, epoch: 51, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 707ms, time_since_start: 01h 54m 30s 876ms, eta: 57m 47s 068ms
[32m2021-03-04T22:43:11 | mmf.trainers.callbacks.logistics: [0mprogress: 13600/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0933, train/total_loss: 0.0002, train/total_loss/avg: 0.0933, max mem: 5552.0, experiment: run, epoch: 52, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 563ms, time_since_start: 01h 55m 22s 440ms, eta: 01h 12m 19s 999ms
[32m2021-03-04T22:43:52 | mmf.trainers.callbacks.logistics: [0mprogress: 13700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0927, train/total_loss: 0.0002, train/total_loss/avg: 0.0927, max mem: 5552.0, experiment: run, epoch: 52, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0., ups: 2.44, time: 41s 348ms, time_since_start: 01h 56m 03s 789ms, eta: 57m 18s 824ms
[32m2021-03-04T22:44:33 | mmf.trainers.callbacks.logistics: [0mprogress: 13800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0920, train/total_loss: 0.0001, train/total_loss/avg: 0.0920, max mem: 5552.0, experiment: run, epoch: 52, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0., ups: 2.44, time: 41s 106ms, time_since_start: 01h 56m 44s 895ms, eta: 56m 17s 456ms
[32m2021-03-04T22:45:24 | mmf.trainers.callbacks.logistics: [0mprogress: 13900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0913, train/total_loss: 0.0001, train/total_loss/avg: 0.0913, max mem: 5552.0, experiment: run, epoch: 53, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 895ms, time_since_start: 01h 57m 35s 790ms, eta: 01h 08m 50s 770ms
[32m2021-03-04T22:46:03 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T22:46:03 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:46:03 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:46:03 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:46:07 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:46:23 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:46:23 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0907, train/total_loss: 0.0002, train/total_loss/avg: 0.0907, max mem: 5552.0, experiment: run, epoch: 53, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 268ms, time_since_start: 01h 58m 35s 059ms, eta: 01h 19m 10s 938ms
[32m2021-03-04T22:46:23 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T22:46:34 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T22:46:34 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:46:34 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:46:34 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:46:50 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:47:05 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:47:05 | mmf.trainers.callbacks.logistics: [0mprogress: 14000/22000, val/hateful_memes/cross_entropy: 2.9111, val/total_loss: 2.9111, val/hateful_memes/accuracy: 0.6463, val/hateful_memes/binary_f1: 0.3535, val/hateful_memes/roc_auc: 0.6269, num_updates: 14000, epoch: 53, iterations: 14000, max_updates: 22000, val_time: 41s 921ms, best_update: 11000, best_iteration: 11000, best_val/hateful_memes/roc_auc: 0.635959
[32m2021-03-04T22:47:55 | mmf.trainers.callbacks.logistics: [0mprogress: 14100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0901, train/total_loss: 0.0002, train/total_loss/avg: 0.0901, max mem: 5552.0, experiment: run, epoch: 54, num_updates: 14100, iterations: 14100, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 626ms, time_since_start: 02h 06s 608ms, eta: 01h 05m 28s 337ms
[32m2021-03-04T22:48:36 | mmf.trainers.callbacks.logistics: [0mprogress: 14200/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0895, train/total_loss: 0.0003, train/total_loss/avg: 0.0895, max mem: 5552.0, experiment: run, epoch: 54, num_updates: 14200, iterations: 14200, max_updates: 22000, lr: 0., ups: 2.44, time: 41s 585ms, time_since_start: 02h 48s 194ms, eta: 54m 10s 147ms
[32m2021-03-04T22:49:17 | mmf.trainers.callbacks.logistics: [0mprogress: 14300/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0889, train/total_loss: 0.0003, train/total_loss/avg: 0.0889, max mem: 5552.0, experiment: run, epoch: 54, num_updates: 14300, iterations: 14300, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 852ms, time_since_start: 02h 01m 29s 047ms, eta: 52m 31s 960ms
[32m2021-03-04T22:50:08 | mmf.trainers.callbacks.logistics: [0mprogress: 14400/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0883, train/total_loss: 0.0003, train/total_loss/avg: 0.0883, max mem: 5552.0, experiment: run, epoch: 55, num_updates: 14400, iterations: 14400, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 311ms, time_since_start: 02h 02m 19s 358ms, eta: 01h 03m 51s 328ms
[32m2021-03-04T22:50:47 | mmf.trainers.callbacks.logistics: [0mprogress: 14500/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0877, train/total_loss: 0.0003, train/total_loss/avg: 0.0877, max mem: 5552.0, experiment: run, epoch: 55, num_updates: 14500, iterations: 14500, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 170ms, time_since_start: 02h 02m 58s 528ms, eta: 49m 03s 636ms
[32m2021-03-04T22:51:26 | mmf.trainers.callbacks.logistics: [0mprogress: 14600/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0871, train/total_loss: 0.0003, train/total_loss/avg: 0.0871, max mem: 5552.0, experiment: run, epoch: 55, num_updates: 14600, iterations: 14600, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 555ms, time_since_start: 02h 03m 38s 084ms, eta: 48m 52s 964ms
[32m2021-03-04T22:52:16 | mmf.trainers.callbacks.logistics: [0mprogress: 14700/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0865, train/total_loss: 0.0003, train/total_loss/avg: 0.0865, max mem: 5552.0, experiment: run, epoch: 56, num_updates: 14700, iterations: 14700, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 871ms, time_since_start: 02h 04m 27s 955ms, eta: 01h 47s 886ms
[32m2021-03-04T22:52:56 | mmf.trainers.callbacks.logistics: [0mprogress: 14800/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0859, train/total_loss: 0.0003, train/total_loss/avg: 0.0859, max mem: 5552.0, experiment: run, epoch: 56, num_updates: 14800, iterations: 14800, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 540ms, time_since_start: 02h 05m 07s 496ms, eta: 47m 32s 603ms
[32m2021-03-04T22:53:46 | mmf.trainers.callbacks.logistics: [0mprogress: 14900/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0854, train/total_loss: 0.0005, train/total_loss/avg: 0.0854, max mem: 5552.0, experiment: run, epoch: 57, num_updates: 14900, iterations: 14900, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 394ms, time_since_start: 02h 05m 57s 890ms, eta: 59m 45s 166ms
[32m2021-03-04T22:54:27 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T22:54:27 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:54:27 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:54:27 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:54:31 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:54:47 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:54:47 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0848, train/total_loss: 0.0005, train/total_loss/avg: 0.0848, max mem: 5552.0, experiment: run, epoch: 57, num_updates: 15000, iterations: 15000, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 261ms, time_since_start: 02h 06m 59s 151ms, eta: 01h 11m 36s 853ms
[32m2021-03-04T22:54:47 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T22:54:58 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T22:54:58 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T22:54:58 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T22:54:58 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T22:55:14 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T22:55:30 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T22:55:30 | mmf.trainers.callbacks.logistics: [0mprogress: 15000/22000, val/hateful_memes/cross_entropy: 2.9770, val/total_loss: 2.9770, val/hateful_memes/accuracy: 0.6370, val/hateful_memes/binary_f1: 0.4215, val/hateful_memes/roc_auc: 0.6207, num_updates: 15000, epoch: 57, iterations: 15000, max_updates: 22000, val_time: 42s 296ms, best_update: 11000, best_iteration: 11000, best_val/hateful_memes/roc_auc: 0.635959
[32m2021-03-04T22:56:08 | mmf.trainers.callbacks.logistics: [0mprogress: 15100/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0842, train/total_loss: 0.0003, train/total_loss/avg: 0.0842, max mem: 5552.0, experiment: run, epoch: 57, num_updates: 15100, iterations: 15100, max_updates: 22000, lr: 0., ups: 2.63, time: 38s 781ms, time_since_start: 02h 08m 20s 231ms, eta: 44m 41s 247ms
[32m2021-03-04T22:56:59 | mmf.trainers.callbacks.logistics: [0mprogress: 15200/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0837, train/total_loss: 0.0003, train/total_loss/avg: 0.0837, max mem: 5552.0, experiment: run, epoch: 58, num_updates: 15200, iterations: 15200, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 432ms, time_since_start: 02h 09m 10s 663ms, eta: 57m 16s 277ms
[32m2021-03-04T22:57:38 | mmf.trainers.callbacks.logistics: [0mprogress: 15300/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0831, train/total_loss: 0.0003, train/total_loss/avg: 0.0831, max mem: 5552.0, experiment: run, epoch: 58, num_updates: 15300, iterations: 15300, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 199ms, time_since_start: 02h 09m 49s 863ms, eta: 43m 51s 647ms
[32m2021-03-04T22:58:17 | mmf.trainers.callbacks.logistics: [0mprogress: 15400/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0826, train/total_loss: 0.0003, train/total_loss/avg: 0.0826, max mem: 5552.0, experiment: run, epoch: 58, num_updates: 15400, iterations: 15400, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 430ms, time_since_start: 02h 10m 29s 294ms, eta: 43m 27s 607ms
[32m2021-03-04T22:59:08 | mmf.trainers.callbacks.logistics: [0mprogress: 15500/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0821, train/total_loss: 0.0003, train/total_loss/avg: 0.0821, max mem: 5552.0, experiment: run, epoch: 59, num_updates: 15500, iterations: 15500, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 199ms, time_since_start: 02h 11m 19s 493ms, eta: 54m 29s 480ms
[32m2021-03-04T22:59:47 | mmf.trainers.callbacks.logistics: [0mprogress: 15600/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0815, train/total_loss: 0.0003, train/total_loss/avg: 0.0815, max mem: 5552.0, experiment: run, epoch: 59, num_updates: 15600, iterations: 15600, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 466ms, time_since_start: 02h 11m 58s 959ms, eta: 42m 10s 914ms
[32m2021-03-04T23:00:38 | mmf.trainers.callbacks.logistics: [0mprogress: 15700/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0811, train/total_loss: 0.0003, train/total_loss/avg: 0.0811, max mem: 5552.0, experiment: run, epoch: 60, num_updates: 15700, iterations: 15700, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 165ms, time_since_start: 02h 12m 50s 126ms, eta: 53m 49s 905ms
[32m2021-03-04T23:01:18 | mmf.trainers.callbacks.logistics: [0mprogress: 15800/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0806, train/total_loss: 0.0003, train/total_loss/avg: 0.0806, max mem: 5552.0, experiment: run, epoch: 60, num_updates: 15800, iterations: 15800, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 461ms, time_since_start: 02h 13m 29s 587ms, eta: 40m 51s 492ms
[32m2021-03-04T23:01:57 | mmf.trainers.callbacks.logistics: [0mprogress: 15900/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0800, train/total_loss: 0.0003, train/total_loss/avg: 0.0800, max mem: 5552.0, experiment: run, epoch: 60, num_updates: 15900, iterations: 15900, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 470ms, time_since_start: 02h 14m 09s 058ms, eta: 40m 12s 536ms
[32m2021-03-04T23:02:48 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T23:02:48 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T23:02:48 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T23:02:48 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T23:02:52 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T23:03:08 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T23:03:08 | mmf.trainers.callbacks.logistics: [0mprogress: 16000/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0797, train/total_loss: 0.0003, train/total_loss/avg: 0.0797, max mem: 5552.0, experiment: run, epoch: 61, num_updates: 16000, iterations: 16000, max_updates: 22000, lr: 0., ups: 1.43, time: 01m 10s 648ms, time_since_start: 02h 15m 19s 707ms, eta: 01h 10m 47s 418ms
[32m2021-03-04T23:03:08 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T23:03:19 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T23:03:19 | mmf.trainers.callbacks.logistics: [0mprogress: 16000/22000, val/hateful_memes/cross_entropy: 2.9191, val/total_loss: 2.9191, val/hateful_memes/accuracy: 0.6389, val/hateful_memes/binary_f1: 0.3997, val/hateful_memes/roc_auc: 0.6250, num_updates: 16000, epoch: 61, iterations: 16000, max_updates: 22000, val_time: 10s 629ms, best_update: 11000, best_iteration: 11000, best_val/hateful_memes/roc_auc: 0.635959
[32m2021-03-04T23:03:57 | mmf.trainers.callbacks.logistics: [0mprogress: 16100/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0792, train/total_loss: 0.0003, train/total_loss/avg: 0.0792, max mem: 5552.0, experiment: run, epoch: 61, num_updates: 16100, iterations: 16100, max_updates: 22000, lr: 0., ups: 2.63, time: 38s 804ms, time_since_start: 02h 16m 09s 143ms, eta: 38m 14s 022ms
[32m2021-03-04T23:04:37 | mmf.trainers.callbacks.logistics: [0mprogress: 16200/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0787, train/total_loss: 0.0003, train/total_loss/avg: 0.0787, max mem: 5552.0, experiment: run, epoch: 61, num_updates: 16200, iterations: 16200, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 313ms, time_since_start: 02h 16m 48s 456ms, eta: 38m 04s 726ms
[32m2021-03-04T23:05:27 | mmf.trainers.callbacks.logistics: [0mprogress: 16300/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0782, train/total_loss: 0.0003, train/total_loss/avg: 0.0782, max mem: 5552.0, experiment: run, epoch: 62, num_updates: 16300, iterations: 16300, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 080ms, time_since_start: 02h 17m 38s 536ms, eta: 47m 40s 284ms
[32m2021-03-04T23:06:06 | mmf.trainers.callbacks.logistics: [0mprogress: 16400/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0777, train/total_loss: 0.0003, train/total_loss/avg: 0.0777, max mem: 5552.0, experiment: run, epoch: 62, num_updates: 16400, iterations: 16400, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 509ms, time_since_start: 02h 18m 18s 046ms, eta: 36m 56s 966ms
[32m2021-03-04T23:06:57 | mmf.trainers.callbacks.logistics: [0mprogress: 16500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0773, train/total_loss: 0.0002, train/total_loss/avg: 0.0773, max mem: 5552.0, experiment: run, epoch: 63, num_updates: 16500, iterations: 16500, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 384ms, time_since_start: 02h 19m 08s 430ms, eta: 46m 16s 694ms
[32m2021-03-04T23:07:37 | mmf.trainers.callbacks.logistics: [0mprogress: 16600/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0771, train/total_loss: 0.0003, train/total_loss/avg: 0.0771, max mem: 5552.0, experiment: run, epoch: 63, num_updates: 16600, iterations: 16600, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 419ms, time_since_start: 02h 19m 48s 850ms, eta: 36m 27s 013ms
[32m2021-03-04T23:08:18 | mmf.trainers.callbacks.logistics: [0mprogress: 16700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0767, train/total_loss: 0.0002, train/total_loss/avg: 0.0767, max mem: 5552.0, experiment: run, epoch: 63, num_updates: 16700, iterations: 16700, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 510ms, time_since_start: 02h 20m 29s 360ms, eta: 35m 51s 355ms
[32m2021-03-04T23:09:10 | mmf.trainers.callbacks.logistics: [0mprogress: 16800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0762, train/total_loss: 0.0002, train/total_loss/avg: 0.0762, max mem: 5552.0, experiment: run, epoch: 64, num_updates: 16800, iterations: 16800, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 148ms, time_since_start: 02h 21m 21s 509ms, eta: 45m 17s 127ms
[32m2021-03-04T23:09:49 | mmf.trainers.callbacks.logistics: [0mprogress: 16900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0758, train/total_loss: 0.0002, train/total_loss/avg: 0.0758, max mem: 5552.0, experiment: run, epoch: 64, num_updates: 16900, iterations: 16900, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 283ms, time_since_start: 02h 22m 792ms, eta: 33m 27s 442ms
[32m2021-03-04T23:10:29 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T23:10:29 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T23:10:29 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T23:10:29 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T23:10:32 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T23:10:49 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T23:10:49 | mmf.trainers.callbacks.logistics: [0mprogress: 17000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0753, train/total_loss: 0.0002, train/total_loss/avg: 0.0753, max mem: 5552.0, experiment: run, epoch: 64, num_updates: 17000, iterations: 17000, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 695ms, time_since_start: 02h 23m 487ms, eta: 49m 50s 728ms
[32m2021-03-04T23:10:49 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T23:10:59 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T23:10:59 | mmf.trainers.callbacks.logistics: [0mprogress: 17000/22000, val/hateful_memes/cross_entropy: 3.0818, val/total_loss: 3.0818, val/hateful_memes/accuracy: 0.6500, val/hateful_memes/binary_f1: 0.3903, val/hateful_memes/roc_auc: 0.6242, num_updates: 17000, epoch: 64, iterations: 17000, max_updates: 22000, val_time: 10s 624ms, best_update: 11000, best_iteration: 11000, best_val/hateful_memes/roc_auc: 0.635959
[32m2021-03-04T23:11:50 | mmf.trainers.callbacks.logistics: [0mprogress: 17100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0749, train/total_loss: 0.0002, train/total_loss/avg: 0.0749, max mem: 5552.0, experiment: run, epoch: 65, num_updates: 17100, iterations: 17100, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 621ms, time_since_start: 02h 24m 01s 735ms, eta: 41m 25s 417ms
[32m2021-03-04T23:12:29 | mmf.trainers.callbacks.logistics: [0mprogress: 17200/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0745, train/total_loss: 0.0005, train/total_loss/avg: 0.0745, max mem: 5552.0, experiment: run, epoch: 65, num_updates: 17200, iterations: 17200, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 294ms, time_since_start: 02h 24m 41s 029ms, eta: 31m 29s 922ms
[32m2021-03-04T23:13:20 | mmf.trainers.callbacks.logistics: [0mprogress: 17300/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0740, train/total_loss: 0.0005, train/total_loss/avg: 0.0740, max mem: 5552.0, experiment: run, epoch: 66, num_updates: 17300, iterations: 17300, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 659ms, time_since_start: 02h 25m 31s 689ms, eta: 39m 45s 758ms
[32m2021-03-04T23:13:59 | mmf.trainers.callbacks.logistics: [0mprogress: 17400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0736, train/total_loss: 0.0002, train/total_loss/avg: 0.0736, max mem: 5552.0, experiment: run, epoch: 66, num_updates: 17400, iterations: 17400, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 108ms, time_since_start: 02h 26m 10s 798ms, eta: 30m 02s 591ms
[32m2021-03-04T23:14:40 | mmf.trainers.callbacks.logistics: [0mprogress: 17500/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0732, train/total_loss: 0.0005, train/total_loss/avg: 0.0732, max mem: 5552.0, experiment: run, epoch: 66, num_updates: 17500, iterations: 17500, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 872ms, time_since_start: 02h 26m 51s 670ms, eta: 30m 42s 942ms
[32m2021-03-04T23:15:31 | mmf.trainers.callbacks.logistics: [0mprogress: 17600/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0728, train/total_loss: 0.0002, train/total_loss/avg: 0.0728, max mem: 5552.0, experiment: run, epoch: 67, num_updates: 17600, iterations: 17600, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 177ms, time_since_start: 02h 27m 42s 848ms, eta: 37m 36s 321ms
[32m2021-03-04T23:16:12 | mmf.trainers.callbacks.logistics: [0mprogress: 17700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0723, train/total_loss: 0.0002, train/total_loss/avg: 0.0723, max mem: 5552.0, experiment: run, epoch: 67, num_updates: 17700, iterations: 17700, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 661ms, time_since_start: 02h 28m 23s 510ms, eta: 29m 11s 959ms
[32m2021-03-04T23:16:51 | mmf.trainers.callbacks.logistics: [0mprogress: 17800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0720, train/total_loss: 0.0002, train/total_loss/avg: 0.0720, max mem: 5552.0, experiment: run, epoch: 67, num_updates: 17800, iterations: 17800, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 651ms, time_since_start: 02h 29m 03s 161ms, eta: 27m 48s 686ms
[32m2021-03-04T23:17:43 | mmf.trainers.callbacks.logistics: [0mprogress: 17900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0719, train/total_loss: 0.0002, train/total_loss/avg: 0.0719, max mem: 5552.0, experiment: run, epoch: 68, num_updates: 17900, iterations: 17900, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 328ms, time_since_start: 02h 29m 54s 490ms, eta: 35m 08s 674ms
[32m2021-03-04T23:18:24 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T23:18:24 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T23:18:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T23:18:24 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T23:18:28 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T23:18:44 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T23:18:44 | mmf.trainers.callbacks.logistics: [0mprogress: 18000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0715, train/total_loss: 0.0002, train/total_loss/avg: 0.0715, max mem: 5552.0, experiment: run, epoch: 68, num_updates: 18000, iterations: 18000, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 391ms, time_since_start: 02h 30m 55s 881ms, eta: 41m 552ms
[32m2021-03-04T23:18:44 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T23:18:55 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T23:18:55 | mmf.trainers.callbacks.logistics: [0mprogress: 18000/22000, val/hateful_memes/cross_entropy: 3.1361, val/total_loss: 3.1361, val/hateful_memes/accuracy: 0.6519, val/hateful_memes/binary_f1: 0.3805, val/hateful_memes/roc_auc: 0.6259, num_updates: 18000, epoch: 68, iterations: 18000, max_updates: 22000, val_time: 10s 509ms, best_update: 11000, best_iteration: 11000, best_val/hateful_memes/roc_auc: 0.635959
[32m2021-03-04T23:19:46 | mmf.trainers.callbacks.logistics: [0mprogress: 18100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0711, train/total_loss: 0.0002, train/total_loss/avg: 0.0711, max mem: 5552.0, experiment: run, epoch: 69, num_updates: 18100, iterations: 18100, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 587ms, time_since_start: 02h 31m 57s 979ms, eta: 33m 35s 945ms
[32m2021-03-04T23:20:25 | mmf.trainers.callbacks.logistics: [0mprogress: 18200/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0707, train/total_loss: 0.0002, train/total_loss/avg: 0.0707, max mem: 5552.0, experiment: run, epoch: 69, num_updates: 18200, iterations: 18200, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 001ms, time_since_start: 02h 32m 36s 981ms, eta: 24m 45s 030ms
[32m2021-03-04T23:21:06 | mmf.trainers.callbacks.logistics: [0mprogress: 18300/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0703, train/total_loss: 0.0002, train/total_loss/avg: 0.0703, max mem: 5552.0, experiment: run, epoch: 69, num_updates: 18300, iterations: 18300, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 806ms, time_since_start: 02h 33m 17s 787ms, eta: 25m 12s 851ms
[32m2021-03-04T23:21:56 | mmf.trainers.callbacks.logistics: [0mprogress: 18400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0699, train/total_loss: 0.0002, train/total_loss/avg: 0.0699, max mem: 5552.0, experiment: run, epoch: 70, num_updates: 18400, iterations: 18400, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 381ms, time_since_start: 02h 34m 08s 168ms, eta: 30m 17s 350ms
[32m2021-03-04T23:22:36 | mmf.trainers.callbacks.logistics: [0mprogress: 18500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0695, train/total_loss: 0.0002, train/total_loss/avg: 0.0695, max mem: 5552.0, experiment: run, epoch: 70, num_updates: 18500, iterations: 18500, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 306ms, time_since_start: 02h 34m 47s 475ms, eta: 22m 58s 470ms
[32m2021-03-04T23:23:15 | mmf.trainers.callbacks.logistics: [0mprogress: 18600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0692, train/total_loss: 0.0001, train/total_loss/avg: 0.0692, max mem: 5552.0, experiment: run, epoch: 70, num_updates: 18600, iterations: 18600, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 790ms, time_since_start: 02h 35m 27s 266ms, eta: 22m 35s 593ms
[32m2021-03-04T23:24:06 | mmf.trainers.callbacks.logistics: [0mprogress: 18700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0688, train/total_loss: 0.0001, train/total_loss/avg: 0.0688, max mem: 5552.0, experiment: run, epoch: 71, num_updates: 18700, iterations: 18700, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 253ms, time_since_start: 02h 36m 17s 519ms, eta: 27m 41s 683ms
[32m2021-03-04T23:24:46 | mmf.trainers.callbacks.logistics: [0mprogress: 18800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0684, train/total_loss: 0.0001, train/total_loss/avg: 0.0684, max mem: 5552.0, experiment: run, epoch: 71, num_updates: 18800, iterations: 18800, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 818ms, time_since_start: 02h 36m 57s 338ms, eta: 21m 16s 750ms
[32m2021-03-04T23:25:36 | mmf.trainers.callbacks.logistics: [0mprogress: 18900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0681, train/total_loss: 0.0001, train/total_loss/avg: 0.0681, max mem: 5552.0, experiment: run, epoch: 72, num_updates: 18900, iterations: 18900, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 442ms, time_since_start: 02h 37m 47s 780ms, eta: 26m 06s 840ms
[32m2021-03-04T23:26:15 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T23:26:15 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T23:26:15 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T23:26:15 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T23:26:19 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T23:26:35 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T23:26:35 | mmf.trainers.callbacks.logistics: [0mprogress: 19000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0677, train/total_loss: 0.0001, train/total_loss/avg: 0.0677, max mem: 5552.0, experiment: run, epoch: 72, num_updates: 19000, iterations: 19000, max_updates: 22000, lr: 0., ups: 1.69, time: 59s 130ms, time_since_start: 02h 38m 46s 911ms, eta: 29m 37s 464ms
[32m2021-03-04T23:26:35 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T23:26:46 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T23:26:46 | mmf.trainers.callbacks.logistics: [0mprogress: 19000/22000, val/hateful_memes/cross_entropy: 3.3306, val/total_loss: 3.3306, val/hateful_memes/accuracy: 0.6500, val/hateful_memes/binary_f1: 0.2982, val/hateful_memes/roc_auc: 0.6201, num_updates: 19000, epoch: 72, iterations: 19000, max_updates: 22000, val_time: 10s 576ms, best_update: 11000, best_iteration: 11000, best_val/hateful_memes/roc_auc: 0.635959
[32m2021-03-04T23:27:26 | mmf.trainers.callbacks.logistics: [0mprogress: 19100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0674, train/total_loss: 0.0001, train/total_loss/avg: 0.0674, max mem: 5552.0, experiment: run, epoch: 72, num_updates: 19100, iterations: 19100, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 980ms, time_since_start: 02h 39m 37s 471ms, eta: 19m 21s 766ms
[32m2021-03-04T23:28:16 | mmf.trainers.callbacks.logistics: [0mprogress: 19200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0670, train/total_loss: 0.0001, train/total_loss/avg: 0.0670, max mem: 5552.0, experiment: run, epoch: 73, num_updates: 19200, iterations: 19200, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 325ms, time_since_start: 02h 40m 27s 796ms, eta: 23m 31s 929ms
[32m2021-03-04T23:28:57 | mmf.trainers.callbacks.logistics: [0mprogress: 19300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0667, train/total_loss: 0.0001, train/total_loss/avg: 0.0667, max mem: 5552.0, experiment: run, epoch: 73, num_updates: 19300, iterations: 19300, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 843ms, time_since_start: 02h 41m 08s 640ms, eta: 18m 24s 979ms
[32m2021-03-04T23:29:36 | mmf.trainers.callbacks.logistics: [0mprogress: 19400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0663, train/total_loss: 0.0001, train/total_loss/avg: 0.0663, max mem: 5552.0, experiment: run, epoch: 73, num_updates: 19400, iterations: 19400, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 524ms, time_since_start: 02h 41m 48s 164ms, eta: 17m 09s 686ms
[32m2021-03-04T23:30:27 | mmf.trainers.callbacks.logistics: [0mprogress: 19500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0660, train/total_loss: 0.0001, train/total_loss/avg: 0.0660, max mem: 5552.0, experiment: run, epoch: 74, num_updates: 19500, iterations: 19500, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 155ms, time_since_start: 02h 42m 39s 320ms, eta: 21m 21s 452ms
[32m2021-03-04T23:31:09 | mmf.trainers.callbacks.logistics: [0mprogress: 19600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0656, train/total_loss: 0.0001, train/total_loss/avg: 0.0656, max mem: 5552.0, experiment: run, epoch: 74, num_updates: 19600, iterations: 19600, max_updates: 22000, lr: 0., ups: 2.44, time: 41s 234ms, time_since_start: 02h 43m 20s 554ms, eta: 16m 31s 612ms
[32m2021-03-04T23:31:59 | mmf.trainers.callbacks.logistics: [0mprogress: 19700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0653, train/total_loss: 0.0000, train/total_loss/avg: 0.0653, max mem: 5552.0, experiment: run, epoch: 75, num_updates: 19700, iterations: 19700, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 654ms, time_since_start: 02h 44m 11s 209ms, eta: 19m 27s 380ms
[32m2021-03-04T23:32:42 | mmf.trainers.callbacks.logistics: [0mprogress: 19800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0650, train/total_loss: 0.0000, train/total_loss/avg: 0.0650, max mem: 5552.0, experiment: run, epoch: 75, num_updates: 19800, iterations: 19800, max_updates: 22000, lr: 0., ups: 2.38, time: 42s 152ms, time_since_start: 02h 44m 53s 361ms, eta: 15m 29s 203ms
[32m2021-03-04T23:33:22 | mmf.trainers.callbacks.logistics: [0mprogress: 19900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0647, train/total_loss: 0.0000, train/total_loss/avg: 0.0647, max mem: 5552.0, experiment: run, epoch: 75, num_updates: 19900, iterations: 19900, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 408ms, time_since_start: 02h 45m 33s 769ms, eta: 14m 10s 266ms
[32m2021-03-04T23:34:13 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T23:34:13 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T23:34:13 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T23:34:13 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T23:34:30 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T23:34:46 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T23:34:46 | mmf.trainers.callbacks.logistics: [0mprogress: 20000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0643, train/total_loss: 0.0000, train/total_loss/avg: 0.0643, max mem: 5552.0, experiment: run, epoch: 76, num_updates: 20000, iterations: 20000, max_updates: 22000, lr: 0., ups: 1.20, time: 01m 23s 903ms, time_since_start: 02h 46m 57s 673ms, eta: 28m 01s 435ms
[32m2021-03-04T23:34:46 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T23:34:57 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T23:34:57 | mmf.trainers.callbacks.logistics: [0mprogress: 20000/22000, val/hateful_memes/cross_entropy: 3.1991, val/total_loss: 3.1991, val/hateful_memes/accuracy: 0.6444, val/hateful_memes/binary_f1: 0.3823, val/hateful_memes/roc_auc: 0.6189, num_updates: 20000, epoch: 76, iterations: 20000, max_updates: 22000, val_time: 10s 920ms, best_update: 11000, best_iteration: 11000, best_val/hateful_memes/roc_auc: 0.635959
[32m2021-03-04T23:35:38 | mmf.trainers.callbacks.logistics: [0mprogress: 20100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0640, train/total_loss: 0.0000, train/total_loss/avg: 0.0640, max mem: 5552.0, experiment: run, epoch: 76, num_updates: 20100, iterations: 20100, max_updates: 22000, lr: 0., ups: 2.44, time: 41s 177ms, time_since_start: 02h 47m 49s 773ms, eta: 13m 03s 942ms
[32m2021-03-04T23:36:19 | mmf.trainers.callbacks.logistics: [0mprogress: 20200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0637, train/total_loss: 0.0000, train/total_loss/avg: 0.0637, max mem: 5552.0, experiment: run, epoch: 76, num_updates: 20200, iterations: 20200, max_updates: 22000, lr: 0., ups: 2.44, time: 41s 234ms, time_since_start: 02h 48m 31s 008ms, eta: 12m 23s 709ms
[32m2021-03-04T23:37:10 | mmf.trainers.callbacks.logistics: [0mprogress: 20300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0634, train/total_loss: 0.0000, train/total_loss/avg: 0.0634, max mem: 5552.0, experiment: run, epoch: 77, num_updates: 20300, iterations: 20300, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 593ms, time_since_start: 02h 49m 21s 601ms, eta: 14m 21s 809ms
[32m2021-03-04T23:37:50 | mmf.trainers.callbacks.logistics: [0mprogress: 20400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0631, train/total_loss: 0.0000, train/total_loss/avg: 0.0631, max mem: 5552.0, experiment: run, epoch: 77, num_updates: 20400, iterations: 20400, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 058ms, time_since_start: 02h 50m 01s 660ms, eta: 10m 42s 224ms
[32m2021-03-04T23:38:41 | mmf.trainers.callbacks.logistics: [0mprogress: 20500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0628, train/total_loss: 0.0000, train/total_loss/avg: 0.0628, max mem: 5552.0, experiment: run, epoch: 78, num_updates: 20500, iterations: 20500, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 334ms, time_since_start: 02h 50m 52s 994ms, eta: 12m 51s 555ms
[32m2021-03-04T23:39:22 | mmf.trainers.callbacks.logistics: [0mprogress: 20600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0625, train/total_loss: 0.0000, train/total_loss/avg: 0.0625, max mem: 5552.0, experiment: run, epoch: 78, num_updates: 20600, iterations: 20600, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 807ms, time_since_start: 02h 51m 33s 802ms, eta: 09m 32s 450ms
[32m2021-03-04T23:40:02 | mmf.trainers.callbacks.logistics: [0mprogress: 20700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0622, train/total_loss: 0.0000, train/total_loss/avg: 0.0622, max mem: 5552.0, experiment: run, epoch: 78, num_updates: 20700, iterations: 20700, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 629ms, time_since_start: 02h 52m 13s 432ms, eta: 08m 36s 213ms
[32m2021-03-04T23:40:52 | mmf.trainers.callbacks.logistics: [0mprogress: 20800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0619, train/total_loss: 0.0000, train/total_loss/avg: 0.0619, max mem: 5552.0, experiment: run, epoch: 79, num_updates: 20800, iterations: 20800, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 308ms, time_since_start: 02h 53m 03s 741ms, eta: 10m 04s 915ms
[32m2021-03-04T23:41:32 | mmf.trainers.callbacks.logistics: [0mprogress: 20900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0616, train/total_loss: 0.0000, train/total_loss/avg: 0.0616, max mem: 5552.0, experiment: run, epoch: 79, num_updates: 20900, iterations: 20900, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 403ms, time_since_start: 02h 53m 44s 144ms, eta: 07m 25s 330ms
[32m2021-03-04T23:42:13 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T23:42:13 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T23:42:13 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T23:42:13 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T23:42:30 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T23:42:46 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T23:42:46 | mmf.trainers.callbacks.logistics: [0mprogress: 21000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0613, train/total_loss: 0.0000, train/total_loss/avg: 0.0613, max mem: 5552.0, experiment: run, epoch: 79, num_updates: 21000, iterations: 21000, max_updates: 22000, lr: 0., ups: 1.37, time: 01m 13s 600ms, time_since_start: 02h 54m 57s 745ms, eta: 12m 17s 480ms
[32m2021-03-04T23:42:46 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T23:42:56 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T23:42:56 | mmf.trainers.callbacks.logistics: [0mprogress: 21000/22000, val/hateful_memes/cross_entropy: 3.2642, val/total_loss: 3.2642, val/hateful_memes/accuracy: 0.6370, val/hateful_memes/binary_f1: 0.3479, val/hateful_memes/roc_auc: 0.6226, num_updates: 21000, epoch: 79, iterations: 21000, max_updates: 22000, val_time: 10s 467ms, best_update: 11000, best_iteration: 11000, best_val/hateful_memes/roc_auc: 0.635959
[32m2021-03-04T23:43:47 | mmf.trainers.callbacks.logistics: [0mprogress: 21100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0610, train/total_loss: 0.0000, train/total_loss/avg: 0.0610, max mem: 5552.0, experiment: run, epoch: 80, num_updates: 21100, iterations: 21100, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 192ms, time_since_start: 02h 55m 58s 408ms, eta: 07m 32s 640ms
[32m2021-03-04T23:44:26 | mmf.trainers.callbacks.logistics: [0mprogress: 21200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0607, train/total_loss: 0.0000, train/total_loss/avg: 0.0607, max mem: 5552.0, experiment: run, epoch: 80, num_updates: 21200, iterations: 21200, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 220ms, time_since_start: 02h 56m 37s 628ms, eta: 05m 14s 391ms
[32m2021-03-04T23:45:17 | mmf.trainers.callbacks.logistics: [0mprogress: 21300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0604, train/total_loss: 0.0000, train/total_loss/avg: 0.0604, max mem: 5552.0, experiment: run, epoch: 81, num_updates: 21300, iterations: 21300, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 693ms, time_since_start: 02h 57m 29s 322ms, eta: 06m 02s 578ms
[32m2021-03-04T23:45:58 | mmf.trainers.callbacks.logistics: [0mprogress: 21400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0601, train/total_loss: 0.0000, train/total_loss/avg: 0.0601, max mem: 5552.0, experiment: run, epoch: 81, num_updates: 21400, iterations: 21400, max_updates: 22000, lr: 0., ups: 2.50, time: 40s 265ms, time_since_start: 02h 58m 09s 588ms, eta: 04m 02s 078ms
[32m2021-03-04T23:46:37 | mmf.trainers.callbacks.logistics: [0mprogress: 21500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0599, train/total_loss: 0.0000, train/total_loss/avg: 0.0599, max mem: 5552.0, experiment: run, epoch: 81, num_updates: 21500, iterations: 21500, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 719ms, time_since_start: 02h 58m 49s 307ms, eta: 03m 18s 996ms
[32m2021-03-04T23:47:27 | mmf.trainers.callbacks.logistics: [0mprogress: 21600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0596, train/total_loss: 0.0000, train/total_loss/avg: 0.0596, max mem: 5552.0, experiment: run, epoch: 82, num_updates: 21600, iterations: 21600, max_updates: 22000, lr: 0., ups: 2.04, time: 49s 870ms, time_since_start: 02h 59m 39s 178ms, eta: 03m 19s 879ms
[32m2021-03-04T23:48:07 | mmf.trainers.callbacks.logistics: [0mprogress: 21700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0593, train/total_loss: 0.0000, train/total_loss/avg: 0.0593, max mem: 5552.0, experiment: run, epoch: 82, num_updates: 21700, iterations: 21700, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 792ms, time_since_start: 03h 18s 970ms, eta: 01m 59s 615ms
[32m2021-03-04T23:48:47 | mmf.trainers.callbacks.logistics: [0mprogress: 21800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0590, train/total_loss: 0.0000, train/total_loss/avg: 0.0590, max mem: 5552.0, experiment: run, epoch: 82, num_updates: 21800, iterations: 21800, max_updates: 22000, lr: 0., ups: 2.56, time: 39s 414ms, time_since_start: 03h 58s 384ms, eta: 01m 18s 985ms
[32m2021-03-04T23:49:37 | mmf.trainers.callbacks.logistics: [0mprogress: 21900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0588, train/total_loss: 0.0000, train/total_loss/avg: 0.0588, max mem: 5552.0, experiment: run, epoch: 83, num_updates: 21900, iterations: 21900, max_updates: 22000, lr: 0., ups: 2.00, time: 50s 719ms, time_since_start: 03h 01m 49s 103ms, eta: 50s 821ms
[32m2021-03-04T23:50:18 | mmf.trainers.callbacks.checkpoint: [0mCheckpoint time. Saving a checkpoint.
[32m2021-03-04T23:50:18 | mmf.utils.checkpoint: [0mCheckpoint save operation started!
[5m[31mWARNING[0m [32m2021-03-04T23:50:18 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T23:50:18 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T23:50:35 | mmf.utils.checkpoint: [0mSaving current checkpoint
[32m2021-03-04T23:50:51 | mmf.utils.checkpoint: [0mCheckpoint save operation finished!
[32m2021-03-04T23:50:51 | mmf.trainers.callbacks.logistics: [0mprogress: 22000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0585, train/total_loss: 0.0000, train/total_loss/avg: 0.0585, max mem: 5552.0, experiment: run, epoch: 83, num_updates: 22000, iterations: 22000, max_updates: 22000, lr: 0., ups: 1.35, time: 01m 14s 048ms, time_since_start: 03h 03m 03s 152ms, eta: 0ms
[32m2021-03-04T23:50:51 | mmf.trainers.core.training_loop: [0mEvaluation time. Running on full validation set...
[32m2021-03-04T23:51:02 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T23:51:02 | mmf.trainers.callbacks.logistics: [0mprogress: 22000/22000, val/hateful_memes/cross_entropy: 3.3499, val/total_loss: 3.3499, val/hateful_memes/accuracy: 0.6444, val/hateful_memes/binary_f1: 0.3654, val/hateful_memes/roc_auc: 0.6199, num_updates: 22000, epoch: 83, iterations: 22000, max_updates: 22000, val_time: 10s 626ms, best_update: 11000, best_iteration: 11000, best_val/hateful_memes/roc_auc: 0.635959
[32m2021-03-04T23:51:03 | mmf.trainers.core.training_loop: [0mStepping into final validation check
[32m2021-03-04T23:51:03 | mmf.utils.checkpoint: [0mRestoring checkpoint
[32m2021-03-04T23:51:03 | mmf.utils.checkpoint: [0mLoading checkpoint
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.embeddings.position_ids from model.bert.mmbt.transformer.embeddings.position_ids
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.embeddings.word_embeddings.weight from model.bert.mmbt.transformer.embeddings.word_embeddings.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.embeddings.position_embeddings.weight from model.bert.mmbt.transformer.embeddings.position_embeddings.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.embeddings.token_type_embeddings.weight from model.bert.mmbt.transformer.embeddings.token_type_embeddings.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.embeddings.LayerNorm.weight from model.bert.mmbt.transformer.embeddings.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.embeddings.LayerNorm.bias from model.bert.mmbt.transformer.embeddings.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.0.attention.self.query.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.0.attention.self.query.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.0.attention.self.key.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.0.attention.self.key.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.0.attention.self.value.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.0.attention.self.value.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.0.attention.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.0.attention.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.0.attention.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.0.attention.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.0.intermediate.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.0.intermediate.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.0.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.0.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.0.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.0.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.0.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.1.attention.self.query.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.1.attention.self.query.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.1.attention.self.key.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.1.attention.self.key.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.1.attention.self.value.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.1.attention.self.value.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.1.attention.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.1.attention.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.1.attention.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.1.attention.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.1.intermediate.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.1.intermediate.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.1.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.1.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.1.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.1.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.1.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.2.attention.self.query.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.2.attention.self.query.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.2.attention.self.key.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.2.attention.self.key.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.2.attention.self.value.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.2.attention.self.value.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.2.attention.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.2.attention.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.2.attention.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.2.attention.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.2.intermediate.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.2.intermediate.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.2.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.2.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.2.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.2.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.2.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.3.attention.self.query.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.3.attention.self.query.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.3.attention.self.key.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.3.attention.self.key.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.3.attention.self.value.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.3.attention.self.value.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.3.attention.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.3.attention.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.3.attention.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.3.attention.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.3.intermediate.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.3.intermediate.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.3.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.3.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.3.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.3.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.3.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.4.attention.self.query.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.4.attention.self.query.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.4.attention.self.key.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.4.attention.self.key.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.4.attention.self.value.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.4.attention.self.value.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.4.attention.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.4.attention.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.4.attention.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.4.attention.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.4.intermediate.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.4.intermediate.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.4.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.4.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.4.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.4.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.4.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.5.attention.self.query.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.5.attention.self.query.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.5.attention.self.key.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.5.attention.self.key.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.5.attention.self.value.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.5.attention.self.value.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.5.attention.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.5.attention.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.5.attention.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.5.attention.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.5.intermediate.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.5.intermediate.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.5.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.5.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.5.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.5.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.5.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.6.attention.self.query.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.6.attention.self.query.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.6.attention.self.key.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.6.attention.self.key.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.6.attention.self.value.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.6.attention.self.value.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.6.attention.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.6.attention.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.6.attention.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.6.attention.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.6.intermediate.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.6.intermediate.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.6.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.6.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.6.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.6.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.6.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.7.attention.self.query.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.7.attention.self.query.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.7.attention.self.key.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.7.attention.self.key.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.7.attention.self.value.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.7.attention.self.value.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.7.attention.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.7.attention.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.7.attention.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.7.attention.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.7.intermediate.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.7.intermediate.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.7.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.7.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.7.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.7.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.7.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.8.attention.self.query.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.8.attention.self.query.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.8.attention.self.key.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.8.attention.self.key.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.8.attention.self.value.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.8.attention.self.value.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.8.attention.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.8.attention.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.8.attention.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.8.attention.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.8.intermediate.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.8.intermediate.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.8.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.8.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.8.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.8.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.8.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.9.attention.self.query.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.9.attention.self.query.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.9.attention.self.key.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.9.attention.self.key.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.9.attention.self.value.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.9.attention.self.value.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.9.attention.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.9.attention.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.9.attention.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.9.attention.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.9.intermediate.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.9.intermediate.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.9.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.9.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.9.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.9.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.9.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.10.attention.self.query.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.10.attention.self.query.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.10.attention.self.key.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.10.attention.self.key.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.10.attention.self.value.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.10.attention.self.value.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.10.attention.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.10.attention.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.10.attention.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.10.attention.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.10.intermediate.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.10.intermediate.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.10.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.10.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.10.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.10.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.10.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.self.query.weight from model.bert.mmbt.transformer.encoder.layer.11.attention.self.query.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.self.query.bias from model.bert.mmbt.transformer.encoder.layer.11.attention.self.query.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.self.key.weight from model.bert.mmbt.transformer.encoder.layer.11.attention.self.key.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.self.key.bias from model.bert.mmbt.transformer.encoder.layer.11.attention.self.key.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.self.value.weight from model.bert.mmbt.transformer.encoder.layer.11.attention.self.value.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.self.value.bias from model.bert.mmbt.transformer.encoder.layer.11.attention.self.value.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.11.attention.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.11.attention.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.11.attention.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.11.attention.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.intermediate.dense.weight from model.bert.mmbt.transformer.encoder.layer.11.intermediate.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.intermediate.dense.bias from model.bert.mmbt.transformer.encoder.layer.11.intermediate.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.output.dense.weight from model.bert.mmbt.transformer.encoder.layer.11.output.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.output.dense.bias from model.bert.mmbt.transformer.encoder.layer.11.output.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.output.LayerNorm.weight from model.bert.mmbt.transformer.encoder.layer.11.output.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.encoder.layer.11.output.LayerNorm.bias from model.bert.mmbt.transformer.encoder.layer.11.output.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.pooler.dense.weight from model.bert.mmbt.transformer.pooler.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.transformer.pooler.dense.bias from model.bert.mmbt.transformer.pooler.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.0.weight from model.bert.mmbt.modal_encoder.encoder.model.0.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.1.weight from model.bert.mmbt.modal_encoder.encoder.model.1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.1.bias from model.bert.mmbt.modal_encoder.encoder.model.1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.1.running_var from model.bert.mmbt.modal_encoder.encoder.model.1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.4.0.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.4.0.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.4.0.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.4.0.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.downsample.0.weight from model.bert.mmbt.modal_encoder.encoder.model.4.0.downsample.0.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.downsample.1.weight from model.bert.mmbt.modal_encoder.encoder.model.4.0.downsample.1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.downsample.1.bias from model.bert.mmbt.modal_encoder.encoder.model.4.0.downsample.1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.downsample.1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.4.0.downsample.1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.downsample.1.running_var from model.bert.mmbt.modal_encoder.encoder.model.4.0.downsample.1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.0.downsample.1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.4.0.downsample.1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.4.1.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.4.1.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.4.1.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.1.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.4.1.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.4.2.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.4.2.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.4.2.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.4.2.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.4.2.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.0.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.0.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.0.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.0.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.downsample.0.weight from model.bert.mmbt.modal_encoder.encoder.model.5.0.downsample.0.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.downsample.1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.0.downsample.1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.downsample.1.bias from model.bert.mmbt.modal_encoder.encoder.model.5.0.downsample.1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.downsample.1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.0.downsample.1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.downsample.1.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.0.downsample.1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.0.downsample.1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.0.downsample.1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.1.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.1.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.1.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.1.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.1.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.2.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.2.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.2.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.2.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.2.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.3.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.3.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.3.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.3.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.3.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.4.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.4.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.4.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.4.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.4.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.5.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.5.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.5.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.5.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.5.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.6.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.6.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.6.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.6.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.6.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.7.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.7.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.7.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.5.7.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.5.7.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.0.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.0.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.0.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.0.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.downsample.0.weight from model.bert.mmbt.modal_encoder.encoder.model.6.0.downsample.0.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.downsample.1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.0.downsample.1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.downsample.1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.0.downsample.1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.downsample.1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.0.downsample.1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.downsample.1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.0.downsample.1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.0.downsample.1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.0.downsample.1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.1.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.1.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.1.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.1.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.1.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.2.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.2.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.2.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.2.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.2.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.3.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.3.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.3.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.3.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.3.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.4.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.4.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.4.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.4.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.4.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.5.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.5.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.5.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.5.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.5.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.6.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.6.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.6.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.6.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.6.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.7.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.7.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.7.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.7.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.7.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.8.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.8.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.8.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.8.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.8.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.9.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.9.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.9.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.9.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.9.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.10.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.10.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.10.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.10.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.10.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.11.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.11.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.11.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.11.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.11.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.12.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.12.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.12.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.12.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.12.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.13.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.13.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.13.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.13.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.13.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.14.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.14.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.14.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.14.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.14.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.15.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.15.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.15.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.15.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.15.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.16.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.16.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.16.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.16.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.16.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.17.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.17.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.17.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.17.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.17.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.18.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.18.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.18.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.18.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.18.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.19.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.19.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.19.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.19.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.19.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.20.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.20.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.20.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.20.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.20.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.21.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.21.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.21.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.21.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.21.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.22.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.22.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.22.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.22.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.22.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.23.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.23.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.23.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.23.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.23.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.24.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.24.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.24.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.24.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.24.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.25.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.25.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.25.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.25.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.25.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.26.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.26.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.26.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.26.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.26.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.27.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.27.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.27.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.27.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.27.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.28.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.28.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.28.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.28.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.28.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.29.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.29.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.29.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.29.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.29.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.30.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.30.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.30.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.30.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.30.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.31.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.31.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.31.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.31.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.31.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.32.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.32.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.32.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.32.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.32.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.33.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.33.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.33.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.33.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.33.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.34.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.34.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.34.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.34.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.34.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.35.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.35.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.35.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.6.35.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.6.35.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.7.0.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.7.0.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.7.0.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.7.0.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.downsample.0.weight from model.bert.mmbt.modal_encoder.encoder.model.7.0.downsample.0.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.downsample.1.weight from model.bert.mmbt.modal_encoder.encoder.model.7.0.downsample.1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.downsample.1.bias from model.bert.mmbt.modal_encoder.encoder.model.7.0.downsample.1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.downsample.1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.7.0.downsample.1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.downsample.1.running_var from model.bert.mmbt.modal_encoder.encoder.model.7.0.downsample.1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.0.downsample.1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.7.0.downsample.1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.7.1.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.7.1.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.7.1.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.1.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.7.1.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.conv1.weight from model.bert.mmbt.modal_encoder.encoder.model.7.2.conv1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn1.weight from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn1.bias from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn1.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn1.running_mean from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn1.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn1.running_var from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn1.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn1.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn1.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.conv2.weight from model.bert.mmbt.modal_encoder.encoder.model.7.2.conv2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn2.weight from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn2.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn2.bias from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn2.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn2.running_mean from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn2.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn2.running_var from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn2.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn2.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn2.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.conv3.weight from model.bert.mmbt.modal_encoder.encoder.model.7.2.conv3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn3.weight from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn3.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn3.bias from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn3.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn3.running_mean from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn3.running_mean
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn3.running_var from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn3.running_var
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.encoder.model.7.2.bn3.num_batches_tracked from model.bert.mmbt.modal_encoder.encoder.model.7.2.bn3.num_batches_tracked
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.proj_embeddings.weight from model.bert.mmbt.modal_encoder.proj_embeddings.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.proj_embeddings.bias from model.bert.mmbt.modal_encoder.proj_embeddings.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.position_embeddings.weight from model.bert.mmbt.modal_encoder.position_embeddings.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.token_type_embeddings.weight from model.bert.mmbt.modal_encoder.token_type_embeddings.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.word_embeddings.weight from model.bert.mmbt.modal_encoder.word_embeddings.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.LayerNorm.weight from model.bert.mmbt.modal_encoder.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.bert.mmbt.modal_encoder.LayerNorm.bias from model.bert.mmbt.modal_encoder.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.dense.weight from model.classifier.0.dense.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.dense.bias from model.classifier.0.dense.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.LayerNorm.weight from model.classifier.0.LayerNorm.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.0.LayerNorm.bias from model.classifier.0.LayerNorm.bias
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.1.weight from model.classifier.1.weight
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mWill load key module.model.classifier.1.bias from model.classifier.1.bias
[5m[31mWARNING[0m [32m2021-03-04T23:51:04 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2021-03-04T23:51:04 | py.warnings: [0m/home2/sagarsj42/git-clone/mmf/mmf/utils/distributed.py:310: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mCheckpoint loaded.
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mCurrent num updates: 11000
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mCurrent iteration: 11000
[32m2021-03-04T23:51:04 | mmf.utils.checkpoint: [0mCurrent epoch: 42
[32m2021-03-04T23:51:09 | mmf.trainers.mmf_trainer: [0mStarting inference on val set
  0%|          | 0/68 [00:00<?, ?it/s]  1%|â–         | 1/68 [00:09<10:33,  9.45s/it]  4%|â–         | 3/68 [00:09<02:42,  2.50s/it]  7%|â–‹         | 5/68 [00:09<01:19,  1.26s/it] 10%|â–ˆ         | 7/68 [00:09<00:46,  1.32it/s] 13%|â–ˆâ–Ž        | 9/68 [00:10<00:29,  2.00it/s] 16%|â–ˆâ–Œ        | 11/68 [00:10<00:20,  2.85it/s] 19%|â–ˆâ–‰        | 13/68 [00:10<00:14,  3.86it/s] 22%|â–ˆâ–ˆâ–       | 15/68 [00:10<00:10,  5.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 17/68 [00:10<00:08,  6.22it/s] 25%|â–ˆâ–ˆâ–Œ       | 17/68 [00:11<00:33,  1.54it/s][32m2021-03-04T23:51:20 | mmf.trainers.core.evaluation_loop: [0mValidation Done
[32m2021-03-04T23:51:20 | mmf.trainers.callbacks.logistics: [0mprogress: 11000/22000, val/hateful_memes/cross_entropy: 2.3279, val/total_loss: 2.3279, val/hateful_memes/accuracy: 0.6426, val/hateful_memes/binary_f1: 0.3971, val/hateful_memes/roc_auc: 0.6360
[32m2021-03-04T23:51:20 | mmf.trainers.callbacks.logistics: [0mFinished run in 03h 03m 32s 321ms

Training MMBT_DEFAULTS complete
********************************************************************
Run complete.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Removing existing data.zip from cache ....
Removal complete.
Removing existing save.zip from cache ....
Removal complete.
Zipping processed data folder in cache ....
/home2/sagarsj42
Zip complete, data.zip ready in cache.
Zipping updated save folder in cache ....
/home2/sagarsj42
Zip complete, save.zip ready in cache.
Removing existing data.zip from share1
Removal complete.
Removing existing save.zip from share1
Removal complete.
Copying data.zip from cache to share1 ....
Copy complete, data.zip ready in share1.
Copying save.zip from cache to share1 ....
Copy complete, save.zip ready in share1.
Program complete.
--------------------------------------------------------------------
